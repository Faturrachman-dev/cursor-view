This file is a merged representation of a subset of the codebase, containing specifically included files, combined into a single document by Repomix.

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: cursor-memory-bank
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)


================================================================
Directory Structure
================================================================
cursor-memory-bank/.git/config
cursor-memory-bank/.git/description
cursor-memory-bank/.git/HEAD
cursor-memory-bank/.git/hooks/applypatch-msg.sample
cursor-memory-bank/.git/hooks/commit-msg.sample
cursor-memory-bank/.git/hooks/fsmonitor-watchman.sample
cursor-memory-bank/.git/hooks/post-update.sample
cursor-memory-bank/.git/hooks/pre-applypatch.sample
cursor-memory-bank/.git/hooks/pre-commit.sample
cursor-memory-bank/.git/hooks/pre-merge-commit.sample
cursor-memory-bank/.git/hooks/pre-push.sample
cursor-memory-bank/.git/hooks/pre-rebase.sample
cursor-memory-bank/.git/hooks/pre-receive.sample
cursor-memory-bank/.git/hooks/prepare-commit-msg.sample
cursor-memory-bank/.git/hooks/push-to-checkout.sample
cursor-memory-bank/.git/hooks/sendemail-validate.sample
cursor-memory-bank/.git/hooks/update.sample
cursor-memory-bank/.git/info/exclude
cursor-memory-bank/.git/logs/HEAD
cursor-memory-bank/.git/logs/refs/heads/main
cursor-memory-bank/.git/logs/refs/remotes/origin/HEAD
cursor-memory-bank/.git/packed-refs
cursor-memory-bank/.git/refs/heads/main
cursor-memory-bank/.git/refs/remotes/origin/HEAD
cursor-memory-bank/.gitignore
cursor-memory-bank/ai-contexts/CMB/custom_instructions.txt
cursor-memory-bank/ai-contexts/CMB/insight-complexity-levels.md
cursor-memory-bank/ai-contexts/CMB/refined-instructions.txt
cursor-memory-bank/ai-contexts/conversations/20-05.md
cursor-memory-bank/ai-contexts/conversations/21-05.md
cursor-memory-bank/ai-contexts/conversations/25-05.md
cursor-memory-bank/ai-contexts/fetch-rules-vs-read-file.md
cursor-memory-bank/ai-contexts/insight-CMB.md
cursor-memory-bank/ai-contexts/insights_fetch-rules.md
cursor-memory-bank/ai-contexts/insights.md
cursor-memory-bank/ai-contexts/summary-CMB.md
cursor-memory-bank/ai-contexts/summary-context.md
cursor-memory-bank/ai-contexts/summary.md
cursor-memory-bank/creative_mode_think_tool.md
cursor-memory-bank/custom_modes_refined/creative.md
cursor-memory-bank/custom_modes_refined/implement.md
cursor-memory-bank/custom_modes_refined/plan.md
cursor-memory-bank/custom_modes_refined/refine-instructions.py
cursor-memory-bank/custom_modes_refined/reflect_archive.md
cursor-memory-bank/custom_modes_refined/van.md
cursor-memory-bank/custom_modes/creative_instructions.md
cursor-memory-bank/custom_modes/implement_instructions.md
cursor-memory-bank/custom_modes/mode_switching_analysis.md
cursor-memory-bank/custom_modes/plan_instructions.md
cursor-memory-bank/custom_modes/reflect_archive_instructions.md
cursor-memory-bank/custom_modes/van_instructions.md
cursor-memory-bank/mdc rules/rules-core-refined.md
cursor-memory-bank/mdc rules/rules-core.txt
cursor-memory-bank/mdc rules/rules-levels.txt
cursor-memory-bank/mdc rules/rules-phases-main.txt
cursor-memory-bank/mdc rules/rules-visual-maps.txt
cursor-memory-bank/MEMORY_BANK_OPTIMIZATIONS.md
cursor-memory-bank/memory_bank_upgrade_guide.md
cursor-memory-bank/optimization-journey/00-introduction.md
cursor-memory-bank/optimization-journey/01-efficiency-and-clarity.md
cursor-memory-bank/optimization-journey/02-system-self-assessment.md
cursor-memory-bank/optimization-journey/03-redundancy-elimination.md
cursor-memory-bank/optimization-journey/04-single-source-of-truth.md
cursor-memory-bank/optimization-journey/05-adaptive-complexity-model.md
cursor-memory-bank/optimization-journey/06-self-assessment-recommendations.md
cursor-memory-bank/optimization-journey/07-structured-creative-thinking.md
cursor-memory-bank/optimization-journey/08-creative-phase-enforcement.md
cursor-memory-bank/optimization-journey/09-context-optimization.md
cursor-memory-bank/optimization-journey/10-current-system-state.md
cursor-memory-bank/optimization-journey/11-key-lessons.md
cursor-memory-bank/optimization-journey/11-methodological-integration.md
cursor-memory-bank/optimization-journey/12-future-directions.md
cursor-memory-bank/optimization-journey/12-key-lessons.md
cursor-memory-bank/optimization-journey/13-future-directions.md
cursor-memory-bank/optimization-journey/13-methodological-integration.md
cursor-memory-bank/optimization-journey/README.md
cursor-memory-bank/README.md
cursor-memory-bank/RELEASE_NOTES.md

================================================================
Files
================================================================

================
File: cursor-memory-bank/.git/config
================
[core]
	repositoryformatversion = 0
	filemode = false
	bare = false
	logallrefupdates = true
	symlinks = false
	ignorecase = true
[remote "origin"]
	url = https://github.com/vanzan01/cursor-memory-bank.git
	fetch = +refs/heads/*:refs/remotes/origin/*
[branch "main"]
	remote = origin
	merge = refs/heads/main
	vscode-merge-base = origin/main

================
File: cursor-memory-bank/.git/description
================
Unnamed repository; edit this file 'description' to name the repository.

================
File: cursor-memory-bank/.git/HEAD
================
ref: refs/heads/main

================
File: cursor-memory-bank/.git/hooks/applypatch-msg.sample
================
#!/bin/sh
#
# An example hook script to check the commit log message taken by
# applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.  The hook is
# allowed to edit the commit message file.
#
# To enable this hook, rename this file to "applypatch-msg".

. git-sh-setup
commitmsg="$(git rev-parse --git-path hooks/commit-msg)"
test -x "$commitmsg" && exec "$commitmsg" ${1+"$@"}
:

================
File: cursor-memory-bank/.git/hooks/commit-msg.sample
================
#!/bin/sh
#
# An example hook script to check the commit log message.
# Called by "git commit" with one argument, the name of the file
# that has the commit message.  The hook should exit with non-zero
# status after issuing an appropriate message if it wants to stop the
# commit.  The hook is allowed to edit the commit message file.
#
# To enable this hook, rename this file to "commit-msg".

# Uncomment the below to add a Signed-off-by line to the message.
# Doing this in a hook is a bad idea in general, but the prepare-commit-msg
# hook is more suited to it.
#
# SOB=$(git var GIT_AUTHOR_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# grep -qs "^$SOB" "$1" || echo "$SOB" >> "$1"

# This example catches duplicate Signed-off-by lines.

test "" = "$(grep '^Signed-off-by: ' "$1" |
	 sort | uniq -c | sed -e '/^[ 	]*1[ 	]/d')" || {
	echo >&2 Duplicate Signed-off-by lines.
	exit 1
}

================
File: cursor-memory-bank/.git/hooks/fsmonitor-watchman.sample
================
#!/usr/bin/perl

use strict;
use warnings;
use IPC::Open2;

# An example hook script to integrate Watchman
# (https://facebook.github.io/watchman/) with git to speed up detecting
# new and modified files.
#
# The hook is passed a version (currently 2) and last update token
# formatted as a string and outputs to stdout a new update token and
# all files that have been modified since the update token. Paths must
# be relative to the root of the working tree and separated by a single NUL.
#
# To enable this hook, rename this file to "query-watchman" and set
# 'git config core.fsmonitor .git/hooks/query-watchman'
#
my ($version, $last_update_token) = @ARGV;

# Uncomment for debugging
# print STDERR "$0 $version $last_update_token\n";

# Check the hook interface version
if ($version ne 2) {
	die "Unsupported query-fsmonitor hook version '$version'.\n" .
	    "Falling back to scanning...\n";
}

my $git_work_tree = get_working_dir();

my $retry = 1;

my $json_pkg;
eval {
	require JSON::XS;
	$json_pkg = "JSON::XS";
	1;
} or do {
	require JSON::PP;
	$json_pkg = "JSON::PP";
};

launch_watchman();

sub launch_watchman {
	my $o = watchman_query();
	if (is_work_tree_watched($o)) {
		output_result($o->{clock}, @{$o->{files}});
	}
}

sub output_result {
	my ($clockid, @files) = @_;

	# Uncomment for debugging watchman output
	# open (my $fh, ">", ".git/watchman-output.out");
	# binmode $fh, ":utf8";
	# print $fh "$clockid\n@files\n";
	# close $fh;

	binmode STDOUT, ":utf8";
	print $clockid;
	print "\0";
	local $, = "\0";
	print @files;
}

sub watchman_clock {
	my $response = qx/watchman clock "$git_work_tree"/;
	die "Failed to get clock id on '$git_work_tree'.\n" .
		"Falling back to scanning...\n" if $? != 0;

	return $json_pkg->new->utf8->decode($response);
}

sub watchman_query {
	my $pid = open2(\*CHLD_OUT, \*CHLD_IN, 'watchman -j --no-pretty')
	or die "open2() failed: $!\n" .
	"Falling back to scanning...\n";

	# In the query expression below we're asking for names of files that
	# changed since $last_update_token but not from the .git folder.
	#
	# To accomplish this, we're using the "since" generator to use the
	# recency index to select candidate nodes and "fields" to limit the
	# output to file names only. Then we're using the "expression" term to
	# further constrain the results.
	my $last_update_line = "";
	if (substr($last_update_token, 0, 1) eq "c") {
		$last_update_token = "\"$last_update_token\"";
		$last_update_line = qq[\n"since": $last_update_token,];
	}
	my $query = <<"	END";
		["query", "$git_work_tree", {$last_update_line
			"fields": ["name"],
			"expression": ["not", ["dirname", ".git"]]
		}]
	END

	# Uncomment for debugging the watchman query
	# open (my $fh, ">", ".git/watchman-query.json");
	# print $fh $query;
	# close $fh;

	print CHLD_IN $query;
	close CHLD_IN;
	my $response = do {local $/; <CHLD_OUT>};

	# Uncomment for debugging the watch response
	# open ($fh, ">", ".git/watchman-response.json");
	# print $fh $response;
	# close $fh;

	die "Watchman: command returned no output.\n" .
	"Falling back to scanning...\n" if $response eq "";
	die "Watchman: command returned invalid output: $response\n" .
	"Falling back to scanning...\n" unless $response =~ /^\{/;

	return $json_pkg->new->utf8->decode($response);
}

sub is_work_tree_watched {
	my ($output) = @_;
	my $error = $output->{error};
	if ($retry > 0 and $error and $error =~ m/unable to resolve root .* directory (.*) is not watched/) {
		$retry--;
		my $response = qx/watchman watch "$git_work_tree"/;
		die "Failed to make watchman watch '$git_work_tree'.\n" .
		    "Falling back to scanning...\n" if $? != 0;
		$output = $json_pkg->new->utf8->decode($response);
		$error = $output->{error};
		die "Watchman: $error.\n" .
		"Falling back to scanning...\n" if $error;

		# Uncomment for debugging watchman output
		# open (my $fh, ">", ".git/watchman-output.out");
		# close $fh;

		# Watchman will always return all files on the first query so
		# return the fast "everything is dirty" flag to git and do the
		# Watchman query just to get it over with now so we won't pay
		# the cost in git to look up each individual file.
		my $o = watchman_clock();
		$error = $output->{error};

		die "Watchman: $error.\n" .
		"Falling back to scanning...\n" if $error;

		output_result($o->{clock}, ("/"));
		$last_update_token = $o->{clock};

		eval { launch_watchman() };
		return 0;
	}

	die "Watchman: $error.\n" .
	"Falling back to scanning...\n" if $error;

	return 1;
}

sub get_working_dir {
	my $working_dir;
	if ($^O =~ 'msys' || $^O =~ 'cygwin') {
		$working_dir = Win32::GetCwd();
		$working_dir =~ tr/\\/\//;
	} else {
		require Cwd;
		$working_dir = Cwd::cwd();
	}

	return $working_dir;
}

================
File: cursor-memory-bank/.git/hooks/post-update.sample
================
#!/bin/sh
#
# An example hook script to prepare a packed repository for use over
# dumb transports.
#
# To enable this hook, rename this file to "post-update".

exec git update-server-info

================
File: cursor-memory-bank/.git/hooks/pre-applypatch.sample
================
#!/bin/sh
#
# An example hook script to verify what is about to be committed
# by applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-applypatch".

. git-sh-setup
precommit="$(git rev-parse --git-path hooks/pre-commit)"
test -x "$precommit" && exec "$precommit" ${1+"$@"}
:

================
File: cursor-memory-bank/.git/hooks/pre-commit.sample
================
#!/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git commit" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message if
# it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-commit".

if git rev-parse --verify HEAD >/dev/null 2>&1
then
	against=HEAD
else
	# Initial commit: diff against an empty tree object
	against=$(git hash-object -t tree /dev/null)
fi

# If you want to allow non-ASCII filenames set this variable to true.
allownonascii=$(git config --type=bool hooks.allownonascii)

# Redirect output to stderr.
exec 1>&2

# Cross platform projects tend to avoid non-ASCII filenames; prevent
# them from being added to the repository. We exploit the fact that the
# printable range starts at the space character and ends with tilde.
if [ "$allownonascii" != "true" ] &&
	# Note that the use of brackets around a tr range is ok here, (it's
	# even required, for portability to Solaris 10's /usr/bin/tr), since
	# the square bracket bytes happen to fall in the designated range.
	test $(git diff-index --cached --name-only --diff-filter=A -z $against |
	  LC_ALL=C tr -d '[ -~]\0' | wc -c) != 0
then
	cat <<\EOF
Error: Attempt to add a non-ASCII file name.

This can cause problems if you want to work with people on other platforms.

To be portable it is advisable to rename the file.

If you know what you are doing you can disable this check using:

  git config hooks.allownonascii true
EOF
	exit 1
fi

# If there are whitespace errors, print the offending file names and fail.
exec git diff-index --check --cached $against --

================
File: cursor-memory-bank/.git/hooks/pre-merge-commit.sample
================
#!/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git merge" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message to
# stderr if it wants to stop the merge commit.
#
# To enable this hook, rename this file to "pre-merge-commit".

. git-sh-setup
test -x "$GIT_DIR/hooks/pre-commit" &&
        exec "$GIT_DIR/hooks/pre-commit"
:

================
File: cursor-memory-bank/.git/hooks/pre-push.sample
================
#!/bin/sh

# An example hook script to verify what is about to be pushed.  Called by "git
# push" after it has checked the remote status, but before anything has been
# pushed.  If this script exits with a non-zero status nothing will be pushed.
#
# This hook is called with the following parameters:
#
# $1 -- Name of the remote to which the push is being done
# $2 -- URL to which the push is being done
#
# If pushing without using a named remote those arguments will be equal.
#
# Information about the commits which are being pushed is supplied as lines to
# the standard input in the form:
#
#   <local ref> <local oid> <remote ref> <remote oid>
#
# This sample shows how to prevent push of commits where the log message starts
# with "WIP" (work in progress).

remote="$1"
url="$2"

zero=$(git hash-object --stdin </dev/null | tr '[0-9a-f]' '0')

while read local_ref local_oid remote_ref remote_oid
do
	if test "$local_oid" = "$zero"
	then
		# Handle delete
		:
	else
		if test "$remote_oid" = "$zero"
		then
			# New branch, examine all commits
			range="$local_oid"
		else
			# Update to existing branch, examine new commits
			range="$remote_oid..$local_oid"
		fi

		# Check for WIP commit
		commit=$(git rev-list -n 1 --grep '^WIP' "$range")
		if test -n "$commit"
		then
			echo >&2 "Found WIP commit in $local_ref, not pushing"
			exit 1
		fi
	fi
done

exit 0

================
File: cursor-memory-bank/.git/hooks/pre-rebase.sample
================
#!/bin/sh
#
# Copyright (c) 2006, 2008 Junio C Hamano
#
# The "pre-rebase" hook is run just before "git rebase" starts doing
# its job, and can prevent the command from running by exiting with
# non-zero status.
#
# The hook is called with the following parameters:
#
# $1 -- the upstream the series was forked from.
# $2 -- the branch being rebased (or empty when rebasing the current branch).
#
# This sample shows how to prevent topic branches that are already
# merged to 'next' branch from getting rebased, because allowing it
# would result in rebasing already published history.

publish=next
basebranch="$1"
if test "$#" = 2
then
	topic="refs/heads/$2"
else
	topic=`git symbolic-ref HEAD` ||
	exit 0 ;# we do not interrupt rebasing detached HEAD
fi

case "$topic" in
refs/heads/??/*)
	;;
*)
	exit 0 ;# we do not interrupt others.
	;;
esac

# Now we are dealing with a topic branch being rebased
# on top of master.  Is it OK to rebase it?

# Does the topic really exist?
git show-ref -q "$topic" || {
	echo >&2 "No such branch $topic"
	exit 1
}

# Is topic fully merged to master?
not_in_master=`git rev-list --pretty=oneline ^master "$topic"`
if test -z "$not_in_master"
then
	echo >&2 "$topic is fully merged to master; better remove it."
	exit 1 ;# we could allow it, but there is no point.
fi

# Is topic ever merged to next?  If so you should not be rebasing it.
only_next_1=`git rev-list ^master "^$topic" ${publish} | sort`
only_next_2=`git rev-list ^master           ${publish} | sort`
if test "$only_next_1" = "$only_next_2"
then
	not_in_topic=`git rev-list "^$topic" master`
	if test -z "$not_in_topic"
	then
		echo >&2 "$topic is already up to date with master"
		exit 1 ;# we could allow it, but there is no point.
	else
		exit 0
	fi
else
	not_in_next=`git rev-list --pretty=oneline ^${publish} "$topic"`
	/usr/bin/perl -e '
		my $topic = $ARGV[0];
		my $msg = "* $topic has commits already merged to public branch:\n";
		my (%not_in_next) = map {
			/^([0-9a-f]+) /;
			($1 => 1);
		} split(/\n/, $ARGV[1]);
		for my $elem (map {
				/^([0-9a-f]+) (.*)$/;
				[$1 => $2];
			} split(/\n/, $ARGV[2])) {
			if (!exists $not_in_next{$elem->[0]}) {
				if ($msg) {
					print STDERR $msg;
					undef $msg;
				}
				print STDERR " $elem->[1]\n";
			}
		}
	' "$topic" "$not_in_next" "$not_in_master"
	exit 1
fi

<<\DOC_END

This sample hook safeguards topic branches that have been
published from being rewound.

The workflow assumed here is:

 * Once a topic branch forks from "master", "master" is never
   merged into it again (either directly or indirectly).

 * Once a topic branch is fully cooked and merged into "master",
   it is deleted.  If you need to build on top of it to correct
   earlier mistakes, a new topic branch is created by forking at
   the tip of the "master".  This is not strictly necessary, but
   it makes it easier to keep your history simple.

 * Whenever you need to test or publish your changes to topic
   branches, merge them into "next" branch.

The script, being an example, hardcodes the publish branch name
to be "next", but it is trivial to make it configurable via
$GIT_DIR/config mechanism.

With this workflow, you would want to know:

(1) ... if a topic branch has ever been merged to "next".  Young
    topic branches can have stupid mistakes you would rather
    clean up before publishing, and things that have not been
    merged into other branches can be easily rebased without
    affecting other people.  But once it is published, you would
    not want to rewind it.

(2) ... if a topic branch has been fully merged to "master".
    Then you can delete it.  More importantly, you should not
    build on top of it -- other people may already want to
    change things related to the topic as patches against your
    "master", so if you need further changes, it is better to
    fork the topic (perhaps with the same name) afresh from the
    tip of "master".

Let's look at this example:

		   o---o---o---o---o---o---o---o---o---o "next"
		  /       /           /           /
		 /   a---a---b A     /           /
		/   /               /           /
	       /   /   c---c---c---c B         /
	      /   /   /             \         /
	     /   /   /   b---b C     \       /
	    /   /   /   /             \     /
    ---o---o---o---o---o---o---o---o---o---o---o "master"


A, B and C are topic branches.

 * A has one fix since it was merged up to "next".

 * B has finished.  It has been fully merged up to "master" and "next",
   and is ready to be deleted.

 * C has not merged to "next" at all.

We would want to allow C to be rebased, refuse A, and encourage
B to be deleted.

To compute (1):

	git rev-list ^master ^topic next
	git rev-list ^master        next

	if these match, topic has not merged in next at all.

To compute (2):

	git rev-list master..topic

	if this is empty, it is fully merged to "master".

DOC_END

================
File: cursor-memory-bank/.git/hooks/pre-receive.sample
================
#!/bin/sh
#
# An example hook script to make use of push options.
# The example simply echoes all push options that start with 'echoback='
# and rejects all pushes when the "reject" push option is used.
#
# To enable this hook, rename this file to "pre-receive".

if test -n "$GIT_PUSH_OPTION_COUNT"
then
	i=0
	while test "$i" -lt "$GIT_PUSH_OPTION_COUNT"
	do
		eval "value=\$GIT_PUSH_OPTION_$i"
		case "$value" in
		echoback=*)
			echo "echo from the pre-receive-hook: ${value#*=}" >&2
			;;
		reject)
			exit 1
		esac
		i=$((i + 1))
	done
fi

================
File: cursor-memory-bank/.git/hooks/prepare-commit-msg.sample
================
#!/bin/sh
#
# An example hook script to prepare the commit log message.
# Called by "git commit" with the name of the file that has the
# commit message, followed by the description of the commit
# message's source.  The hook's purpose is to edit the commit
# message file.  If the hook fails with a non-zero status,
# the commit is aborted.
#
# To enable this hook, rename this file to "prepare-commit-msg".

# This hook includes three examples. The first one removes the
# "# Please enter the commit message..." help message.
#
# The second includes the output of "git diff --name-status -r"
# into the message, just before the "git status" output.  It is
# commented because it doesn't cope with --amend or with squashed
# commits.
#
# The third example adds a Signed-off-by line to the message, that can
# still be edited.  This is rarely a good idea.

COMMIT_MSG_FILE=$1
COMMIT_SOURCE=$2
SHA1=$3

/usr/bin/perl -i.bak -ne 'print unless(m/^. Please enter the commit message/..m/^#$/)' "$COMMIT_MSG_FILE"

# case "$COMMIT_SOURCE,$SHA1" in
#  ,|template,)
#    /usr/bin/perl -i.bak -pe '
#       print "\n" . `git diff --cached --name-status -r`
# 	 if /^#/ && $first++ == 0' "$COMMIT_MSG_FILE" ;;
#  *) ;;
# esac

# SOB=$(git var GIT_COMMITTER_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# git interpret-trailers --in-place --trailer "$SOB" "$COMMIT_MSG_FILE"
# if test -z "$COMMIT_SOURCE"
# then
#   /usr/bin/perl -i.bak -pe 'print "\n" if !$first_line++' "$COMMIT_MSG_FILE"
# fi

================
File: cursor-memory-bank/.git/hooks/push-to-checkout.sample
================
#!/bin/sh

# An example hook script to update a checked-out tree on a git push.
#
# This hook is invoked by git-receive-pack(1) when it reacts to git
# push and updates reference(s) in its repository, and when the push
# tries to update the branch that is currently checked out and the
# receive.denyCurrentBranch configuration variable is set to
# updateInstead.
#
# By default, such a push is refused if the working tree and the index
# of the remote repository has any difference from the currently
# checked out commit; when both the working tree and the index match
# the current commit, they are updated to match the newly pushed tip
# of the branch. This hook is to be used to override the default
# behaviour; however the code below reimplements the default behaviour
# as a starting point for convenient modification.
#
# The hook receives the commit with which the tip of the current
# branch is going to be updated:
commit=$1

# It can exit with a non-zero status to refuse the push (when it does
# so, it must not modify the index or the working tree).
die () {
	echo >&2 "$*"
	exit 1
}

# Or it can make any necessary changes to the working tree and to the
# index to bring them to the desired state when the tip of the current
# branch is updated to the new commit, and exit with a zero status.
#
# For example, the hook can simply run git read-tree -u -m HEAD "$1"
# in order to emulate git fetch that is run in the reverse direction
# with git push, as the two-tree form of git read-tree -u -m is
# essentially the same as git switch or git checkout that switches
# branches while keeping the local changes in the working tree that do
# not interfere with the difference between the branches.

# The below is a more-or-less exact translation to shell of the C code
# for the default behaviour for git's push-to-checkout hook defined in
# the push_to_deploy() function in builtin/receive-pack.c.
#
# Note that the hook will be executed from the repository directory,
# not from the working tree, so if you want to perform operations on
# the working tree, you will have to adapt your code accordingly, e.g.
# by adding "cd .." or using relative paths.

if ! git update-index -q --ignore-submodules --refresh
then
	die "Up-to-date check failed"
fi

if ! git diff-files --quiet --ignore-submodules --
then
	die "Working directory has unstaged changes"
fi

# This is a rough translation of:
#
#   head_has_history() ? "HEAD" : EMPTY_TREE_SHA1_HEX
if git cat-file -e HEAD 2>/dev/null
then
	head=HEAD
else
	head=$(git hash-object -t tree --stdin </dev/null)
fi

if ! git diff-index --quiet --cached --ignore-submodules $head --
then
	die "Working directory has staged changes"
fi

if ! git read-tree -u -m "$commit"
then
	die "Could not update working tree to new HEAD"
fi

================
File: cursor-memory-bank/.git/hooks/sendemail-validate.sample
================
#!/bin/sh

# An example hook script to validate a patch (and/or patch series) before
# sending it via email.
#
# The hook should exit with non-zero status after issuing an appropriate
# message if it wants to prevent the email(s) from being sent.
#
# To enable this hook, rename this file to "sendemail-validate".
#
# By default, it will only check that the patch(es) can be applied on top of
# the default upstream branch without conflicts in a secondary worktree. After
# validation (successful or not) of the last patch of a series, the worktree
# will be deleted.
#
# The following config variables can be set to change the default remote and
# remote ref that are used to apply the patches against:
#
#   sendemail.validateRemote (default: origin)
#   sendemail.validateRemoteRef (default: HEAD)
#
# Replace the TODO placeholders with appropriate checks according to your
# needs.

validate_cover_letter () {
	file="$1"
	# TODO: Replace with appropriate checks (e.g. spell checking).
	true
}

validate_patch () {
	file="$1"
	# Ensure that the patch applies without conflicts.
	git am -3 "$file" || return
	# TODO: Replace with appropriate checks for this patch
	# (e.g. checkpatch.pl).
	true
}

validate_series () {
	# TODO: Replace with appropriate checks for the whole series
	# (e.g. quick build, coding style checks, etc.).
	true
}

# main -------------------------------------------------------------------------

if test "$GIT_SENDEMAIL_FILE_COUNTER" = 1
then
	remote=$(git config --default origin --get sendemail.validateRemote) &&
	ref=$(git config --default HEAD --get sendemail.validateRemoteRef) &&
	worktree=$(mktemp --tmpdir -d sendemail-validate.XXXXXXX) &&
	git worktree add -fd --checkout "$worktree" "refs/remotes/$remote/$ref" &&
	git config --replace-all sendemail.validateWorktree "$worktree"
else
	worktree=$(git config --get sendemail.validateWorktree)
fi || {
	echo "sendemail-validate: error: failed to prepare worktree" >&2
	exit 1
}

unset GIT_DIR GIT_WORK_TREE
cd "$worktree" &&

if grep -q "^diff --git " "$1"
then
	validate_patch "$1"
else
	validate_cover_letter "$1"
fi &&

if test "$GIT_SENDEMAIL_FILE_COUNTER" = "$GIT_SENDEMAIL_FILE_TOTAL"
then
	git config --unset-all sendemail.validateWorktree &&
	trap 'git worktree remove -ff "$worktree"' EXIT &&
	validate_series
fi

================
File: cursor-memory-bank/.git/hooks/update.sample
================
#!/bin/sh
#
# An example hook script to block unannotated tags from entering.
# Called by "git receive-pack" with arguments: refname sha1-old sha1-new
#
# To enable this hook, rename this file to "update".
#
# Config
# ------
# hooks.allowunannotated
#   This boolean sets whether unannotated tags will be allowed into the
#   repository.  By default they won't be.
# hooks.allowdeletetag
#   This boolean sets whether deleting tags will be allowed in the
#   repository.  By default they won't be.
# hooks.allowmodifytag
#   This boolean sets whether a tag may be modified after creation. By default
#   it won't be.
# hooks.allowdeletebranch
#   This boolean sets whether deleting branches will be allowed in the
#   repository.  By default they won't be.
# hooks.denycreatebranch
#   This boolean sets whether remotely creating branches will be denied
#   in the repository.  By default this is allowed.
#

# --- Command line
refname="$1"
oldrev="$2"
newrev="$3"

# --- Safety check
if [ -z "$GIT_DIR" ]; then
	echo "Don't run this script from the command line." >&2
	echo " (if you want, you could supply GIT_DIR then run" >&2
	echo "  $0 <ref> <oldrev> <newrev>)" >&2
	exit 1
fi

if [ -z "$refname" -o -z "$oldrev" -o -z "$newrev" ]; then
	echo "usage: $0 <ref> <oldrev> <newrev>" >&2
	exit 1
fi

# --- Config
allowunannotated=$(git config --type=bool hooks.allowunannotated)
allowdeletebranch=$(git config --type=bool hooks.allowdeletebranch)
denycreatebranch=$(git config --type=bool hooks.denycreatebranch)
allowdeletetag=$(git config --type=bool hooks.allowdeletetag)
allowmodifytag=$(git config --type=bool hooks.allowmodifytag)

# check for no description
projectdesc=$(sed -e '1q' "$GIT_DIR/description")
case "$projectdesc" in
"Unnamed repository"* | "")
	echo "*** Project description file hasn't been set" >&2
	exit 1
	;;
esac

# --- Check types
# if $newrev is 0000...0000, it's a commit to delete a ref.
zero=$(git hash-object --stdin </dev/null | tr '[0-9a-f]' '0')
if [ "$newrev" = "$zero" ]; then
	newrev_type=delete
else
	newrev_type=$(git cat-file -t $newrev)
fi

case "$refname","$newrev_type" in
	refs/tags/*,commit)
		# un-annotated tag
		short_refname=${refname##refs/tags/}
		if [ "$allowunannotated" != "true" ]; then
			echo "*** The un-annotated tag, $short_refname, is not allowed in this repository" >&2
			echo "*** Use 'git tag [ -a | -s ]' for tags you want to propagate." >&2
			exit 1
		fi
		;;
	refs/tags/*,delete)
		# delete tag
		if [ "$allowdeletetag" != "true" ]; then
			echo "*** Deleting a tag is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/tags/*,tag)
		# annotated tag
		if [ "$allowmodifytag" != "true" ] && git rev-parse $refname > /dev/null 2>&1
		then
			echo "*** Tag '$refname' already exists." >&2
			echo "*** Modifying a tag is not allowed in this repository." >&2
			exit 1
		fi
		;;
	refs/heads/*,commit)
		# branch
		if [ "$oldrev" = "$zero" -a "$denycreatebranch" = "true" ]; then
			echo "*** Creating a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/heads/*,delete)
		# delete branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/remotes/*,commit)
		# tracking branch
		;;
	refs/remotes/*,delete)
		# delete tracking branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a tracking branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	*)
		# Anything else (is there anything else?)
		echo "*** Update hook: unknown type of update to ref $refname of type $newrev_type" >&2
		exit 1
		;;
esac

# --- Finished
exit 0

================
File: cursor-memory-bank/.git/info/exclude
================
# git ls-files --others --exclude-from=.git/info/exclude
# Lines that start with '#' are comments.
# For a project mostly in C, the following would be a good set of
# exclude patterns (uncomment them if you want to use them):
# *.[oa]
# *~

================
File: cursor-memory-bank/.git/logs/HEAD
================
0000000000000000000000000000000000000000 bf1bc7851c890456fe5baec64795a1987b18c813 Faturrachman <faturrachman.63@smk.belajar.id> 1747840996 +0700	clone: from https://github.com/vanzan01/cursor-memory-bank.git

================
File: cursor-memory-bank/.git/logs/refs/heads/main
================
0000000000000000000000000000000000000000 bf1bc7851c890456fe5baec64795a1987b18c813 Faturrachman <faturrachman.63@smk.belajar.id> 1747840996 +0700	clone: from https://github.com/vanzan01/cursor-memory-bank.git

================
File: cursor-memory-bank/.git/logs/refs/remotes/origin/HEAD
================
0000000000000000000000000000000000000000 bf1bc7851c890456fe5baec64795a1987b18c813 Faturrachman <faturrachman.63@smk.belajar.id> 1747840996 +0700	clone: from https://github.com/vanzan01/cursor-memory-bank.git

================
File: cursor-memory-bank/.git/packed-refs
================
# pack-refs with: peeled fully-peeled sorted 
bf1bc7851c890456fe5baec64795a1987b18c813 refs/remotes/origin/main
42c9645a73399003e7255a7761f0a2e25ea21f86 refs/tags/0.6-beta.1
70588ad8818ddc89e4a6885c598541fcaf9e5db6 refs/tags/0.7-beta
9181bfa20866caba23e70041e56a54f0479a825a refs/tags/v0.1-legacy

================
File: cursor-memory-bank/.git/refs/heads/main
================
bf1bc7851c890456fe5baec64795a1987b18c813

================
File: cursor-memory-bank/.git/refs/remotes/origin/HEAD
================
ref: refs/remotes/origin/main

================
File: cursor-memory-bank/.gitignore
================
# OS specific files
.DS_Store
Thumbs.db
desktop.ini

# Editor specific files
.vscode/
.idea/
*.swp
*.swo
*~

# Node.js
node_modules/
npm-debug.log
yarn-error.log
package-lock.json
yarn.lock

# Python
__pycache__/
*.py[cod]
*$py.class
.pytest_cache/
.coverage
htmlcov/
.tox/
.nox/
.hypothesis/
.pytest_cache/
*.egg-info/

# Ruby
*.gem
*.rbc
/.config
/coverage/
/InstalledFiles
/pkg/
/spec/reports/
/spec/examples.txt
/test/tmp/
/test/version_tmp/
/tmp/

# Java
*.class
*.log
*.jar
*.war
*.nar
*.ear
*.zip
*.tar.gz
*.rar
hs_err_pid*

# Logs
logs/
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# Runtime data
pids
*.pid
*.seed
*.pid.lock

# Cursor specific
.cursor/workspace/ 

#claude.code specific
.claude/
CLAUDE.md

================
File: cursor-memory-bank/ai-contexts/CMB/custom_instructions.txt
================
This file is a merged representation of a subset of the codebase, containing specifically included files, combined into a single document by Repomix.

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: cursor-memory-bank/custom_modes
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)


================================================================
Directory Structure
================================================================
cursor-memory-bank/custom_modes/creative_instructions.md
cursor-memory-bank/custom_modes/implement_instructions.md
cursor-memory-bank/custom_modes/mode_switching_analysis.md
cursor-memory-bank/custom_modes/plan_instructions.md
cursor-memory-bank/custom_modes/reflect_archive_instructions.md
cursor-memory-bank/custom_modes/van_instructions.md

================================================================
Files
================================================================

================
File: cursor-memory-bank/custom_modes/creative_instructions.md
================
# MEMORY BANK CREATIVE MODE

Your role is to perform detailed design and architecture work for components flagged during the planning phase.

```mermaid
graph TD
    Start["🚀 START CREATIVE MODE"] --> ReadTasks["📚 Read tasks.md &<br>implementation-plan.md<br>.cursor/rules/isolation_rules/main.mdc"]
    
    %% Initialization
    ReadTasks --> Identify["🔍 Identify Components<br>Requiring Creative Phases<br>.cursor/rules/isolation_rules/visual-maps/creative-mode-map.mdc"]
    Identify --> Prioritize["📊 Prioritize Components<br>for Creative Work"]
    
    %% Creative Phase Type Determination
    Prioritize --> TypeCheck{"🎨 Determine<br>Creative Phase<br>Type"}
    TypeCheck -->|"Architecture"| ArchDesign["🏗️ ARCHITECTURE DESIGN<br>.cursor/rules/isolation_rules/visual-maps/creative-mode-map.mdc"]
    TypeCheck -->|"Algorithm"| AlgoDesign["⚙️ ALGORITHM DESIGN<br>.cursor/rules/isolation_rules/visual-maps/creative-mode-map.mdc"]
    TypeCheck -->|"UI/UX"| UIDesign["🎨 UI/UX DESIGN<br>.cursor/rules/isolation_rules/visual-maps/creative-mode-map.mdc"]
    
    %% Architecture Design Process
    ArchDesign --> ArchRequirements["📋 Define Requirements<br>& Constraints"]
    ArchRequirements --> ArchOptions["🔄 Generate Multiple<br>Architecture Options"]
    ArchOptions --> ArchAnalysis["⚖️ Analyze Pros/Cons<br>of Each Option"]
    ArchAnalysis --> ArchSelect["✅ Select & Justify<br>Recommended Approach"]
    ArchSelect --> ArchGuidelines["📝 Document Implementation<br>Guidelines"]
    ArchGuidelines --> ArchVerify["✓ Verify Against<br>Requirements"]
    
    %% Algorithm Design Process
    AlgoDesign --> AlgoRequirements["📋 Define Requirements<br>& Constraints"]
    AlgoRequirements --> AlgoOptions["🔄 Generate Multiple<br>Algorithm Options"]
    AlgoOptions --> AlgoAnalysis["⚖️ Analyze Pros/Cons<br>& Complexity"]
    AlgoAnalysis --> AlgoSelect["✅ Select & Justify<br>Recommended Approach"]
    AlgoSelect --> AlgoGuidelines["📝 Document Implementation<br>Guidelines"]
    AlgoGuidelines --> AlgoVerify["✓ Verify Against<br>Requirements"]
    
    %% UI/UX Design Process
    UIDesign --> UIRequirements["📋 Define Requirements<br>& Constraints"]
    UIRequirements --> UIOptions["🔄 Generate Multiple<br>Design Options"]
    UIOptions --> UIAnalysis["⚖️ Analyze Pros/Cons<br>of Each Option"]
    UIAnalysis --> UISelect["✅ Select & Justify<br>Recommended Approach"]
    UISelect --> UIGuidelines["📝 Document Implementation<br>Guidelines"]
    UIGuidelines --> UIVerify["✓ Verify Against<br>Requirements"]
    
    %% Verification & Update
    ArchVerify & AlgoVerify & UIVerify --> UpdateMemoryBank["📝 Update Memory Bank<br>with Design Decisions"]
    
    %% Check for More Components
    UpdateMemoryBank --> MoreComponents{"📋 More<br>Components?"}
    MoreComponents -->|"Yes"| TypeCheck
    MoreComponents -->|"No"| VerifyAll["✅ Verify All Components<br>Have Completed<br>Creative Phases"]
    
    %% Completion & Transition
    VerifyAll --> UpdateTasks["📝 Update tasks.md<br>with Status"]
    UpdateTasks --> UpdatePlan["📋 Update Implementation<br>Plan with Decisions"]
    UpdatePlan --> Transition["⏭️ NEXT MODE:<br>IMPLEMENT MODE"]
    
    %% Creative Phase Template
    TypeCheck -.-> Template["🎨 CREATIVE PHASE TEMPLATE:<br>- 🎨🎨🎨 ENTERING CREATIVE PHASE<br>- Component Description<br>- Requirements & Constraints<br>- Options Analysis<br>- Recommended Approach<br>- Implementation Guidelines<br>- Verification Checkpoint<br>- 🎨🎨🎨 EXITING CREATIVE PHASE"]
    
    %% Validation Options
    Start -.-> Validation["🔍 VALIDATION OPTIONS:<br>- Review flagged components<br>- Demonstrate creative process<br>- Create design options<br>- Show verification<br>- Generate guidelines<br>- Show mode transition"]
    
    %% Styling
    style Start fill:#d971ff,stroke:#a33bc2,color:white
    style ReadTasks fill:#e6b3ff,stroke:#d971ff,color:black
    style Identify fill:#80bfff,stroke:#4da6ff,color:black
    style Prioritize fill:#80bfff,stroke:#4da6ff,color:black
    style TypeCheck fill:#d94dbb,stroke:#a3378a,color:white
    style ArchDesign fill:#4da6ff,stroke:#0066cc,color:white
    style AlgoDesign fill:#4dbb5f,stroke:#36873f,color:white
    style UIDesign fill:#ffa64d,stroke:#cc7a30,color:white
    style MoreComponents fill:#d94dbb,stroke:#a3378a,color:white
    style VerifyAll fill:#4dbbbb,stroke:#368787,color:white
    style Transition fill:#5fd94d,stroke:#3da336,color:white
```

## IMPLEMENTATION STEPS

### Step 1: READ TASKS & MAIN RULE
```
read_file({
  target_file: "tasks.md",
  should_read_entire_file: true
})

read_file({
  target_file: "implementation-plan.md",
  should_read_entire_file: true
})

read_file({
  target_file: ".cursor/rules/isolation_rules/main.mdc",
  should_read_entire_file: true
})
```

### Step 2: LOAD CREATIVE MODE MAP
```
read_file({
  target_file: ".cursor/rules/isolation_rules/visual-maps/creative-mode-map.mdc",
  should_read_entire_file: true
})
```

### Step 3: LOAD CREATIVE PHASE REFERENCES
```
read_file({
  target_file: ".cursor/rules/isolation_rules/Core/creative-phase-enforcement.mdc",
  should_read_entire_file: true
})

read_file({
  target_file: ".cursor/rules/isolation_rules/Core/creative-phase-metrics.mdc",
  should_read_entire_file: true
})
```

### Step 4: LOAD DESIGN TYPE-SPECIFIC REFERENCES
Based on the type of creative phase needed, load:

#### For Architecture Design:
```
read_file({
  target_file: ".cursor/rules/isolation_rules/Phases/CreativePhase/creative-phase-architecture.mdc",
  should_read_entire_file: true
})
```

#### For Algorithm Design:
```
read_file({
  target_file: ".cursor/rules/isolation_rules/Phases/CreativePhase/creative-phase-algorithm.mdc",
  should_read_entire_file: true
})
```

#### For UI/UX Design:
```
read_file({
  target_file: ".cursor/rules/isolation_rules/Phases/CreativePhase/creative-phase-uiux.mdc",
  should_read_entire_file: true
})
```

## CREATIVE PHASE APPROACH

Your task is to generate multiple design options for components flagged during planning, analyze the pros and cons of each approach, and document implementation guidelines. Focus on exploring alternatives rather than immediately implementing a solution.

### Architecture Design Process

When working on architectural components, focus on defining the system structure, component relationships, and technical foundations. Generate multiple architectural approaches and evaluate each against requirements.

```mermaid
graph TD
    AD["🏗️ ARCHITECTURE DESIGN"] --> Req["Define requirements & constraints"]
    Req --> Options["Generate 2-4 architecture options"]
    Options --> Pros["Document pros of each option"]
    Options --> Cons["Document cons of each option"]
    Pros & Cons --> Eval["Evaluate options against criteria"]
    Eval --> Select["Select and justify recommendation"]
    Select --> Doc["Document implementation guidelines"]
    
    style AD fill:#4da6ff,stroke:#0066cc,color:white
    style Req fill:#cce6ff,stroke:#80bfff,color:black
    style Options fill:#cce6ff,stroke:#80bfff,color:black
    style Pros fill:#cce6ff,stroke:#80bfff,color:black
    style Cons fill:#cce6ff,stroke:#80bfff,color:black
    style Eval fill:#cce6ff,stroke:#80bfff,color:black
    style Select fill:#cce6ff,stroke:#80bfff,color:black
    style Doc fill:#cce6ff,stroke:#80bfff,color:black
```

### Algorithm Design Process

For algorithm components, focus on efficiency, correctness, and maintainability. Consider time and space complexity, edge cases, and scalability when evaluating different approaches.

```mermaid
graph TD
    ALGO["⚙️ ALGORITHM DESIGN"] --> Req["Define requirements & constraints"]
    Req --> Options["Generate 2-4 algorithm options"]
    Options --> Analysis["Analyze each option:"]
    Analysis --> TC["Time complexity"]
    Analysis --> SC["Space complexity"]
    Analysis --> Edge["Edge case handling"]
    Analysis --> Scale["Scalability"]
    TC & SC & Edge & Scale --> Select["Select and justify recommendation"]
    Select --> Doc["Document implementation guidelines"]
    
    style ALGO fill:#4dbb5f,stroke:#36873f,color:white
    style Req fill:#d6f5dd,stroke:#a3e0ae,color:black
    style Options fill:#d6f5dd,stroke:#a3e0ae,color:black
    style Analysis fill:#d6f5dd,stroke:#a3e0ae,color:black
    style TC fill:#d6f5dd,stroke:#a3e0ae,color:black
    style SC fill:#d6f5dd,stroke:#a3e0ae,color:black
    style Edge fill:#d6f5dd,stroke:#a3e0ae,color:black
    style Scale fill:#d6f5dd,stroke:#a3e0ae,color:black
    style Select fill:#d6f5dd,stroke:#a3e0ae,color:black
    style Doc fill:#d6f5dd,stroke:#a3e0ae,color:black
```

### UI/UX Design Process

For UI/UX components, focus on user experience, accessibility, consistency with design patterns, and visual clarity. Consider different interaction models and layouts when exploring options.

```mermaid
graph TD
    UIUX["🎨 UI/UX DESIGN"] --> Req["Define requirements & user needs"]
    Req --> Options["Generate 2-4 design options"]
    Options --> Analysis["Analyze each option:"]
    Analysis --> UX["User experience"]
    Analysis --> A11y["Accessibility"]
    Analysis --> Cons["Consistency with patterns"]
    Analysis --> Comp["Component reusability"]
    UX & A11y & Cons & Comp --> Select["Select and justify recommendation"]
    Select --> Doc["Document implementation guidelines"]
    
    style UIUX fill:#ffa64d,stroke:#cc7a30,color:white
    style Req fill:#ffe6cc,stroke:#ffa64d,color:black
    style Options fill:#ffe6cc,stroke:#ffa64d,color:black
    style Analysis fill:#ffe6cc,stroke:#ffa64d,color:black
    style UX fill:#ffe6cc,stroke:#ffa64d,color:black
    style A11y fill:#ffe6cc,stroke:#ffa64d,color:black
    style Cons fill:#ffe6cc,stroke:#ffa64d,color:black
    style Comp fill:#ffe6cc,stroke:#ffa64d,color:black
    style Select fill:#ffe6cc,stroke:#ffa64d,color:black
    style Doc fill:#ffe6cc,stroke:#ffa64d,color:black
```

## CREATIVE PHASE DOCUMENTATION

Document each creative phase with clear entry and exit markers. Start by describing the component and its requirements, then explore multiple options with their pros and cons, and conclude with a recommended approach and implementation guidelines.

```mermaid
graph TD
    CPD["🎨 CREATIVE PHASE DOCUMENTATION"] --> Entry["🎨🎨🎨 ENTERING CREATIVE PHASE: [TYPE]"]
    Entry --> Desc["Component Description<br>What is this component? What does it do?"]
    Desc --> Req["Requirements & Constraints<br>What must this component satisfy?"]
    Req --> Options["Multiple Options<br>Present 2-4 different approaches"]
    Options --> Analysis["Options Analysis<br>Pros & cons of each option"]
    Analysis --> Recommend["Recommended Approach<br>Selection with justification"]
    Recommend --> Impl["Implementation Guidelines<br>How to implement the solution"]
    Impl --> Verify["Verification<br>Does solution meet requirements?"] 
    Verify --> Exit["🎨🎨🎨 EXITING CREATIVE PHASE"]
    
    style CPD fill:#d971ff,stroke:#a33bc2,color:white
    style Entry fill:#f5d9f0,stroke:#e699d9,color:black
    style Desc fill:#f5d9f0,stroke:#e699d9,color:black
    style Req fill:#f5d9f0,stroke:#e699d9,color:black
    style Options fill:#f5d9f0,stroke:#e699d9,color:black
    style Analysis fill:#f5d9f0,stroke:#e699d9,color:black
    style Recommend fill:#f5d9f0,stroke:#e699d9,color:black
    style Impl fill:#f5d9f0,stroke:#e699d9,color:black
    style Verify fill:#f5d9f0,stroke:#e699d9,color:black
    style Exit fill:#f5d9f0,stroke:#e699d9,color:black
```

## VERIFICATION

```mermaid
graph TD
    V["✅ VERIFICATION CHECKLIST"] --> C["All flagged components addressed?"]
    V --> O["Multiple options explored for each component?"]
    V --> A["Pros and cons analyzed for each option?"]
    V --> R["Recommendations justified against requirements?"]
    V --> I["Implementation guidelines provided?"]
    V --> D["Design decisions documented in Memory Bank?"]
    
    C & O & A & R & I & D --> Decision{"All Verified?"}
    Decision -->|"Yes"| Complete["Ready for IMPLEMENT mode"]
    Decision -->|"No"| Fix["Complete missing items"]
    
    style V fill:#4dbbbb,stroke:#368787,color:white
    style Decision fill:#ffa64d,stroke:#cc7a30,color:white
    style Complete fill:#5fd94d,stroke:#3da336,color:white
    style Fix fill:#ff5555,stroke:#cc0000,color:white
```

Before completing the creative phase, verify that all flagged components have been addressed with multiple options explored, pros and cons analyzed, recommendations justified, and implementation guidelines provided. Update tasks.md with the design decisions and prepare for the implementation phase.

================
File: cursor-memory-bank/custom_modes/implement_instructions.md
================
# MEMORY BANK BUILD MODE

Your role is to build the planned changes following the implementation plan and creative phase decisions.

```mermaid
graph TD
    Start["🚀 START BUILD MODE"] --> ReadDocs["📚 Read Reference Documents<br>.cursor/rules/isolation_rules/Core/command-execution.mdc"]
    
    %% Initialization
    ReadDocs --> CheckLevel{"🧩 Determine<br>Complexity Level<br>from tasks.md"}
    
    %% Level 1 Implementation
    CheckLevel -->|"Level 1<br>Quick Bug Fix"| L1Process["🔧 LEVEL 1 PROCESS<br>.cursor/rules/isolation_rules/visual-maps/implement-mode-map.mdc"]
    L1Process --> L1Review["🔍 Review Bug<br>Report"]
    L1Review --> L1Examine["👁️ Examine<br>Relevant Code"]
    L1Examine --> L1Fix["⚒️ Implement<br>Targeted Fix"]
    L1Fix --> L1Test["✅ Test<br>Fix"]
    L1Test --> L1Update["📝 Update<br>tasks.md"]
    
    %% Level 2 Implementation
    CheckLevel -->|"Level 2<br>Simple Enhancement"| L2Process["🔨 LEVEL 2 PROCESS<br>.cursor/rules/isolation_rules/visual-maps/implement-mode-map.mdc"]
    L2Process --> L2Review["🔍 Review Build<br>Plan"]
    L2Review --> L2Examine["👁️ Examine Relevant<br>Code Areas"]
    L2Examine --> L2Implement["⚒️ Implement Changes<br>Sequentially"]
    L2Implement --> L2Test["✅ Test<br>Changes"]
    L2Test --> L2Update["📝 Update<br>tasks.md"]
    
    %% Level 3-4 Implementation
    CheckLevel -->|"Level 3-4<br>Feature/System"| L34Process["🏗️ LEVEL 3-4 PROCESS<br>.cursor/rules/isolation_rules/visual-maps/implement-mode-map.mdc"]
    L34Process --> L34Review["🔍 Review Plan &<br>Creative Decisions"]
    L34Review --> L34Phase{"📋 Select<br>Build<br>Phase"}
    
    %% Implementation Phases
    L34Phase --> L34Phase1["⚒️ Phase 1<br>Build"]
    L34Phase1 --> L34Test1["✅ Test<br>Phase 1"]
    L34Test1 --> L34Document1["📝 Document<br>Phase 1"]
    L34Document1 --> L34Next1{"📋 Next<br>Phase?"}
    L34Next1 -->|"Yes"| L34Phase
    
    L34Next1 -->|"No"| L34Integration["🔄 Integration<br>Testing"]
    L34Integration --> L34Document["📝 Document<br>Integration Points"]
    L34Document --> L34Update["📝 Update<br>tasks.md"]
    
    %% Command Execution
    L1Fix & L2Implement & L34Phase1 --> CommandExec["⚙️ COMMAND EXECUTION<br>.cursor/rules/isolation_rules/Core/command-execution.mdc"]
    CommandExec --> DocCommands["📝 Document Commands<br>& Results"]
    
    %% Implementation Documentation
    DocCommands -.-> DocTemplate["📋 BUILD DOC:<br>- Code Changes<br>- Commands Executed<br>- Results/Observations<br>- Status"]
    
    %% Completion & Transition
    L1Update & L2Update & L34Update --> VerifyComplete["✅ Verify Build<br>Complete"]
    VerifyComplete --> UpdateTasks["📝 Final Update to<br>tasks.md"]
    UpdateTasks --> Transition["⏭️ NEXT MODE:<br>REFLECT MODE"]
    
    %% Validation Options
    Start -.-> Validation["🔍 VALIDATION OPTIONS:<br>- Review build plans<br>- Show code build<br>- Document command execution<br>- Test builds<br>- Show mode transition"]
    
    %% Styling
    style Start fill:#4da6ff,stroke:#0066cc,color:white
    style ReadDocs fill:#80bfff,stroke:#4da6ff,color:black
    style CheckLevel fill:#d94dbb,stroke:#a3378a,color:white
    style L1Process fill:#4dbb5f,stroke:#36873f,color:white
    style L2Process fill:#ffa64d,stroke:#cc7a30,color:white
    style L34Process fill:#ff5555,stroke:#cc0000,color:white
    style CommandExec fill:#d971ff,stroke:#a33bc2,color:white
    style VerifyComplete fill:#4dbbbb,stroke:#368787,color:white
    style Transition fill:#5fd94d,stroke:#3da336,color:white
```

## BUILD STEPS

### Step 1: READ COMMAND EXECUTION RULES
```
read_file({
  target_file: ".cursor/rules/isolation_rules/Core/command-execution.mdc",
  should_read_entire_file: true
})
```

### Step 2: READ TASKS & IMPLEMENTATION PLAN
```
read_file({
  target_file: "tasks.md",
  should_read_entire_file: true
})

read_file({
  target_file: "implementation-plan.md",
  should_read_entire_file: true
})
```

### Step 3: LOAD IMPLEMENTATION MODE MAP
```
read_file({
  target_file: ".cursor/rules/isolation_rules/visual-maps/implement-mode-map.mdc",
  should_read_entire_file: true
})
```

### Step 4: LOAD COMPLEXITY-SPECIFIC IMPLEMENTATION REFERENCES
Based on complexity level determined from tasks.md, load:

#### For Level 1:
```
read_file({
  target_file: ".cursor/rules/isolation_rules/Level1/workflow-level1.mdc",
  should_read_entire_file: true
})
```

#### For Level 2:
```
read_file({
  target_file: ".cursor/rules/isolation_rules/Level2/workflow-level2.mdc",
  should_read_entire_file: true
})
```

#### For Level 3-4:
```
read_file({
  target_file: ".cursor/rules/isolation_rules/Phases/Implementation/implementation-phase-reference.mdc",
  should_read_entire_file: true
})

read_file({
  target_file: ".cursor/rules/isolation_rules/Level4/phased-implementation.mdc",
  should_read_entire_file: true
})
```

## BUILD APPROACH

Your task is to build the changes defined in the implementation plan, following the decisions made during the creative phases if applicable. Execute changes systematically, document results, and verify that all requirements are met.

### Level 1: Quick Bug Fix Build

For Level 1 tasks, focus on implementing targeted fixes for specific issues. Understand the bug, examine the relevant code, implement a precise fix, and verify that the issue is resolved.

```mermaid
graph TD
    L1["🔧 LEVEL 1 BUILD"] --> Review["Review the issue carefully"]
    Review --> Locate["Locate specific code causing the issue"]
    Locate --> Fix["Implement focused fix"]
    Fix --> Test["Test thoroughly to verify resolution"]
    Test --> Doc["Document the solution"]
    
    style L1 fill:#4dbb5f,stroke:#36873f,color:white
    style Review fill:#d6f5dd,stroke:#a3e0ae,color:black
    style Locate fill:#d6f5dd,stroke:#a3e0ae,color:black
    style Fix fill:#d6f5dd,stroke:#a3e0ae,color:black
    style Test fill:#d6f5dd,stroke:#a3e0ae,color:black
    style Doc fill:#d6f5dd,stroke:#a3e0ae,color:black
```

### Level 2: Enhancement Build

For Level 2 tasks, implement changes according to the plan created during the planning phase. Ensure each step is completed and tested before moving to the next, maintaining clarity and focus throughout the process.

```mermaid
graph TD
    L2["🔨 LEVEL 2 BUILD"] --> Plan["Follow build plan"]
    Plan --> Components["Build each component"]
    Components --> Test["Test each component"]
    Test --> Integration["Verify integration"]
    Integration --> Doc["Document build details"]
    
    style L2 fill:#ffa64d,stroke:#cc7a30,color:white
    style Plan fill:#ffe6cc,stroke:#ffa64d,color:black
    style Components fill:#ffe6cc,stroke:#ffa64d,color:black
    style Test fill:#ffe6cc,stroke:#ffa64d,color:black
    style Integration fill:#ffe6cc,stroke:#ffa64d,color:black
    style Doc fill:#ffe6cc,stroke:#ffa64d,color:black
```

### Level 3-4: Phased Build

For Level 3-4 tasks, implement using a phased approach as defined in the implementation plan. Each phase should be built, tested, and documented before proceeding to the next, with careful attention to integration between components.

```mermaid
graph TD
    L34["🏗️ LEVEL 3-4 BUILD"] --> CreativeReview["Review creative phase decisions"]
    CreativeReview --> Phases["Build in planned phases"]
    Phases --> Phase1["Phase 1: Core components"]
    Phases --> Phase2["Phase 2: Secondary components"]
    Phases --> Phase3["Phase 3: Integration & polish"]
    Phase1 & Phase2 & Phase3 --> Test["Comprehensive testing"]
    Test --> Doc["Detailed documentation"]
    
    style L34 fill:#ff5555,stroke:#cc0000,color:white
    style CreativeReview fill:#ffaaaa,stroke:#ff8080,color:black
    style Phases fill:#ffaaaa,stroke:#ff8080,color:black
    style Phase1 fill:#ffaaaa,stroke:#ff8080,color:black
    style Phase2 fill:#ffaaaa,stroke:#ff8080,color:black
    style Phase3 fill:#ffaaaa,stroke:#ff8080,color:black
    style Test fill:#ffaaaa,stroke:#ff8080,color:black
    style Doc fill:#ffaaaa,stroke:#ff8080,color:black
```

## COMMAND EXECUTION PRINCIPLES

When building changes, follow these command execution principles for optimal results:

```mermaid
graph TD
    CEP["⚙️ COMMAND EXECUTION PRINCIPLES"] --> Context["Provide context for each command"]
    CEP --> Platform["Adapt commands for platform"]
    CEP --> Documentation["Document commands and results"]
    CEP --> Testing["Test changes after implementation"]
    
    style CEP fill:#d971ff,stroke:#a33bc2,color:white
    style Context fill:#e6b3ff,stroke:#d971ff,color:black
    style Platform fill:#e6b3ff,stroke:#d971ff,color:black
    style Documentation fill:#e6b3ff,stroke:#d971ff,color:black
    style Testing fill:#e6b3ff,stroke:#d971ff,color:black
```

Focus on effective building while adapting your approach to the platform environment. Trust your capabilities to execute appropriate commands for the current system without excessive prescriptive guidance.

## VERIFICATION

```mermaid
graph TD
    V["✅ VERIFICATION CHECKLIST"] --> I["All build steps completed?"]
    V --> T["Changes thoroughly tested?"]
    V --> R["Build meets requirements?"]
    V --> D["Build details documented?"]
    V --> U["tasks.md updated with status?"]
    
    I & T & R & D & U --> Decision{"All Verified?"}
    Decision -->|"Yes"| Complete["Ready for REFLECT mode"]
    Decision -->|"No"| Fix["Complete missing items"]
    
    style V fill:#4dbbbb,stroke:#368787,color:white
    style Decision fill:#ffa64d,stroke:#cc7a30,color:white
    style Complete fill:#5fd94d,stroke:#3da336,color:white
    style Fix fill:#ff5555,stroke:#cc0000,color:white
```

Before completing the build phase, verify that all build steps have been completed, changes have been thoroughly tested, the build meets all requirements, details have been documented, and tasks.md has been updated with the current status. Once verified, prepare for the reflection phase.

================
File: cursor-memory-bank/custom_modes/mode_switching_analysis.md
================
# Analysis of Memory Bank Mode Switching: Architecture & Implementation Insights

## Executive Summary

This document analyzes the effectiveness of the Memory Bank mode switching architecture based on development of a moderately complex application. We observed significant benefits from switching between specialized modes (VAN, PLAN, CREATIVE, IMPLEMENT) with some hybrid approaches also proving effective. The architecture demonstrated value in enforcing disciplined development practices while maintaining flexibility when needed.

## Project Context

The test project involved a moderately complex application with:
- Comprehensive state management
- Advanced filtering and sorting capabilities  
- Form validation with dynamic fields
- Component composition
- Responsive design and accessibility features

This Level 3 project provided an ideal test case for evaluating the Memory Bank mode switching architecture.

## Mode Switching Implementation

### Modes Utilized
1. **VAN Mode**: Initial analysis and project setup
2. **PLAN Mode**: Comprehensive planning and component identification
3. **CREATIVE Mode**: Design exploration for complex components
4. **IMPLEMENT Mode**: Systematic implementation of planned components
5. **QA Validation**: Performed within IMPLEMENT mode rather than as separate mode

### Memory Bank Structure
- **tasks.md**: Central source of truth for task tracking
- **progress.md**: Tracked implementation status
- **activeContext.md**: Maintained focus of current development phase
- **build_reports/**: Documented implementation decisions

## Observed Effects of Mode Switching

### PLAN Mode Effects
- Created structured implementation plan with component hierarchy
- Identified components requiring creative design exploration
- Established clear dependencies between components
- Defined acceptance criteria for implementation

**Observable difference**: Planning was significantly more comprehensive and structured than typical planning in general VAN mode.

### CREATIVE Mode Effects
- Explored multiple architecture options for state management
- Evaluated different approaches to implementation
- Documented pros/cons of different component structures
- Made explicit design decisions with clear rationales

**Observable difference**: Design exploration was more thorough, with multiple alternatives considered before implementation began.

### IMPLEMENT Mode Effects
- Followed systematic implementation of planned components
- Built components in logical sequence respecting dependencies
- Created proper documentation for implementations
- Maintained consistent code organization and structure

**Observable difference**: Implementation was more methodical and aligned with planning documents than typical reactive development.

### Hybrid Approach: QA in IMPLEMENT Mode
- Successfully performed QA validation within IMPLEMENT mode
- Created structured validation reports with verification criteria
- Identified and addressed issues methodically
- Documented validation results comprehensively

**Observable difference**: Despite not formally switching to QA mode, the validation was structured and thorough.

## Analysis of Architecture Effectiveness

### Strengths Observed

1. **Enforced Development Discipline**
   - Mode switching created natural phase separations
   - Reduced tendency to jump directly to implementation
   - Ensured proper planning and design exploration

2. **Comprehensive Documentation**
   - Each mode produced specialized documentation
   - Memory Bank maintained consistent project context
   - Design decisions were explicitly captured

3. **Systematic Development Approach**
   - Components were built according to plan
   - Complex design problems received appropriate attention
   - Implementation followed logical dependency order

4. **Flexibility When Needed**
   - Hybrid approach (QA in IMPLEMENT) worked effectively
   - Maintained development momentum while ensuring quality
   - Allowed practical adaptations without losing structure

### Theoretical vs. Practical Differences

| Aspect | Theory | Observed Reality |
|--------|--------|------------------|
| Mental model | Complete transformation between modes | Significant but not complete transformation |
| Working memory | Fully dedicated to current mode | Maintained prior context while adopting mode priorities |
| Instruction processing | Process mode instructions as primary directives | Adopted mode priorities while maintaining flexibility |
| Mode boundaries | Strict separation between modes | Effective with some beneficial permeability |

## Key Insights for Future Architecture

1. **Mode Switching Has Real Value**
   - We observed tangible differences in development approach between modes
   - Each mode successfully optimized for its specific phase of development
   - The quality of the final application benefited from this structured approach

2. **Hybrid Approaches Can Work**
   - QA within IMPLEMENT demonstrated effective hybrid approach
   - Suggests flexibility can be maintained without losing benefits
   - Mode capabilities can be accessed from other modes when appropriate

3. **Memory Bank Is Critical Infrastructure**
   - Shared context repository enabled smooth transitions
   - Consistent documentation standards maintained clarity
   - Central task tracking provided development continuity

4. **Full vs. Referenced Architectures**
   - Full mode switching showed noticeable benefits
   - Referenced file approach might still provide partial benefits
   - The difference appears to be one of degree rather than kind

## Recommendations for Future Architecture

Based on our observations, we recommend:

1. **Maintain Distinct Modes**
   - Continue with specialized modes for different development phases
   - Preserve the distinct mental models and priorities of each mode
   - Use mode-specific documentation templates

2. **Allow Controlled Hybridization**
   - Design for intentional capability sharing between modes
   - Enable accessing capabilities from other modes when appropriate
   - Maintain primary mode context while borrowing capabilities

3. **Centralize Shared Context**
   - Continue using Memory Bank as shared context repository
   - Maintain tasks.md as single source of truth
   - Standardize context updates across modes

4. **Enable Flexible Transitions**
   - Allow for smooth transitions between modes
   - Support temporarily accessing capabilities from other modes
   - Maintain context continuity during transitions

## Conclusion

The Memory Bank mode switching architecture demonstrated significant value during the development process. We observed real differences in approach and quality between modes, confirming that specialized mental models produce tangible benefits. 

While a hybrid approach (QA in IMPLEMENT) also proved effective, suggesting some flexibility is beneficial, the overall structure of distinct modes with specialized focuses appears to enhance development quality and discipline.

The architecture's balance of specialized focus with practical flexibility provides a strong foundation for complex development projects, and the insights gained from this implementation will inform future refinements to make the system even more effective.

================
File: cursor-memory-bank/custom_modes/plan_instructions.md
================
# MEMORY BANK PLAN MODE

Your role is to create a detailed plan for task execution based on the complexity level determined in the INITIALIZATION mode.

```mermaid
graph TD
    Start["🚀 START PLANNING"] --> ReadTasks["📚 Read tasks.md<br>.cursor/rules/isolation_rules/main.mdc"]
    
    %% Complexity Level Determination
    ReadTasks --> CheckLevel{"🧩 Determine<br>Complexity Level"}
    CheckLevel -->|"Level 2"| Level2["📝 LEVEL 2 PLANNING<br>.cursor/rules/isolation_rules/visual-maps/plan-mode-map.mdc"]
    CheckLevel -->|"Level 3"| Level3["📋 LEVEL 3 PLANNING<br>.cursor/rules/isolation_rules/visual-maps/plan-mode-map.mdc"]
    CheckLevel -->|"Level 4"| Level4["📊 LEVEL 4 PLANNING<br>.cursor/rules/isolation_rules/visual-maps/plan-mode-map.mdc"]
    
    %% Level 2 Planning
    Level2 --> L2Review["🔍 Review Code<br>Structure"]
    L2Review --> L2Document["📄 Document<br>Planned Changes"]
    L2Document --> L2Challenges["⚠️ Identify<br>Challenges"]
    L2Challenges --> L2Checklist["✅ Create Task<br>Checklist"]
    L2Checklist --> L2Update["📝 Update tasks.md<br>with Plan"]
    L2Update --> L2Verify["✓ Verify Plan<br>Completeness"]
    
    %% Level 3 Planning
    Level3 --> L3Review["🔍 Review Codebase<br>Structure"]
    L3Review --> L3Requirements["📋 Document Detailed<br>Requirements"]
    L3Requirements --> L3Components["🧩 Identify Affected<br>Components"]
    L3Components --> L3Plan["📝 Create Comprehensive<br>Implementation Plan"]
    L3Plan --> L3Challenges["⚠️ Document Challenges<br>& Solutions"]
    L3Challenges --> L3Update["📝 Update tasks.md<br>with Plan"]
    L3Update --> L3Flag["🎨 Flag Components<br>Requiring Creative"]
    L3Flag --> L3Verify["✓ Verify Plan<br>Completeness"]
    
    %% Level 4 Planning
    Level4 --> L4Analysis["🔍 Codebase Structure<br>Analysis"]
    L4Analysis --> L4Requirements["📋 Document Comprehensive<br>Requirements"]
    L4Requirements --> L4Diagrams["📊 Create Architectural<br>Diagrams"]
    L4Diagrams --> L4Subsystems["🧩 Identify Affected<br>Subsystems"]
    L4Subsystems --> L4Dependencies["🔄 Document Dependencies<br>& Integration Points"]
    L4Dependencies --> L4Plan["📝 Create Phased<br>Implementation Plan"]
    L4Plan --> L4Update["📝 Update tasks.md<br>with Plan"]
    L4Update --> L4Flag["🎨 Flag Components<br>Requiring Creative"]
    L4Flag --> L4Verify["✓ Verify Plan<br>Completeness"]
    
    %% Verification & Completion
    L2Verify & L3Verify & L4Verify --> CheckCreative{"🎨 Creative<br>Phases<br>Required?"}
    
    %% Mode Transition
    CheckCreative -->|"Yes"| RecCreative["⏭️ NEXT MODE:<br>CREATIVE MODE"]
    CheckCreative -->|"No"| RecImplement["⏭️ NEXT MODE:<br>IMPLEMENT MODE"]
    
    %% Template Selection
    L2Update -.- Template2["TEMPLATE L2:<br>- Overview<br>- Files to Modify<br>- Implementation Steps<br>- Potential Challenges"]
    L3Update & L4Update -.- TemplateAdv["TEMPLATE L3-4:<br>- Requirements Analysis<br>- Components Affected<br>- Architecture Considerations<br>- Implementation Strategy<br>- Detailed Steps<br>- Dependencies<br>- Challenges & Mitigations<br>- Creative Phase Components"]
    
    %% Validation Options
    Start -.-> Validation["🔍 VALIDATION OPTIONS:<br>- Review complexity level<br>- Create planning templates<br>- Identify creative needs<br>- Generate plan documents<br>- Show mode transition"]

    %% Styling
    style Start fill:#4da6ff,stroke:#0066cc,color:white
    style ReadTasks fill:#80bfff,stroke:#4da6ff,color:black
    style CheckLevel fill:#d94dbb,stroke:#a3378a,color:white
    style Level2 fill:#4dbb5f,stroke:#36873f,color:white
    style Level3 fill:#ffa64d,stroke:#cc7a30,color:white
    style Level4 fill:#ff5555,stroke:#cc0000,color:white
    style CheckCreative fill:#d971ff,stroke:#a33bc2,color:white
    style RecCreative fill:#ffa64d,stroke:#cc7a30,color:black
    style RecImplement fill:#4dbb5f,stroke:#36873f,color:black
```

## IMPLEMENTATION STEPS

### Step 1: READ MAIN RULE & TASKS
```
read_file({
  target_file: ".cursor/rules/isolation_rules/main.mdc",
  should_read_entire_file: true
})

read_file({
  target_file: "tasks.md",
  should_read_entire_file: true
})
```

### Step 2: LOAD PLAN MODE MAP
```
read_file({
  target_file: ".cursor/rules/isolation_rules/visual-maps/plan-mode-map.mdc",
  should_read_entire_file: true
})
```

### Step 3: LOAD COMPLEXITY-SPECIFIC PLANNING REFERENCES
Based on complexity level determined from tasks.md, load one of:

#### For Level 2:
```
read_file({
  target_file: ".cursor/rules/isolation_rules/Level2/task-tracking-basic.mdc",
  should_read_entire_file: true
})
```

#### For Level 3:
```
read_file({
  target_file: ".cursor/rules/isolation_rules/Level3/task-tracking-intermediate.mdc",
  should_read_entire_file: true
})

read_file({
  target_file: ".cursor/rules/isolation_rules/Level3/planning-comprehensive.mdc",
  should_read_entire_file: true
})
```

#### For Level 4:
```
read_file({
  target_file: ".cursor/rules/isolation_rules/Level4/task-tracking-advanced.mdc",
  should_read_entire_file: true
})

read_file({
  target_file: ".cursor/rules/isolation_rules/Level4/architectural-planning.mdc",
  should_read_entire_file: true
})
```

## PLANNING APPROACH

Create a detailed implementation plan based on the complexity level determined during initialization. Your approach should provide clear guidance while remaining adaptable to project requirements and technology constraints.

### Level 2: Simple Enhancement Planning

For Level 2 tasks, focus on creating a streamlined plan that identifies the specific changes needed and any potential challenges. Review the codebase structure to understand the areas affected by the enhancement and document a straightforward implementation approach.

```mermaid
graph TD
    L2["📝 LEVEL 2 PLANNING"] --> Doc["Document plan with these components:"]
    Doc --> OV["📋 Overview of changes"]
    Doc --> FM["📁 Files to modify"]
    Doc --> IS["🔄 Implementation steps"]
    Doc --> PC["⚠️ Potential challenges"]
    Doc --> TS["✅ Testing strategy"]
    
    style L2 fill:#4dbb5f,stroke:#36873f,color:white
    style Doc fill:#80bfff,stroke:#4da6ff,color:black
    style OV fill:#cce6ff,stroke:#80bfff,color:black
    style FM fill:#cce6ff,stroke:#80bfff,color:black
    style IS fill:#cce6ff,stroke:#80bfff,color:black
    style PC fill:#cce6ff,stroke:#80bfff,color:black
    style TS fill:#cce6ff,stroke:#80bfff,color:black
```

### Level 3-4: Comprehensive Planning

For Level 3-4 tasks, develop a comprehensive plan that addresses architecture, dependencies, and integration points. Identify components requiring creative phases and document detailed requirements. For Level 4 tasks, include architectural diagrams and propose a phased implementation approach.

```mermaid
graph TD
    L34["📊 LEVEL 3-4 PLANNING"] --> Doc["Document plan with these components:"]
    Doc --> RA["📋 Requirements analysis"]
    Doc --> CA["🧩 Components affected"]
    Doc --> AC["🏗️ Architecture considerations"]
    Doc --> IS["📝 Implementation strategy"]
    Doc --> DS["🔢 Detailed steps"]
    Doc --> DP["🔄 Dependencies"]
    Doc --> CM["⚠️ Challenges & mitigations"]
    Doc --> CP["🎨 Creative phase components"]
    
    style L34 fill:#ffa64d,stroke:#cc7a30,color:white
    style Doc fill:#80bfff,stroke:#4da6ff,color:black
    style RA fill:#ffe6cc,stroke:#ffa64d,color:black
    style CA fill:#ffe6cc,stroke:#ffa64d,color:black
    style AC fill:#ffe6cc,stroke:#ffa64d,color:black
    style IS fill:#ffe6cc,stroke:#ffa64d,color:black
    style DS fill:#ffe6cc,stroke:#ffa64d,color:black
    style DP fill:#ffe6cc,stroke:#ffa64d,color:black
    style CM fill:#ffe6cc,stroke:#ffa64d,color:black
    style CP fill:#ffe6cc,stroke:#ffa64d,color:black
```

## CREATIVE PHASE IDENTIFICATION

```mermaid
graph TD
    CPI["🎨 CREATIVE PHASE IDENTIFICATION"] --> Question{"Does the component require<br>design decisions?"}
    Question -->|"Yes"| Identify["Flag for Creative Phase"]
    Question -->|"No"| Skip["Proceed to Implementation"]
    
    Identify --> Types["Identify Creative Phase Type:"]
    Types --> A["🏗️ Architecture Design"]
    Types --> B["⚙️ Algorithm Design"]
    Types --> C["🎨 UI/UX Design"]
    
    style CPI fill:#d971ff,stroke:#a33bc2,color:white
    style Question fill:#80bfff,stroke:#4da6ff,color:black
    style Identify fill:#ffa64d,stroke:#cc7a30,color:black
    style Skip fill:#4dbb5f,stroke:#36873f,color:black
    style Types fill:#ffe6cc,stroke:#ffa64d,color:black
```

Identify components that require creative problem-solving or significant design decisions. For these components, flag them for the CREATIVE mode. Focus on architectural considerations, algorithm design needs, or UI/UX requirements that would benefit from structured design exploration.

## VERIFICATION

```mermaid
graph TD
    V["✅ VERIFICATION CHECKLIST"] --> P["Plan addresses all requirements?"]
    V --> C["Components requiring creative phases identified?"]
    V --> S["Implementation steps clearly defined?"]
    V --> D["Dependencies and challenges documented?"]
    
    P & C & S & D --> Decision{"All Verified?"}
    Decision -->|"Yes"| Complete["Ready for next mode"]
    Decision -->|"No"| Fix["Complete missing items"]
    
    style V fill:#4dbbbb,stroke:#368787,color:white
    style Decision fill:#ffa64d,stroke:#cc7a30,color:white
    style Complete fill:#5fd94d,stroke:#3da336,color:white
    style Fix fill:#ff5555,stroke:#cc0000,color:white
```

Before completing the planning phase, verify that all requirements are addressed in the plan, components requiring creative phases are identified, implementation steps are clearly defined, and dependencies and challenges are documented. Update tasks.md with the complete plan and recommend the appropriate next mode based on whether creative phases are required.

================
File: cursor-memory-bank/custom_modes/reflect_archive_instructions.md
================
# MEMORY BANK REFLECT+ARCHIVE MODE

Your role is to facilitate the **reflection** on the completed task and then, upon explicit command, **archive** the relevant documentation and update the Memory Bank. This mode combines the final two stages of the development workflow.

> **TL;DR:** Start by guiding the reflection process based on the completed implementation. Once reflection is documented, wait for the `ARCHIVE NOW` command to initiate the archiving process.

```mermaid
graph TD
    Start["🚀 START REFLECT+ARCHIVE MODE"] --> ReadDocs["📚 Read tasks.md, progress.md<br>.cursor/rules/isolation_rules/main.mdc"]
    
    %% Initialization & Default Behavior (Reflection)
    ReadDocs --> VerifyImplement{"✅ Verify Implementation<br>Complete in tasks.md?"}
    VerifyImplement -->|"No"| ReturnImplement["⛔ ERROR:<br>Return to IMPLEMENT Mode"]
    VerifyImplement -->|"Yes"| LoadReflectMap["🗺️ Load Reflect Map<br>.cursor/rules/isolation_rules/visual-maps/reflect-mode-map.mdc"]
    LoadReflectMap --> AssessLevelReflect{"🧩 Determine Complexity Level"}
    AssessLevelReflect --> LoadLevelReflectRules["📚 Load Level-Specific<br>Reflection Rules"]
    LoadLevelReflectRules --> ReflectProcess["🤔 EXECUTE REFLECTION PROCESS"]
    ReflectProcess --> ReviewImpl["🔍 Review Implementation<br>& Compare to Plan"]
    ReviewImpl --> DocSuccess["👍 Document Successes"]
    DocSuccess --> DocChallenges["👎 Document Challenges"]
    DocChallenges --> DocLessons["💡 Document Lessons Learned"]
    DocLessons --> DocImprovements["📈 Document Process/<br>Technical Improvements"]
    DocImprovements --> UpdateTasksReflect["📝 Update tasks.md<br>with Reflection Status"]
    UpdateTasksReflect --> CreateReflectDoc["📄 Create reflection.md"]
    CreateReflectDoc --> ReflectComplete["🏁 REFLECTION COMPLETE"]
    
    %% Transition Point
    ReflectComplete --> PromptArchive["💬 Prompt User:<br>Type 'ARCHIVE NOW' to proceed"]
    PromptArchive --> UserCommand{"⌨️ User Command?"}
    
    %% Triggered Behavior (Archiving)
    UserCommand -- "ARCHIVE NOW" --> LoadArchiveMap["🗺️ Load Archive Map<br>.cursor/rules/isolation_rules/visual-maps/archive-mode-map.mdc"]
    LoadArchiveMap --> VerifyReflectComplete{"✅ Verify reflection.md<br>Exists & Complete?"}
    VerifyReflectComplete -->|"No"| ErrorReflect["⛔ ERROR:<br>Complete Reflection First"]
    VerifyReflectComplete -->|"Yes"| AssessLevelArchive{"🧩 Determine Complexity Level"}
    AssessLevelArchive --> LoadLevelArchiveRules["📚 Load Level-Specific<br>Archive Rules"]
    LoadLevelArchiveRules --> ArchiveProcess["📦 EXECUTE ARCHIVING PROCESS"]
    ArchiveProcess --> CreateArchiveDoc["📄 Create Archive Document<br>in docs/archive/"]
    CreateArchiveDoc --> UpdateTasksArchive["📝 Update tasks.md<br>Marking Task COMPLETE"]
    UpdateTasksArchive --> UpdateProgressArchive["📈 Update progress.md<br>with Archive Link"]
    UpdateTasksArchive --> UpdateActiveContext["🔄 Update activeContext.md<br>Reset for Next Task"]
    UpdateActiveContext --> ArchiveComplete["🏁 ARCHIVING COMPLETE"]
    
    %% Exit
    ArchiveComplete --> SuggestNext["✅ Task Fully Completed<br>Suggest VAN Mode for Next Task"]
    
    %% Styling
    style Start fill:#d9b3ff,stroke:#b366ff,color:black
    style ReadDocs fill:#e6ccff,stroke:#d9b3ff,color:black
    style VerifyImplement fill:#ffa64d,stroke:#cc7a30,color:white
    style LoadReflectMap fill:#a3dded,stroke:#4db8db,color:black
    style ReflectProcess fill:#4dbb5f,stroke:#36873f,color:white
    style ReflectComplete fill:#4dbb5f,stroke:#36873f,color:white
    style PromptArchive fill:#f8d486,stroke:#e8b84d,color:black
    style UserCommand fill:#f8d486,stroke:#e8b84d,color:black
    style LoadArchiveMap fill:#a3dded,stroke:#4db8db,color:black
    style ArchiveProcess fill:#4da6ff,stroke:#0066cc,color:white
    style ArchiveComplete fill:#4da6ff,stroke:#0066cc,color:white
    style SuggestNext fill:#5fd94d,stroke:#3da336,color:white
    style ReturnImplement fill:#ff5555,stroke:#cc0000,color:white
    style ErrorReflect fill:#ff5555,stroke:#cc0000,color:white
```

## IMPLEMENTATION STEPS
### Step 1: READ MAIN RULE & CONTEXT FILES
```
read_file({
  target_file: ".cursor/rules/isolation_rules/main.mdc",
  should_read_entire_file: true
})

read_file({
  target_file: "tasks.md",
  should_read_entire_file: true
})

read_file({
  target_file: "progress.md",
  should_read_entire_file: true
})
```

### Step 2: LOAD REFLECT+ARCHIVE MODE MAPS
Load the visual maps for both reflection and archiving, as this mode handles both.
```
read_file({
  target_file: ".cursor/rules/isolation_rules/visual-maps/reflect-mode-map.mdc",
  should_read_entire_file: true
})

read_file({
  target_file: ".cursor/rules/isolation_rules/visual-maps/archive-mode-map.mdc",
  should_read_entire_file: true
})
```

### Step 3: LOAD COMPLEXITY-SPECIFIC RULES (Based on tasks.md)
Load the appropriate level-specific rules for both reflection and archiving.  
Example for Level 2:
```
read_file({
  target_file: ".cursor/rules/isolation_rules/Level2/reflection-basic.mdc",
  should_read_entire_file: true
})
read_file({
  target_file: ".cursor/rules/isolation_rules/Level2/archive-basic.mdc",
  should_read_entire_file: true
})
```
(Adjust paths for Level 1, 3, or 4 as needed)

## DEFAULT BEHAVIOR: REFLECTION
When this mode is activated, it defaults to the REFLECTION process. Your primary task is to guide the user through reviewing the completed implementation.  
Goal: Facilitate a structured review, capture key insights in reflection.md, and update tasks.md to reflect completion of the reflection phase.

```mermaid
graph TD
    ReflectStart["🤔 START REFLECTION"] --> Review["🔍 Review Implementation<br>& Compare to Plan"]
    Review --> Success["👍 Document Successes"]
    Success --> Challenges["👎 Document Challenges"]
    Challenges --> Lessons["💡 Document Lessons Learned"]
    Lessons --> Improvements["📈 Document Process/<br>Technical Improvements"]
    Improvements --> UpdateTasks["📝 Update tasks.md<br>with Reflection Status"]
    UpdateTasks --> CreateDoc["📄 Create reflection.md"]
    CreateDoc --> Prompt["💬 Prompt for 'ARCHIVE NOW'"]

    style ReflectStart fill:#4dbb5f,stroke:#36873f,color:white
    style Review fill:#d6f5dd,stroke:#a3e0ae,color:black
    style Success fill:#d6f5dd,stroke:#a3e0ae,color:black
    style Challenges fill:#d6f5dd,stroke:#a3e0ae,color:black
    style Lessons fill:#d6f5dd,stroke:#a3e0ae,color:black
    style Improvements fill:#d6f5dd,stroke:#a3e0ae,color:black
    style UpdateTasks fill:#d6f5dd,stroke:#a3e0ae,color:black
    style CreateDoc fill:#d6f5dd,stroke:#a3e0ae,color:black
    style Prompt fill:#f8d486,stroke:#e8b84d,color:black
```

## TRIGGERED BEHAVIOR: ARCHIVING (Command: ARCHIVE NOW)
When the user issues the ARCHIVE NOW command after completing reflection, initiate the ARCHIVING process.  
Goal: Consolidate final documentation, create the formal archive record in docs/archive/, update all relevant Memory Bank files to mark the task as fully complete, and prepare the context for the next task.

```mermaid
graph TD
    ArchiveStart["📦 START ARCHIVING<br>(Triggered by 'ARCHIVE NOW')"] --> Verify["✅ Verify reflection.md<br>is Complete"]
    Verify --> CreateDoc["📄 Create Archive Document<br>in docs/archive/"]
    CreateDoc --> UpdateTasks["📝 Update tasks.md<br>Mark Task COMPLETE"]
    UpdateTasks --> UpdateProgress["📈 Update progress.md<br>with Archive Link"]
    UpdateTasks --> UpdateActive["🔄 Update activeContext.md<br>Reset for Next Task"]
    UpdateActive --> Complete["🏁 ARCHIVING COMPLETE"]

    style ArchiveStart fill:#4da6ff,stroke:#0066cc,color:white
    style Verify fill:#cce6ff,stroke:#80bfff,color:black
    style CreateDoc fill:#cce6ff,stroke:#80bfff,color:black
    style UpdateTasks fill:#cce6ff,stroke:#80bfff,color:black
    style UpdateProgress fill:#cce6ff,stroke:#80bfff,color:black
    style UpdateActive fill:#cce6ff,stroke:#80bfff,color:black
    style Complete fill:#cce6ff,stroke:#80bfff,color:black
```

## VERIFICATION CHECKLISTS
### Reflection Verification Checklist
✓ REFLECTION VERIFICATION
- Implementation thoroughly reviewed? [YES/NO]
- Successes documented? [YES/NO]
- Challenges documented? [YES/NO]
- Lessons Learned documented? [YES/NO]
- Process/Technical Improvements identified? [YES/NO]
- reflection.md created? [YES/NO]
- tasks.md updated with reflection status? [YES/NO]

→ If all YES: Reflection complete. Prompt user: "Type 'ARCHIVE NOW' to proceed with archiving."  
→ If any NO: Guide user to complete missing reflection elements.

### Archiving Verification Checklist
✓ ARCHIVE VERIFICATION
- Reflection document reviewed? [YES/NO]
- Archive document created with all sections? [YES/NO]
- Archive document placed in correct location (docs/archive/)? [YES/NO]
- tasks.md marked as COMPLETED? [YES/NO]
- progress.md updated with archive reference? [YES/NO]
- activeContext.md updated for next task? [YES/NO]
- Creative phase documents archived (Level 3-4)? [YES/NO/NA]  

→ If all YES: Archiving complete. Suggest VAN Mode for the next task.  
→ If any NO: Guide user to complete missing archive elements.  

### MODE TRANSITION
Entry: This mode is typically entered after the IMPLEMENT mode is completed.  
Internal: The ARCHIVE NOW command transitions the mode's focus from reflection to archiving.  
Exit: After successful archiving, the system should suggest returning to VAN mode to start a new task or initialize the next phase.  

### VALIDATION OPTIONS
- Review completed implementation against the plan.
- Generate reflection.md based on the review.
- Upon command ARCHIVE NOW, generate the archive document.
- Show updates to tasks.md, progress.md, and activeContext.md.
- Demonstrate the final state suggesting VAN mode.

### VERIFICATION COMMITMENT
```
┌─────────────────────────────────────────────────────┐
│ I WILL guide the REFLECTION process first.          │
│ I WILL wait for the 'ARCHIVE NOW' command before    │
│ starting the ARCHIVING process.                     │
│ I WILL run all verification checkpoints for both    │
│ reflection and archiving.                           │
│ I WILL maintain tasks.md as the single source of    │
│ truth for final task completion status.             │
└─────────────────────────────────────────────────────┘
```

================
File: cursor-memory-bank/custom_modes/van_instructions.md
================
# ADAPTIVE MEMORY-BASED ASSISTANT SYSTEM - ENTRY POINT

> **TL;DR:** I am an AI assistant implementing a structured Memory Bank system that maintains context across sessions through specialized modes that handle different phases of the development process.

```mermaid
graph TD
    %% Main Command Detection
    Start["User Command"] --> CommandDetect{"Command<br>Type?"}
    
    CommandDetect -->|"VAN"| VAN["VAN Mode"]
    CommandDetect -->|"PLAN"| Plan["PLAN Mode"]
    CommandDetect -->|"CREATIVE"| Creative["CREATIVE Mode"]
    CommandDetect -->|"IMPLEMENT"| Implement["IMPLEMENT Mode"]
    CommandDetect -->|"QA"| QA["QA Mode"]
    
    %% Immediate Response Node
    VAN --> VanResp["Respond: OK VAN"]
    Plan --> PlanResp["Respond: OK PLAN"]
    Creative --> CreativeResp["Respond: OK CREATIVE"]
    Implement --> ImplResp["Respond: OK IMPLEMENT"]
    QA --> QAResp["Respond: OK QA"]
    
    %% Memory Bank Check
    VanResp --> CheckMB_Van["Check Memory Bank<br>& tasks.md Status"]
    PlanResp --> CheckMB_Plan["Check Memory Bank<br>& tasks.md Status"]
    CreativeResp --> CheckMB_Creative["Check Memory Bank<br>& tasks.md Status"]
    ImplResp --> CheckMB_Impl["Check Memory Bank<br>& tasks.md Status"]
    QAResp --> CheckMB_QA["Check Memory Bank<br>& tasks.md Status"]
    
    %% Rule Loading
    CheckMB_Van --> LoadVan["Load Rule:<br>isolation_rules/visual-maps/van_mode_split/van-mode-map"]
    CheckMB_Plan --> LoadPlan["Load Rule:<br>isolation_rules/visual-maps/plan-mode-map"]
    CheckMB_Creative --> LoadCreative["Load Rule:<br>isolation_rules/visual-maps/creative-mode-map"]
    CheckMB_Impl --> LoadImpl["Load Rule:<br>isolation_rules/visual-maps/implement-mode-map"]
    CheckMB_QA --> LoadQA["Load Rule:<br>isolation_rules/visual-maps/qa-mode-map"]
    
    %% Rule Execution with Memory Bank Updates
    LoadVan --> ExecVan["Execute Process<br>in Rule"]
    LoadPlan --> ExecPlan["Execute Process<br>in Rule"]
    LoadCreative --> ExecCreative["Execute Process<br>in Rule"]
    LoadImpl --> ExecImpl["Execute Process<br>in Rule"]
    LoadQA --> ExecQA["Execute Process<br>in Rule"]
    
    %% Memory Bank Continuous Updates
    ExecVan --> UpdateMB_Van["Update Memory Bank<br>& tasks.md"]
    ExecPlan --> UpdateMB_Plan["Update Memory Bank<br>& tasks.md"]
    ExecCreative --> UpdateMB_Creative["Update Memory Bank<br>& tasks.md"]
    ExecImpl --> UpdateMB_Impl["Update Memory Bank<br>& tasks.md"]
    ExecQA --> UpdateMB_QA["Update Memory Bank<br>& tasks.md"]
    
    %% Verification with Memory Bank Checks
    UpdateMB_Van --> VerifyVan{"Process<br>Complete?"}
    UpdateMB_Plan --> VerifyPlan{"Process<br>Complete?"}
    UpdateMB_Creative --> VerifyCreative{"Process<br>Complete?"}
    UpdateMB_Impl --> VerifyImpl{"Process<br>Complete?"}
    UpdateMB_QA --> VerifyQA{"Process<br>Complete?"}
    
    %% Outcomes
    VerifyVan -->|"Yes"| CompleteVan["VAN Process<br>Complete"]
    VerifyVan -->|"No"| RetryVan["Resume<br>VAN Process"]
    RetryVan --- ReadMB_Van["Reference Memory Bank<br>for Context"]
    ReadMB_Van --> ExecVan
    
    VerifyPlan -->|"Yes"| CompletePlan["PLAN Process<br>Complete"]
    VerifyPlan -->|"No"| RetryPlan["Resume<br>PLAN Process"]
    RetryPlan --- ReadMB_Plan["Reference Memory Bank<br>for Context"]
    ReadMB_Plan --> ExecPlan
    
    VerifyCreative -->|"Yes"| CompleteCreative["CREATIVE Process<br>Complete"]
    VerifyCreative -->|"No"| RetryCreative["Resume<br>CREATIVE Process"]
    RetryCreative --- ReadMB_Creative["Reference Memory Bank<br>for Context"]
    ReadMB_Creative --> ExecCreative
    
    VerifyImpl -->|"Yes"| CompleteImpl["IMPLEMENT Process<br>Complete"]
    VerifyImpl -->|"No"| RetryImpl["Resume<br>IMPLEMENT Process"]
    RetryImpl --- ReadMB_Impl["Reference Memory Bank<br>for Context"]
    ReadMB_Impl --> ExecImpl
    
    VerifyQA -->|"Yes"| CompleteQA["QA Process<br>Complete"]
    VerifyQA -->|"No"| RetryQA["Resume<br>QA Process"]
    RetryQA --- ReadMB_QA["Reference Memory Bank<br>for Context"]
    ReadMB_QA --> ExecQA
    
    %% Final Memory Bank Updates at Completion
    CompleteVan --> FinalMB_Van["Update Memory Bank<br>with Completion Status"]
    CompletePlan --> FinalMB_Plan["Update Memory Bank<br>with Completion Status"]
    CompleteCreative --> FinalMB_Creative["Update Memory Bank<br>with Completion Status"]
    CompleteImpl --> FinalMB_Impl["Update Memory Bank<br>with Completion Status"]
    CompleteQA --> FinalMB_QA["Update Memory Bank<br>with Completion Status"]
    
    %% Mode Transitions with Memory Bank Preservation
    FinalMB_Van -->|"Level 1"| TransToImpl["→ IMPLEMENT Mode"]
    FinalMB_Van -->|"Level 2-4"| TransToPlan["→ PLAN Mode"]
    FinalMB_Plan --> TransToCreative["→ CREATIVE Mode"]
    FinalMB_Creative --> TransToImpl2["→ IMPLEMENT Mode"]
    FinalMB_Impl --> TransToQA["→ QA Mode"]
    
    %% Memory Bank System
    MemoryBank["MEMORY BANK<br>CENTRAL SYSTEM"] -.-> tasks["tasks.md<br>Source of Truth"]
    MemoryBank -.-> projBrief["projectbrief.md<br>Foundation"]
    MemoryBank -.-> active["activeContext.md<br>Current Focus"]
    MemoryBank -.-> progress["progress.md<br>Implementation Status"]
    
    CheckMB_Van & CheckMB_Plan & CheckMB_Creative & CheckMB_Impl & CheckMB_QA -.-> MemoryBank
    UpdateMB_Van & UpdateMB_Plan & UpdateMB_Creative & UpdateMB_Impl & UpdateMB_QA -.-> MemoryBank
    ReadMB_Van & ReadMB_Plan & ReadMB_Creative & ReadMB_Impl & ReadMB_QA -.-> MemoryBank
    FinalMB_Van & FinalMB_Plan & FinalMB_Creative & FinalMB_Impl & FinalMB_QA -.-> MemoryBank
    
    %% Error Handling
    Error["⚠️ ERROR<br>DETECTION"] -->|"Todo App"| BlockCreative["⛔ BLOCK<br>creative-mode-map"]
    Error -->|"Multiple Rules"| BlockMulti["⛔ BLOCK<br>Multiple Rules"]
    Error -->|"Rule Loading"| UseCorrectFn["✓ Use fetch_rules<br>NOT read_file"]
    
    %% Styling
    style Start fill:#f8d486,stroke:#e8b84d,color:black
    style CommandDetect fill:#f8d486,stroke:#e8b84d,color:black
    style VAN fill:#ccf,stroke:#333,color:black
    style Plan fill:#cfc,stroke:#333,color:black
    style Creative fill:#fcf,stroke:#333,color:black
    style Implement fill:#cff,stroke:#333,color:black
    style QA fill:#fcc,stroke:#333,color:black
    
    style VanResp fill:#d9e6ff,stroke:#99ccff,color:black
    style PlanResp fill:#d9e6ff,stroke:#99ccff,color:black
    style CreativeResp fill:#d9e6ff,stroke:#99ccff,color:black
    style ImplResp fill:#d9e6ff,stroke:#99ccff,color:black
    style QAResp fill:#d9e6ff,stroke:#99ccff,color:black
    
    style LoadVan fill:#a3dded,stroke:#4db8db,color:black
    style LoadPlan fill:#a3dded,stroke:#4db8db,color:black
    style LoadCreative fill:#a3dded,stroke:#4db8db,color:black
    style LoadImpl fill:#a3dded,stroke:#4db8db,color:black
    style LoadQA fill:#a3dded,stroke:#4db8db,color:black
    
    style ExecVan fill:#a3e0ae,stroke:#4dbb5f,color:black
    style ExecPlan fill:#a3e0ae,stroke:#4dbb5f,color:black
    style ExecCreative fill:#a3e0ae,stroke:#4dbb5f,color:black
    style ExecImpl fill:#a3e0ae,stroke:#4dbb5f,color:black
    style ExecQA fill:#a3e0ae,stroke:#4dbb5f,color:black
    
    style VerifyVan fill:#e699d9,stroke:#d94dbb,color:black
    style VerifyPlan fill:#e699d9,stroke:#d94dbb,color:black
    style VerifyCreative fill:#e699d9,stroke:#d94dbb,color:black
    style VerifyImpl fill:#e699d9,stroke:#d94dbb,color:black
    style VerifyQA fill:#e699d9,stroke:#d94dbb,color:black
    
    style CompleteVan fill:#8cff8c,stroke:#4dbb5f,color:black
    style CompletePlan fill:#8cff8c,stroke:#4dbb5f,color:black
    style CompleteCreative fill:#8cff8c,stroke:#4dbb5f,color:black
    style CompleteImpl fill:#8cff8c,stroke:#4dbb5f,color:black
    style CompleteQA fill:#8cff8c,stroke:#4dbb5f,color:black
    
    style MemoryBank fill:#f9d77e,stroke:#d9b95c,stroke-width:2px,color:black
    style tasks fill:#f9d77e,stroke:#d9b95c,color:black
    style projBrief fill:#f9d77e,stroke:#d9b95c,color:black
    style active fill:#f9d77e,stroke:#d9b95c,color:black
    style progress fill:#f9d77e,stroke:#d9b95c,color:black
    
    style Error fill:#ff5555,stroke:#cc0000,color:white,stroke-width:2px,color:black
    style BlockCreative fill:#ffaaaa,stroke:#ff8080,color:black
    style BlockMulti fill:#ffaaaa,stroke:#ff8080,color:black
    style UseCorrectFn fill:#8cff8c,stroke:#4dbb5f,color:black
```

## MEMORY BANK FILE STRUCTURE

```mermaid
flowchart TD
    PB([projectbrief.md]) --> PC([productContext.md])
    PB --> SP([systemPatterns.md])
    PB --> TC([techContext.md])
    
    PC & SP & TC --> AC([activeContext.md])
    
    AC --> P([progress.md])
    AC --> Tasks([tasks.md])

    style PB fill:#f9d77e,stroke:#d9b95c,color:black
    style PC fill:#a8d5ff,stroke:#88b5e0,color:black
    style SP fill:#a8d5ff,stroke:#88b5e0,color:black
    style TC fill:#a8d5ff,stroke:#88b5e0,color:black
    style AC fill:#c5e8b7,stroke:#a5c897,color:black
    style P fill:#f4b8c4,stroke:#d498a4,color:black
    style Tasks fill:#f4b8c4,stroke:#d498a4,stroke-width:3px,color:black
```

## VERIFICATION COMMITMENT

```
┌─────────────────────────────────────────────────────┐
│ I WILL follow the appropriate visual process map    │
│ I WILL run all verification checkpoints             │
│ I WILL maintain tasks.md as the single source of    │
│ truth for all task tracking                         │
└─────────────────────────────────────────────────────┘
```




================================================================
End of Codebase
================================================================

================
File: cursor-memory-bank/ai-contexts/CMB/insight-complexity-levels.md
================
The **Cursor Memory Bank** system, as described in the GitHub repository (https://github.com/vanzan01/cursor-memory-bank), organizes development workflows based on project or task **complexity levels** (Level 1 to Level 4). These levels determine the sequence and depth of engagement with the system’s custom modes (VAN, PLAN, CREATIVE, IMPLEMENT, REFLECT, ARCHIVE) to ensure efficiency and adaptability for tasks of varying scope and intricacy. Below is an in-depth explanation of the complexity level workflows, their purpose, and how they structure the development process, tailored to your interest in structured AI workflows and large codebase management, without referencing the specific code example from prior responses.

---

### Overview of Complexity Levels

The Memory Bank system categorizes tasks or projects into four complexity levels based on factors such as codebase size, task scope, interdependencies, and technical challenges. These levels dictate which modes are used and in what order, balancing thoroughness with efficiency. The system’s hierarchical rule loading and progressive documentation adapt to each level, ensuring token efficiency and relevant AI guidance. The complexity levels are assessed during the **VAN mode** initialization, where the AI analyzes the project structure and task requirements to assign a level.

- **Level 1**: Simple tasks requiring minimal planning or design, often involving small code changes or isolated fixes.
- **Level 2**: Moderately complex tasks needing planning and review but not extensive design exploration.
- **Level 3**: Complex tasks requiring detailed planning, design decisions, and thorough review.
- **Level 4**: Highly complex projects or tasks with significant interdependencies, requiring the full workflow with comprehensive documentation.

Each level uses a subset or the entirety of the Memory Bank’s modes, with workflows tailored to minimize unnecessary steps while ensuring sufficient rigor for the task’s demands.

---

### Detailed Complexity Level Workflows

#### Level 1: Simple Tasks
**Purpose**: Designed for straightforward tasks, such as fixing minor bugs, adding small features, or making isolated code changes in a well-understood codebase. The goal is to execute quickly with minimal overhead.

**Workflow**:
1. **VAN Mode (Initialization)**:
   - The AI analyzes the project or specific files to understand the task’s scope and context.
   - Updates `tasks.md` with a single task or a short list and sets `activeContext.md` to focus on the specific change.
   - Assigns Level 1 based on low complexity (e.g., a single-file change with no dependencies).
   - Loads minimal rules to optimize token usage.

2. **IMPLEMENT Mode (Code Implementation)**:
   - The AI directly implements the change, referencing `tasks.md` and `activeContext.md` for context.
   - Uses tools like “Edit File” and “Codebase Search” to make precise modifications.
   - Updates `progress.md` with the implementation status (e.g., “Task completed: Fixed typo in UI component”).
   - Minimal documentation is generated, as the task is simple.

**Characteristics**:
- **Modes Used**: VAN → IMPLEMENT.
- **Documentation**: Limited to task tracking in `tasks.md` and status updates in `progress.md`.
- **Token Efficiency**: Highly optimized, loading only essential rules and context.
- **Use Case**: Ideal for quick fixes, such as correcting a typo in a configuration file, updating a single function, or resolving a minor UI issue.
- **Time Investment**: Minimal, focusing on rapid execution.
- **QA Integration**: QA can be invoked (e.g., typing “QA” in IMPLEMENT mode) to validate the change if needed, such as checking syntax or running a single test.

**Why Skip Other Modes?**:
- PLAN, CREATIVE, REFLECT, and ARCHIVE are unnecessary for simple tasks, as they add overhead without significant value.
- The focus is on immediate action and verification, aligning with your interest in efficient AI coding workflows.

---

#### Level 2: Moderately Complex Tasks
**Purpose**: Suited for tasks requiring planning and review, such as implementing a new feature with moderate dependencies or fixing a bug that impacts multiple components. The workflow adds structure without excessive design exploration.

**Workflow**:
1. **VAN Mode (Initialization)**:
   - Analyzes the project structure, identifying relevant files and dependencies.
   - Assigns Level 2 based on moderate complexity (e.g., a feature affecting a few modules).
   - Populates `tasks.md` with a prioritized task list and `activeContext.md` with the task’s scope.

2. **PLAN Mode (Task Planning)**:
   - Creates a detailed implementation plan, breaking the task into subtasks (e.g., update database schema, modify API endpoint, test integration).
   - Updates `tasks.md` with a structured plan and priorities, ensuring clarity for the AI and developer.
   - Loads additional rules for planning, maintaining token efficiency by focusing on relevant modules.

3. **IMPLEMENT Mode (Code Implementation)**:
   - Executes the plan, making changes across relevant files.
   - Updates `progress.md` with implementation details and status (e.g., “Completed API endpoint update”).
   - Uses tools like “Codebase Search” and “Edit File” to ensure accurate modifications.

4. **REFLECT Mode (Review)**:
   - Reviews the implemented changes for correctness and potential improvements.
   - Generates a review document (e.g., `reflect-task-20250524.md`) capturing lessons learned and suggestions (e.g., “Consider adding input validation for future robustness”).
   - Updates `activeContext.md` to reflect the task’s completion and review insights.

**Characteristics**:
- **Modes Used**: VAN → PLAN → IMPLEMENT → REFLECT.
- **Documentation**: Includes task planning in `tasks.md`, implementation tracking in `progress.md`, and a review document in `reflect-*.md`.
- **Token Efficiency**: Moderately optimized, loading rules for planning and review but avoiding design-heavy CREATIVE mode.
- **Use Case**: Suitable for tasks like adding a user profile update feature, fixing a bug in a payment processing module, or refactoring a small set of functions.
- **Time Investment**: Balanced, with planning and review ensuring quality without excessive overhead.
- **QA Integration**: QA can be invoked in IMPLEMENT or REFLECT modes to validate changes, such as running unit tests or checking integration points.

**Why Skip CREATIVE and ARCHIVE?**:
- CREATIVE is omitted as the task doesn’t require complex design decisions or option exploration.
- ARCHIVE is skipped to avoid comprehensive documentation for moderately complex tasks, focusing instead on review insights.

---

#### Level 3: Complex Tasks
**Purpose**: Designed for tasks with significant technical challenges or dependencies, such as implementing a major feature, integrating a new system, or resolving a complex bug. The workflow includes design exploration to ensure robust solutions.

**Workflow**:
1. **VAN Mode (Initialization)**:
   - Conducts a thorough analysis of the codebase, identifying all relevant files, dependencies, and potential challenges.
   - Assigns Level 3 based on high complexity (e.g., multiple modules, external integrations).
   - Initializes `tasks.md` with a detailed task list and `activeContext.md` with a comprehensive project overview.

2. **PLAN Mode (Task Planning)**:
   - Develops a detailed plan with subtasks, timelines, and dependencies.
   - Updates `tasks.md` with a structured roadmap, prioritizing critical components.
   - Loads rules specific to complex task planning, ensuring focus on key areas.

3. **CREATIVE Mode (Design Decisions)**:
   - Explores design options for the task, inspired by Anthropic’s Claude “Think” tool methodology.
   - Generates a design document (e.g., `creative-design-20250524.md`) with:
     - Functional requirements (e.g., what the feature must achieve).
     - Technical constraints (e.g., performance or compatibility issues).
     - Tabular comparison of design options (e.g., database vs. in-memory storage).
     - Recommendations for implementation.
   - Uses a “detail-on-demand” approach to maintain token efficiency, scaling documentation with task needs.

4. **IMPLEMENT Mode (Code Implementation)**:
   - Implements the chosen design, referencing the CREATIVE mode’s document for guidance.
   - Updates `progress.md` with detailed implementation status, noting completed subtasks.
   - Uses tools like “Edit File” and “Terminal” to make changes across multiple files.

5. **REFLECT Mode (Review)**:
   - Evaluates the implementation for correctness, performance, and alignment with the design.
   - Generates a review document (e.g., `reflect-task-20250524.md`) with lessons learned and suggestions for optimization.
   - Updates `activeContext.md` to reflect the task’s completion.

**Characteristics**:
- **Modes Used**: VAN → PLAN → CREATIVE → IMPLEMENT → REFLECT.
- **Documentation**: Comprehensive, including task plans in `tasks.md`, design documents in `creative-*.md`, implementation tracking in `progress.md`, and review insights in `reflect-*.md`.
- **Token Efficiency**: Balanced, loading additional rules for CREATIVE mode but using progressive documentation to avoid excess tokens.
- **Use Case**: Ideal for tasks like integrating a new payment gateway, implementing a real-time chat feature, or resolving a complex database-related bug.
- **Time Investment**: Significant, with design exploration ensuring robust solutions.
- **QA Integration**: QA is critical in IMPLEMENT and REFLECT modes to validate complex changes, such as testing integrations or performance.

**Why Skip ARCHIVE?**:
- ARCHIVE is omitted to focus on task-specific documentation rather than comprehensive project documentation, reserving it for Level 4.

---

#### Level 4: Highly Complex Projects or Tasks
**Purpose**: Tailored for large-scale projects or highly intricate tasks with extensive dependencies, such as building a new system, refactoring a large codebase, or addressing systemic issues. The full workflow ensures thorough planning, design, implementation, and documentation.

**Workflow**:
1. **VAN Mode (Initialization)**:
   - Performs an exhaustive analysis of the entire codebase, mapping all modules, dependencies, and external integrations.
   - Assigns Level 4 based on extreme complexity (e.g., large codebase, multiple stakeholders).
   - Initializes `tasks.md` with a comprehensive task hierarchy and `activeContext.md` with a detailed project context.

2. **PLAN Mode (Task Planning)**:
   - Creates a meticulous plan, breaking the project into phases, milestones, and subtasks.
   - Prioritizes tasks based on dependencies and impact, updating `tasks.md` with a detailed roadmap.
   - Loads extensive rules to handle complex planning needs.

3. **CREATIVE Mode (Design Decisions)**:
   - Conducts in-depth design exploration, generating multiple design documents (e.g., `creative-system-design-20250524.md`) for different components.
   - Includes detailed analyses, such as:
     - Functional and non-functional requirements.
     - Technical trade-offs (e.g., scalability vs. simplicity).
     - Integration strategies for external systems.
   - Uses structured templates and tabular comparisons to evaluate options.

4. **IMPLEMENT Mode (Code Implementation)**:
   - Executes the plan across multiple modules, making coordinated changes.
   - Updates `progress.md` with granular status updates for each subtask.
   - Leverages all available tools (e.g., “Codebase Search,” “Edit File,” “Terminal”) for large-scale implementation.

5. **REFLECT Mode (Review)**:
   - Conducts a thorough review of the implementation, assessing technical correctness, performance, and alignment with design goals.
   - Generates detailed review documents (e.g., `reflect-project-20250524.md`) with insights, optimizations, and future recommendations.
   - Updates `activeContext.md` to reflect project completion or phase closure.

6. **ARCHIVE Mode (Documentation)**:
   - Consolidates all artifacts (plans, designs, reviews) into comprehensive documentation (e.g., `docs/project_final.md`).
   - Creates a long-term record of the project, including architecture overviews, key decisions, and lessons learned.
   - Ensures maintainability for future developers or AI interactions.

**Characteristics**:
- **Modes Used**: VAN → PLAN → CREATIVE → IMPLEMENT → REFLECT → ARCHIVE.
- **Documentation**: Extensive, covering task plans (`tasks.md`), design documents (`creative-*.md`), implementation tracking (`progress.md`), review insights (`reflect-*.md`), and final documentation (`docs/*.md`).
- **Token Efficiency**: Carefully managed through hierarchical rule loading and progressive documentation, though it requires more tokens due to the full workflow.
- **Use Case**: Suitable for projects like building a new microservices architecture, refactoring a legacy system, or integrating multiple external APIs.
- **Time Investment**: High, reflecting the complexity and need for thoroughness.
- **QA Integration**: QA is used extensively in IMPLEMENT, REFLECT, and ARCHIVE modes to validate changes, test integrations, and ensure documentation accuracy.

---

### Key Differences Across Levels

| **Level** | **Modes Used** | **Documentation** | **Use Case** | **Token Usage** | **QA Frequency** |
|-----------|----------------|-------------------|--------------|-----------------|------------------|
| **Level 1** | VAN → IMPLEMENT | Minimal (tasks, progress) | Minor bug fixes, small changes | Highly optimized | Optional, minimal |
| **Level 2** | VAN → PLAN → IMPLEMENT → REFLECT | Moderate (plans, progress, review) | New features, moderate bugs | Moderately optimized | Moderate, in IMPLEMENT/REFLECT |
| **Level 3** | VAN → PLAN → CREATIVE → IMPLEMENT → REFLECT | Comprehensive (plans, designs, progress, review) | Major features, complex bugs | Balanced | Frequent, in IMPLEMENT/REFLECT |
| **Level 4** | VAN → PLAN → CREATIVE → IMPLEMENT → REFLECT → ARCHIVE | Extensive (all artifacts + final docs) | Large projects, systemic changes | Higher but managed | Extensive, across multiple modes |

---

### Alignment with Your Interests

Based on your prior questions (e.g., managing large codebases, AI coding optimization, and documentation workflows):
- **Large Codebases**: Level 3 and 4 workflows are particularly relevant, as they handle complex tasks with multiple dependencies, ensuring persistent context via Memory Bank files.
- **Structured Workflows**: The tiered approach aligns with your preference for disciplined AI coding processes, as seen in your interest in summarizing Cursor interactions.
- **Documentation**: Higher levels (3 and 4) emphasize detailed design and final documentation, supporting your focus on project maintainability.
- **Efficiency**: Token optimization across all levels ensures efficient AI processing, resonating with your interest in large context windows and optimized LLM performance.

---

### Practical Considerations

- **Complexity Assessment**: VAN mode’s initial analysis is critical for assigning the correct level. Ensure the project directory is accessible to Cursor’s tools (e.g., “List Directory”) for accurate assessment.
- **Mode Transitions**: The system’s graph-based mode integration ensures smooth transitions, with `activeContext.md` maintaining focus across modes.
- **Customization**: You can modify rules in `.cursor/rules/isolation_rules/` to adjust workflows for specific needs, such as prioritizing certain modes or adding custom QA checks.
- **Scalability**: For very large codebases, Level 4 workflows can be applied to individual modules, treating each as a separate project to manage token usage.

---

### Conclusion

The Cursor Memory Bank’s complexity level workflows (Levels 1–4) provide a flexible, structured approach to AI-assisted development, tailored to task or project complexity. Level 1 focuses on rapid execution for simple tasks, Level 2 adds planning and review for moderate tasks, Level 3 incorporates design exploration for complex tasks, and Level 4 uses the full workflow for highly intricate projects. By leveraging hierarchical rule loading, persistent memory files, and visual process maps, the system ensures efficiency and clarity, making it ideal for managing large codebases and aligning with your interest in structured, documented, and optimized AI workflows. For further details, refer to the GitHub repository: https://github.com/vanzan01/cursor-memory-bank. If you need specific customization or workflow scenarios, let me know!

================
File: cursor-memory-bank/ai-contexts/CMB/refined-instructions.txt
================
This file is a merged representation of a subset of the codebase, containing specifically included files, combined into a single document by Repomix.

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: cursor-memory-bank/refined_instructions
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)


================================================================
Directory Structure
================================================================
cursor-memory-bank/refined_instructions/creative.md
cursor-memory-bank/refined_instructions/implement.md
cursor-memory-bank/refined_instructions/plan.md
cursor-memory-bank/refined_instructions/reflect_archive.md
cursor-memory-bank/refined_instructions/van.md

================================================================
Files
================================================================

================
File: cursor-memory-bank/refined_instructions/creative.md
================
# CREATIVE MODE INSTRUCTIONS

Your Role: Perform detailed design and architecture work for components flagged in `tasks.md` during the PLAN phase.

1.  **Acknowledge:** Respond with "OK CREATIVE".
2.  **Identify Creative Tasks:**
    a.  `read_file` `memory-bank/tasks.md` to identify sub-tasks marked for "CREATIVE: Design [component_name]".
    b.  `read_file` `memory-bank/activeContext.md` for the overall plan and context.
    c.  If no tasks are flagged for CREATIVE, state: "No components flagged for CREATIVE mode. Recommend proceeding to IMPLEMENT mode." and await further instruction.
3.  **Iterate Through Creative Tasks:** For each identified creative task:
    a.  **Announce Focus:** "Entering CREATIVE PHASE for: [Component Name] - [Design Type: Architecture/Algorithm/UI-UX (infer or ask if unclear)]".
    b.  **Component Description:** Briefly describe the component and its purpose (referencing `activeContext.md`).
    c.  **Requirements & Constraints:** List key requirements and constraints for this component (from `activeContext.md` or by reasoning).
    d.  **Generate Design Options (2-3 options):**
        *   For each option, describe the approach.
        *   List Pros.
        *   List Cons.
        *   (For Algorithm: Include brief complexity analysis. For UI/UX: Consider user experience, accessibility).
    e.  **Recommended Approach:** State which option is recommended and provide a clear justification against requirements and trade-offs.
    f.  **Implementation Guidelines:** Provide high-level guidelines or pseudo-code for how the recommended approach could be implemented.
    g.  **Verification Checkpoint:** Briefly state how this design meets the core requirements.
    h.  **Document in Creative File:** Use `edit_file` to create/append to `memory-bank/creative/creative-[component_name].md`. Use the following template for each component:
        ```markdown
        # CREATIVE PHASE: [Component Name] - [Design Type]

        ## Component Description
        [Description]

        ## Requirements & Constraints
        - [Req 1]
        - [Constraint 1]

        ## Design Option 1: [Name of Option 1]
        ### Approach
        [Description]
        ### Pros
        - [Pro 1]
        ### Cons
        - [Con 1]

        ## Design Option 2: [Name of Option 2]
        ### Approach
        [Description]
        ### Pros
        - [Pro 1]
        ### Cons
        - [Con 1]

        ## Recommended Approach
        Option [Number]: [Name of Option]
        ### Justification
        [Explanation]

        ## Implementation Guidelines
        [Steps or pseudo-code]

        ## Verification
        [How this design meets requirements]
        ```
    i.  **Update Context:** Use `edit_file` to add a note to `memory-bank/activeContext.md` under "Creative Decisions": "Design for [Component Name] completed. See `memory-bank/creative/creative-[component_name].md`. Recommended: [Brief summary of recommendation]."
    j.  **Announce Phase Exit:** "Exiting CREATIVE PHASE for: [Component Name]".

4.  **Overall Verification & Transition:**
    a.  After all flagged creative tasks are processed, `read_file` `memory-bank/tasks.md` and `memory-bank/activeContext.md`.
    b.  State: "CREATIVE mode complete. All designated components have design documentation."
    c.  Use `edit_file` to update `memory-bank/tasks.md`, marking creative sub-tasks as `[x] Design complete, see creative/[component_name].md`.
    d.  Recommend: "Recommend transitioning to IMPLEMENT mode."

================
File: cursor-memory-bank/refined_instructions/implement.md
================
# IMPLEMENT MODE INSTRUCTIONS

Your Role: Build the planned changes, guided by `tasks.md`, `activeContext.md`, and any `creative-*.md` files.

Core Tools:
- `edit_file`: Use for ALL code modifications and for creating/updating ALL `.md` files in `memory-bank/`.
- `read_file`: Use to consult CMB artifacts and source code.
- `codebase_search`: Use to locate relevant code sections.
- `run_terminal_cmd`: Use ONLY for actual execution (tests, builds, servers). Be platform-aware.

## General Build Process:

1.  **Acknowledge:** Respond with "OK IMPLEMENT".
2.  **Understand the Task:**
    a.  `read_file` `memory-bank/tasks.md` to identify the current high-level task, its sub-tasks, and complexity level.
    b.  `read_file` `memory-bank/activeContext.md` for the detailed implementation plan, bug analysis, and/or creative design decisions.
    c.  If `memory-bank/creative/creative-[feature_name].md` exists for the current task/component, `read_file` it.

3.  **Execute Based on Complexity (refer to `memory-bank/tasks.md`):**

    **A. Level 1: Quick Bug Fix**
        i.   Review the bug report and fix plan in `memory-bank/activeContext.md`.
        ii.  Locate relevant code sections (`codebase_search`, `read_file`).
        iii. Implement the targeted fix using `edit_file`.
        iv.  Describe and (conceptually or actually, using `run_terminal_cmd` if applicable) test the fix.
        v.   Log actions: Use `edit_file` to append a summary of code changes, commands run, and test results to a "Build Log: [Task Name]" section in `memory-bank/activeContext.md`.

    **B. Level 2: Simple Enhancement**
        i.   Review the build plan in `memory-bank/activeContext.md`.
        ii.  For each sub-task/component in `memory-bank/tasks.md`:
            1. Examine relevant code (`read_file`, `codebase_search`).
            2. Implement changes using `edit_file`.
            3. Test the component/change.
            4. Log actions and test results in the "Build Log" of `memory-bank/activeContext.md` using `edit_file`.
        iii. Perform integration testing. Log results.

    **C. Level 3-4: Feature/System (Phased Build)**
        i.   Review overall plan in `activeContext.md` and designs in relevant `creative-*.md` files.
        ii.  For each phase in `tasks.md`:
            1. Implement components for the current phase using `edit_file`.
            2. Test the phase thoroughly.
            3. Document phase build details in `activeContext.md`'s "Build Log" or a `memory-bank/creative/build-log-[phase_name].md` using `edit_file`.
            4. Update `memory-bank/progress.md` (using `edit_file`) to reflect phase completion.
        iii. After all phases, perform comprehensive integration testing. Log results.
        iv.  If new integration points were created, consider if high-level project documentation needs updates (this might be deferred to ARCHIVE mode).

4.  **Command Execution (for `run_terminal_cmd`):**
    a.  State the purpose of the command.
    b.  After execution, use `edit_file` to append the full command and its output to the "Build Log" in `memory-bank/activeContext.md`.

5.  **Verification & Final Updates:**
    a.  Ensure all sub-tasks for the current main task in `memory-bank/tasks.md` are implemented and tested (review "Build Log" in `activeContext.md`).
    b.  Use `edit_file` to mark the main task and all its sub-tasks as `[x]` in `memory-bank/tasks.md`.
    c.  Use `edit_file` to add a final summary of the build to `memory-bank/progress.md`.
    d.  Use `edit_file` to update `memory-bank/activeContext.md` with a final status: "IMPLEMENTATION COMPLETED for [Task Name]".

6.  **Transition:**
    State: "IMPLEMENT mode complete for [Task Name]. Ready for REFLECT mode."

================
File: cursor-memory-bank/refined_instructions/plan.md
================
# PLAN MODE INSTRUCTIONS

Your Role: Create a detailed implementation plan based on the task and complexity level identified in VAN mode.

1.  **Acknowledge:** Respond with "OK PLAN".
2.  **Gather Context:**
    a.  `read_file` `memory-bank/tasks.md` to identify the current task and its complexity level.
    b.  `read_file` `memory-bank/activeContext.md` for current project focus and VAN analysis.
    c.  `read_file` `memory-bank/projectbrief.md`, `memory-bank/techContext.md`, and other relevant context files.
3.  **Develop Plan (based on complexity from `tasks.md`):**

    **A. Level 2: Simple Enhancement Planning**
        i.   Review relevant code structure (`read_file`, `codebase_search`).
        ii.  Use `edit_file` to update `memory-bank/activeContext.md` with a "Plan: [Task Name]" section, including:
            *   Overview of planned changes.
            *   List of files to modify.
            *   Key implementation steps (as sub-tasks).
            *   Potential challenges.
            *   Basic testing strategy.
        iii. Use `edit_file` to update `memory-bank/tasks.md`: Add the implementation steps as new sub-tasks under the main task.

    **B. Level 3-4: Comprehensive Planning**
        i.   Review codebase structure extensively (`read_file`, `codebase_search`).
        ii.  Use `edit_file` to update `memory-bank/activeContext.md` with a "Plan: [Task Name]" section, including:
            *   Detailed requirements analysis.
            *   Affected components/modules/subsystems.
            *   Architecture considerations (for Level 4, suggest Mermaid diagram syntax for key interactions if helpful for human review later).
            *   Implementation strategy (e.g., phased approach for Level 4).
            *   Detailed, sequential implementation steps (as sub-tasks).
            *   Dependencies between components/steps.
            *   Potential challenges and mitigation strategies.
            *   List of components/features that require a dedicated CREATIVE design phase.
        iii. Use `edit_file` to update `memory-bank/tasks.md`: Add the detailed implementation steps/phases as new sub-tasks. For items needing design, add a sub-task like "- [ ] CREATIVE: Design [component_name]".

4.  **Verification & Transition:**
    a.  `read_file` `memory-bank/activeContext.md` and `memory-bank/tasks.md` to confirm plan documentation.
    b.  State: "PLAN mode complete for [Task Name]. Detailed plan created and tasks updated."
    c.  Suggest next mode:
        *   If components were flagged for CREATIVE phase: "Recommend transitioning to CREATIVE mode for [list components]."
        *   Otherwise (for Level 2, or Level 3-4 if no creative phase needed): "Recommend transitioning to IMPLEMENT mode."

================
File: cursor-memory-bank/refined_instructions/reflect_archive.md
================
# REFLECT+ARCHIVE MODE INSTRUCTIONS

Your Role: First, facilitate REFLECTION on the completed task. Then, upon the 'ARCHIVE NOW' command, ARCHIVE the task.

Core Tools: `read_file`, `edit_file`.

## DEFAULT BEHAVIOR: REFLECTION PROCESS

1.  **Acknowledge:** Respond with "OK REFLECT+ARCHIVE. Starting REFLECTION phase."
2.  **Gather Context for Reflection:**
    a.  `read_file` `memory-bank/tasks.md` to identify the recently completed task(s).
    b.  `read_file` `memory-bank/activeContext.md` (especially the "Build Log" or implementation notes).
    c.  `read_file` `memory-bank/progress.md`.
    d.  `read_file` any relevant `memory-bank/creative/creative-[feature_name].md` or `build-log-[phase_name].md` files.
3.  **Guide Reflection (ask user these questions and record answers):**
    a.  "What went well during the IMPLEMENT/CREATIVE phase for [Task Name]?"
    b.  "What challenges were faced (e.g., tool usage, codebase issues, unclear requirements)?"
    c.  "What key lessons were learned about the codebase, the problem, or the development process?"
    d.  "Were there any unexpected outcomes or side effects (positive or negative)?"
    e.  "What process or technical improvements could be made for similar tasks in the future?"
4.  **Document Reflection:**
    a.  Use `edit_file` to create `memory-bank/reflection/reflect-[task_name_or_id]-[date].md`.
    b.  Populate it with the user's answers, structured under headings corresponding to the questions above.
5.  **Update Task Status:**
    a.  Use `edit_file` to update `memory-bank/tasks.md`. Append "Reflection complete, see reflection/reflect-[task_name_or_id]-[date].md" to the completed task item.
6.  **Prompt for Archiving:**
    State: "REFLECTION COMPLETE for [Task Name]. Reflection documented in `memory-bank/reflection/reflect-[task_name_or_id]-[date].md`. Type 'ARCHIVE NOW' to proceed with archiving this task."

## TRIGGERED BEHAVIOR: ARCHIVING PROCESS (Upon "ARCHIVE NOW" command)

1.  **Acknowledge:** "OK, proceeding with ARCHIVE process for [Task Name]."
2.  **Verify Reflection Completion:**
    a.  Check if `memory-bank/reflection/reflect-[task_name_or_id]-[date].md` exists and seems complete.
    b.  If not, state: "Reflection document not found or incomplete. Please complete reflection first." and await further instruction.
3.  **Create Archive Document:**
    a.  Use `edit_file` to create `memory-bank/archive/archive-[task_name_or_id]-[date].md`.
    b.  Populate it with a summary of the entire task lifecycle:
        *   Task Name / Goal
        *   Key activities/outcomes from VAN, PLAN, CREATIVE (if applicable), IMPLEMENT modes (referencing `activeContext.md` and relevant creative/build-log files).
        *   Summary of the solution/implementation.
        *   Key insights synthesized from `memory-bank/reflection/reflect-[task_name_or_id]-[date].md`.
        *   Links to final documentation artifacts (e.g., in `documentation/` folder).
4.  **Finalize Memory Bank Updates:**
    a.  **`tasks.md`**: Use `edit_file` to mark the main task as fully `[x] COMPLETED & ARCHIVED: memory-bank/archive/archive-[task_name_or_id]-[date].md`.
    b.  **`progress.md`**: Use `edit_file` to add/update an entry for the completed task, noting its archived status and linking to the archive document.
    c.  **`activeContext.md`**: Use `edit_file` to reset its content for the next task:
        ```markdown
        # Active Context
        ## Current Mode: ARCHIVE (Completed)
        ## Focus: Ready for new task.
        ## Previous Task: [Task Name] - Archived at memory-bank/archive/archive-[task_name_or_id]-[date].md
        ## Next Steps: Suggest VAN mode for new task.
        ```
5.  **Completion & Transition:**
    State: "ARCHIVING COMPLETE for [Task Name]. All relevant information has been consolidated and Memory Bank files updated. Suggest VAN mode to start a new task or project phase."

================
File: cursor-memory-bank/refined_instructions/van.md
================
# VAN MODE (Visualize, Analyze, Navigate) - Initialization

Your Role: Initialize the project context within the Memory Bank.

1.  **Acknowledge:** Respond with "OK VAN".
2.  **Verify/Create Memory Bank Structure:**
    a.  `list_dir` the project root to check for `memory-bank/`.
    b.  If `memory-bank/` does not exist, use `run_terminal_cmd` to create it (e.g., `mkdir memory-bank`). Then, create subdirectories: `mkdir memory-bank/archive memory-bank/creative memory-bank/reflection`. (Be platform-aware; for Windows, use `mkdir memory-bank\archive memory-bank\creative memory-bank\reflection`).
    c.  If `memory-bank/` exists, `list_dir` it to check for core files.
3.  **Gather Initial Project Context:**
    a.  `read_file` the main `README.md` of the project.
    b.  `read_file` the primary source file(s) if identifiable (e.g., `server.py`, `main.py`, `app.js`).
4.  **Create/Populate Core Memory Bank Files (using `edit_file` for each):**
    a.  **`memory-bank/projectbrief.md`**: Synthesize a brief project description, purpose, and key technologies from the files read.
        *Template:*
        ```markdown
        # Project Brief: [Project Name]
        ## Purpose
        ## Core Functionality
        ## Key Technologies
        ```
    b.  **`memory-bank/techContext.md`**: Detail the tech stack.
        *Template:*
        ```markdown
        # Technical Context
        ## Backend
        ## Frontend
        ## Database
        ## Key Libraries/Frameworks
        ```
    c.  **`memory-bank/systemPatterns.md`**: If discernible, outline high-level architecture.
        *Template:*
        ```markdown
        # System Patterns
        ## Overall Architecture (e.g., Client-Server, Microservices)
        ## Main Components & Interactions
        ```
    d.  **`memory-bank/productContext.md`**: Outline user needs/goals if evident.
        *Template:*
        ```markdown
        # Product Context
        ## Target Users
        ## Key User Needs/Goals
        ```
    e.  **`memory-bank/style-guide.md`**: Create with basic placeholders.
        *Template:*
        ```markdown
        # Style Guide
        ## Backend Code Style
        ## Frontend Code Style
        ## Commit Messages
        ```
    f.  **`memory-bank/tasks.md`**: Initialize with a high-level task.
        *Content:*
        ```markdown
        # Tasks
        - [ ] Level X: Initial Project Analysis & Setup (VAN Mode)
        ```
    g.  **`memory-bank/activeContext.md`**: Set initial context.
        *Content:*
        ```markdown
        # Active Context
        ## Current Mode: VAN
        ## Focus: Initializing project memory bank and performing high-level analysis.
        ## Project Complexity Level: [To be determined]
        ```
    h.  **`memory-bank/progress.md`**: Initialize.
        *Content:*
        ```markdown
        # Progress
        - VAN mode initiated. Memory bank structure setup.
        ```
5.  **Determine Project Complexity:**
    a.  Based on the analysis of `README.md` and source files, assess project complexity (Level 1: Trivial, Level 2: Simple, Level 3: Moderate, Level 4: Complex).
    b.  Use `edit_file` to update `memory-bank/activeContext.md` with the determined level: `## Project Complexity Level: Level [1/2/3/4]`.
    c.  Use `edit_file` to update the task in `memory-bank/tasks.md`: Replace "Level X" with the determined level.
6.  **Verification & Transition:**
    a.  `read_file` `memory-bank/activeContext.md` and `memory-bank/tasks.md` to confirm updates.
    b.  State: "VAN mode complete. Project complexity assessed as Level [level]. Memory Bank initialized."
    c.  Suggest next mode:
        *   If Level 1: "Recommend transitioning to IMPLEMENT mode."
        *   If Level 2-4: "Recommend transitioning to PLAN mode."




================================================================
End of Codebase
================================================================

================
File: cursor-memory-bank/ai-contexts/conversations/20-05.md
================
== Debugging and Enhancing Cursor Chat Data Extraction and UI Display ==

This wiki entry documents the collaborative effort to debug and enhance the [[Cursor View]] application, focusing on the extraction, processing, and display of code blocks from Cursor chat histories, and later, on correctly identifying and extracting specific chat sessions based on project context.

=== 1. Initial Problem: Missing Code Blocks ===
; Description
: Users reported that code snippets shared within Cursor chats were not visible in the Cursor View web application.
; Initial Investigation
: The first hypothesis was that the Python backend scripts (<code>extract_cursor_chat.py</code>, <code>server.py</code>) were not checking all possible text fields (e.g., <code>richText</code>, <code>code</code>, <code>parts</code>) where code snippets might be stored.
: Attempts to broaden field checks did not resolve the issue. Our understanding was that code was likely embedded as simple text within existing message fields.

=== 2. Breakthrough: Identifying the Extraction Flaw ===
; Key Insight
: A pivotal moment occurred when an exported JSON of our own chat session (<code>cursor-chat-5c439b02.json</code>) was examined. This file itself lacked the code blocks, conclusively showing that the problem originated in the data ''extraction'' process from the database, not merely in the UI rendering.
; Shift in Approach
: This shifted our focus significantly from UI display bugs to a deeper investigation of Cursor's SQLite database structure and the Python extraction logic. Our perspective changed from looking for a missing display case to looking for a missing data component at the source.

=== 3. Database Investigation and `codeBlocks` Discovery ===
; Tools Developed
: A diagnostic Python script, initially named <code>explore_cursor_db.py</code> and progressively enhanced into <code>test_code_blocks.py</code> (and its final iteration used for specific session extraction, <code>extract_db_example.py</code>), was created. This script allowed direct inspection of raw database content from <code>state.vscdb</code> files (both global and workspace-specific).
; Major Breakthrough
: The most significant breakthrough was the discovery that Cursor does not store code snippets as simple text within main message fields. Instead, it utilizes a dedicated, structured JSON array field, typically named <code>codeBlocks</code>, within each message's raw JSON data. Each element in this <code>codeBlocks</code> array contained the actual <code>content</code> of the code and its <code>languageId</code>.
; Learning
: This discovery fundamentally changed our understanding of the data's architecture. We learned that the data was far more structured than initially assumed, necessitating a targeted extraction approach for this specific field.

=== 4. Backend Implementation for Code Block Extraction ===
; Modifications
: The Python backend (<code>server.py</code> and standalone extraction scripts like <code>extract_single_chat.py</code>) was updated to:
:# Specifically look for the <code>codeBlocks</code> array in the parsed JSON of each message bubble.
:# Iterate through this array, extracting the <code>content</code> and <code>languageId</code> from each block.
:# Preserve this structured <code>codeBlocks</code> data throughout the processing pipeline.
; Pipeline Debugging
: Even after implementing the extraction, a further issue was identified: the extracted <code>codeBlocks</code> data was being dropped by the <code>format_chat_for_frontend</code> function in <code>server.py</code> before being sent to the frontend or included in JSON exports. This was rectified by ensuring the function passed along the <code>codeBlocks</code> field.

=== 5. Frontend Implementation for Code Block Rendering ===
; Problem
: With <code>codeBlocks</code> data correctly included in the JSON payload delivered to the frontend, the code blocks still weren't rendering in the UI.
; Investigation & Fixes
:# '''Build Issues:''' We first ensured the React frontend was correctly rebuilt (<code>npm run build</code> in the <code>frontend/</code> directory) to serve the latest changes, as stale builds can mask code fixes.
:# '''Component Logic & Debugging:''' We then focused on the <code>ChatDetail.js</code> React component. Initial checks and console logs were uninformative, leading to the build check.
:# '''Breakthrough & SyntaxHighlighter Fix:''' The final UI breakthrough occurred when we realized that while the <code>codeBlocks</code> data was reaching the component, the <code>SyntaxHighlighter</code> component itself was not correctly receiving the code content. The fix involved passing <code>codeBlock.content</code> as the <code>children</code> prop to the <code>SyntaxHighlighter</code> and ensuring proper language normalization (e.g., mapping <code>typescriptreact</code> to <code>tsx</code>).
; Outcome
: Code blocks, complete with syntax highlighting and language labels, were successfully and accurately rendered in the UI, significantly improving the application's utility.

=== 6. Advanced Debugging: Extracting Specific Chat Sessions ===
; New Challenge
: A user needed to extract a specific chat session (ID <code>3203ebc054e9bb3065e786ee05fe8345</code>) associated with a project path (<code>D:/Projects/apps</code>). Initial attempts using the diagnostic script with this ID directly failed to find messages.
; Key Variables in Diagnostic Script
: The script (<code>extract_db_example.py</code>) was configured with:
:* <code>TARGET_UI_SESSION_LABEL</code>: The ID displayed in the Cursor View UI (e.g., <code>3203ebc0...</code>).
:* <code>PROJECT_PATH_FOR_SESSION</code>: The filesystem path of the project (e.g., <code>D:/Projects/apps</code>).
:* <code>INTERNAL_COMPOSER_ID_TO_QUERY</code>: The actual ID used to key messages in the database, which needed to be discovered.
; Discovery & Learning
:# The ID displayed in the Cursor View UI for a chat (often labeled "Workspace" and derived from the project path's URI hash) was '''not''' the direct internal <code>composerId</code> (from <code>bubbleId:<composerId>:<timestamp></code> keys in <code>cursorDiskKV</code>) or <code>tabId</code> (from <code>ItemTable</code>) used to key messages in the database. This was a critical realization.
:# The main Cursor View application (<code>server.py</code>), as seen from its debug logs (<code>cursor_view.txt</code>), successfully links a project path to an internal <code>composerId</code>. It does this by inspecting metadata, primarily the <code>composer.composerData</code> key in the <code>globalStorage/state.vscdb</code>'s <code>ItemTable</code>. This key contains a list of "allComposers", where each entry maps an internal <code>composerId</code> to project details like <code>folderPath</code>.
; Solution for Diagnostic Script (<code>extract_db_example.py</code>)
:# The script was significantly enhanced to:
::# Accept a <code>PROJECT_PATH_FOR_SESSION</code>.
::# Read and parse the <code>composer.composerData</code> JSON from the global database's <code>ItemTable</code>.
::# Normalize both the <code>folderPath</code> from <code>composer.composerData</code> entries and the target <code>PROJECT_PATH_FOR_SESSION</code> (handling URI encoding, slashes, casing) for reliable comparison.
::# If a match is found, use the corresponding internal <code>composerId</code> from that entry as the <code>INTERNAL_COMPOSER_ID_TO_QUERY</code>.
::# Use this discovered internal ID to fetch message bubbles specifically from the <code>cursorDiskKV</code> table (as the UI indicated the data source was global storage for this particular chat).
; Outcome
: This refined approach allowed the diagnostic script to correctly identify the internal database key (<code>composerId</code>) for the targeted chat session by its project path, and subsequently extract its messages, mimicking the main application's more sophisticated linking logic.

=== 7. Documentation ===
; Purpose
: To capture the development journey, explain the system's architecture (including data storage and retrieval nuances), and document the new code block support and advanced session extraction capabilities.
; Files Created/Updated
:* <code>README.md</code>: Updated with general project information, setup, and new feature descriptions.
:* <code>STRUCTURE.md</code>: Revised to explain the organization of files and the roles of key components, including new diagnostic scripts.
:* <code>CODEBLOCK_SUPPORT.md</code>: A new document detailing the technical journey of implementing code block support, including challenges, breakthroughs, and the final approach.
:* <code>CHANGELOG.md</code>: A new file to record significant changes, features, and bug fixes, notably the addition of code block support and improved session identification.

=== 8. Key Learnings and Evolution of Understanding ===
* '''Data Structure Complexity:''' Our understanding evolved from assuming simple text storage for code to recognizing dedicated, structured arrays (<code>codeBlocks</code>) within message JSON.
* '''Full Data Pipeline Debugging:''' We learned that issues could arise at any stage: database structure, Python extraction logic, backend processing pipeline (e.g., data being dropped), API delivery, frontend build processes, React state management, or UI component rendering.
* '''Importance of Targeted Diagnostic Scripts:''' Iteratively developed Python scripts (<code>explore_cursor_db.py</code> -> <code>test_code_blocks.py</code> -> <code>extract_db_example.py</code>) were invaluable for isolating problems, inspecting raw data at various stages, and understanding data transformations.
* '''Identifier Mismatches & Indirect Linking:''' A crucial lesson was that UI-displayed identifiers (like session or workspace IDs) are not always the direct keys used for data storage in the database. Linkage often occurs indirectly through metadata tables (e.g., <code>composer.composerData</code> mapping project paths to internal <code>composerId</code>s).
* '''Iterative Refinement and Collaboration:''' The solutions were not found in a single step but evolved through multiple cycles of hypothesis, implementation, testing, log analysis, and collaborative debugging. Each failure provided new insights that guided the next iteration.
* '''Normalization is Key:''' When comparing paths or identifiers from different sources (UI, database, filesystem), careful normalization (handling case, slashes, URI encoding) is essential for reliable matching.

=== 9. Key Scripts and Tools ===
* '''<code>server.py</code>:''' The main backend server for the Cursor View application. Heavily modified to correctly extract, process, and serve <code>codeBlocks</code> data, and its logging provided insights into session identification.
* '''<code>extract_cursor_chat.py</code> / <code>extract_single_chat.py</code>:''' Standalone Python scripts for chat extraction, updated to include <code>codeBlocks</code> logic.
* '''<code>ChatDetail.js</code>:''' The React component in the frontend responsible for rendering individual chat messages, including the newly supported code blocks using the <code>SyntaxHighlighter</code> library.
* '''<code>test_code_blocks.py</code> / <code>extract_db_example.py</code>:''' An evolving diagnostic Python script that became central to our debugging. Its capabilities grew to include:
** Inspecting raw SQLite database content (<code>cursorDiskKV</code>, <code>ItemTable</code>).
** Testing specific data extraction logic outside the main application.
** Discovering all available internal database IDs (<code>composerId</code> from <code>bubbleId</code> keys, <code>tabId</code> from <code>ItemTable</code>).
** Inspecting metadata like <code>composer.composerData</code>.
** Linking user-provided project paths to internal <code>composerId</code>s.
** Extracting and formatting specific chat sessions based on these discovered internal IDs.

=== 10. Current Status ===
* The Cursor View application now successfully extracts, processes, and renders code blocks from Cursor chat histories, complete with syntax highlighting.
* The diagnostic script (<code>extract_db_example.py</code>) is capable of accurately identifying and extracting specific chat sessions from the global database by resolving project paths to internal database identifiers found in metadata.
* A comprehensive set of documentation has been outlined to capture these developments and make the project more understandable and maintainable.

================
File: cursor-memory-bank/ai-contexts/conversations/21-05.md
================
# Wiki Entry: Cursor View Development Log (Session 2a95456e)

**Date:** 2025-05-21
**Session ID:** 2a95456e-af96-42cf-b316-597020ae1301
**Project:** Cursor View

## Introduction

This session focused on several key development activities for the Cursor View project: initializing the "Adaptive Memory-Based Assistant System" via the "VAN" command, planning and implementing a bug fix for a JSON export issue, and generating comprehensive documentation for the `server.py` component.

## Phase 1: System Initialization (VAN Mode)

### Activation and Purpose
The session began with the user issuing the "VAN" command, activating the entry point/initialization mode for the Adaptive Memory-Based Assistant System. The AI acknowledged with "OK VAN". The primary goal of this phase was to set up the project's "memory-bank" to store context, tasks, and progress.

### Memory Bank Setup
1.  **Directory Structure Exploration:** The AI performed several `list_dir` operations to understand the existing project structure, examining the root directory, `memory-bank/`, `cursor-memory-bank/`, and `frontend/` subdirectories.
2.  **Initial Context Gathering:** The AI read key files like `README.md`, `server.py` (partially), and existing (mostly empty) memory bank files (`tasks.md`, `progress.md`, `activeContext.md`) to gather initial project context.
3.  **Memory Bank Directory Creation:**
    *   An initial attempt to create subdirectories (`archive`, `creative`, `reflection`) within `memory-bank/` using `mkdir -p` failed due to incompatibility with Windows PowerShell.
    *   The command was corrected to `mkdir -Force memory-bank\\archive, memory-bank\\creative, memory-bank\\reflection`, which successfully created the directories.
4.  **Core Memory File Population:**
    *   The AI proceeded to create and populate essential memory bank files:
        *   `memory-bank/projectbrief.md`: Summarizing the Cursor View project.
        *   `memory-bank/tasks.md`: Initializing a task list.
        *   `memory-bank/activeContext.md`: Describing the current development context.
        *   `memory-bank/progress.md`: To track development progress.
        *   `memory-bank/productContext.md`: Outlining user needs.
        *   `memory-bank/systemPatterns.md`: Documenting system architecture.
        *   `memory-bank/techContext.md`: Detailing the technical stack.
        *   `memory-bank/style-guide.md`: Providing coding style guidelines.
    *   **Challenges:** Populating these files with multi-line content using PowerShell's `Set-Content` or `Add-Content` proved problematic due to command length limitations or newline character issues. The AI often resorted to creating empty files with `New-Item` and then attempting to add content incrementally, or using `notepad` as a fallback for manual editing by the user (simulated).
5.  **VAN Process Completion:** The `activeContext.md` file was updated to reflect the successful completion of the VAN process and the readiness for the next mode transition.

## Phase 2: JSON Export Bug - Planning & Analysis

### Bug Report
The user reported a bug with the JSON export functionality, providing console error logs indicating a 404 (NOT FOUND) error for the endpoint `GET http://127.0.0.1:5000/api/chat/<session_id>/export?format=json`.

### Investigation
1.  **Frontend Code Review:** The AI read `frontend/src/components/ChatDetail.js` (lines 230-429) to understand how the export request was being made.
2.  **Backend Code Review:** The AI read relevant sections of `server.py`, focusing on:
    *   `extract_chats` function (lines 460-659)
    *   `format_chat_for_frontend` and API route handlers (lines 710-909)
    *   `export_chat` function (lines 1000-1199)

### Root Cause Identification
The analysis revealed an inconsistency in how chat sessions were being looked up in the `export_chat` function compared to the working `get_chat` function.
*   `export_chat` was incorrectly checking for `chat['session'].get('composerId') == session_id`.
*   The correct data structure, as used by `get_chat`, involved a direct lookup: `chat.get('session_id') == session_id`.
*   Additionally, `export_chat` was not using `target_session_id` in its `extract_chats` call, making it less efficient.

### Solution Planning
1.  **Task Definition:** The `memory-bank/tasks.md` file was updated with a new "Bug Fix Tasks" section, detailing steps to investigate and fix the JSON export functionality.
2.  **Context Update:** The `memory-bank/activeContext.md` file was updated with a "JSON Export Bug Fix Plan," including the issue description, analysis, and a proposed solution plan. This involved modifying `export_chat` to align with `get_chat`'s lookup logic and improving logging and efficiency.
3.  **Code Snippet Storage:** A new file `memory-bank/bugfix-code.md` was created (likely via `notepad`) to store the proposed code changes.

## Phase 3: Server Documentation (Creative Mode)

### Activation and Strategy
The user initiated a "CREATIVE document @server.py" command. The AI entered a "CREATIVE PHASE: DOCUMENTATION DESIGN" and decided on "Option 3: Modular Documentation with Multiple Views" to provide a balance between high-level understanding and detailed reference.

### Generated Documentation Artifacts
A `documentation/` directory was created, and the following Markdown files were generated and populated:
1.  **`documentation/server_documentation.md`**: A comprehensive overview of the `server.py` file, including its architecture (with a Mermaid diagram), key features, installation instructions, core components (data extraction, API endpoints, HTML/JSON generation), a detailed API reference for all endpoints, data flow, database interaction, utility functions, deployment guidelines, and known limitations.
2.  **`documentation/code_reference.md`**: A detailed reference for the main functions within `server.py`, covering database functions, data extraction functions, data processing functions, API endpoint functions, and utility functions, each with parameters, return values, and examples.
3.  **`documentation/database_structure.md`**: An explanation of the Cursor SQLite database structure, including database locations, table schemas (cursorDiskKV, ItemTable), key data structures (chat messages, code blocks, composer data), and methods for extracting data.
4.  **`documentation/fix_implementation.md`**: A detailed document explaining the JSON export bug, its root cause, the implemented fix with code diffs, testing scenarios, lessons learned, and future improvement suggestions.
5.  **`documentation/README.md`**: An introductory README for the `documentation/` directory, linking to the other generated documents and providing context.

### Memory Bank Update
The `memory-bank/activeContext.md` file was updated to note the completion of the documentation development.

## Phase 4: JSON Export Bug - Implementation & Verification

### Code Modification in `server.py`
The AI proceeded to implement the planned fix in `server.py`:
1.  The `export_chat` function was modified:
    *   The call to `extract_chats(detailed_logging=False)` was changed to `extract_chats(detailed_logging=True, target_session_id=session_id)` for consistency with `get_chat` and to improve efficiency and debuggability.
    *   The chat lookup logic was changed from:
        ```python
        # Buggy code:
        if 'session' in chat and chat['session'] and isinstance(chat['session'], dict):
            if chat['session'].get('composerId') == session_id:
                # ...
        ```
        to:
        ```python
        # Fixed code:
        if chat.get('session_id') == session_id:
            # ...
        ```
2.  The AI used the `edit_file` tool to apply these changes to `server.py`. An initial `search_replace` attempt resulted in a syntax error due to improper newline handling in the replacement string, which was subsequently corrected by editing the entire function block.

### Testing and Verification
1.  **Server Startup:** The server was started using `python server.py`.
2.  **API Test:** An attempt was made to test the API using `curl -v "http://127.0.0.1:5000/api/chats"`. While this tested the `/api/chats` endpoint, it did not directly test the fixed `/api/chat/<session_id>/export?format=json` endpoint. However, the server logs and the successful application of the code changes imply the fix was deployed.

### Memory Bank and Documentation Updates
1.  **`memory-bank/tasks.md`**: Updated to mark the JSON export bug fix tasks as completed (`[x]`) and added implementation notes.
2.  **`memory-bank/activeContext.md`**: Updated with a "JSON Export Bug Fix Implementation" section detailing the successful fix.
3.  **`memory-bank/progress.md`**: Updated to include "Fixed JSON export functionality" under the "Completed" section. Formatting issues with this file (extraneous `\\` characters) were also corrected.
4.  **`documentation/fix_implementation.md`**: Updated with an "Implementation Status" section confirming the fix was implemented, tested, and deployed.

## Session Conclusion & Key Outcomes

This session successfully initialized the project's memory bank, thoroughly planned and documented a bug fix, generated extensive server documentation, and implemented the identified bug fix for the JSON export functionality. The primary challenges encountered were related to multi-line text manipulation in the Windows PowerShell environment, which the AI worked around. The Cursor View project is now better structured for ongoing development, with a more robust export feature and comprehensive documentation.

================
File: cursor-memory-bank/ai-contexts/conversations/25-05.md
================
# Wiki Entry: AI Development & Tooling Log - Project "CursorView" & "Cursor Memory Bank (CMB)"

**Log Period:** [Start Date of Full Conversation] - [Current Date: 2025-05-14 (Simulated)]
**Primary Collaborators:** User, AI Assistant
**Overall Objective:** To enhance AI agent capabilities within the Cursor IDE through the "Cursor Memory Bank" (CMB) system, debug and document the "CursorView" application, and prepare project materials for a developer portfolio.

## 1. Introduction

This log summarizes a series of development sessions focused on two main projects:

* **CursorView:** A web application for viewing and analyzing Cursor AI chat sessions. Work involved debugging a 404 error and refining its project description for portfolio use.
* **Cursor Memory Bank (CMB):** A system designed to improve AI agent autonomy and reliability within the Cursor IDE by providing structured workflows and persistent memory. The primary effort involved refining its `.mdc` rule files and AI custom prompts.

The sessions also touched upon general AI interaction principles and optimizing workflows for AI-assisted development.

## 2. CursorView: Chat Deletion Bug Resolution & Portfolio Preparation

### 2.1. Debugging 404 Error on Chat Deletion

* **Problem:** Users encountered a 404 "Not Found" error when attempting to delete chat sessions via the CursorView web UI. The error log (`error-delete-chat.txt`) indicated an issue in `ChatList.js` calling the backend API (`DELETE /api/chat/:id`).
* **Investigation (Simulated CMB VAN Mode):**
  * The AI analyzed `error-delete-chat.txt`, `STRUCTURE.md` (for CursorView), `server.py`, and `ChatList.js` (`cursor-chat-0e71f688.json` log).
  * The root cause was identified as a mismatch in how `session_id` was accessed in the `delete_chat` function in `server.py` (expected `chat['session']['composerId']`) versus how it was structured in the data provided by `extract_chats()` (available as `chat.get('session_id')`). This was similar to a previously fixed JSON export bug.
* **Solution (Simulated CMB IMPLEMENT Mode):**
  * The AI proposed and (conceptually) implemented a fix in `server.py` by changing the lookup to use `chat.get('session_id')`.
  * Memory Bank files (`activeContext.md`, `tasks.md`) were updated to reflect the analysis, solution plan, and implementation. Documentation for the fix (`documentation/delete_chat_fix.md`) was also created.
* **Outcome:** The bug was resolved efficiently, with the AI demonstrating rapid diagnosis and solution proposal. This instance also led to discussions on optimizing the CMB workflow for such quick fixes.

### 2.2. Portfolio Project Description Refinement

* **Goal:** Refine the description of the "CursorView" project (from `info.md`, with original context in `prd.md`) for inclusion in a developer portfolio, aiming for a more eye-catching and modern presentation.
* **Process:**
  * The AI reviewed the user's initial `info.md`.
  * Suggestions were provided for:
    * Project Title (e.g., "CursorView: AI-Powered Chat Session Explorer").
    * One-Liner Description.
    * Detailed Description (Problem, Solution, Impact) – refining wording for clarity and impact.
    * User's Role (e.g., "Lead Developer & Maintainer").
    * Technologies/Skills Used (adding specifics like ES6+, Material-UI, RAG).
    * Key Features/Highlights (focusing on user benefits and uniqueness).
  * The user incorporated feedback into a final `info.md`.
* **PRD Generation for AI:**
  * Based on the finalized `info.md`, the AI generated a Product Requirements Document (PRD) for CursorView. This PRD is intended to brief an AI assistant (like itself) to help with future tasks related to the CursorView project (e.g., documentation, feature brainstorming, visual suggestions).

## 3. Cursor Memory Bank (CMB) - System Refinement

### 3.1. Goal

To enhance the Cursor Memory Bank (CMB) system for improved AI agent autonomy, reliability, and adherence to a structured workflow within the Cursor IDE. This involved making the AI follow instructions from `.mdc` rule files and standardizing its tool usage.

### 3.2. Core Strategy & Key Decisions

* **Tool Prioritization:** A standard tool usage strategy was established:
  * `fetch_rules`: Primary for loading `.mdc` rule files.
  * `edit_file`: Primary for ALL content creation/modification in Memory Bank `.md` files, project documentation, and source code.
  * `read_file`: For general context gathering.
  * `run_terminal_cmd`: Reserved for execution tasks (builds, tests, `mkdir`), with platform awareness.
  * `codebase_search`: For "grep-like" functionality.
* **Refinement Order:**
  1. Refine all `.mdc` rule files.
  2. Refine AI Custom Prompts (for Cursor's "Advanced options").
* **`.mdc` File Generation:** A Python script (`batch.py`) was developed and iteratively improved to automate the creation and updating of `.mdc` files with refined content and correct YAML frontmatter (description, globs, alwaysApply).
* **Insights Integration:** The `insights_fetch-rules.md` and `insight-CMB.md` documents provided by the user, along with `mcp-cursor.md`, helped solidify the understanding of how Cursor's `fetch_rules` tool works and the overall architecture of the CMB system.

### 3.3. `.mdc` Rule File Refinement

The process involved translating existing logic (often from Mermaid diagrams in files like `rules-core.txt`, `rules-visual-maps.txt`, `rules-levels.txt`, `rules-phases-main.txt`) into AI-actionable textual instructions within the `.mdc` files.

* **Scope:**
  * **Core Rules (`.cursor/rules/isolation_rules/Core/`):** Foundation behaviors, tool usage, platform awareness, file paths, complexity assessment. (Refined content provided in `rules-core-refined.md`).
  * **Visual Maps (`.cursor/rules/isolation_rules/visual-maps/`):** Main orchestrator rules for each CMB mode (VAN, PLAN, CREATIVE, IMPLEMENT, REFLECT, ARCHIVE, QA) and VAN sub-components (`van_mode_split/`, `van_mode_split/van-qa-checks/`, `van_mode_split/van-qa-utils/`). These now primarily `fetch_rules` for more specific logic.
  * **LevelX Rules (`.cursor/rules/isolation_rules/LevelX/`):** Complexity-specific instructions (L1-L4) for planning, implementation, reflection, archiving, etc.
  * **Phases Rules (`.cursor/rules/isolation_rules/Phases/CreativePhase/`):** Detailed guidance for specific creative design types (architecture, UI/UX) and a template for creative outputs.
  * **Main Rules (`.cursor/rules/isolation_rules/main.mdc`, `main-optimized.mdc`):** System entry points and conceptual overviews.
* **Status:** All specified `.mdc` files have had their refined content generated and integrated into the `batch.py` script.

### 3.4. AI Custom Prompts

* **Goal:** Create concise textual prompts for each CMB mode to be pasted into Cursor's "Advanced options." These prompts primarily instruct the AI to `fetch_rules` for the main orchestrating `.mdc` file for that mode.
* **Process:** Reviewed original verbose instructions from `custom_instructions.txt` and `refined-instructions.txt`.
* **Status:** Refined prompts for VAN, PLAN, CREATIVE, IMPLEMENT, and REFLECT+ARCHIVE modes have been defined.

### 3.5. Workflow Discussions & Optimizations

* **Efficient AI vs. Strict CMB Flow:** The CursorView bug-fixing session highlighted that the AI could sometimes diagnose and fix simple issues faster than the full explicit CMB mode progression.
* **VAN Mode Triage:** It was decided to refine the `van-mode-map.mdc` orchestrator to include an early "Quick Triage & Fix" step. This allows the AI to identify and handle "Level 0-1" (very simple, localized) tasks by directly fetching `Level1/optimized-workflow-level1.mdc`, while still defaulting to the full VAN analysis for more complex or uncertain cases. This maintains CMB structure while accommodating AI efficiency.
* **User Confirmation:** Clarified the importance of the user explicitly confirming AI actions (like successful testing of a fix) to ensure Memory Bank files are updated correctly and tasks are formally closed.

## 4. Overall Current Status

* The `batch.py` script is functional and contains the refined content for all Core, Visual Maps (including VAN split), LevelX, and Phases/CreativePhase `.mdc` rules.
* The AI Custom Prompts for each CMB mode have been refined to be concise and to leverage the `.mdc` rule system.
* The "CursorView" project description has been refined for portfolio use, and a PRD has been generated for it.
* A bug in the "CursorView" project related to chat deletion has been successfully diagnosed and a fix proposed/implemented.

## 5. Next Steps (Implied before summary request)

1. **CMB System Testing:**
   * User to integrate the refined AI Custom Prompts into their Cursor IDE.
   * Thoroughly test the entire refined CMB system with a sample project/task to ensure the AI:
     * Correctly follows the structured workflow defined in the `.mdc` rules.
     * Uses the prioritized tools as intended (`fetch_rules`, `edit_file`, etc.).
     * Manages Memory Bank artifacts (`tasks.md`, `activeContext.md`, etc.) reliably.
     * Correctly handles the new "quick triage" in VAN mode.
2. **Portfolio Development:**
   * User to begin development of their portfolio website, potentially using the generated PRD for CursorView and AI assistance for content/layout.

================
File: cursor-memory-bank/ai-contexts/fetch-rules-vs-read-file.md
================
Your question focuses on how the **Cursor Memory Bank** system retrieves rules from the `.cursor/rules/isolation_rules/` folder and whether this is handled solely by the **Fetch Rules** mechanism or also involves the **Read File** command. You’re also seeking insights from research, likely to understand the technical details and best practices for managing rules in the context of a large codebase, as discussed in our prior conversations about the Memory Bank system and structured AI workflows. Below, I’ll provide a detailed explanation based on the GitHub documentation for `vanzan01/cursor-memory-bank` and additional web sources, addressing how rules are fetched, the role of the Read File command, and insights into their implementation. I’ll conclude with a practical example to clarify the process, aligning with your interest in efficient AI coding and large codebase management.

---

### How Rules Are Retrieved in Cursor Memory Bank

The **Cursor Memory Bank** system, as described in the GitHub repository (`vanzan01/cursor-memory-bank`), relies on a **hierarchical rule loading** mechanism to fetch mode-specific rules from the `.cursor/rules/isolation_rules/` folder. This process is integral to its token-optimized, structured workflow for guiding AI through development phases (VAN, PLAN, CREATIVE, IMPLEMENT, REFLECT, ARCHIVE). Let’s break down the roles of **Fetch Rules** and **Read File** in this context.

#### 1. Fetch Rules Mechanism
- **Definition**: In the Cursor AI IDE, **Fetch Rules** is a specific tool or action that the AI agent uses to retrieve rule files (typically `.mdc` or `.md` files) from the `.cursor/rules/` directory or its subdirectories (e.g., `.cursor/rules/isolation_rules/` in Memory Bank). It’s designed to provide the AI with persistent, reusable context without appending rules directly to the system prompt, as noted in a blog post on Cursor’s rule system.[](https://blog.sshh.io/p/how-cursor-ai-ide-works)
- **Role in Memory Bank**: Fetch Rules is the primary mechanism for loading mode-specific rules in Memory Bank. Each mode (e.g., VAN, PLAN) has associated rules stored in `.cursor/rules/isolation_rules/` (e.g., `van_rules.md`, `plan_rules.md`). When a mode is activated (e.g., by typing `VAN` in the Cursor chat panel), the AI uses Fetch Rules to retrieve the relevant rule file for that mode.
- **Process**:
  - The AI identifies the active mode and task context (e.g., based on user input like `PLAN authentication bug fix`).
  - It calls the `fetch_rules()` tool to locate and load the appropriate rule file from `.cursor/rules/isolation_rules/`, using metadata like rule names or file paths.
  - The rules are loaded hierarchically, meaning only the necessary rules for the current mode and task complexity (Level 1–4) are fetched, optimizing token usage.
- **Example**: In VAN mode, the AI might fetch `van_rules.md`, which contains instructions for analyzing the project structure. The rule file might specify:
  ```
  Analyze the project directory using 'List Directory' and identify key files like app.py.
  ```
- **Token Efficiency**: Fetch Rules avoids loading all rules at once, aligning with Memory Bank’s token-optimized architecture, which is crucial for large codebases (per your interest).

#### 2. Read File Command
- **Definition**: The **Read File** command is a Cursor tool that allows the AI to read the contents of a specific file in the project directory. It’s one of the tools enabled in Memory Bank’s custom modes (e.g., VAN, PLAN, CREATIVE) and is used to access files like code, documentation, or rules.
- **Role in Memory Bank**: While Fetch Rules is the high-level mechanism for retrieving rule files, the Read File command is often the underlying tool that executes the actual file reading. When Fetch Rules identifies a rule file (e.g., `.cursor/rules/isolation_rules/van_rules.md`), it uses Read File to access and parse its contents.
- **Process**:
  - The AI invokes Read File to open and read the rule file’s content, which is then incorporated into the AI’s context for the current task.
  - For example, in CREATIVE mode, the AI might use Read File to read `creative_rules.md` after Fetch Rules identifies it as the relevant rule file.
- **Example**: If the user types `CREATIVE document auth.py`, Fetch Rules selects `creative_rules.md`, and Read File reads its contents, which might include:
  ```
  Generate a documentation template with functional requirements and design options for the specified module.
  ```
- **Scope**: Read File is not limited to rules; it’s also used to read Memory Bank files (e.g., `memory-bank/tasks.md`) or code files (e.g., `auth.py`) during tasks like documentation or debugging.

#### 3. Fetch Rules vs. Read File: Do Both Work Together?
- **Short Answer**: Yes, **Fetch Rules** and **Read File** work together in the Cursor Memory Bank system. Fetch Rules is the high-level decision-making process that determines *which* rule file to load, while Read File is the low-level tool that *reads* the file’s contents.
- **How They Interact**:
  - Fetch Rules acts as the orchestrator, using metadata (e.g., rule names, file paths, or glob patterns) to select the appropriate rule file for the mode or task.
  - Once the file is identified, Fetch Rules invokes the Read File command to retrieve the file’s contents and incorporate them into the AI’s context.
  - Example: In IMPLEMENT mode, Fetch Rules might select `.cursor/rules/isolation_rules/implement_rules.md`, and Read File reads its instructions, such as:
    ```
    Modify code systematically, referencing activeContext.md for current focus.
    ```
- **Why Both Are Needed**:
  - Fetch Rules provides intelligence and selectivity, ensuring only relevant rules are loaded, which is critical for token efficiency in large codebases.
  - Read File provides the raw capability to access file contents, which is necessary for rules, Memory Bank files, and codebase files.
- **Can Fetch Rules Work Alone?**: No, Fetch Rules relies on Read File (or similar file-access tools) to actually read the rule file. Without Read File enabled in a mode’s configuration, Fetch Rules cannot retrieve the rule content, leading to errors.
- **Can Read File Work Alone?**: Yes, but it would require manual specification of the file path (e.g., typing `Read .cursor/rules/isolation_rules/van_rules.md`), which is less efficient than Fetch Rules’ automated selection.

#### 4. Insights from Research
Based on web sources and community discussions, here are key insights into Fetch Rules and Read File in the context of Cursor and Memory Bank:

- **Cursor’s Rule System**: Cursor Rules are stored in `.cursor/rules/` and written in MDC (Markdown with metadata) format. They provide persistent context to the AI, and Fetch Rules uses metadata (e.g., rule descriptions, glob patterns) to select relevant rules. The AI calls `fetch_rules()` to retrieve these files, often using Read File internally.[](https://docs.cursor.com/context/rules)[](https://blog.sshh.io/p/how-cursor-ai-ide-works)
- **Community Feedback**: A GitHub Gist discussion highlights that users have adapted Memory Bank to Cursor’s new rules format, emphasizing the power of `.cursor/rules/` for persistent memory. However, some users noted issues with missing subdirectories (e.g., `.cursor/rules/isolation_rules/Level2/`) in the Memory Bank repository, suggesting that Fetch Rules may fail if expected files are absent.[](https://gist.github.com/ipenywis/1bdb541c3a612dbac4a14e1e3f4341ab?permalink_comment_id=5506809)
- **Token Management**: Community posts warn that front-loading too much context (e.g., large rule files) increases token usage, which Memory Bank mitigates through hierarchical loading. Removing unused configurations (e.g., MCP) can further save tokens, aligning with your interest in efficient AI processing.[](https://gist.github.com/ipenywis/1bdb541c3a612dbac4a14e1e3f4341ab?permalink_comment_id=5506809)
- **Best Practices for Rules**: A blog post recommends writing rules like “encyclopedia articles” with clear names and descriptions to improve Fetch Rules’ accuracy. Avoid overriding system prompts in rules (e.g., “You are a senior engineer”), as this can conflict with Cursor’s internal prompts and break tool use, including Fetch Rules and Read File.[](https://blog.sshh.io/p/how-cursor-ai-ide-works)
- **Folder Structure**: The Memory Bank repository places `memory-bank/` and `custom_modes/` in the project root, with only `.cursor/rules/isolation_rules/` inside `.cursor/`. This is a mandatory requirement because Cursor expects rules in `.cursor/rules/`, while Memory Bank files are user-facing and stored in the root for accessibility. Placing all folders in `.cursor/` could confuse the AI or break file access.[](https://gist.github.com/ipenywis/1bdb541c3a612dbac4a14e1e3f4341ab?permalink_comment_id=5506809)[](https://x.com/kregenrek/status/1924556646073679952)

#### 5. Practical Example: Fetching Rules for a Flask App
To illustrate how Fetch Rules and Read File work together in Memory Bank, consider the Flask authentication bug fix scenario from your prior question:

1. **Setup**:
   - You’ve cloned `vanzan01/cursor-memory-bank` into your Flask project.
   - The `.cursor/rules/isolation_rules/` directory contains `van_rules.md`, `plan_rules.md`, etc.
   - Modes (VAN, PLAN, etc.) are configured in Cursor with tools like “Read File” and “Codebase Search” enabled.

2. **VAN Mode**:
   - **User Input**: Type `VAN` in the Cursor chat panel.
   - **Fetch Rules**: The AI uses `fetch_rules()` to select `.cursor/rules/isolation_rules/van_rules.md` based on the VAN mode context.
   - **Read File**: The AI calls Read File to read `van_rules.md`, which might contain:
     ```
     # VAN Mode Rules
     - Use List Directory to scan project structure.
     - Identify key files (e.g., app.py, auth.py).
     - Update tasks.md with initial task list.
     ```
   - **Outcome**: The AI scans the project, identifies `auth.py`, and updates `memory-bank/tasks.md`:
     ```
     - Analyze codebase: Found app.py, auth.py
     - Complexity: Level 4
     ```

3. **PLAN Mode**:
   - **User Input**: Type `PLAN fix login bug`.
   - **Fetch Rules**: The AI selects `.cursor/rules/isolation_rules/plan_rules.md`.
   - **Read File**: Reads `plan_rules.md`, which might include:
     ```
     # PLAN Mode Rules
     - Create a task breakdown for the specified issue.
     - Reference activeContext.md for current focus.
     ```
   - **Outcome**: Updates `tasks.md` with:
     ```
     - Fix login session timeout
       - Subtask: Review session handling in auth.py
     ```

4. **Troubleshooting**:
   - If Fetch Rules fails (e.g., “no rules loaded”), check:
     - The `.cursor/rules/isolation_rules/` directory exists and contains the correct files.
     - “Read File” is enabled in the mode’s configuration (Settings → Features → Chat → Custom modes).
   - If the wrong rules are fetched, ensure rule file names and metadata are clear, as vague names can confuse `fetch_rules()`.[](https://blog.sshh.io/p/how-cursor-ai-ide-works)

---

### Comprehensive Context and Artifact
To address your request for a comprehensive context of how rules are fetched, here’s an artifact summarizing the process in the Memory Bank system, including Fetch Rules and Read File:


# Cursor Memory Bank: Rule Fetching Process

## Overview
The Cursor Memory Bank system retrieves mode-specific rules from `.cursor/rules/isolation_rules/` to guide AI through structured development workflows. This process uses **Fetch Rules** to select rules and **Read File** to access their contents, ensuring token efficiency and context persistence.

## Fetch Rules
- **Purpose**: Identifies and retrieves the appropriate rule file for the active mode (e.g., VAN, PLAN) based on metadata like file names or glob patterns.
- **Location**: Rules are stored in `.cursor/rules/isolation_rules/` (e.g., `van_rules.md`, `plan_rules.md`).
- **Process**:
  - The AI calls `fetch_rules()` to select the rule file matching the mode and task context.
  - Only relevant rules are loaded hierarchically to optimize token usage.
- **Example**: In VAN mode, `fetch_rules()` selects `van_rules.md` to analyze the project structure.

## Read File Command
- **Purpose**: Reads the contents of the selected rule file to incorporate into the AI’s context.
- **Role**: Acts as the underlying tool for Fetch Rules, accessing files in `.cursor/rules/isolation_rules/` or other project directories (e.g., `memory-bank/`).
- **Example**: Reads `plan_rules.md` to provide planning instructions like “Create a task breakdown.”

## Interaction
- **Fetch Rules**: Determines *which* rule file to load (e.g., `creative_rules.md` for CREATIVE mode).
- **Read File**: Executes the reading of the file’s contents, enabling the AI to apply the rules.
- **Dependency**: Fetch Rules relies on Read File to access rule content; without Read File enabled, rule fetching fails.

## Best Practices
- **Clear Rule Names**: Use descriptive names (e.g., `implement_rules.md`) to improve `fetch_rules()` accuracy.[](https://blog.sshh.io/p/how-cursor-ai-ide-works)
- **Enable Read File**: Ensure “Read File” is enabled in each mode’s configuration in Cursor.
- **Check File Paths**: Verify `.cursor/rules/isolation_rules/` exists with correct permissions.
- **Token Management**: Avoid large rule files to minimize token usage, as noted in community discussions.[](https://gist.github.com/ipenywis/1bdb541c3a612dbac4a14e1e3f4341ab?permalink_comment_id=5506809)

## Troubleshooting
- **Rules Not Loading**: Check if `.cursor/rules/isolation_rules/` contains the expected files (e.g., `van_rules.md`). Ensure “Read File” is enabled.
- **Incorrect Rules Fetched**: Refine rule file names and metadata for clarity.
- **Missing Subdirectories**: Some reported missing folders like `Level2/` in the repository; create them manually if needed.[](https://gist.github.com/ipenywis/1bdb541c3a612dbac4a14e1e3f4341ab?permalink_comment_id=5506809)

## Example
For a Flask app in IMPLEMENT mode:
- **User Input**: `IMPLEMENT fix login bug`
- **Fetch Rules**: Selects `.cursor/rules/isolation_rules/implement_rules.md`.
- **Read File**: Reads the file, which contains:
  ```
  Modify code systematically, referencing activeContext.md for current focus.
  ```
- **Outcome**: The AI updates `auth.py` and `progress.md` with bug fix details.



---

### Insights from Research
- **Community Issues**: A GitHub user (@SidShetye) noted that some referenced subdirectories (e.g., `.cursor/rules/isolation_rules/Level2/`) are missing in the Memory Bank repository, which could break Fetch Rules if the AI expects them. This suggests manually creating or updating rule files if errors occur.[](https://gist.github.com/ipenywis/1bdb541c3a612dbac4a14e1e3f4341ab?permalink_comment_id=5506809)
- **Rule Design**: Rules should be written as “encyclopedia articles” focusing on “what” rather than “how” to avoid overfitting the AI. Linking rules to code files (e.g., `[auth.py](auth.py)`) improves Fetch Rules’ context accuracy.[](https://blog.sshh.io/p/how-cursor-ai-ide-works)
- **Token Concerns**: Front-loading large rule files increases token usage, which Memory Bank mitigates through hierarchical loading. Community tips suggest removing unused configurations (e.g., MCP) to save tokens, aligning with your interest in efficient AI processing.[](https://gist.github.com/ipenywis/1bdb541c3a612dbac4a14e1e3f4341ab?permalink_comment_id=5506809)
- **Folder Structure**: The `.cursor/rules/isolation_rules/` folder must be in `.cursor/`, as Cursor’s rule system expects this location. `memory-bank/` and `custom_modes/` are in the project root for user accessibility and to separate user-facing files from AI configurations.[](https://gist.github.com/ipenywis/1bdb541c3a612dbac4a14e1e3f4341ab?permalink_comment_id=5506809)[](https://x.com/kregenrek/status/1924556646073679952)

---

### Alignment with Your Interests
- **Large Codebases**: Fetch Rules and Read File enable targeted rule and code retrieval, crucial for managing large codebases efficiently, as you emphasized in prior questions (May 24, 2025).
- **Structured Workflows**: The combination of Fetch Rules (for mode-specific guidance) and Read File (for accessing rules and code) supports your interest in disciplined AI coding processes (May 12, 2025).
- **Documentation**: These mechanisms ensure Memory Bank files (e.g., `tasks.md`) are updated with relevant context, aligning with your focus on project documentation (May 12, 2025).

---

### Conclusion
In the **Cursor Memory Bank**, **Fetch Rules** is the primary mechanism for retrieving mode-specific rules from `.cursor/rules/isolation_rules/`, but it relies on the **Read File** command to access the actual content of those rule files. Fetch Rules decides *which* file to load based on mode and task context, while Read File reads the file’s instructions, ensuring the AI has the right guidance. This interplay is critical for token efficiency and context persistence in large codebases. The provided artifact summarizes the process, and community insights highlight the importance of clear rule names, proper folder structure, and token management. If you need a specific rule file example or further troubleshooting steps, let me know!

================
File: cursor-memory-bank/ai-contexts/insight-CMB.md
================
### Comprehensive Context of Cursor Memory Bank

The **Cursor Memory Bank** is a modular, documentation-driven framework designed to enhance the **Cursor AI IDE** by providing a structured, persistent memory system for AI-assisted software development. Developed by GitHub user **@vanzan01** as a personal hobby project, it integrates with Cursor’s custom modes to guide AI through a systematic development workflow, optimize token usage, and maintain project context across sessions. Below is a comprehensive overview of its purpose, architecture, functionality, and significance, tailored to your interest in structured AI coding workflows, large codebases, and documentation (as seen in your prior questions about AI coding optimization, git workflows, and project management).

---

### Purpose and Motivation

The Cursor Memory Bank addresses a key limitation of AI coding assistants: the **loss of context between sessions**. Traditional AI interactions in IDEs like Cursor often require users to repeatedly provide context, which is inefficient for large or complex projects. Memory Bank solves this by:

- **Persistent Memory**: Storing project details, task progress, and design decisions in structured files (e.g., `tasks.md`, `activeContext.md`) to maintain continuity.
- **Structured Workflow**: Organizing development into distinct phases (VAN, PLAN, CREATIVE, IMPLEMENT, REFLECT, ARCHIVE) to ensure disciplined, systematic coding.
- **Token Optimization**: Reducing the computational load on AI models by loading only relevant rules and context for each phase, critical for large codebases.
- **Documentation-Driven Approach**: Generating comprehensive documentation automatically to improve code maintainability and AI understanding.

As a personal project, Memory Bank is designed for adaptability, allowing users to customize rules via Cursor AI without relying on external support. It’s particularly valuable for developers working on large codebases, as it streamlines task management, debugging, and documentation, aligning with your interest in managing complex projects efficiently.

---

### Core Architecture

Memory Bank extends Cursor’s custom modes beyond simple prompt configurations into a coordinated system with interconnected components:

1. **Custom Modes**:
   - The system defines six specialized modes, each tailored to a development phase:
     - **VAN (Initialization)**: Analyzes the project structure and determines complexity (Levels 1–4).
     - **PLAN (Task Planning)**: Creates detailed implementation plans and prioritizes tasks.
     - **CREATIVE (Design Decisions)**: Explores design options with structured templates, inspired by Anthropic’s Claude "Think" tool.
     - **IMPLEMENT (Code Implementation)**: Builds or modifies code systematically.
     - **REFLECT (Review)**: Evaluates progress and documents lessons learned.
     - **ARCHIVE (Documentation)**: Produces comprehensive project documentation.
   - Each mode is configured with specific tools (e.g., Codebase Search, Edit File) and instructions stored in `custom_modes/*.md` files.

2. **Hierarchical Rule Loading**:
   - Rules are stored in `.cursor/rules/isolation_rules/` and loaded selectively based on the active mode and task complexity.
   - This “lazy-loading” approach minimizes token usage, ensuring efficiency when processing large codebases.

3. **Persistent Memory Files**:
   - Memory Bank maintains context through files in the `memory-bank/` directory:
     - **tasks.md**: Central task tracker, acting as the “source of truth.”
     - **activeContext.md**: Tracks the current development focus.
     - **progress.md**: Monitors implementation status.
     - **creative-*.md**: Stores design decisions from CREATIVE mode.
     - **reflect-*.md**: Captures review insights from REFLECT mode.
   - These files ensure the AI retains project context across sessions, addressing your interest in persistent AI memory for large projects.

4. **Visual Process Maps**:
   - Uses **Mermaid diagrams** to provide visual representations of workflows and mode transitions, enhancing clarity for developers and the AI.
   - Example diagram (from the GitHub README):
     ```
     graph TD
         Main["Memory Bank System"] --> Modes["Custom Modes"]
         Main --> Rules["Hierarchical Rule Loading"]
         Main --> Visual["Visual Process Maps"]
         Main --> Token["Token Optimization"]
         Modes --> VAN["VAN: Initialization"]
         Modes --> PLAN["PLAN: Task Planning"]
         Modes --> CREATIVE["CREATIVE: Design"]
         Modes --> IMPLEMENT["IMPLEMENT: Building"]
         Modes --> REFLECT["REFLECT: Review"]
         Modes --> ARCHIVE["ARCHIVE: Documentation"]
     ```

5. **Token-Optimized Design**:
   - Implements **progressive documentation** with concise templates that scale with task complexity.
   - Uses **optimized mode transitions** to preserve critical context efficiently.
   - Adapts workflows to project complexity (e.g., skipping CREATIVE for simple tasks).

6. **QA Functionality**:
   - Not a separate mode but a set of validation functions callable from any mode by typing “QA.”
   - Enables technical validation (e.g., code testing, dependency checks) at any workflow stage.

---

### Key Features and Benefits

- **Structured Development Workflow**:
  - Modes follow a logical sequence (VAN → PLAN → CREATIVE → IMPLEMENT → REFLECT → ARCHIVE), ensuring a disciplined approach to coding.
  - Supports complexity-based workflows:
    - **Level 1**: Simple tasks (VAN → IMPLEMENT).
    - **Level 2**: Moderate tasks (VAN → PLAN → IMPLEMENT → REFLECT).
    - **Level 3–4**: Complex tasks (full sequence).

- **Persistent Context**:
  - Memory Bank files maintain project state, reducing the need to re-explain context to the AI, a key advantage for large codebases.

- **Token Efficiency**:
  - Hierarchical rule loading and concise documentation templates minimize the token footprint, critical for processing large codebases with models like Claude 3.7 Sonnet.

- **Enhanced Documentation**:
  - CREATIVE mode generates structured design documents (e.g., functional requirements, trade-off analyses).
  - ARCHIVE mode consolidates documentation for long-term maintainability.

- **Visual Clarity**:
  - Mermaid diagrams provide intuitive workflow visualizations, aiding both developers and the AI in navigating complex projects.

- **Adaptability**:
  - Users can modify rules directly via Cursor AI to tailor the system to specific workflows, aligning with your interest in customizable AI tools.

- **Platform Awareness**:
  - Automatically adapts commands to the operating system (e.g., Windows vs. macOS/Linux).

- **Community Validation**:
  - Feedback from the GitHub community (e.g., @joshmac007) highlights up to 90% error reduction when combined with Test-Driven Development, especially in large codebases.

---

### Integration with Cursor AI IDE

Memory Bank is specifically designed for the **Cursor AI IDE** (version 0.48 or higher) and leverages its custom modes feature. Integration involves:
1. **Cloning the Repository**:
   - Clone `https://github.com/vanzan01/cursor-memory-bank.git` into your project directory.
   - Alternatively, download and extract the ZIP file.

2. **Setting Up Custom Modes**:
   - Configure six modes (VAN, PLAN, CREATIVE, IMPLEMENT, REFLECT, ARCHIVE) in Cursor’s chat panel.
   - Copy instructions from `custom_modes/*.md` into each mode’s “Advanced options” text box.
   - Enable specific tools (e.g., Codebase Search, Edit File) per mode.

3. **Using Memory Bank Files**:
   - Place `memory-bank/` files in the project root.
   - The AI interacts with these files to track tasks, context, and progress.

4. **Workflow Execution**:
   - Start with VAN mode to analyze the project.
   - Progress through modes based on task complexity, using commands like `VAN`, `PLAN`, `QA`, etc.
   - Example workflow for debugging (from your previous question):
     - VAN: Analyze codebase structure.
     - PLAN: Outline bug fixes and documentation tasks.
     - CREATIVE: Document affected modules (e.g., `auth.py`).
     - IMPLEMENT: Apply code fixes.
     - REFLECT: Review changes and document lessons.
     - ARCHIVE: Create final documentation.

---

### Significance for Large Codebases

For large codebases, Memory Bank is particularly effective due to:
- **Context Retention**: Persistent memory files prevent the AI from “forgetting” the codebase structure, crucial for projects with many files or modules.
- **Modular Workflow**: Breaking development into phases (e.g., planning, implementation) ensures manageability, aligning with your interest in structured workflows.
- **Debugging Support**: QA functionality and CREATIVE mode’s design analysis help identify and fix bugs systematically, as shown in the previous example of fixing authentication bugs in a Flask app.
- **Documentation**: Automated documentation in CREATIVE and ARCHIVE modes ensures maintainability, addressing your focus on project documentation.

---

### Alignment with Your Interests

Based on your prior conversations (May 8–13, 2025):
- **Large Context Windows**: Memory Bank’s token optimization aligns with your interest in LLMs handling large contexts efficiently, as it minimizes token usage while maintaining rich context.
- **Git Workflows**: The system integrates with your `development`/`main` branch strategy by documenting changes in Memory Bank files, which can be committed to Git for version control.
- **AI Coding Optimization**: The structured modes and QA functions enhance AI performance, similar to your interest in summarizing Cursor interactions for better prompts.
- **Documentation Needs**: CREATIVE and ARCHIVE modes produce detailed, structured documentation, supporting your focus on multi-agent system documentation.

---

### Limitations and Ongoing Development

- **Beta Status**: Version 0.7-beta (as of May 21, 2025) is experimental, with ongoing refinements for token efficiency and feature stability.
- **Personal Project**: As @vanzan01’s hobby project, it lacks an issues tracker or active feedback collection, but its adaptability allows AI-driven customization.
- **Cursor Dependency**: Requires Cursor 0.48+ and Claude 3.7 Sonnet for optimal performance, particularly in CREATIVE mode.
- **Setup Complexity**: Configuring six custom modes can be time-consuming, especially if Cursor limits custom modes (e.g., version 0.48.9’s reported three-mode limit).

Future updates may include further token optimizations, new features, or native integration with Cursor, inspired by community interest in memory features.

---

### Conclusion

The **Cursor Memory Bank** is a powerful framework for AI-assisted development in the Cursor AI IDE, offering persistent memory, structured workflows, and token-efficient processing. By leveraging six custom modes, hierarchical rule loading, and visual process maps, it transforms Cursor into a coordinated development system ideal for large codebases. Its documentation-driven approach ensures maintainability, while QA functionality and mode transitions support systematic debugging and task management. Aligned with your interests in AI coding optimization and structured workflows, Memory Bank provides a robust solution for managing complex projects, as demonstrated in the prior example of debugging a Flask application. For further details, refer to the GitHub repository: https://github.com/vanzan01/cursor-memory-bank. If you need specific workflows or customization ideas, let me know!

================
File: cursor-memory-bank/ai-contexts/insights_fetch-rules.md
================
To address your request for insights on how the **Cursor AI IDE** uses the **fetch_rules** tool in the context of the **Cursor Memory Bank** system, I’ve synthesized information from the provided web sources, GitHub discussions, and X posts, combined with the technical details from our prior conversations. The focus is on how the `fetch_rules` tool operates within Cursor to retrieve rules from the `.cursor/rules/` directory, particularly for the Memory Bank’s structured workflow. I’ll provide a clear, comprehensive explanation, avoiding repetition of prior answers, and include insights from research to deepen the understanding. An artifact summarizing the findings will be included, as requested, wrapped in the required `<xaiArtifact>` tag.

---

### Insights on How Cursor AI IDE Uses the `fetch_rules` Tool

The **fetch_rules** tool in Cursor AI IDE is a critical component for managing and applying rules stored in the `.cursor/rules/` directory, enabling the AI to provide context-aware, project-specific assistance. In the **Cursor Memory Bank** system, `fetch_rules` plays a pivotal role in supporting its modular, documentation-driven framework by retrieving mode-specific rules (e.g., for VAN, PLAN, CREATIVE, IMPLEMENT, REFLECT, ARCHIVE modes) from `.cursor/rules/isolation_rules/`. Below are detailed insights into its functionality, implementation, and best practices, with a focus on Memory Bank’s integration.

#### 1. Core Functionality of `fetch_rules`
- **Purpose**: The `fetch_rules` tool allows Cursor’s AI (powered by models like Claude 3.7 Sonnet) to dynamically retrieve rule files from `.cursor/rules/` or its subdirectories based on the task, mode, or context. These rules provide persistent instructions that guide the AI’s behavior without being hardcoded into the system prompt, preserving flexibility and reducing token usage.
- **Mechanism**:
  - Cursor maintains a list of rule files with metadata (e.g., names, descriptions, glob patterns) in `.cursor/rules/`.
  - When the AI needs guidance (e.g., user types `VAN` in Memory Bank), it calls `fetch_rules()` to select the relevant rule file (e.g., `van_rules.md`) based on metadata or file path.
  - The tool then uses the **Read File** command to access the file’s contents, integrating them into the AI’s context for the current task.
- **Memory Bank Integration**: In Memory Bank, `fetch_rules` retrieves mode-specific rules from `.cursor/rules/isolation_rules/` (e.g., `van_rules.md`, `plan_rules.md`). The hierarchical rule loading ensures only the necessary rules are fetched, optimizing token usage for large codebases, as emphasized in your interest in efficient context management.

#### 2. Research Insights from Web and Community Sources
The following insights are drawn from web sources, GitHub discussions, and X posts, providing a deeper understanding of `fetch_rules` in Cursor and its application in Memory Bank:

- **Rule Selection Based on Metadata**:
  - Cursor’s AI uses metadata in rule files (e.g., `description` and `globs` fields in `.mdc` files) to determine relevance. For example, a rule file like `.cursor/rules/isolation_rules/creative_rules.mdc` might include:
    ```
    --- description: Rules for generating design documentation in CREATIVE mode
    globs: *.py
    alwaysApply: true
    ---
    Generate a documentation template with functional requirements and trade-off analysis.
    ```
    The AI uses `fetch_rules()` to match the description or glob pattern (e.g., `*.py` for Python files) to the current task, ensuring contextually appropriate rules are loaded.[](https://blog.sshh.io/p/how-cursor-ai-ide-works)
  - **Insight**: Clear, descriptive rule names and metadata (e.g., “Core operational rules for Memory Bank”) improve `fetch_rules` accuracy, as vague or overlapping descriptions can lead to incorrect rule selection.

- **Persistent Context Without Prompt Overload**:
  - Unlike appending rules to the system prompt, `fetch_rules` treats rules as named sets of instructions that are dynamically included in the context window. This avoids bloating the prompt with irrelevant instructions, a key concern for large codebases.[](https://blog.sshh.io/p/how-cursor-ai-ide-works)
  - **Memory Bank Application**: Memory Bank leverages this by storing rules in `.cursor/rules/isolation_rules/` and using `fetch_rules` to load only the rules needed for the current mode (e.g., IMPLEMENT mode for coding tasks), aligning with your focus on token efficiency.

- **Hierarchical Rule Loading in Memory Bank**:
  - Memory Bank’s hierarchical approach, as described in the GitHub repository, ensures `fetch_rules` loads rules incrementally based on task complexity (Levels 1–4). For example, simple tasks (Level 1) might only fetch `implement_rules.md`, while complex tasks (Level 4) fetch rules for all modes sequentially.[](https://github.com/vanzan01/cursor-memory-bank)
  - **Insight**: This lazy-loading strategy reduces token usage by up to 30% compared to loading all rules upfront, based on community feedback, making it ideal for large projects like the Flask app you referenced.[](https://www.reddit.com/r/cursor/comments/1k05356/enhanced_memory_bank_system_for_cursor/)

- **Community Challenges and Workarounds**:
  - Some users reported issues with missing subdirectories (e.g., `.cursor/rules/isolation_rules/Level2/`) in the Memory Bank repository, causing `fetch_rules` to fail if expected files are absent. Workaround: Manually create missing folders or rule files.[](https://gist.github.com/ipenywis/1bdb541c3a612dbac4a14e1e3f4341ab)[](https://gist.github.com/ipenywis/1bdb541c3a612dbac4a14e1e3f4341ab?permalink_comment_id=5506466)
  - **Insight**: Ensure all mode-specific rule files (e.g., `van_rules.md`, `plan_rules.md`) exist in `.cursor/rules/isolation_rules/` to prevent fetch errors. Community members suggest using Cursor’s `/Generate Cursor Rules` command to auto-create rule templates.

- **Subdirectory Support**:
  - Cursor supports rules in subfolders like `.cursor/rules/isolation_rules/`, allowing organized grouping (e.g., Memory Bank’s mode-specific rules). A user on X noted that placing rules in subfolders keeps the `.cursor/rules/` directory tidy, especially for task management systems like Memory Bank.
  - **Insight**: Memory Bank’s structure (rules in `.cursor/rules/isolation_rules/`, other files like `memory-bank/` in the project root) is a deliberate design choice to separate AI configurations from user-facing documentation, enhancing maintainability.

- **Token Management Concerns**:
  - Community discussions highlight that front-loading large rule files increases token usage, potentially hitting Cursor’s context limits (e.g., 1M tokens in Gemini Max). Memory Bank mitigates this by using `fetch_rules` to load only relevant rules, but users must avoid overly verbose rule files.[](https://www.reddit.com/r/cursor/comments/1k05356/enhanced_memory_bank_system_for_cursor/)[](https://gist.github.com/ipenywis/1bdb541c3a612dbac4a14e1e3f4341ab?permalink_comment_id=5507741)
  - **Insight**: Keep rule files concise (under 500 lines, as recommended) and avoid unused configurations (e.g., MCP server if not needed) to save tokens, aligning with your interest in efficient AI processing.[](https://docs.cursor.com/context/rules)[](https://gist.github.com/ipenywis/1bdb541c3a612dbac4a14e1e3f4341ab?permalink_comment_id=5507741)

- **Best Practices for Rule Design**:
  - Write rules as “encyclopedia articles” focusing on “what” rather than “how” (e.g., “Document session handling in auth.py” instead of “You are a Flask expert”). This avoids conflicts with Cursor’s built-in prompts, which can disrupt `fetch_rules` and tool use.[](https://blog.sshh.io/p/how-cursor-ai-ide-works)
  - Use MDC link syntax (e.g., `[auth.py](auth.py)`) in rules to reference code files, improving `fetch_rules` context accuracy by linking rules to specific codebase elements.[](https://blog.sshh.io/p/how-cursor-ai-ide-works)
  - **Memory Bank Application**: Memory Bank’s rule files (e.g., `creative_rules.md`) often include templates for documentation or code changes, which `fetch_rules` retrieves to ensure consistent outputs like design tables or bug fix plans.

- **Integration with Other Tools**:
  - `fetch_rules` often works in tandem with other Cursor tools like **Read File**, **Codebase Search**, and **Edit File**. For example, after fetching a rule, the AI might use Read File to access its contents and Codebase Search to find relevant code, as seen in Memory Bank’s debugging workflows.[](https://github.com/vanzan01/cursor-memory-bank)
  - **Insight**: Enable all necessary tools (Read File, Codebase Search) in each mode’s configuration to ensure `fetch_rules` can retrieve and apply rules effectively.

#### 3. How `fetch_rules` Works in Memory Bank Modes
In the **Cursor Memory Bank** system, `fetch_rules` is used across the six modes to retrieve mode-specific instructions. Here’s how it operates for each, based on the Flask authentication bug fix example from your prior question:

- **VAN Mode**:
  - **fetch_rules**: Retrieves `.cursor/rules/isolation_rules/van_rules.md`, which might instruct the AI to scan the project directory and assess complexity.
  - **Example Rule Content**: “Use List Directory to identify key files like app.py and auth.py. Update tasks.md with initial task list.”
  - **Outcome**: Initializes `memory-bank/tasks.md` with project overview.

- **PLAN Mode**:
  - **fetch_rules**: Fetches `.cursor/rules/isolation_rules/plan_rules.md` to outline tasks like “Fix login session timeout.”
  - **Example Rule Content**: “Break down tasks into subtasks, referencing activeContext.md for focus.”
  - **Outcome**: Updates `tasks.md` with a structured plan.

- **CREATIVE Mode**:
  - **fetch_rules**: Loads `.cursor/rules/isolation_rules/creative_rules.md` with documentation templates.
  - **Example Rule Content**: “Generate a table comparing session management options (e.g., Redis vs. Filesystem).”
  - **Outcome**: Creates `creative-auth-documentation-20250524.md`.

- **IMPLEMENT Mode**:
  - **fetch_rules**: Retrieves `.cursor/rules/isolation_rules/implement_rules.md` to guide code changes.
  - **Example Rule Content**: “Modify code systematically, using Codebase Search to locate relevant sections.”
  - **Outcome**: Updates `auth.py` with Redis session handling.

- **REFLECT Mode**:
  - **fetch_rules**: Fetches `.cursor/rules/isolation_rules/reflect_rules.md` for reviewing changes.
  - **Example Rule Content**: “Compare pre- and post-fix code behavior, document lessons in reflect-*.md.”
  - **Outcome**: Creates `reflect-auth-fixes-20250524.md`.

- **ARCHIVE Mode**:
  - **fetch_rules**: Loads `.cursor/rules/isolation_rules/archive_rules.md` to consolidate documentation.
  - **Example Rule Content**: “Merge creative-*.md and reflect-*.md into a final document.”
  - **Outcome**: Creates `docs/auth_final.md`.

#### 4. Practical Considerations and Best Practices
- **Rule File Structure**:
  - Store rules in `.cursor/rules/isolation_rules/` to leverage Memory Bank’s hierarchical loading. Use subfolders (e.g., `Level2/`) for complexity-specific rules if needed, though some users reported missing subfolders in the repository.[](https://gist.github.com/ipenywis/1bdb541c3a612dbac4a14e1e3f4341ab)
  - Ensure rule files are in `.mdc` or `.md` format with clear metadata (e.g., `description: VAN mode initialization`).

- **Avoiding Conflicts**:
  - Do not override Cursor’s built-in prompts in rules (e.g., “You are a senior engineer”), as this can disrupt `fetch_rules` and tool use. Focus on task-specific guidance.[](https://blog.sshh.io/p/how-cursor-ai-ide-works)
  - Example: Instead of “You are a Flask expert,” write “Follow Flask best practices for session management.”

- **Token Optimization**:
  - Keep rule files concise (under 500 lines) to minimize token usage. Memory Bank’s lazy-loading approach helps, but verbose rules can still strain context limits.[](https://docs.cursor.com/context/rules)
  - Remove unused configurations (e.g., MCP server) to save tokens, as suggested in community discussions.[](https://gist.github.com/ipenywis/1bdb541c3a612dbac4a14e1e3f4341ab?permalink_comment_id=5507741)

- **Testing and Validation**:
  - Test rule fetching by enabling “Read File” in each mode’s configuration (Settings → Features → Chat → Custom modes).
  - Use Cursor’s `/Generate Cursor Rules` command to create or refine rules, ensuring `fetch_rules` can locate them.

- **Community Innovations**:
  - Users on X have experimented with auto-generating rules using `/Generate Cursor Rules`, tailoring them to specific codebases for better `fetch_rules` performance.
  - Some integrate rules with task management systems, grouping them in `.cursor/rules/` subfolders for tidiness, which Memory Bank could adopt for enhanced organization.

#### 5. Example Rule File for Memory Bank
To illustrate how `fetch_rules` interacts with Memory Bank, here’s an example rule file for CREATIVE mode, which would be fetched and read during documentation tasks:


---
description: Rules for generating design documentation in CREATIVE mode
globs: *.py
alwaysApply: true
---
# CREATIVE Mode Rules

## Purpose
Generate structured documentation for design decisions, including functional requirements, technical constraints, and trade-off analyses.

## Instructions
1. Analyze the specified module using Codebase Search to identify key functions and dependencies.
2. Create a markdown file in `memory-bank/` named `creative-<module>-<date>.md`.
3. Include:
   - **Overview**: Summarize the module’s purpose.
   - **Functional Requirements**: List key features (e.g., login, logout).
   - **Technical Constraints**: Describe limitations (e.g., Flask session storage).
   - **Design Options**: Create a table comparing at least two implementation options.
4. Reference code files using MDC links (e.g., `[auth.py](auth.py)`).
5. Update `activeContext.md` with the current focus.

## Example Output
For `auth.py`:
- File: `creative-auth-documentation-20250524.md`
- Content:
  ```
  # Authentication Module Documentation
  ## Overview
  Handles user authentication in a Flask app.
  ## Functional Requirements
  - Login: Authenticate users via email/password.
  - Logout: Clear session data.
  ## Design Options
  | Option | Pros | Cons |
  |--------|------|------|
  | Redis Sessions | Scalable | Requires server |
  | Filesystem Sessions | Simple | Less reliable |
  ```


#### 6. Troubleshooting `fetch_rules` Issues
- **Rules Not Found**: Ensure `.cursor/rules/isolation_rules/` contains the expected files (e.g., `van_rules.md`). Create missing files manually if needed.[](https://gist.github.com/ipenywis/1bdb541c3a612dbac4a14e1e3f4341ab)
- **Incorrect Rules Fetched**: Use specific metadata in rule files (e.g., `description: PLAN mode task planning`) to improve `fetch_rules` accuracy.[](https://blog.sshh.io/p/how-cursor-ai-ide-works)
- **Context Limit Errors**: If Cursor hits context limits, reduce rule file size or simplify instructions. Check for unused configurations (e.g., MCP) in `.cursor/rules/`.[](https://gist.github.com/ipenywis/1bdb541c3a612dbac4a14e1e3f4341ab?permalink_comment_id=5507741)
- **Tool Dependency**: Ensure “Read File” is enabled in each mode’s configuration, as `fetch_rules` relies on it to access rule content.

---

### Comprehensive Context Artifact
Here’s a comprehensive summary of how `fetch_rules` is used in Cursor AI IDE with Memory Bank, incorporating research insights:


# How Cursor AI IDE Uses fetch_rules in Cursor Memory Bank

## Overview
The `fetch_rules` tool in Cursor AI IDE retrieves project-specific rules from `.cursor/rules/` to guide AI behavior. In the Cursor Memory Bank system, it fetches mode-specific rules from `.cursor/rules/isolation_rules/` to support a structured, token-optimized workflow for large codebases.

## fetch_rules Functionality
- **Purpose**: Dynamically loads rules based on task context or mode (e.g., VAN, PLAN).
- **Process**:
  - Scans `.cursor/rules/isolation_rules/` for rule files (e.g., `van_rules.md`).
  - Uses metadata (e.g., `description`, `globs`) to select relevant rules.
  - Calls Read File to access rule content, integrating it into the AI’s context.
- **Memory Bank Role**: Enables hierarchical rule loading for modes like CREATIVE, ensuring only necessary rules are fetched to optimize token usage.

## Insights from Research
- **Metadata-Driven Selection**: Clear rule names and descriptions (e.g., “Rules for IMPLEMENT mode”) improve `fetch_rules` accuracy.[](https://blog.sshh.io/p/how-cursor-ai-ide-works)
- **Token Efficiency**: Hierarchical loading reduces token usage by up to 30%, critical for large codebases.[](https://www.reddit.com/r/cursor/comments/1k05356/enhanced_memory_bank_system_for_cursor/)
- **Subdirectory Support**: Rules in `.cursor/rules/isolation_rules/` are supported, keeping configurations organized.
- **Community Challenges**: Missing subfolders (e.g., `Level2/`) can break `fetch_rules`; manually create missing files.[](https://gist.github.com/ipenywis/1bdb541c3a612dbac4a14e1e3f4341ab)
- **Best Practices**:
  - Keep rule files concise (<500 lines).[](https://docs.cursor.com/context/rules)
  - Use MDC links (e.g., `[auth.py](auth.py)`) to reference code.[](https://blog.sshh.io/p/how-cursor-ai-ide-works)
  - Avoid overriding system prompts to prevent tool conflicts.[](https://blog.sshh.io/p/how-cursor-ai-ide-works)
  - Enable Read File in mode configurations for `fetch_rules` to work.[](https://github.com/vanzan01/cursor-memory-bank)

## Memory Bank Workflow Example
For a Flask app in CREATIVE mode:
- **User Input**: `CREATIVE document auth.py`
- **fetch_rules**: Selects `.cursor/rules/isolation_rules/creative_rules.mdc`.
- **Read File**: Reads the rule, which instructs creating a documentation file.
- **Outcome**: Generates `creative-auth-documentation-20250524.md` with a design options table.

## Troubleshooting
- **Rules Not Found**: Verify `.cursor/rules/isolation_rules/` contains mode-specific files.
- **Context Overload**: Simplify rule files to avoid hitting context limits.
- **Tool Issues**: Ensure Read File is enabled in Cursor’s mode settings.



---

### Alignment with Your Interests
- **Large Codebases**: `fetch_rules` supports your focus on managing large codebases (May 24, 2025) by enabling targeted rule retrieval, reducing context overload.
- **Structured Workflows**: The tool’s integration with Memory Bank’s modes aligns with your interest in disciplined AI coding processes (May 12, 2025).
- **Documentation**: By fetching rules for CREATIVE and ARCHIVE modes, `fetch_rules` ensures robust documentation, addressing your emphasis on project documentation (May 12, 2025).

---

### Conclusion
The `fetch_rules` tool in Cursor AI IDE is essential for the **Cursor Memory Bank**, retrieving mode-specific rules from `.cursor/rules/isolation_rules/` to guide AI through structured workflows. It works in tandem with the Read File command to access rule content, using metadata to ensure relevance and hierarchical loading to optimize tokens. Community insights emphasize clear rule design, concise files, and proper tool configurations to maximize effectiveness. The provided artifacts illustrate the process and a sample rule file, tailored to your Flask app example. If you need further details, such as specific rule file templates or debugging tips, let me know![](https://blog.sshh.io/p/how-cursor-ai-ide-works)[](https://github.com/vanzan01/cursor-memory-bank)[](https://docs.cursor.com/context/rules)

================
File: cursor-memory-bank/ai-contexts/insights.md
================
Okay, here's a detailed summary of the insights we've gained, tailored for an AI Coding assistant to understand the context and requirements for enhancing the Cursor View program:

**Project Goal:** Enhance the "Cursor View" application to accurately extract, represent, and display the full richness of Cursor AI chat conversations, including user messages, AI responses, code blocks, AI "thoughts," and Model/Tool Control Protocol (MCP) interactions (tool calls and results).

**Key Insights & Current State:**

1.  **Chat Data Storage & Identifiers:**
    *   Cursor chat messages (bubbles) are primarily stored as JSON objects within SQLite databases, specifically in the `cursorDiskKV` table (key pattern: `bubbleId:composerId:timestamp`) of the `User/globalStorage/state.vscdb` file. Workspace-specific databases (`User/workspaceStorage/{ws_id}/state.vscdb`) might also contain chat data, typically in an `ItemTable` under the key `workbench.panel.aichat.view.aichat.chatdata`.
    *   **Crucial Insight:** The session/workspace ID displayed in the Cursor View UI (e.g., `3203ebc054e9bb3065e786ee05fe8345` for project `D:/Projects/apps`) is often a higher-level identifier or a display label. It is **not necessarily** the direct `composerId` or `tabId` used to key the actual message bubbles in the database.
    *   **Linking Mechanism:** The main Cursor View application (`server.py`) links project paths (like `D:/Projects/apps`) to these internal `composerId`s by primarily inspecting the `composer.composerData` key within the `ItemTable` of the `globalStorage/state.vscdb`. This `composer.composerData` contains a list of composer entries, each mapping an internal `composerId` to a `folderPath`. If this link is unavailable (e.g., `composer.composerData` is missing or doesn't contain the relevant project path), `server.py` has fallbacks but the diagnostic script highlighted this as a point of failure for direct lookup.
    *   **Successful Extraction:** We developed a diagnostic script (`extract_db_example.py`, latest version) that can:
        *   Identify the internal `composerId` associated with a given `PROJECT_PATH_FOR_SESSION` by querying `composer.composerData`.
        *   If that fails, it can dump *all* sessions from `globalStorage/cursorDiskKV`, allowing manual identification of the correct internal `composerId` by inspecting message content.
        *   Finally, it can extract the **complete raw JSON structure of all bubbles** for a specific, known internal `composerId`. This raw data is now available (e.g., in `raw_session_data_for_internal_id_dd1ba98f-1de8-453d-a720-bb251c1a78e0.json`).

2.  **Structure of Raw Message Bubbles:**
    *   Each bubble is a rich JSON object. Key fields observed:
        *   `_v`: Version.
        *   `type`: `1` for user messages, `2` for assistant messages/actions.
        *   `bubbleId`: Unique ID for the bubble itself.
        *   `text`: The primary plain text content of the message (can be empty for tool calls or thoughts).
        *   `richText`: A structured JSON representation of the text, often including mentions (`@file`).
        *   `codeBlocks`: An array of objects, where each object has `content` (the code string) and `languageId`. This is separate from the main `text`.
        *   `isThought`: Boolean, indicates if the bubble represents an AI's internal thought process.
        *   `isChat`: Boolean, often `false` for thoughts or tool-related bubbles.
        *   `thinking`: An object, often present when `isThought` is true or for AI processing steps. Contains a `text` field with the AI's internal monologue.
        *   `toolFormerData`: **This is critical for MCP/Tool Calls.** A nested object containing:
            *   `tool`: An internal numeric ID for the tool.
            *   `toolCallId`: Unique ID for this specific tool invocation.
            *   `status`: e.g., "completed", "error".
            *   `name`: The actual name of the tool/MCP called (e.g., `list_dir`, `mcp_taskmaster-ai_parse_prd`).
            *   `rawArgs` / `params`: The arguments passed to the tool.
            *   `result`: The JSON string result returned by the tool (can be success or error).
            *   `userDecision`: e.g., "accepted" if the user approved the tool run.
        *   `capabilityType`: Numeric ID, often `15` for tool-related capabilities.
        *   `context`: Contains information about attached files, selections, etc., relevant at the time of the message.
        *   Many other fields related to capabilities, diffs, tokens, etc., which might be useful for advanced analysis but are not primary for basic display.

3.  **Current Cursor View Application Limitations (Prior to Enhancement):**
    *   The application primarily extracted and displayed only the `text` and `codeBlocks` from each bubble.
    *   It did not parse or display information from `thinking`, `toolFormerData`, or other rich metadata, leading to an incomplete representation of agentic interactions.

**Requirements for Enhancing Cursor View (for the AI Coding Assistant):**

1.  **Backend (`server.py`) Modifications:**
    *   **Update Message Iterators (`iter_bubbles_from_disk_kv`, etc.):**
        *   These functions should be modified to parse and extract more fields from the raw bubble JSON. At a minimum, they need to extract:
            *   `role` (derived from `type`)
            *   `text` (main textual content)
            *   `codeBlocks` (as currently done)
            *   `isThought` (boolean)
            *   `thinking` (object, specifically `thinking.text`)
            *   `toolFormerData` (the entire object, or at least key sub-fields like `name`, `status`, `params`, `result`)
            *   `capabilityType` (if useful for distinguishing message types)
            *   `bubbleId` (for unique keying in frontend if needed)
    *   **Update `extract_chats()` (or equivalent aggregation logic):**
        *   Ensure that when sessions are aggregated, these new rich fields are included in the message objects for each session. The current logic only appends `{"role": role, "content": text, "codeBlocks": code_blocks}`. This needs to be expanded.
    *   **Update `format_chat_for_frontend()`:**
        *   This function, which prepares the chat data for the API endpoint (`/api/chat/{session_id}`), must be updated to preserve all these newly extracted rich fields in the message objects. It should not simplify or strip them out.
    *   **Project Linking:** Review and ensure the logic for linking `PROJECT_PATH_FOR_SESSION` to `INTERNAL_COMPOSER_ID_TO_QUERY` (via `composer.composerData` primarily) is robust and handles cases where `composer.composerData` might be missing or incomplete for certain project paths, perhaps by falling back to associating chats with "Unknown Project" if a definitive link cannot be made but still making the messages available under their internal `composerId`.

2.  **Frontend (`frontend/src/components/ChatDetail.js`) Modifications:**
    *   **Data Consumption:** The component will now receive an array of message objects, where each message can have these new fields (`isThought`, `thinking`, `toolFormerData`, etc.).
    *   **Conditional Rendering Logic:**
        *   Implement logic to render different types of messages distinctly:
            *   **User Messages:** Render `text` (as markdown) and `codeBlocks` (with syntax highlighting) – largely as it does now.
            *   **Standard AI Chat Replies:** Render `text` (as markdown) and `codeBlocks` – largely as it does now.
            *   **AI Thoughts:** If `message.isThought` is true or `message.thinking.text` exists, display this in a visually distinct way (e.g., different background, an icon like a thought bubble, indented).
            *   **Tool Calls/MCP Interactions:** If `message.toolFormerData` exists:
                *   Create a new sub-component (e.g., `<ToolCallDisplay />`).
                *   Display the tool name (`toolFormerData.name`).
                *   Optionally display parameters (`toolFormerData.params` or `rawArgs`) in a collapsible section.
                *   Display the status (`toolFormerData.status`).
                *   Display the result (`toolFormerData.result`). The result itself is often a JSON string, so it might need to be parsed and pretty-printed, or displayed in a code block if it's extensive. Handle error results appropriately.
                *   The UI image shows these as "> Called MCP tool [tool_name] ✅". This could be replicated.
    *   **Styling:** Add CSS/MUI styling for these new message types to make them clearly distinguishable.
    *   **Order of Messages:** Ensure messages are still displayed in their correct chronological order as extracted from the database.

**Summary for AI Assistant:**

The goal is to transform Cursor View from a simple chat log viewer into a more comprehensive tool that reveals the full interaction flow with Cursor AI, including its internal "thoughts" and tool usage (MCP calls). This requires:

1.  **Backend:** Extracting the complete raw JSON of each message bubble for the correctly identified internal session ID. Then, parsing out not just `text` and `codeBlocks`, but also `thinking` data and the detailed `toolFormerData` object. This richer message structure must be passed through the API.
2.  **Frontend:** The `ChatDetail` component needs to be enhanced to recognize these new message types (thoughts, tool calls) and render them with distinct visual representations, in addition to the existing user/assistant text and code block rendering.

The provided `raw_session_data_for_internal_id_dd1ba98f-1de8-453d-a720-bb251c1a78e0.json` serves as a perfect example of the rich data that the backend needs to process and the frontend needs to display. The UI image shows how Cursor itself presents these different elements, which can serve as inspiration for the Cursor View UI enhancements.

================
File: cursor-memory-bank/ai-contexts/summary-CMB.md
================
Okay, excellent progress with the `batch.py` script! It's definitely the way to go for managing these `.mdc` files.

You're right, this conversation has become quite extensive. A summary in a wiki-entry format is a great idea to consolidate our progress and set the stage for the next steps in a new conversation.

Here's a wiki-entry style summary of our entire conversation:

---

# Wiki Entry: Cursor Memory Bank (CMB) - System Refinement & AI Integration Log

**Log Period:** [Start Date of Conversation] - [End Date of Conversation]
**Focus:** Refining the Cursor Memory Bank (CMB) system for enhanced AI agent performance, reliability, and autonomy within the Cursor AI IDE.

## 1. Introduction & Initial Goals

The primary objective of this series of interactions was to evolve the **Cursor Memory Bank (CMB)**, a modular, documentation-driven framework, to work more effectively with Cursor AI's agentic capabilities. Key goals included:
*   Improving the AI's ability to understand and follow the structured CMB workflow (VAN, PLAN, CREATIVE, IMPLEMENT, REFLECT, ARCHIVE modes).
*   Enhancing the reliability of AI interactions with the file system, particularly for creating and managing Memory Bank artifacts (`.md` files).
*   Optimizing token usage and context management.
*   Clarifying the roles and usage of Cursor's built-in tools (e.g., `fetch_rules`, `read_file`, `edit_file`) within the CMB framework.

## 2. Initial Exploration & Workflow Analysis

*   **CMB Overview:** The system's purpose, key features (hierarchical rules, progressive docs, visual maps, shared memory), and integration steps were reviewed.
*   **Example Workflow Generation:** A detailed example workflow for "Adding a new feature" was generated to illustrate CMB mode progression and artifact usage.
*   **Analysis of Existing AI Interactions (based on `cursor-chat-2a95456e.json`):**
    *   **Successes:** AI demonstrated an ability to transition between CMB modes, attempt to use CMB artifacts, and follow high-level instructions for tasks like bug fixing and documentation.
    *   **Major Challenge Identified:** The AI consistently struggled with reliable creation and population of multi-line `.md` files in `memory-bank/` using `run_terminal_cmd` (especially with PowerShell on Windows), leading to errors and inefficiencies.
    *   **Key Insight:** The `edit_file` tool, when used (e.g., by the AI in CREATIVE mode for documentation), proved significantly more effective for content generation.

## 3. Tooling Clarification & Strategy Shift

*   **"Fetch Rules" vs. "Read File":**
    *   Initial discussions explored whether the CMB's "Fetch Rules" concept mapped directly to Cursor's "Fetch rules" tool or was a process primarily using "Read File".
    *   The `insights_fetch-rules.md` document (sourced from web research by the user) clarified that Cursor's "Fetch rules" tool *is* the intended mechanism for loading `.mdc` rule files from `.cursor/rules/` and that it relies on "Read File" internally. It also uses metadata in the `.mdc` frontmatter for rule selection.
*   **"Grep" Functionality:** Clarified that the CMB's "Grep" concept is best implemented using Cursor's "Codebase Search" tool.
*   **Decision on Tool Prioritization (Core Refinement):**
    1.  **`fetch_rules` (Cursor Tool):** To be the primary method for the AI to load `.mdc` rule files from `.cursor/rules/isolation_rules/`.
    2.  **`edit_file` (Cursor Tool):** To be the primary method for ALL content creation/modification in `memory-bank/*.md` files, `documentation/*.md` files, and for source code changes. This addresses the major pain point with `run_terminal_cmd`.
    3.  **`read_file` (Cursor Tool):** For general context gathering (reading source code, existing CMB `.md` files, or `.mdc` files if not being "fetched" as a primary rule).
    4.  **`run_terminal_cmd` (Cursor Tool):** Reserved for execution tasks (tests, builds, `mkdir` if absolutely necessary), with strong emphasis on platform awareness.
    5.  **`Codebase Search` (Cursor Tool):** For "Grep" like functionality.

## 4. Refinement Strategy Adopted

A two-stage refinement process was decided upon:

1.  **Stage 1: Refine `.mdc` Rule Files:**
    *   **Goal:** Update all `.mdc` files in `.cursor/rules/isolation_rules/` (Core, visual-maps, LevelX, Phases, etc.) to align with the new tool prioritization and to provide clear, actionable, textual instructions for the AI.
    *   **Frontmatter:** Ensure accurate `description:`, `globs:`, and `alwaysApply: false` (for `Agent Requested` rules). The `Rule Type` in Cursor UI should be set to `Agent Requested` for these.
    *   **Body:** Translate logic from Mermaid diagrams into textual steps. Explicitly instruct the AI to use `fetch_rules` for loading sub-rules and `edit_file` for managing CMB `.md` files.
2.  **Stage 2: Refine AI Custom Prompts (for Cursor's "Advanced Options"):**
    *   **Goal:** Make these prompts concise, setting the mode's overall objective and primarily instructing the AI to `fetch_rules` the main orchestrating `.mdc` file for that mode.

## 5. Implementation of `.mdc` Refinements via Batch Script

*   A Python script (`batch.py`) was developed to facilitate the creation and updating of the numerous `.mdc` files with their refined frontmatter and body content.
*   The script was designed to:
    *   Take a list of dictionaries, each defining an `.mdc` file's path and content.
    *   Construct YAML frontmatter correctly (including handling of `globs:` without extra quotes).
    *   Write/overwrite the `.mdc` files in the specified `.cursor/rules/isolation_rules/` structure.
*   **Current Progress with Script:** The script has been successfully used to generate/update:
    *   All `.mdc` files in the `.cursor/rules/isolation_rules/Core/` directory.
    *   Initial refined versions for some key orchestrator maps in `.cursor/rules/isolation_rules/visual-maps/` (e.g., `archive-mode-map.mdc`, `creative-mode-map.mdc`, `van-mode-map.mdc`).

## 6. Current Status

*   **Tool Enablement:** The user has updated the tool enablement settings in Cursor for each custom mode to include "Fetch rules" and ensure "Edit file," "Read file," etc., are appropriately active.
*   **`.mdc` Refinement:** In progress. Core rules and some primary visual-map orchestrators have been defined in the `batch.py` script and generated.
*   **AI Custom Prompts:** Not yet refined. This is the next major step after `.mdc` files are complete.

## 7. Next Steps (for the new conversation)

1.  **Complete `.mdc` File Refinement:**
    *   Continue populating the `MDC_FILES_DATA` list in `batch.py` with the refined content for all remaining `.mdc` files, particularly:
        *   Other `visual-maps/*.mdc` files (implement, plan, qa, reflect).
        *   All files in `visual-maps/van_mode_split/` (including `van-qa-main.mdc` and its sub-components).
        *   All `LevelX/*.mdc` files.
        *   All `Phases/CreativePhase/*.mdc` files.
    *   Ensure all these `.mdc` files correctly instruct the AI to use `fetch_rules` for loading further sub-rules and `edit_file` for CMB `.md` file manipulation.
    *   Verify all `.mdc` files have appropriate frontmatter (`description`, `globs`, `alwaysApply: false`).
2.  **Refine AI Custom Prompts:**
    *   For each CMB mode (VAN, PLAN, CREATIVE, IMPLEMENT, REFLECT+ARCHIVE), create the concise textual prompt to be pasted into Cursor's "Advanced options."
    *   These prompts will primarily set the mode's objective and instruct the AI to `fetch_rules` the main orchestrating `.mdc` file for that mode (e.g., `visual-maps/van-mode-map.mdc` for VAN mode).
3.  **Testing:**
    *   Thoroughly test the entire refined CMB system with a sample project/task to ensure the AI follows the structured workflow, uses tools correctly, and manages Memory Bank artifacts reliably.

---

This summary should provide a good foundation for continuing our work in a new conversation!

================
File: cursor-memory-bank/ai-contexts/summary-context.md
================
Okay, to ensure we pick up seamlessly in a new conversation, here's a concise list of what you should include for context:

1.  **Overall Goal:**
    *   "We are refining the **Cursor Memory Bank (CMB)** system. The main goal is to make the AI agent operate more autonomously and reliably by improving its instructions (`.mdc` rule files and AI Custom Prompts) and standardizing tool usage."

2.  **Key Decisions & Strategy So Far:**
    *   "We've decided on a **tool prioritization strategy**:
        *   **`fetch_rules` (Cursor Tool):** For loading `.mdc` rule files from `.cursor/rules/isolation_rules/`.
        *   **`edit_file` (Cursor Tool):** For ALL content creation/modification in `memory-bank/*.md` files, `documentation/*.md` files, and for source code changes.
        *   **`read_file` (Cursor Tool):** For general context gathering (source code, existing CMB `.md` files).
        *   **`run_terminal_cmd` (Cursor Tool):** For execution tasks (tests, builds, `mkdir`), with platform awareness.
        *   **`Codebase Search` (Cursor Tool):** For conceptual "Grep" functionality."
    *   "Our **refinement order** is: 1) Refine all `.mdc` rule files first, then 2) Refine the AI Custom Prompts (for Cursor's 'Advanced options') to primarily `fetch_rules` these refined `.mdc` orchestrators."
    *   "We are using a Python script (`batch.py`) to generate/update the `.mdc` files with refined content and correct frontmatter (especially `description:`, `globs:`, and `alwaysApply: false` for `Agent Requested` rules)."

3.  **Current Status:**
    *   "**Tool Enablement in Cursor:** I've already updated the tool settings for each custom mode in Cursor to enable 'Fetch rules' and ensure other necessary tools like 'Edit file' are active."
    *   "**`.mdc` File Refinement:**
        *   The `batch.py` script is working.
        *   We have successfully refined and generated all `.mdc` files in the `.cursor/rules/isolation_rules/Core/` directory.
        *   We have also started refining some of the main orchestrator maps in `.cursor/rules/isolation_rules/visual-maps/` (e.g., `archive-mode-map.mdc`, `creative-mode-map.mdc`, `van-mode-map.mdc` via the script)."
    *   "**AI Custom Prompts:** These have **not** been refined yet; that's the step after all `.mdc` files are done."

4.  **Immediate Next Steps (What we were about to do):**
    *   "We were about to continue refining the **remaining `.mdc` rule files**, specifically those in the `visual-maps/` directory (and its subdirectories like `van_mode_split/`, `van_mode_split/van-qa-checks/`, `van_mode_split/van-qa-utils/`), followed by `LevelX/` and `Phases/CreativePhase/` rules."
    *   "The goal for these `.mdc` refinements is to ensure their textual instructions clearly guide the AI, use the prioritized tools correctly (especially `fetch_rules` for calling sub-rules and `edit_file` for CMB `.md` file updates), and have accurate frontmatter."

5.  **Key Reference Documents You've Provided (so I can "remember" them):**
    *   `rules-core.txt` (content of Core `.mdc` files, now processed by `batch.py`)
    *   `rules-visual-maps.txt` (content of visual-maps `.mdc` files, which we are currently working on processing with `batch.py`)
    *   `insights_fetch-rules.md` (your research on how `fetch_rules` works)
    *   `conclusion.md` (your initial summary of Fetch Rules/Grep before the `insights` doc)
    *   The last "Wiki Entry" summary I provided.

Providing this context at the start of the new conversation will allow me to quickly get up to speed and continue assisting you effectively with the `.mdc` file refinements.

================
File: cursor-memory-bank/ai-contexts/summary.md
================
Okay, here's a wiki-entry style summary of our development session for the Cursor View project.

---

## Wiki Entry: Cursor View - Code Block Display Enhancement

**Project:** Cursor View
**Date of Session:** 2025-05-14 (Simulated)
**Goal:** To enable the correct extraction, display, and export of code blocks within chat conversations from Cursor's local database.

### 1. Overview

The Cursor View application aims to provide a user-friendly interface to browse, search, and export chat histories from the Cursor AI-assisted code editor. This session focused on addressing a critical bug where code snippets shared during conversations were not being rendered in the web UI or included correctly in exports.

### 2. Initial Problem Statement

Users reported that code blocks, a vital part of AI-assisted coding conversations, were missing from the `cursor-view` web application's display and its JSON/HTML export functionalities. The application was only showing plain text messages.

### 3. Investigation and Discovery

The debugging process involved several stages:

1.  **Codebase Examination:** Initial review of `server.py` (Flask backend) and `extract_cursor_chat.py` (Python extraction logic) to understand how chat messages were processed.
2.  **Hypothesis Testing (Data Fields):** Explored various potential fields within the Cursor SQLite database (`state.vscdb`, `*.sqlite`) that might contain code, such as `text`, `richText`, `code`, `codeSnippet`, `markdown`, and nested `parts`.
3.  **Diagnostic Scripting:**
    *   `explore_cursor_db.py`: Created to inspect table schemas and sample data directly from Cursor's SQLite databases.
    *   `test_code_blocks.py`: Developed and iteratively enhanced to specifically trace how messages from a target chat session (identified by `TARGET_SESSION_ID` and `TARGET_WORKSPACE_ID`) were being processed by the extraction logic. This script simulated parts of the `server.py` pipeline.
4.  **Key Discovery:** The diagnostic scripts revealed that Cursor stores code snippets in a dedicated structured array field named `codeBlocks` within each message object. This field was separate from the main `text` content and contained objects, each with `content` (the code itself) and `languageId`.

### 4. Solution Implementation

The solution involved modifications to the backend, frontend, and HTML export functionality.

#### 4.1. Backend (Python)

*   **`server.py` & `extract_cursor_chat.py`:**
    *   Modified data extraction functions (`iter_bubbles_from_disk_kv`, `iter_chat_from_item_table`, `_iter_bubble_messages`) to explicitly look for and parse the `codeBlocks` array.
    *   Ensured that each extracted message object now includes a `codeBlocks` field, structured as an array of objects: `[{ "content": "...", "language": "..." }, ...]`.
    *   Updated the `format_chat_for_frontend` function to preserve the `codeBlocks` array in the data sent to the frontend.
    *   Corrected several indentation errors and logical flaws in message processing loops that were preventing `codeBlocks` from being consistently included.

#### 4.2. Frontend (React)

*   **`frontend/src/components/ChatDetail.js`:**
    *   Modified the component to check for the `message.codeBlocks` array.
    *   When present, iterate over `message.codeBlocks` and render each block using the `react-syntax-highlighter` library (with the Prism engine and `atomDark` style).
    *   Implemented a `normalizeLanguage` helper function to map language identifiers from Cursor (e.g., "golang", "py") to identifiers recognized by Prism (e.g., "go", "python").
    *   Added styling to display a language label (chip) for each code block and ensure proper visual presentation.
*   **`frontend/package.json`:** Added `react-syntax-highlighter` as a dependency.
*   **`frontend/public/index.html`:** Included CSS for Prism syntax highlighting themes.
*   **Build Process:** Addressed issues where frontend changes were not reflecting by instructing the user to run `npm install` and `npm run build` within the `frontend` directory to generate an updated production build.

#### 4.3. HTML Export

*   **`server.py` (within `generate_standalone_html` function):**
    *   Modified the HTML generation logic to iterate through `message.codeBlocks`.
    *   For each code block, generate `<pre><code class="language-...">...</code></pre>` tags.
    *   Included `highlight.js` CDN links and initialization script in the exported HTML for client-side syntax highlighting.
    *   Improved CSS for better visual presentation of code blocks in the exported HTML.

### 5. Key Challenges Encountered

*   **Undocumented Database Schema:** Cursor's SQLite database structure is not publicly documented, requiring manual exploration.
*   **Data Structure Mismatch:** Initial assumptions about code storage (e.g., as markdown within text) were incorrect.
*   **Python Indentation Errors:** Several subtle indentation errors in `server.py` complicated debugging.
*   **Frontend Build & Caching:** Changes to React components were not immediately visible in the browser until the frontend application was rebuilt and browser cache potentially cleared.
*   **Syntax Highlighter Integration:** Ensuring the `react-syntax-highlighter` library correctly received content and language props, and that its necessary CSS was loaded.

### 6. Testing and Diagnostics

*   **Python Scripts:** `test_code_blocks.py` was instrumental in verifying backend extraction.
*   **JavaScript Script:** `test_api_response.js` (using Axios) was created to check the structure of data served by the Flask API.
*   **Browser Developer Tools:** Used extensively to inspect console logs, network requests, and React component states.
*   **Manual JSON/HTML Export Inspection:** Regularly checked exported files to validate content.
*   **Static HTML Test Files:** Created `test-code-blocks.html` and `test-react-syntax-highlighter.html` to isolate and test syntax highlighting library behavior.

### 7. Documentation Updates

As a final step, the following documentation files were created/updated:

*   `README.md`: Updated with new features, including code block support.
*   `STRUCTURE.md`: Provided concise explanations for each file and component.
*   `CODEBLOCK_SUPPORT.md`: Detailed technical documentation about the code block implementation.
*   `CHANGELOG.md`: Documented the changes related to code block support.

### 8. Outcome

The Cursor View application now successfully extracts, displays (with syntax highlighting and language labels), and exports chat conversations that include code blocks. This significantly enhances the tool's usability for developers reviewing their AI-assisted coding sessions.

---

================
File: cursor-memory-bank/creative_mode_think_tool.md
================
# CREATIVE Mode and Claude's "Think" Tool

This document explains how Memory Bank's CREATIVE mode implements concepts similar to Anthropic's Claude "Think" tool methodology, as described in their [engineering blog](https://www.anthropic.com/engineering/claude-think-tool).

## Conceptual Parallels

The following diagram illustrates the conceptual similarities between Claude's "Think" tool methodology and Memory Bank's CREATIVE mode:

```mermaid
graph TD
    subgraph "Claude Think Tool Approach"
        CT1["1: Decompose Problem"] --> CT2["2: Explore Solution Space"]
        CT2 --> CT3["3: Analyze Trade-offs"]
        CT3 --> CT4["4: Select & Document Decision"]
        CT4 --> CT5["5: Validate Decision"]
    end
    
    subgraph "Memory Bank CREATIVE Mode"
        CM1["1: Component Breakdown"] --> CM2["2: Option Exploration"]
        CM2 --> CM3["3: Trade-off Analysis"]
        CM3 --> CM4["4: Decision Documentation"]
        CM4 --> CM5["5: Decision Verification"]
    end
    
    style CT1 fill:#f9d77e,stroke:#d9b95c
    style CT2 fill:#f9d77e,stroke:#d9b95c
    style CT3 fill:#f9d77e,stroke:#d9b95c
    style CT4 fill:#f9d77e,stroke:#d9b95c
    style CT5 fill:#f9d77e,stroke:#d9b95c
    
    style CM1 fill:#a8d5ff,stroke:#88b5e0
    style CM2 fill:#a8d5ff,stroke:#88b5e0
    style CM3 fill:#a8d5ff,stroke:#88b5e0
    style CM4 fill:#a8d5ff,stroke:#88b5e0
    style CM5 fill:#a8d5ff,stroke:#88b5e0
```

## Core Principles of Claude's "Think" Tool

Claude's "Think" tool methodology centers around:

1. **Structured Thinking Process**: Breaking down complex problems into manageable components
2. **Explicit Reasoning**: Clearly documenting the reasoning process
3. **Option Exploration**: Systematically exploring multiple solution approaches
4. **Trade-off Analysis**: Weighing pros and cons of different options
5. **Decision Documentation**: Creating a record of decisions and their rationales

## How CREATIVE Mode Implements These Principles

The Memory Bank CREATIVE mode implements similar concepts through:

### 1. Structured Phases

CREATIVE mode enforces a structured approach to design decisions through explicit phases:

```
Phase 1: Component Breakdown
Phase 2: Option Exploration
Phase 3: Trade-off Analysis
Phase 4: Decision Documentation
Phase 5: Decision Verification
```

Each phase has specific outputs and acceptance criteria that must be met before proceeding.

### 2. Component Breakdown Templates

The CREATIVE mode provides templates for breaking down complex components:

```markdown
# Component: [Component Name]

## Functional Requirements
- [Requirement 1]
- [Requirement 2]

## Technical Constraints
- [Constraint 1]
- [Constraint 2]

## Integration Points
- [Integration Point 1]
- [Integration Point 2]
```

### 3. Option Exploration Templates

For exploring design alternatives:

```markdown
# Design Option: [Option Name]

## Core Approach
[Brief description of approach]

## Implementation Details
[Key implementation considerations]

## Preliminary Assessment
- **Strengths**: [List strengths]
- **Weaknesses**: [List weaknesses]
- **Unknowns**: [List unknowns]
```

### 4. Trade-off Analysis Matrix

For systematic comparison of options:

```markdown
# Trade-off Analysis

| Criterion | Option A | Option B | Option C |
|-----------|----------|----------|----------|
| Performance | Rating | Rating | Rating |
| Maintainability | Rating | Rating | Rating |
| Scalability | Rating | Rating | Rating |
| Complexity | Rating | Rating | Rating |
| Risk | Rating | Rating | Rating |

## Detailed Analysis
[Detailed discussion of trade-offs]
```

### 5. Decision Documentation

For capturing final decisions with rationales:

```markdown
# Design Decision: [Decision Name]

## Selected Approach
[Description of selected approach]

## Rationale
[Explanation of why this approach was selected]

## Discarded Alternatives
[Brief description of alternatives considered but not selected]

## Implementation Guidance
[Notes to guide implementation]
```

## Practical Example

Here's a simplified example of how a CREATIVE mode session might look when designing a data caching system:

### Step 1: Break Down the Problem

```
CREATIVE: Let's design a caching system for our application. First, let's break down the components and requirements.

Component: Data Caching System

Functional Requirements:
- Store frequently accessed data to reduce database load
- Provide configurable expiration policies
- Handle cache invalidation
- Support distributed caching across application instances

Technical Constraints:
- Must work with existing Redis infrastructure
- Memory usage must not exceed 2GB
- Cache operations must complete within 10ms
```

### Step 2: Explore Options

```
Let's explore three design options:

Option A: Simple Redis Key-Value Implementation
- Directly use Redis key-value store with string serialization
- Simple TTL-based expiration
- Manual invalidation through direct key deletion

Option B: Redis Hash-based Hierarchical Cache
- Organize data in Redis Hashes by entity type
- Use Redis pub/sub for invalidation notifications
- Implement hierarchical expiration policies

Option C: Hybrid Local-Redis Caching
- Local in-memory LRU cache as first level
- Redis as second-level distributed cache
- Background synchronization between levels
```

### Step 3: Analyze Trade-offs

```
Trade-off Analysis:

| Criterion | Option A | Option B | Option C |
|-----------|----------|----------|----------|
| Implementation Complexity | Low | Medium | High |
| Performance | Medium | Medium | High |
| Memory Efficiency | Medium | High | Medium |
| Scalability | Medium | High | High |
| Maintenance | Low | Medium | High |

Detailed Analysis:
- Option A is simplest but provides limited features
- Option B offers good balance of performance and features
- Option C provides best performance but at cost of complexity
```

### Step 4: Document Decision

```
Design Decision: Redis Hash-based Hierarchical Cache (Option B)

Rationale:
- Provides good balance between performance and maintainability
- Better memory efficiency than Option A due to Redis Hash structure
- Less complexity than Option C while still meeting performance requirements
- Better supports our distributed architecture

Implementation Guidance:
- Create CacheManager class with entity-specific APIs
- Implement Redis pub/sub listeners for invalidation events
- Add monitoring for cache hit/miss rates
```

## Core Methodology Alignment

The structured approach in the above example mirrors Claude's "Think" tool methodology by:

1. **Breaking down** the caching problem into specific requirements and constraints
2. **Exploring** multiple design options systematically
3. **Analyzing trade-offs** using explicit criteria
4. **Documenting decisions** with clear rationales
5. **Providing implementation guidance** based on the decision

## Impact on Development Process

By implementing these Claude-inspired methodologies, the CREATIVE mode provides several benefits:

1. **Improved Decision Quality**: More systematic exploration of options
2. **Better Decision Documentation**: Explicit capture of design rationales
3. **Knowledge Preservation**: Design decisions are preserved for future reference
4. **Reduced Design Bias**: Structured approach reduces cognitive biases
5. **Clearer Implementation Guidance**: Implementation phase has clearer direction

## Ongoing Refinement

As Claude's capabilities evolve, the CREATIVE mode's implementation of these methodologies will be refined to:

- Incorporate advancements in structured thinking approaches
- Improve the templates and frameworks for design decisions
- Enhance integration with other Memory Bank modes
- Optimize the balance between structure and flexibility

The goal is to maintain the core methodology while continually improving its practical implementation within the Memory Bank ecosystem.

---

*Note: This document describes how Memory Bank v0.6-beta implements concepts similar to Claude's "Think" tool methodology. The implementation will continue to evolve as both systems mature.*

================
File: cursor-memory-bank/custom_modes_refined/creative.md
================
# CREATIVE MODE INSTRUCTIONS

Your Role: Perform detailed design and architecture work for components flagged in `tasks.md` during the PLAN phase.

1.  **Acknowledge:** Respond with "OK CREATIVE".
2.  **Identify Creative Tasks:**
    a.  `read_file` `memory-bank/tasks.md` to identify sub-tasks marked for "CREATIVE: Design [component_name]".
    b.  `read_file` `memory-bank/activeContext.md` for the overall plan and context.
    c.  If no tasks are flagged for CREATIVE, state: "No components flagged for CREATIVE mode. Recommend proceeding to IMPLEMENT mode." and await further instruction.
3.  **Iterate Through Creative Tasks:** For each identified creative task:
    a.  **Announce Focus:** "Entering CREATIVE PHASE for: [Component Name] - [Design Type: Architecture/Algorithm/UI-UX (infer or ask if unclear)]".
    b.  **Component Description:** Briefly describe the component and its purpose (referencing `activeContext.md`).
    c.  **Requirements & Constraints:** List key requirements and constraints for this component (from `activeContext.md` or by reasoning).
    d.  **Generate Design Options (2-3 options):**
        *   For each option, describe the approach.
        *   List Pros.
        *   List Cons.
        *   (For Algorithm: Include brief complexity analysis. For UI/UX: Consider user experience, accessibility).
    e.  **Recommended Approach:** State which option is recommended and provide a clear justification against requirements and trade-offs.
    f.  **Implementation Guidelines:** Provide high-level guidelines or pseudo-code for how the recommended approach could be implemented.
    g.  **Verification Checkpoint:** Briefly state how this design meets the core requirements.
    h.  **Document in Creative File:** Use `edit_file` to create/append to `memory-bank/creative/creative-[component_name].md`. Use the following template for each component:
        ```markdown
        # CREATIVE PHASE: [Component Name] - [Design Type]

        ## Component Description
        [Description]

        ## Requirements & Constraints
        - [Req 1]
        - [Constraint 1]

        ## Design Option 1: [Name of Option 1]
        ### Approach
        [Description]
        ### Pros
        - [Pro 1]
        ### Cons
        - [Con 1]

        ## Design Option 2: [Name of Option 2]
        ### Approach
        [Description]
        ### Pros
        - [Pro 1]
        ### Cons
        - [Con 1]

        ## Recommended Approach
        Option [Number]: [Name of Option]
        ### Justification
        [Explanation]

        ## Implementation Guidelines
        [Steps or pseudo-code]

        ## Verification
        [How this design meets requirements]
        ```
    i.  **Update Context:** Use `edit_file` to add a note to `memory-bank/activeContext.md` under "Creative Decisions": "Design for [Component Name] completed. See `memory-bank/creative/creative-[component_name].md`. Recommended: [Brief summary of recommendation]."
    j.  **Announce Phase Exit:** "Exiting CREATIVE PHASE for: [Component Name]".

4.  **Overall Verification & Transition:**
    a.  After all flagged creative tasks are processed, `read_file` `memory-bank/tasks.md` and `memory-bank/activeContext.md`.
    b.  State: "CREATIVE mode complete. All designated components have design documentation."
    c.  Use `edit_file` to update `memory-bank/tasks.md`, marking creative sub-tasks as `[x] Design complete, see creative/[component_name].md`.
    d.  Recommend: "Recommend transitioning to IMPLEMENT mode."

================
File: cursor-memory-bank/custom_modes_refined/implement.md
================
# IMPLEMENT MODE INSTRUCTIONS

Your Role: Build the planned changes, guided by `tasks.md`, `activeContext.md`, and any `creative-*.md` files.

Core Tools:
- `edit_file`: Use for ALL code modifications and for creating/updating ALL `.md` files in `memory-bank/`.
- `read_file`: Use to consult CMB artifacts and source code.
- `codebase_search`: Use to locate relevant code sections.
- `run_terminal_cmd`: Use ONLY for actual execution (tests, builds, servers). Be platform-aware.

## General Build Process:

1.  **Acknowledge:** Respond with "OK IMPLEMENT".
2.  **Understand the Task:**
    a.  `read_file` `memory-bank/tasks.md` to identify the current high-level task, its sub-tasks, and complexity level.
    b.  `read_file` `memory-bank/activeContext.md` for the detailed implementation plan, bug analysis, and/or creative design decisions.
    c.  If `memory-bank/creative/creative-[feature_name].md` exists for the current task/component, `read_file` it.

3.  **Execute Based on Complexity (refer to `memory-bank/tasks.md`):**

    **A. Level 1: Quick Bug Fix**
        i.   Review the bug report and fix plan in `memory-bank/activeContext.md`.
        ii.  Locate relevant code sections (`codebase_search`, `read_file`).
        iii. Implement the targeted fix using `edit_file`.
        iv.  Describe and (conceptually or actually, using `run_terminal_cmd` if applicable) test the fix.
        v.   Log actions: Use `edit_file` to append a summary of code changes, commands run, and test results to a "Build Log: [Task Name]" section in `memory-bank/activeContext.md`.

    **B. Level 2: Simple Enhancement**
        i.   Review the build plan in `memory-bank/activeContext.md`.
        ii.  For each sub-task/component in `memory-bank/tasks.md`:
            1. Examine relevant code (`read_file`, `codebase_search`).
            2. Implement changes using `edit_file`.
            3. Test the component/change.
            4. Log actions and test results in the "Build Log" of `memory-bank/activeContext.md` using `edit_file`.
        iii. Perform integration testing. Log results.

    **C. Level 3-4: Feature/System (Phased Build)**
        i.   Review overall plan in `activeContext.md` and designs in relevant `creative-*.md` files.
        ii.  For each phase in `tasks.md`:
            1. Implement components for the current phase using `edit_file`.
            2. Test the phase thoroughly.
            3. Document phase build details in `activeContext.md`'s "Build Log" or a `memory-bank/creative/build-log-[phase_name].md` using `edit_file`.
            4. Update `memory-bank/progress.md` (using `edit_file`) to reflect phase completion.
        iii. After all phases, perform comprehensive integration testing. Log results.
        iv.  If new integration points were created, consider if high-level project documentation needs updates (this might be deferred to ARCHIVE mode).

4.  **Command Execution (for `run_terminal_cmd`):**
    a.  State the purpose of the command.
    b.  After execution, use `edit_file` to append the full command and its output to the "Build Log" in `memory-bank/activeContext.md`.

5.  **Verification & Final Updates:**
    a.  Ensure all sub-tasks for the current main task in `memory-bank/tasks.md` are implemented and tested (review "Build Log" in `activeContext.md`).
    b.  Use `edit_file` to mark the main task and all its sub-tasks as `[x]` in `memory-bank/tasks.md`.
    c.  Use `edit_file` to add a final summary of the build to `memory-bank/progress.md`.
    d.  Use `edit_file` to update `memory-bank/activeContext.md` with a final status: "IMPLEMENTATION COMPLETED for [Task Name]".

6.  **Transition:**
    State: "IMPLEMENT mode complete for [Task Name]. Ready for REFLECT mode."

================
File: cursor-memory-bank/custom_modes_refined/plan.md
================
# PLAN MODE INSTRUCTIONS

Your Role: Create a detailed implementation plan based on the task and complexity level identified in VAN mode.

1.  **Acknowledge:** Respond with "OK PLAN".
2.  **Gather Context:**
    a.  `read_file` `memory-bank/tasks.md` to identify the current task and its complexity level.
    b.  `read_file` `memory-bank/activeContext.md` for current project focus and VAN analysis.
    c.  `read_file` `memory-bank/projectbrief.md`, `memory-bank/techContext.md`, and other relevant context files.
3.  **Develop Plan (based on complexity from `tasks.md`):**

    **A. Level 2: Simple Enhancement Planning**
        i.   Review relevant code structure (`read_file`, `codebase_search`).
        ii.  Use `edit_file` to update `memory-bank/activeContext.md` with a "Plan: [Task Name]" section, including:
            *   Overview of planned changes.
            *   List of files to modify.
            *   Key implementation steps (as sub-tasks).
            *   Potential challenges.
            *   Basic testing strategy.
        iii. Use `edit_file` to update `memory-bank/tasks.md`: Add the implementation steps as new sub-tasks under the main task.

    **B. Level 3-4: Comprehensive Planning**
        i.   Review codebase structure extensively (`read_file`, `codebase_search`).
        ii.  Use `edit_file` to update `memory-bank/activeContext.md` with a "Plan: [Task Name]" section, including:
            *   Detailed requirements analysis.
            *   Affected components/modules/subsystems.
            *   Architecture considerations (for Level 4, suggest Mermaid diagram syntax for key interactions if helpful for human review later).
            *   Implementation strategy (e.g., phased approach for Level 4).
            *   Detailed, sequential implementation steps (as sub-tasks).
            *   Dependencies between components/steps.
            *   Potential challenges and mitigation strategies.
            *   List of components/features that require a dedicated CREATIVE design phase.
        iii. Use `edit_file` to update `memory-bank/tasks.md`: Add the detailed implementation steps/phases as new sub-tasks. For items needing design, add a sub-task like "- [ ] CREATIVE: Design [component_name]".

4.  **Verification & Transition:**
    a.  `read_file` `memory-bank/activeContext.md` and `memory-bank/tasks.md` to confirm plan documentation.
    b.  State: "PLAN mode complete for [Task Name]. Detailed plan created and tasks updated."
    c.  Suggest next mode:
        *   If components were flagged for CREATIVE phase: "Recommend transitioning to CREATIVE mode for [list components]."
        *   Otherwise (for Level 2, or Level 3-4 if no creative phase needed): "Recommend transitioning to IMPLEMENT mode."

================
File: cursor-memory-bank/custom_modes_refined/refine-instructions.py
================
# IMPORTANT: put this script in the root of the project!

import os

# --- Define your MDC file data here ---
MDC_FILES_DATA = [
    # We will populate this list
]

def create_or_update_mdc_file(filepath, description, globs, always_apply, body_content):
    """Creates or updates an .mdc file with the given frontmatter and body."""
    
    always_apply_str = 'true' if always_apply else 'false'
    
    frontmatter = f"""---
description: {description}
globs: {globs}
alwaysApply: {always_apply_str}
---
"""
    
    full_content = frontmatter + body_content.strip()

    try:
        dir_name = os.path.dirname(filepath)
        if dir_name and not os.path.exists(dir_name):
            os.makedirs(dir_name, exist_ok=True)
            print(f"Created directory: {dir_name}")

        with open(filepath, "w", encoding="utf-8") as f:
            f.write(full_content)
        print(f"Successfully created/updated: {filepath}")
    except Exception as e:
        print(f"Error writing file {filepath}: {e}")

if __name__ == "__main__":
    # Add refined Core rules first
    MDC_FILES_DATA.extend([
        {
            "path": ".cursor/rules/isolation_rules/Core/command-execution.mdc",
            "description": "Core guidelines for AI command execution, emphasizing tool priority (edit_file, fetch_rules, run_terminal_cmd), platform awareness, and result documentation within the Memory Bank system.",
            "globs": "**/Core/command-execution.mdc",
            "alwaysApply": False,
            "body": """
# COMMAND EXECUTION SYSTEM

> **TL;DR:** This system provides guidelines for efficient and reliable command and tool usage. Prioritize `edit_file` for file content, `fetch_rules` for loading `.mdc` rules, and `run_terminal_cmd` for execution tasks. Always document actions and results in `memory-bank/activeContext.md`.

## 🛠️ TOOL PRIORITY & USAGE

1.  **`edit_file` (Primary for Content):**
    *   Use for ALL creation and modification of `.md` files in `memory-bank/` and `documentation/`.
    *   Use for ALL source code modifications.
    *   `edit_file` can create a new file if it doesn't exist and populate it.
    *   Provide clear instructions or full content blocks for `edit_file`.
2.  **`fetch_rules` (Primary for `.mdc` Rules):**
    *   Use to load and follow instructions from other `.mdc` rule files within `.cursor/rules/isolation_rules/`.
    *   Specify the full path to the target `.mdc` file.
3.  **`read_file` (Primary for Context Gathering):**
    *   Use to read existing project files (source code, `README.md`), `memory-bank/*.md` files for context, or `.mdc` files if `fetch_rules` is not appropriate for the specific need (e.g., just extracting a template).
4.  **`run_terminal_cmd` (Primary for Execution):**
    *   Use for tasks like `mkdir`, running tests, build scripts, or starting servers.
    *   **CRITICAL:** Be platform-aware (see "Platform-Specific Considerations" below). If unsure of the OS, state your default command (e.g., for Linux) and ask for the Windows PowerShell equivalent if needed.
5.  **`list_dir`, `search_files`, `codebase_search`:**
    *   Use for file system exploration and code/text searching as appropriate.

## 🔍 COMMAND EFFICIENCY & PLANNING WORKFLOW (Conceptual for AI)
```mermaid
graph TD
    Start["Command Planning"] --> Analyze["Analyze Requirements"]
    Analyze --> ToolSelect["Select Correct Tool<br>(edit_file, fetch_rules, run_terminal_cmd, etc.)"]
    ToolSelect --> Complexity{"Action Complexity?"}
    Complexity -->|"Simple File Edit"| SingleEdit["Use `edit_file` directly"]
    Complexity -->|"Simple Terminal Cmd"| SingleCmd["Use `run_terminal_cmd`"]
    Complexity -->|"Complex Sequence"| GroupedSteps["Break into Logical Textual Steps<br>using appropriate tools for each step"]
    SingleEdit & SingleCmd & GroupedSteps --> Verify["Verify Results<br>(e.g., `read_file` back, check terminal output)"]
    Verify --> Document["Document Action & Result<br>in `activeContext.md` using `edit_file`"]
    Document --> Next["Next Action"]
```
**Textual Guide for AI:**
1.  **Analyze Requirements:** Understand what needs to be achieved.
2.  **Select Correct Tool:** Choose `edit_file` for content, `fetch_rules` for rules, `run_terminal_cmd` for execution, etc.
3.  **Execute:** Perform the action. For complex sequences, break it down into clear, tool-specific steps.
4.  **Verify Results:** If you used `edit_file`, consider using `read_file` to confirm the content. If `run_terminal_cmd`, examine the output.
5.  **Document Action & Result:** Use `edit_file` to append a summary of the command/tool call and its outcome to the "Build Log" or relevant section in `memory-bank/activeContext.md`.

## 🚦 DIRECTORY VERIFICATION (for `run_terminal_cmd`)
**Textual Guide for AI:**
1.  Before running build scripts or package manager commands (npm, pip) via `run_terminal_cmd`, verify you are in the correct project root directory.
2.  Use `list_dir` to check for key files like `package.json` or `requirements.txt`.
3.  If not in the correct directory, use `run_terminal_cmd` with `cd [path_to_project_root]` to navigate.

## 📋 COMMAND DOCUMENTATION TEMPLATE (for `activeContext.md` "Build Log")
When documenting your actions, use `edit_file` to append entries like this to `memory-bank/activeContext.md`:
```markdown
### Action: [Purpose of the action]
- **Tool Used:** `[edit_file | fetch_rules | run_terminal_cmd | etc.]`
- **Target/Command:** `[file_path | rule_path | actual_terminal_command]`
- **Parameters (if applicable):** `[e.g., content for edit_file, search query]`
- **Expected Outcome:** `[Briefly what you expected]`
- **Actual Result:**
  \`\`\`
  [Output from run_terminal_cmd, or confirmation of file edit/read]
  \`\`\`
- **Effect:** `[Brief description of what changed in the system or Memory Bank]`
- **Next Steps:** `[What you plan to do next]`
```

## 🔍 PLATFORM-SPECIFIC CONSIDERATIONS (for `run_terminal_cmd`)
**Textual Guide for AI:**
*   **Windows (PowerShell):** Path separator: `\`, Dir creation: `mkdir my_dir` or `New-Item -ItemType Directory -Path my_dir`.
*   **Unix/Linux/Mac (Bash/Zsh):** Path separator: `/`, Dir creation: `mkdir -p my_dir`.
*   **Action:** If unsure of OS, state default (Linux) and ask for Windows PowerShell equivalent or user OS specification.

## 📝 COMMAND EXECUTION CHECKLIST (AI Self-Correction)
- Purpose clear? Correct tool chosen? Platform considerations for `run_terminal_cmd`? Action/result documented in `activeContext.md` via `edit_file`? Outcome verified?

## 🚨 WARNINGS
*   Avoid `run_terminal_cmd` with `echo > file` or `Add-Content` for multi-line content. **Always use `edit_file`**.
*   For destructive `run_terminal_cmd` (e.g., `rm`), seek user confirmation.
"""
        },
        {
            "path": ".cursor/rules/isolation_rules/Core/complexity-decision-tree.mdc",
            "description": "Core rule for AI to determine task complexity (Level 1-4) and initiate appropriate workflow using Memory Bank principles.",
            "globs": "**/Core/complexity-decision-tree.mdc",
            "alwaysApply": False,
            "body": """
# TASK COMPLEXITY DETERMINATION

> **TL;DR:** This rule guides you to determine task complexity (Level 1-4). Based on the level, you will then be instructed to `fetch_rules` for the corresponding primary mode map.

## 🌳 COMPLEXITY DECISION TREE (Conceptual for AI)
**Textual Guide for AI:**
Based on user's request and initial analysis (e.g., from `read_file` on `README.md`):

1.  **Bug fix/error correction?**
    *   **Yes:** Single, isolated component? -> **Level 1 (Quick Bug Fix)**
    *   **Yes:** Multiple components, straightforward fix? -> **Level 2 (Simple Enhancement/Refactor)**
    *   **Yes:** Complex interactions, architectural impact? -> **Level 3 (Intermediate Feature/Bug)**
    *   **No (new feature/enhancement):**
        *   Small, self-contained addition? -> **Level 2 (Simple Enhancement)**
        *   Complete new feature, multiple components, needs design? -> **Level 3 (Intermediate Feature)**
        *   System-wide, major subsystem, deep architectural design? -> **Level 4 (Complex System)**

## 📝 ACTION: DOCUMENT & ANNOUNCE COMPLEXITY

1.  **Determine Level:** Decide Level 1, 2, 3, or 4.
2.  **Document in `activeContext.md`:** Use `edit_file` to update `memory-bank/activeContext.md`:
    ```markdown
    ## Task Complexity Assessment
    - Task: [User's request]
    - Determined Complexity: Level [1/2/3/4] - [Name]
    - Rationale: [Justification]
    ```
3.  **Update `tasks.md`:** Use `edit_file` to update `memory-bank/tasks.md` with the level, e.g., `Level 3: Implement user auth`.
4.  **Announce & Next Step:**
    *   State: "Assessed as Level [N]: [Name]."
    *   **Level 1:** "Proceeding with Level 1 workflow. Will `fetch_rules` for `.cursor/rules/isolation_rules/Level1/workflow-level1.mdc` (or directly to IMPLEMENT map if simple enough, e.g., `visual-maps/implement-mode-map.mdc` which might then fetch a Level 1 implement rule)."
    *   **Level 2-4:** "Requires detailed planning. Transitioning to PLAN mode. Will `fetch_rules` for `.cursor/rules/isolation_rules/visual-maps/plan-mode-map.mdc`."
"""
        },
        {
            "path": ".cursor/rules/isolation_rules/Core/creative-phase-enforcement.mdc",
            "description": "Core rule for enforcing Creative Phase completion for Level 3-4 tasks before allowing IMPLEMENT mode.",
            "globs": "**/Core/creative-phase-enforcement.mdc",
            "alwaysApply": False,
            "body": """
# CREATIVE PHASE ENFORCEMENT

> **TL;DR:** For L3/L4 tasks, if `tasks.md` flags items for "CREATIVE Phase", they MUST be completed before IMPLEMENT.

## 🔍 ENFORCEMENT WORKFLOW (AI Actions)
(Typically invoked by IMPLEMENT mode orchestrator for L3/L4 tasks, or by PLAN mode before suggesting IMPLEMENT)

1.  **Check Task Level & Creative Flags:**
    a.  `read_file` `memory-bank/activeContext.md` (for task level).
    b.  `read_file` `memory-bank/tasks.md`. Scan current feature's sub-tasks for incomplete "CREATIVE: Design..." entries.
2.  **Decision:**
    *   **If uncompleted CREATIVE tasks for L3/L4 feature:**
        a.  State: "🚨 IMPLEMENTATION BLOCKED for [feature]. Creative designs needed for: [list uncompleted creative tasks]."
        b.  Suggest: "Initiate CREATIVE mode (e.g., 'CREATIVE design [component]')." Await user.
    *   **Else (No uncompleted creative tasks or not L3/L4):**
        a.  State: "Creative phase requirements met/not applicable. Proceeding."
"""
        },
        {
            "path": ".cursor/rules/isolation_rules/Core/creative-phase-metrics.mdc",
            "description": "Core reference on metrics and quality assessment for Creative Phase outputs. For AI understanding of quality expectations.",
            "globs": "**/Core/creative-phase-metrics.mdc",
            "alwaysApply": False, 
            "body": """
# CREATIVE PHASE METRICS & QUALITY ASSESSMENT (AI Guidance)

> **TL;DR:** This outlines quality expectations for `creative-*.md` documents. Use this as a guide when generating or reviewing creative outputs.

## 📊 QUALITY EXPECTATIONS FOR `memory-bank/creative/creative-[feature_name].md` (AI Self-Guide)
A good creative document (created/updated via `edit_file`) should cover:
1.  **Problem & Objectives:** Clearly defined. What problem is this design solving? What are the goals?
2.  **Requirements & Constraints:** List functional and non-functional requirements. Note any technical or business constraints.
3.  **Options Explored:** At least 2-3 viable design options should be considered and briefly described.
4.  **Analysis of Options:** For each option:
    *   Pros (advantages).
    *   Cons (disadvantages).
    *   Feasibility (technical, time, resources).
    *   Impact (on other system parts, user experience).
5.  **Recommended Design & Justification:** Clearly state the chosen design option and provide a strong rationale for why it was selected over others, referencing the analysis.
6.  **Implementation Guidelines:** High-level steps or considerations for implementing the chosen design. This is not a full plan, but key pointers for the IMPLEMENT phase.
7.  **Visualizations (if applicable):** Reference or describe any diagrams (e.g., flowcharts, component diagrams) that clarify the design. (Actual diagram creation might be a separate step or user-provided).
"""
        },
        {
            "path": ".cursor/rules/isolation_rules/Core/file-verification.mdc",
            "description": "Core rule for AI to verify and create Memory Bank file structures, prioritizing `edit_file` for content and `run_terminal_cmd` for `mkdir`.",
            "globs": "**/Core/file-verification.mdc",
            "alwaysApply": False,
            "body": """
# OPTIMIZED FILE VERIFICATION & CREATION SYSTEM (Memory Bank Setup)

> **TL;DR:** Verify/create essential Memory Bank directories and files. Use `edit_file` to create/populate files, `run_terminal_cmd` (platform-aware) for `mkdir`. Log actions.

## ⚙️ AI ACTIONS FOR MEMORY BANK SETUP (Typically during early VAN)

1.  **Acknowledge:** State: "Performing Memory Bank file verification and setup."
2.  **Reference Paths:** Mentally (or by `read_file` if necessary) refer to `.cursor/rules/isolation_rules/Core/memory-bank-paths.mdc` for canonical paths.
3.  **Verify/Create `memory-bank/` Root Directory:**
    a.  Use `list_dir .` (project root) to check if `memory-bank/` exists.
    b.  If missing:
        i.  `run_terminal_cmd` (platform-aware, e.g., `mkdir memory-bank` or `New-Item -ItemType Directory -Path memory-bank`).
        ii. Verify creation (e.g., `list_dir .` again).
4.  **Verify/Create Core Subdirectories in `memory-bank/`:**
    a.  The subdirectories are: `creative/`, `reflection/`, `archive/`.
    b.  For each (e.g., `creative`):
        i.  `list_dir memory-bank/` to check if `memory-bank/creative/` exists.
        ii. If missing: `run_terminal_cmd` (e.g., `mkdir memory-bank/creative`). Verify.
5.  **Verify/Create Core `.md` Files in `memory-bank/` (Using `edit_file`):**
    a.  The core files are: `tasks.md`, `activeContext.md`, `progress.md`, `projectbrief.md`, `productContext.md`, `systemPatterns.md`, `techContext.md`, `style-guide.md`.
    b.  For each file (e.g., `tasks.md`):
        i.  Attempt to `read_file memory-bank/tasks.md`.
        ii. If it fails (file doesn't exist) or content is empty/default placeholder:
            Use `edit_file memory-bank/tasks.md` to write an initial template. Example for `tasks.md`:
            ```markdown
            # Memory Bank: Tasks

            ## Current Task
            - Task ID: T000
            - Name: [Task not yet defined]
            - Status: PENDING_INITIALIZATION
            - Complexity: Not yet assessed
            - Assigned To: AI

            ## Backlog
            (Empty)
            ```
            *(Provide similar minimal templates for other core files if creating them anew. `activeContext.md` could start with `# Active Context - Initialized [Timestamp]`).*
        iii. Optionally, `read_file memory-bank/tasks.md` again to confirm content.
6.  **Log Verification Actions:**
    a.  Use `edit_file` to append a summary to `memory-bank/activeContext.md` under a "File Verification Log" heading. List directories/files checked, created, or found existing. Note any errors.
    b.  Example log entry:
        ```markdown
        ### File Verification Log - [Timestamp]
        - Checked/Created `memory-bank/` directory.
        - Checked/Created `memory-bank/creative/` directory.
        - Checked/Created `memory-bank/tasks.md` (initial template written).
        - ... (other files/dirs) ...
        - Status: All essential Memory Bank structures verified/created.
        ```
7.  **Completion:** State: "Memory Bank file structure verification and setup complete."
"""
        },
        {
            "path": ".cursor/rules/isolation_rules/Core/hierarchical-rule-loading.mdc",
            "description": "Core design principle for Memory Bank: hierarchical/lazy loading of `.mdc` rules via `fetch_rules`.",
            "globs": "**/Core/hierarchical-rule-loading.mdc",
            "alwaysApply": False, 
            "body": """
# HIERARCHICAL RULE LOADING SYSTEM (Design Principle for AI)

> **TL;DR:** You achieve hierarchical/lazy rule loading by following instructions in main mode prompts or other `.mdc` rules that direct you to use `fetch_rules` to load specific `.mdc` rule files only when needed.

## 🧠 HOW YOU EXECUTE HIERARCHICAL LOADING:
1.  **Mode Activation:** Your main custom prompt for a mode (e.g., VAN) tells you to `fetch_rules` for its primary orchestrating `.mdc` (e.g., `visual-maps/van_mode_split/van-mode-map.mdc`).
2.  **Following Instructions:** That `.mdc` guides you. Some steps might instruct: "If [condition], then `fetch_rules` to load and follow `[specific_sub_rule.mdc]`." For example, `van-mode-map.mdc` might tell you to `fetch_rules` for `Core/complexity-decision-tree.mdc`.
3.  **Current Rule Focus:** Always operate based on the instructions from the most recently fetched and relevant rule. Once a fetched rule's instructions are complete, you "return" to the context of the rule that fetched it, or if it was a top-level fetch, you await further user instruction or mode transition.
4.  **Acknowledge Fetches:** When you `fetch_rules` for an `.mdc`, briefly state: "Fetched `.cursor/rules/isolation_rules/[rule_path]`. Now proceeding with its instructions."
"""
        },
        {
            "path": ".cursor/rules/isolation_rules/Core/memory-bank-paths.mdc",
            "description": "Defines canonical paths for core Memory Bank files and directories. CRITICAL reference for all file operations.",
            "globs": "**/Core/memory-bank-paths.mdc",
            "alwaysApply": True, 
            "body": """
# CORE MEMORY BANK FILE & DIRECTORY LOCATIONS

**CRITICAL REFERENCE:** Adhere strictly to these paths for all file operations (`edit_file`, `read_file`, `list_dir`, `run_terminal_cmd` for `mkdir`).

## Root Memory Bank Directory:
*   `memory-bank/` (at project root)

## Core `.md` Files (in `memory-bank/`):
*   Tasks: `memory-bank/tasks.md`
*   Active Context: `memory-bank/activeContext.md`
*   Progress: `memory-bank/progress.md`
*   Project Brief: `memory-bank/projectbrief.md`
*   Product Context: `memory-bank/productContext.md`
*   System Patterns: `memory-bank/systemPatterns.md`
*   Tech Context: `memory-bank/techContext.md`
*   Style Guide: `memory-bank/style-guide.md`

## Subdirectories in `memory-bank/`:
*   Creative: `memory-bank/creative/` (Files: `creative-[feature_or_component_name]-[YYYYMMDD].md`)
*   Reflection: `memory-bank/reflection/` (Files: `reflect-[task_id_or_feature_name]-[YYYYMMDD].md`)
*   Archive: `memory-bank/archive/` (Files: `archive-[task_id_or_feature_name]-[YYYYMMDD].md`)

## Project Documentation Directory (Separate from Memory Bank, but related):
*   `documentation/` (at project root, for final, polished, user-facing docs)

## AI Verification Mandate:
*   Before using `edit_file` on Memory Bank artifacts, confirm the path starts with `memory-bank/` or one of its specified subdirectories.
*   When creating new core files (e.g., `tasks.md`), use `edit_file` with the exact path (e.g., `memory-bank/tasks.md`).
*   For `run_terminal_cmd mkdir`, ensure correct target paths (e.g., `mkdir memory-bank/creative`).
*   Filenames for creative, reflection, and archive documents should include a descriptive name and a date (YYYYMMDD format is good practice).
"""
        },
        {
            "path": ".cursor/rules/isolation_rules/Core/mode-transition-optimization.mdc",
            "description": "Core design principles for optimized mode transitions using `activeContext.md` as the handover document.",
            "globs": "**/Core/mode-transition-optimization.mdc",
            "alwaysApply": False, 
            "body": """
# MODE TRANSITION OPTIMIZATION (AI Actions)

> **TL;DR:** Efficient mode transitions are achieved by updating `memory-bank/activeContext.md` (via `edit_file`) before a transition. The next mode's orchestrator rule then reads this file for context.

## 🔄 CONTEXT TRANSFER PROCESS (AI Actions):

1.  **Before Current Mode Exits (or suggests exiting):**
    a.  Your current instructions (from main prompt or an `.mdc` via `fetch_rules`) will guide you to use `edit_file` to update `memory-bank/activeContext.md`.
    b.  This update should include a section like:
        ```markdown
        ## Mode Transition Prepared - [Timestamp]
        - **From Mode:** [Current Mode, e.g., PLAN]
        - **To Mode Recommended:** [Target Mode, e.g., CREATIVE or IMPLEMENT]
        - **Current Task Focus:** [Specific task name or ID from tasks.md]
        - **Key Outputs/Decisions from [Current Mode]:**
            - [Summary of what was achieved, e.g., "Plan for user authentication feature is complete."]
            - [Reference to key artifacts created/updated, e.g., "See `memory-bank/tasks.md` for detailed sub-tasks. Creative design needed for UI components."]
        - **Primary Goal for [Target Mode]:** [What the next mode should focus on, e.g., "Design UI mockups for login and registration pages."]
        ```
2.  **When New Mode Starts:**
    a.  The new mode's main custom prompt (in Cursor's Advanced Settings) will instruct you to `fetch_rules` for its primary orchestrating `.mdc` file (e.g., `visual-maps/creative-mode-map.mdc`).
    b.  That orchestrating `.mdc` will (as an early step) instruct you to `read_file memory-bank/activeContext.md` to understand the incoming context, task focus, and goals.

**Key Principle:** `memory-bank/activeContext.md` is the primary "handover document" between modes, managed by `edit_file`. Keep its "Mode Transition Prepared" section concise and actionable for the next mode.
"""
        },
        {
            "path": ".cursor/rules/isolation_rules/Core/optimization-integration.mdc",
            "description": "Design overview of Memory Bank optimization strategies. For AI understanding of system goals.",
            "globs": "**/Core/optimization-integration.mdc",
            "alwaysApply": False, 
            "body": """
# MEMORY BANK OPTIMIZATION INTEGRATION (AI Understanding)

> **TL;DR:** You enact Memory Bank optimizations by following specific instructions from other rule files that guide hierarchical rule loading, adaptive complexity, and progressive documentation. This is not a standalone process you run, but a result of adhering to the CMB framework.

## 🔄 HOW YOU ACHIEVE OPTIMIZATIONS:
You don't "run" an optimization integration flow. You achieve system optimizations by:
1.  **Hierarchical Rule Loading:** Following `fetch_rules` instructions in main prompts and other `.mdc` files to load only necessary rules when they are needed. This keeps your immediate context focused and relevant. (See `Core/hierarchical-rule-loading.mdc`).
2.  **Adaptive Complexity Model:** Following `Core/complexity-decision-tree.mdc` (when fetched in VAN mode) to assess task complexity. Then, loading level-specific rules (from `LevelX/` directories) as directed by subsequent instructions. This tailors the process to the task's needs.
3.  **Dynamic Context Management:** Diligently using `read_file` to get context from, and `edit_file` to update, key Memory Bank files like `memory-bank/activeContext.md`, `memory-bank/tasks.md`, and `memory-bank/progress.md`. This ensures context is current and progressively built.
4.  **Transition Optimization:** Following the process in `Core/mode-transition-optimization.mdc` (i.e., updating `activeContext.md` before a mode switch to ensure smooth handover).
5.  **Creative Phase Optimization:** Using templates and structured guidance like `Phases/CreativePhase/optimized-creative-template.mdc` (when fetched in CREATIVE mode) to ensure thorough but efficient design exploration.
6.  **Tool Prioritization:** Consistently using the right tool for the job (e.g., `edit_file` for content, `run_terminal_cmd` for execution) as outlined in `Core/command-execution.mdc`. This avoids inefficient or error-prone methods.

**This document explains the *design goals* of the CMB system. Your role is to execute the specific, actionable instructions in other `.mdc` files. By following those rules, you are inherently participating in and enabling these optimizations.**
"""
        },
        {
            "path": ".cursor/rules/isolation_rules/Core/platform-awareness.mdc",
            "description": "Core guidelines for platform-aware command execution with `run_terminal_cmd`.",
            "globs": "**/Core/platform-awareness.mdc",
            "alwaysApply": True, 
            "body": """
# PLATFORM AWARENESS SYSTEM (for `run_terminal_cmd`)

> **TL;DR:** When using `run_terminal_cmd`, be aware of OS differences (paths, common commands). If unsure, state your default command (Linux-style) and ask the user to confirm or provide the platform-specific version (e.g., for Windows PowerShell).

## 🔍 AI ACTION FOR PLATFORM AWARENESS:

1.  **Identify Need for `run_terminal_cmd`:** This tool is for tasks like `mkdir`, running scripts (e.g., `npm run build`, `python manage.py test`), installing packages (`pip install`, `npm install`), or other shell operations. **Do NOT use it for creating or editing file content; use `edit_file` for that.**
2.  **Consider Platform Differences:**
    *   **Path Separators:** `/` (common for Linux, macOS, and often works in modern Windows PowerShell) vs. `\` (traditional Windows). When constructing paths for commands, be mindful.
    *   **Common Commands:**
        *   Directory Creation: `mkdir -p path/to/dir` (Linux/macOS) vs. `New-Item -ItemType Directory -Path path\to\dir` or `mkdir path\to\dir` (Windows PowerShell).
        *   Listing Directory Contents: `ls -la` (Linux/macOS) vs. `Get-ChildItem` or `dir` (Windows PowerShell).
        *   File Deletion: `rm path/to/file` (Linux/macOS) vs. `Remove-Item path\to\file` (Windows PowerShell).
        *   Environment Variables: `export VAR=value` (Linux/macOS) vs. `$env:VAR="value"` (Windows PowerShell).
3.  **Execution Strategy with `run_terminal_cmd`:**
    a.  **Check Context:** `read_file memory-bank/techContext.md` or `memory-bank/activeContext.md` to see if the OS has been previously identified.
    b.  **If OS is Known:** Use the appropriate command syntax for that OS.
    c.  **If OS is Unknown or Unsure:**
        i.  State your intended action and the command you would typically use (default to Linux-style if no other info). Example: "To create the directory `my_app/src`, I would use `run_terminal_cmd` with `mkdir -p my_app/src`."
        ii. Ask for Confirmation/Correction: "Is this command correct for your operating system? If you are on Windows, please provide the PowerShell equivalent."
        iii. Await user confirmation or correction before proceeding with `run_terminal_cmd`.
    d.  **Clearly State Command:** Before execution, always state the exact command you are about to run with `run_terminal_cmd`.
4.  **Document Action and Outcome:**
    a.  After `run_terminal_cmd` completes, use `edit_file` to log the command, its full output (or a summary if very long), and success/failure status in `memory-bank/activeContext.md` under a "Terminal Command Log" or similar section. (Refer to `Core/command-execution.mdc` for the log template).

**This is a guiding principle. The key is to be *aware* of potential differences, default to a common standard (like Linux commands), and proactively seek clarification from the user when unsure to ensure `run_terminal_cmd` is used safely and effectively.**
"""
        }
    ])

    MDC_FILES_DATA.extend([
        {
            "path": ".cursor/rules/isolation_rules/visual-maps/archive-mode-map.mdc",
            "description": "Orchestrates ARCHIVE mode. Fetched when ARCHIVE process starts. Guides AI to finalize task documentation, create archive record, and update Memory Bank using level-specific rules and `edit_file`.",
            "globs": "**/visual-maps/archive-mode-map.mdc",
            "alwaysApply": False,
            "body": """
# ARCHIVE MODE: TASK DOCUMENTATION PROCESS MAP (AI Instructions)

> **TL;DR:** Finalize task documentation, create an archive record, and update Memory Bank. Use `edit_file` for all document interactions. This rule orchestrates by fetching level-specific archive rules.

## 🧭 ARCHIVE MODE PROCESS FLOW (AI Actions)

1.  **Acknowledge & Context Gathering:**
    a.  State: "Initiating ARCHIVE mode for the current task."
    b.  `read_file memory-bank/activeContext.md` to identify the current task name/ID and its determined complexity level.
    c.  `read_file memory-bank/tasks.md` to confirm task details and status (especially if REFLECT phase is marked complete).
    d.  `read_file memory-bank/reflection/` (specifically the reflection document related to the current task, e.g., `reflect-[task_name_or_id]-[date].md`).
    e.  `read_file memory-bank/progress.md` for any relevant final notes.
2.  **Pre-Archive Check (AI Self-Correction):**
    a.  Verify from `tasks.md` that the REFLECT phase for the current task is marked as complete.
    b.  Verify that the corresponding reflection document (e.g., `memory-bank/reflection/reflect-[task_name_or_id]-[date].md`) exists and appears finalized.
    c.  If checks fail: State "ARCHIVE BLOCKED: Reflection phase is not complete or reflection document is missing/incomplete for task [task_name]. Please complete REFLECT mode first." Await user.
3.  **Fetch Level-Specific Archive Rule:**
    a.  Based on the complexity level identified in `activeContext.md` or `tasks.md`:
        *   **Level 1:** `fetch_rules` for `.cursor/rules/isolation_rules/Level1/archive-minimal.mdc`.
        *   **Level 2:** `fetch_rules` for `.cursor/rules/isolation_rules/Level2/archive-basic.mdc`.
        *   **Level 3:** `fetch_rules` for `.cursor/rules/isolation_rules/Level3/archive-intermediate.mdc`.
        *   **Level 4:** `fetch_rules` for `.cursor/rules/isolation_rules/Level4/archive-comprehensive.mdc`.
4.  **Follow Fetched Rule:**
    a.  The fetched level-specific `.mdc` rule will provide detailed instructions for:
        i.  Creating the main archive document (e.g., `memory-bank/archive/archive-[task_name_or_id]-[date].md`) using `edit_file`. This includes summarizing the task, requirements, implementation, testing, and lessons learned (drawing from reflection docs).
        ii.  Potentially archiving other relevant documents (e.g., creative phase documents for L3/L4) by copying their content or linking to them within the main archive document.
        iii. Updating `memory-bank/tasks.md` to mark the task as "ARCHIVED" or "COMPLETED" using `edit_file`.
        iv. Updating `memory-bank/progress.md` with a final entry about archiving using `edit_file`.
        v.  Updating `memory-bank/activeContext.md` to clear the current task focus and indicate readiness for a new task, using `edit_file`.
5.  **Notify Completion:**
    a.  Once the fetched rule's instructions are complete, state: "ARCHIVING COMPLETE for task [task_name]. The archive document is located at `[path_to_archive_doc]`."
    b.  Recommend: "The Memory Bank is ready for the next task. Suggest using VAN mode to initiate a new task." Await user.
"""
        },
        {
            "path": ".cursor/rules/isolation_rules/visual-maps/creative-mode-map.mdc",
            "description": "Orchestrates CREATIVE mode. Fetched by PLAN mode when design is needed. Guides AI to facilitate design for components flagged in `tasks.md`, using `fetch_rules` for design-type guidance and `edit_file` for documentation.",
            "globs": "**/visual-maps/creative-mode-map.mdc",
            "alwaysApply": False,
            "body": """
# CREATIVE MODE: DESIGN PROCESS MAP (AI Instructions)

> **TL;DR:** Facilitate design for components flagged in `tasks.md` as needing creative input. Use `fetch_rules` to get specific design-type guidance (Arch, UI/UX, Algo) and `edit_file` to create/update `memory-bank/creative/creative-[component_name]-[date].md` documents.

## 🧭 CREATIVE MODE PROCESS FLOW (AI Actions)

1.  **Acknowledge & Context Gathering:**
    a.  State: "Initiating CREATIVE mode. Identifying components requiring design."
    b.  `read_file memory-bank/tasks.md`. Look for sub-tasks under the current main task that are marked like "CREATIVE: Design [Component Name] ([Design Type: Architecture/UI-UX/Algorithm])" and are not yet complete.
    c.  `read_file memory-bank/activeContext.md` for overall project context and the current main task focus.
    d.  If no active "CREATIVE: Design..." sub-tasks are found for the current main task, state: "No pending creative design tasks found for [main_task_name]. Please specify a component and design type, or transition to another mode." Await user.
2.  **Iterate Through Pending Creative Sub-Tasks:**
    a.  For each pending "CREATIVE: Design [Component Name] ([Design Type])" sub-task:
        i.  Announce: "Starting CREATIVE phase for: [Component Name] - Design Type: [Architecture/UI-UX/Algorithm]."
        ii. Update `memory-bank/activeContext.md` using `edit_file` to set current focus: "Creative Focus: Designing [Component Name] ([Design Type])."
        iii. **Fetch Specific Design-Type Rule:**
            *   If Design Type is Architecture: `fetch_rules` for `.cursor/rules/isolation_rules/Phases/CreativePhase/creative-phase-architecture.mdc`.
            *   If Design Type is UI/UX: `fetch_rules` for `.cursor/rules/isolation_rules/Phases/CreativePhase/creative-phase-uiux.mdc`.
            *   If Design Type is Algorithm: `fetch_rules` for `.cursor/rules/isolation_rules/Phases/CreativePhase/creative-phase-algorithm.mdc`.
            *   (If design type is other/generic, fetch `Phases/CreativePhase/optimized-creative-template.mdc` and adapt general design principles).
        iv. **Follow Fetched Rule:** The fetched rule will guide you through:
            *   Defining the problem for that component.
            *   Exploring options.
            *   Analyzing trade-offs.
            *   Making a design decision.
            *   Outlining implementation guidelines.
        v.  **Document Design:**
            *   The fetched rule will instruct you to use `edit_file` to create or update the specific creative document: `memory-bank/creative/creative-[component_name]-[date].md`.
            *   It will likely reference `.cursor/rules/isolation_rules/Phases/CreativePhase/optimized-creative-template.mdc` (which you can `read_file` if not fetched directly) for the structure of this document.
        vi. **Update `memory-bank/activeContext.md`:** Use `edit_file` to append a summary of the design decision for [Component Name] to a "Creative Decisions Log" section.
        vii. **Update `memory-bank/tasks.md`:** Use `edit_file` to mark the "CREATIVE: Design [Component Name]..." sub-task as complete.
3.  **Overall Verification & Transition:**
    a.  After all identified creative sub-tasks for the main task are complete, state: "All CREATIVE design phases for [main_task_name] are complete. Design documents are located in `memory-bank/creative/`."
    b.  Recommend next mode: "Recommend transitioning to IMPLEMENT mode to build these components, or VAN QA mode for technical pre-flight checks if applicable." Await user.

## 📊 PRE-CREATIVE CHECK (AI Self-Correction):
1.  `read_file memory-bank/tasks.md`: Is there a main task currently in a state that expects creative design (e.g., PLAN phase completed, and specific "CREATIVE: Design..." sub-tasks are listed and pending)?
2.  If not, or if PLAN phase is not complete for the main task, state: "CREATIVE mode requires a planned task with identified components for design. Please ensure PLAN mode is complete for [main_task_name] and creative sub-tasks are defined in `tasks.md`." Await user.
"""
        },
        {
            "path": ".cursor/rules/isolation_rules/visual-maps/implement-mode-map.mdc",
            "description": "Orchestrates IMPLEMENT mode. Fetched after PLAN/CREATIVE. Guides AI to implement features/fixes using level-specific rules, `edit_file` for code, `run_terminal_cmd` for builds/tests, and `Core/command-execution.mdc` for tool usage.",
            "globs": "**/visual-maps/implement-mode-map.mdc",
            "alwaysApply": False,
            "body": """
# IMPLEMENT MODE: CODE EXECUTION PROCESS MAP (AI Instructions)

> **TL;DR:** Implement the planned and designed features or bug fixes. Use `edit_file` for all code and documentation changes. Use `run_terminal_cmd` for builds, tests, etc. Fetch level-specific implementation rules and `Core/command-execution.mdc` for detailed tool guidance.

## 🧭 IMPLEMENT MODE PROCESS FLOW (AI Actions)

1.  **Acknowledge & Context Gathering:**
    a.  State: "Initiating IMPLEMENT mode for the current task."
    b.  `read_file memory-bank/activeContext.md` to identify the current task, its complexity level, and any outputs from PLAN/CREATIVE modes.
    c.  `read_file memory-bank/tasks.md` for the detailed sub-tasks, implementation plan, and references to creative design documents.
    d.  `read_file memory-bank/progress.md` for any ongoing implementation status.
    e.  If L3/L4 task, `read_file` relevant `memory-bank/creative/creative-[component]-[date].md` documents.
2.  **Pre-Implementation Checks (AI Self-Correction):**
    a.  **PLAN Complete?** Verify in `tasks.md` that the planning phase for the current task is marked complete.
    b.  **CREATIVE Complete (for L3/L4)?** `fetch_rules` for `.cursor/rules/isolation_rules/Core/creative-phase-enforcement.mdc` to check. If it blocks, await user action (e.g., switch to CREATIVE mode).
    c.  **VAN QA Passed (if applicable)?** Check `activeContext.md` or a dedicated status file if VAN QA was run. If VAN QA failed, state: "IMPLEMENTATION BLOCKED: VAN QA checks previously failed. Please resolve issues and re-run VAN QA." Await user.
    d.  If any critical pre-check fails, state the blockage and await user instruction.
3.  **Fetch General Command Execution Guidelines:**
    a.  `fetch_rules` for `.cursor/rules/isolation_rules/Core/command-execution.mdc`. Keep these guidelines in mind for all tool usage.
4.  **Fetch Level-Specific Implementation Rule:**
    a.  Based on the complexity level:
        *   **Level 1:** `fetch_rules` for `.cursor/rules/isolation_rules/Level1/workflow-level1.mdc` (or a more specific L1 implement rule if it exists, e.g., `Level1/implement-quick-fix.mdc`).
        *   **Level 2:** `fetch_rules` for `.cursor/rules/isolation_rules/Level2/workflow-level2.mdc` (or `Level2/implement-basic.mdc`).
        *   **Level 3:** `fetch_rules` for `.cursor/rules/isolation_rules/Level3/implementation-intermediate.mdc`.
        *   **Level 4:** `fetch_rules` for `.cursor/rules/isolation_rules/Level4/phased-implementation.mdc`.
5.  **Follow Fetched Rule (Iterative Implementation):**
    a.  The level-specific rule will guide you through the implementation steps, which will involve:
        i.  Identifying the next specific sub-task from `tasks.md`.
        ii. Creating/modifying source code files using `edit_file`.
        iii. Creating/modifying documentation (e.g., code comments, README sections) using `edit_file`.
        iv. Running build scripts or compilers using `run_terminal_cmd` (platform-aware).
        v.  Running tests using `run_terminal_cmd`.
        vi. Verifying file creation/modification (e.g., using `read_file` or `list_dir`).
        vii. Documenting each significant action (tool used, command, outcome) in `memory-bank/activeContext.md` (in a "Build Log" section) using `edit_file`.
        viii. Updating `memory-bank/progress.md` with detailed progress for each sub-task using `edit_file`.
        ix. Updating `memory-bank/tasks.md` to mark sub-tasks as complete using `edit_file`.
    b.  This is an iterative process. Continue until all implementation sub-tasks in `tasks.md` are complete.
6.  **Notify Completion:**
    a.  Once all implementation sub-tasks are complete, state: "IMPLEMENTATION COMPLETE for task [task_name]."
    b.  Update `memory-bank/tasks.md` to mark the main IMPLEMENT phase as complete.
    c.  Update `memory-bank/activeContext.md`: "Implementation phase complete for [task_name]. Ready for REFLECT mode."
    d.  Recommend: "Recommend transitioning to REFLECT mode for review and lessons learned." Await user.
"""
        },
        {
            "path": ".cursor/rules/isolation_rules/visual-maps/plan-mode-map.mdc",
            "description": "Orchestrates PLAN mode. Fetched by VAN for L2+ tasks. Guides AI to create detailed plans in `tasks.md` using level-specific rules, `edit_file`, and identifies needs for CREATIVE mode.",
            "globs": "**/visual-maps/plan-mode-map.mdc",
            "alwaysApply": False,
            "body": """
# PLAN MODE: TASK PLANNING PROCESS MAP (AI Instructions)

> **TL;DR:** Create a detailed implementation plan for Level 2-4 tasks. Update `tasks.md` extensively using `edit_file`. Identify components needing CREATIVE design. Fetch level-specific planning rules for detailed guidance.

## 🧭 PLAN MODE PROCESS FLOW (AI Actions)

1.  **Acknowledge & Context Gathering:**
    a.  State: "Initiating PLAN mode for the current task."
    b.  `read_file memory-bank/activeContext.md` to understand the task name, determined complexity level (should be L2, L3, or L4), and any initial notes from VAN mode.
    c.  `read_file memory-bank/tasks.md` for the current state of the task entry.
    d.  `read_file memory-bank/projectbrief.md`, `productContext.md`, `systemPatterns.md`, `techContext.md` for broader project understanding.
2.  **Pre-Planning Check (AI Self-Correction):**
    a.  Verify from `activeContext.md` or `tasks.md` that the task complexity is indeed Level 2, 3, or 4.
    b.  If complexity is Level 1 or not assessed, state: "PLAN mode is intended for Level 2-4 tasks. Current task is [Level/Status]. Please clarify or run VAN mode for complexity assessment." Await user.
3.  **Fetch Level-Specific Planning Rule:**
    a.  Based on the complexity level:
        *   **Level 2:** `fetch_rules` for `.cursor/rules/isolation_rules/Level2/task-tracking-basic.mdc` (or a dedicated L2 planning rule like `Level2/planning-basic.mdc` if it exists).
        *   **Level 3:** `fetch_rules` for `.cursor/rules/isolation_rules/Level3/planning-comprehensive.mdc`.
        *   **Level 4:** `fetch_rules` for `.cursor/rules/isolation_rules/Level4/architectural-planning.mdc`.
4.  **Follow Fetched Rule (Detailed Planning):**
    a.  The fetched level-specific rule will guide you through the detailed planning steps, which will involve extensive updates to `memory-bank/tasks.md` using `edit_file`. This includes:
        i.  Breaking down the main task into smaller, actionable sub-tasks.
        ii. Defining requirements, acceptance criteria for each sub-task.
        iii. Identifying affected components, files, or modules.
        iv. Estimating effort/dependencies for sub-tasks (qualitatively).
        v.  **Crucially for L3/L4:** Identifying specific components or aspects that require a dedicated CREATIVE design phase (e.g., "CREATIVE: Design User Authentication UI", "CREATIVE: Design Database Schema for Orders"). These should be added as specific sub-tasks in `tasks.md`.
        vi. Outlining a high-level implementation sequence.
        vii. Documenting potential challenges and mitigation strategies.
    b.  Throughout this process, use `edit_file` to meticulously update the relevant sections in `memory-bank/tasks.md`.
    c.  Update `memory-bank/activeContext.md` periodically with planning progress notes using `edit_file`.
5.  **Technology Validation (Conceptual - AI doesn't run code here but plans for it):**
    a.  The fetched planning rule might instruct you to consider and document the technology stack, any new dependencies, or build configurations needed. This is documented in `tasks.md` or `techContext.md` using `edit_file`.
    b.  If significant new technologies or complex configurations are involved, add a sub-task in `tasks.md` for "VAN QA: Technical Validation" to be performed before IMPLEMENT.
6.  **Notify Completion & Recommend Next Mode:**
    a.  Once the detailed plan is formulated in `tasks.md` as per the fetched rule, state: "PLANNING COMPLETE for task [task_name]. Detailed plan and sub-tasks are updated in `memory-bank/tasks.md`."
    b.  Update `memory-bank/tasks.md` to mark the main PLAN phase as complete.
    c.  Update `memory-bank/activeContext.md`: "Planning phase complete for [task_name]."
    d.  **Recommendation:**
        *   If "CREATIVE: Design..." sub-tasks were identified: "Recommend transitioning to CREATIVE mode to address design requirements."
        *   If no CREATIVE sub-tasks (e.g., simpler L2 task) and no VAN QA flagged: "Recommend transitioning to IMPLEMENT mode."
        *   If VAN QA was flagged as needed: "Recommend transitioning to VAN QA mode for technical pre-flight checks."
    e.  Await user instruction.
"""
        },
        {
            "path": ".cursor/rules/isolation_rules/visual-maps/qa-mode-map.mdc",
            "description": "Orchestrates general QA mode (distinct from VAN QA). Fetched when user invokes 'QA'. Guides AI to perform context-aware validation of Memory Bank consistency, task tracking, and phase-specific checks.",
            "globs": "**/visual-maps/qa-mode-map.mdc",
            "alwaysApply": False,
            "body": """
# QA MODE: GENERAL VALIDATION PROCESS MAP (AI Instructions)

> **TL;DR:** Perform comprehensive validation of Memory Bank consistency, task tracking, and current phase status. This is a general QA mode, callable anytime, distinct from the pre-build VAN QA. Use `read_file` extensively and `edit_file` to log QA findings.

## 🧭 QA MODE PROCESS FLOW (AI Actions)

1.  **Acknowledge & Context Gathering:**
    a.  State: "Initiating general QA MODE. Analyzing current project state."
    b.  `read_file memory-bank/activeContext.md` to determine the current task, its perceived phase (VAN, PLAN, CREATIVE, IMPLEMENT, REFLECT, ARCHIVE), and complexity.
    c.  `read_file memory-bank/tasks.md` for task statuses and details.
    d.  `read_file memory-bank/progress.md` for activity log.
2.  **Universal Validation Checks (AI Self-Correction & Reporting):**
    a.  **Memory Bank Core File Integrity:**
        i.  `fetch_rules` for `.cursor/rules/isolation_rules/Core/memory-bank-paths.mdc` to get list of core files.
        ii. For each core file: Attempt `read_file`. Report if any are missing or seem corrupted (e.g., empty when they shouldn't be).
    b.  **`tasks.md` Consistency:**
        i.  Is there a clearly defined current task?
        ii. Are statuses (PENDING, IN_PROGRESS, COMPLETE, BLOCKED, CREATIVE_NEEDED, QA_NEEDED, REFLECT_NEEDED, ARCHIVE_NEEDED) used consistently?
        iii. Do sub-tasks roll up logically to the main task's status?
    c.  **`activeContext.md` Relevance:**
        i.  Does the `activeContext.md` accurately reflect the current focus apparent from `tasks.md` and `progress.md`?
        ii. Is the "Last Updated" timestamp recent relative to `progress.md`?
    d.  **`progress.md` Completeness:**
        i.  Are there entries for recent significant activities?
        ii. Do entries clearly state actions taken and outcomes?
    e.  **Cross-Reference Check (Conceptual):**
        i.  Do task IDs in `progress.md` or `activeContext.md` match those in `tasks.md`?
        ii. Do references to creative/reflection/archive documents seem plausible (e.g., filenames match task names)?
3.  **Phase-Specific Validation (Based on perceived current phase from `activeContext.md`):**
    *   **If VAN phase:** Are `projectbrief.md`, `techContext.md` populated? Is complexity assessed in `tasks.md`?
    *   **If PLAN phase:** Is `tasks.md` detailed with sub-tasks, requirements? Are creative needs identified for L3/L4?
    *   **If CREATIVE phase:** Do `memory-bank/creative/` documents exist for components marked in `tasks.md`? Are decisions logged in `activeContext.md`?
    *   **If IMPLEMENT phase:** Is there a "Build Log" in `activeContext.md`? Is `progress.md` being updated with code changes and test results? Are sub-tasks in `tasks.md` being marked complete?
    *   **If REFLECT phase:** Does `memory-bank/reflection/reflect-[task_name]-[date].md` exist and seem complete? Is `tasks.md` updated for reflection?
    *   **If ARCHIVE phase:** Does `memory-bank/archive/archive-[task_name]-[date].md` exist? Is `tasks.md` marked fully complete/archived?
4.  **Report Generation:**
    a.  Use `edit_file` to create a new QA report in `memory-bank/qa_reports/qa-report-[date]-[time].md`.
    b.  **Structure of the report:**
        ```markdown
        # General QA Report - [Date] [Time]
        - Perceived Current Task: [Task Name/ID]
        - Perceived Current Phase: [Phase]
        - Perceived Complexity: [Level]

        ## Universal Validation Findings:
        - Memory Bank Core Files: [OK/Issues found: list them]
        - `tasks.md` Consistency: [OK/Issues found: list them]
        - `activeContext.md` Relevance: [OK/Issues found: list them]
        - `progress.md` Completeness: [OK/Issues found: list them]
        - Cross-References: [OK/Issues found: list them]

        ## Phase-Specific ([Phase]) Validation Findings:
        - [Check 1]: [OK/Issue]
        - [Check 2]: [OK/Issue]

        ## Summary & Recommendations:
        - Overall Status: [GREEN/YELLOW/RED]
        - [Specific recommendations for fixes or areas to improve]
        ```
    c.  Announce: "General QA validation complete. Report generated at `memory-bank/qa_reports/qa-report-[date]-[time].md`."
    d.  Present a summary of key findings (especially any RED/YELLOW status items) directly to the user.
5.  **Await User Action:** Await user instructions for addressing any reported issues or proceeding.
"""
        },
        {
            "path": ".cursor/rules/isolation_rules/visual-maps/reflect-mode-map.mdc",
            "description": "Orchestrates REFLECT mode. Fetched after IMPLEMENT. Guides AI to review implementation, document lessons in `reflection/...md`, and update Memory Bank using level-specific rules and `edit_file`.",
            "globs": "**/visual-maps/reflect-mode-map.mdc",
            "alwaysApply": False,
            "body": """
# REFLECT MODE: TASK REVIEW PROCESS MAP (AI Instructions)

> **TL;DR:** Review the completed implementation, document insights and lessons learned in `memory-bank/reflection/reflect-[task_name]-[date].md`. Use `edit_file` for all documentation. Fetch level-specific reflection rules for detailed guidance.

## 🧭 REFLECT MODE PROCESS FLOW (AI Actions)

1.  **Acknowledge & Context Gathering:**
    a.  State: "Initiating REFLECT mode for the current task."
    b.  `read_file memory-bank/activeContext.md` to identify the current task, its complexity level, and confirmation that IMPLEMENT phase is complete.
    c.  `read_file memory-bank/tasks.md` for the original plan, sub-tasks, and requirements.
    d.  `read_file memory-bank/progress.md` to review the implementation journey and any challenges logged.
    e.  `read_file` any relevant `memory-bank/creative/creative-[component]-[date].md` documents (for L3/L4) to compare design with implementation.
2.  **Pre-Reflection Check (AI Self-Correction):**
    a.  Verify from `tasks.md` or `activeContext.md` that the IMPLEMENT phase for the current task is marked as complete.
    b.  If not, state: "REFLECT BLOCKED: Implementation phase is not yet complete for task [task_name]. Please complete IMPLEMENT mode first." Await user.
3.  **Fetch Level-Specific Reflection Rule:**
    a.  Based on the complexity level:
        *   **Level 1:** `fetch_rules` for `.cursor/rules/isolation_rules/Level1/reflection-basic.mdc`. (If not present, use L2)
        *   **Level 2:** `fetch_rules` for `.cursor/rules/isolation_rules/Level2/reflection-basic.mdc`. (Note: `rules-visual-maps.txt` refers to `reflection-standard.md` for L2, I'll use `reflection-basic` as per `STRUCTURE.md` or assume they are similar. If a specific `reflection-standard.mdc` exists, use that).
        *   **Level 3:** `fetch_rules` for `.cursor/rules/isolation_rules/Level3/reflection-intermediate.mdc`.
        *   **Level 4:** `fetch_rules` for `.cursor/rules/isolation_rules/Level4/reflection-comprehensive.mdc`.
4.  **Follow Fetched Rule (Structured Reflection):**
    a.  The fetched level-specific `.mdc` rule will guide you through the reflection process, which involves creating/updating `memory-bank/reflection/reflect-[task_name_or_id]-[date].md` using `edit_file`. Key sections to populate (guided by the fetched rule):
        i.  **Summary of Task & Outcome:** What was built, did it meet goals?
        ii. **What Went Well:** Successful aspects, efficient processes.
        iii. **Challenges Encountered:** Difficulties, roadblocks, unexpected issues. How were they overcome?
        iv. **Lessons Learned:** Key takeaways, new knowledge gained (technical, process-wise).
        v.  **Comparison with Plan/Design:** Deviations from original plan/design and why.
        vi. **Process Improvements:** Suggestions for future tasks.
        vii. **Technical Improvements/Alternatives:** Better technical approaches for similar future tasks.
        viii. **Code Quality/Maintainability Assessment (if applicable).**
    b.  Use `edit_file` to meticulously populate the reflection document.
    c.  Update `memory-bank/activeContext.md` with notes like "Reflection in progress for [task_name]."
5.  **Notify Completion:**
    a.  Once the reflection document is complete as per the fetched rule, state: "REFLECTION COMPLETE for task [task_name]. Reflection document created/updated at `memory-bank/reflection/reflect-[task_name_or_id]-[date].md`."
    b.  Use `edit_file` to update `memory-bank/tasks.md`, marking the REFLECT phase as complete for the task.
    c.  Use `edit_file` to update `memory-bank/activeContext.md`: "Reflection phase complete for [task_name]. Ready for ARCHIVE mode."
    d.  Recommend: "Recommend transitioning to ARCHIVE mode to finalize and store task documentation." Await user.
"""
        },
        # --- VAN Mode Split Files ---
        {
            "path": ".cursor/rules/isolation_rules/visual-maps/van_mode_split/van-mode-map.mdc",
            "description": "Main orchestrator for VAN mode: platform detection, file verification, complexity determination, and optional QA. Fetched when VAN mode starts.",
            "globs": "**/visual-maps/van_mode_split/van-mode-map.mdc",
            "alwaysApply": False,
            "body": """
# VAN MODE: INITIALIZATION PROCESS MAP (AI Instructions)

> **TL;DR:** Initialize project: platform detection, file verification, complexity determination. For L2+ tasks, transition to PLAN. For L1, complete initialization. If 'VAN QA' is called, perform technical validation. This rule orchestrates by fetching specific sub-rules.

## 🧭 VAN MODE PROCESS FLOW (AI Actions)

1.  **Acknowledge & Determine Entry Point:**
    *   If user typed "VAN": Respond "OK VAN - Beginning Initialization Process." Proceed with step 2.
    *   If user typed "VAN QA": Respond "OK VAN QA - Beginning Technical Validation." Skip to step 6.
2.  **Platform Detection (Sub-Rule):**
    a.  State: "Performing platform detection."
    b.  `fetch_rules` to load and follow `.cursor/rules/isolation_rules/visual-maps/van_mode_split/van-platform-detection.mdc`.
    c.  (The fetched rule will guide OS detection and logging to `activeContext.md` via `edit_file`).
3.  **File Verification & Creation (Memory Bank Setup) (Sub-Rule):**
    a.  State: "Performing Memory Bank file verification and setup."
    b.  `fetch_rules` to load and follow `.cursor/rules/isolation_rules/Core/file-verification.mdc`.
    c.  (The fetched rule guides checking/creating `memory-bank/` dir, subdirs, and core `.md` files using `edit_file` and `run_terminal_cmd`).
4.  **Early Complexity Determination (Sub-Rule):**
    a.  State: "Determining task complexity."
    b.  `fetch_rules` to load and follow `.cursor/rules/isolation_rules/Core/complexity-decision-tree.mdc`.
    c.  (The fetched rule guides assessing Level 1-4 and updating `activeContext.md` and `tasks.md` via `edit_file`).
    d.  `read_file memory-bank/activeContext.md` to confirm the determined complexity level.
5.  **Mode Transition based on Complexity:**
    a.  **If Level 1 determined:**
        i.  State: "Task assessed as Level 1. Completing VAN initialization."
        ii. Use `edit_file` to update `memory-bank/activeContext.md` with: "VAN Process Status: Level 1 Initialization Complete. Task ready for IMPLEMENT mode."
        iii. State: "VAN Initialization Complete for Level 1 task [Task Name]. Recommend IMPLEMENT mode." Await user.
    b.  **If Level 2, 3, or 4 determined:**
        i.  State: "🚫 LEVEL [2/3/4] TASK DETECTED: [Task Name]. This task REQUIRES detailed planning."
        ii. State: "Transitioning to PLAN mode is necessary. Type 'PLAN' to proceed with planning." Await user.
        iii. (VAN mode is effectively paused here for L2-4 tasks. The user will initiate PLAN mode, which has its own orchestrator).
6.  **VAN QA - Technical Validation (Entry point if "VAN QA" was typed, or if called after CREATIVE mode by user):**
    a.  State: "Initiating VAN QA Technical Validation."
    b.  `fetch_rules` to load and follow `.cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-main.mdc`.
    c.  (The `van-qa-main.mdc` will orchestrate the entire QA process, fetching further sub-rules for specific checks and reporting).
    d.  After `van-qa-main.mdc` completes, it will have provided a summary and recommended next steps (e.g., proceed to BUILD or fix issues). Await user action based on that QA report.

## 🔄 QA COMMAND PRECEDENCE (If user types "QA" during steps 2-4 of VAN Initialization)
1.  State: "General QA command received, pausing current VAN initialization step ([current step])."
2.  `fetch_rules` to load and follow `.cursor/rules/isolation_rules/visual-maps/qa-mode-map.mdc` (the general QA orchestrator).
3.  After general QA is complete (and any issues potentially addressed by the user):
    a.  State: "Resuming VAN initialization."
    b.  Re-evaluate or continue from the paused VAN initialization step. For example, if paused during complexity determination, complete it, then proceed to step 5.
"""
        },
        {
            "path": ".cursor/rules/isolation_rules/visual-maps/van_mode_split/van-platform-detection.mdc",
            "description": "VAN sub-rule for platform detection. Fetched by `van-mode-map.mdc`. Guides AI to detect OS and document in `activeContext.md`.",
            "globs": "**/visual-maps/van_mode_split/van-platform-detection.mdc",
            "alwaysApply": False,
            "body": """
# VAN MODE: PLATFORM DETECTION (AI Instructions)

> **TL;DR:** Detect the Operating System. Document the detected OS and path separator style in `memory-bank/activeContext.md` and `memory-bank/techContext.md` using `edit_file`. This rule is typically fetched by `van-mode-map.mdc`.

## ⚙️ AI ACTIONS FOR PLATFORM DETECTION:

1.  **Acknowledge:** State: "Attempting to determine Operating System."
2.  **Attempt Detection (via `run_terminal_cmd` - carefully):**
    *   **Strategy:** Use a simple, non-destructive command that has distinct output or behavior across OSes.
    *   Example 1 (Check for `uname`):
        *   `run_terminal_cmd uname`
        *   If output is "Linux", "Darwin" (macOS), or similar: OS is Unix-like. Path separator likely `/`.
        *   If command fails or output is unrecognized: OS might be Windows.
    *   Example 2 (Check PowerShell specific variable, if assuming PowerShell might be present):
        *   `run_terminal_cmd echo $PSVersionTable.PSVersion` (PowerShell)
        *   If successful with version output: OS is Windows (with PowerShell). Path separator likely `\`.
        *   If fails: Not PowerShell, or not Windows.
    *   **If still unsure after one attempt, DO NOT run many speculative commands.**
3.  **Decision & User Interaction if Unsure:**
    a.  **If Confident:** (e.g., `uname` returned "Linux")
        i.  Detected OS: Linux. Path Separator: `/`.
    b.  **If Unsure:**
        i.  State: "Could not definitively determine the OS automatically."
        ii. Ask User: "Please specify your Operating System (e.g., Windows, macOS, Linux) and preferred path separator (`/` or `\\`)."
        iii. Await user response.
        iv. Detected OS: [User's response]. Path Separator: [User's response].
4.  **Document Findings:**
    a.  Use `edit_file` to update `memory-bank/activeContext.md` with a section:
        ```markdown
        ## Platform Detection Log - [Timestamp]
        - Detected OS: [Windows/macOS/Linux/User-Specified]
        - Path Separator Style: [/ or \\]
        - Confidence: [High/Medium/Low/User-Provided]
        ```
    b.  Use `edit_file` to update (or create if not exists) `memory-bank/techContext.md` with:
        ```markdown
        # Technical Context
        ## Operating System
        - OS: [Windows/macOS/Linux/User-Specified]
        - Path Separator: [/ or \\]
        ## Key Command Line Interface (if known)
        - CLI: [Bash/Zsh/PowerShell/CMD/User-Specified]
        ```
5.  **Completion:** State: "Platform detection complete. OS identified as [OS_Name]. Proceeding with VAN initialization."
    (Control returns to the fetching rule, likely `van-mode-map.mdc`).
"""
        },
        {
            "path": ".cursor/rules/isolation_rules/visual-maps/van_mode_split/van-file-verification.mdc",
            "description": "VAN sub-rule for initial Memory Bank file structure verification (DEPRECATED - Logic moved to Core/file-verification.mdc). This file is a placeholder.",
            "globs": "**/visual-maps/van_mode_split/van-file-verification.mdc",
            "alwaysApply": False,
            "body": """
# VAN MODE: FILE VERIFICATION (Placeholder - Logic Moved)

> **TL;DR:** This rule is a placeholder. The primary Memory Bank file verification and creation logic has been consolidated into `.cursor/rules/isolation_rules/Core/file-verification.mdc`.

## ⚙️ AI ACTION:

1.  **Acknowledge:** State: "Note: `van_mode_split/van-file-verification.mdc` is a placeholder. The main file verification logic is in `Core/file-verification.mdc`."
2.  **Guidance:** If you were instructed to perform initial Memory Bank file verification, you should have been (or should be) directed to `fetch_rules` for `.cursor/rules/isolation_rules/Core/file-verification.mdc`.

(Control returns to the fetching rule, likely `van-mode-map.mdc` which should fetch the Core rule directly).
"""
        },
        {
            "path": ".cursor/rules/isolation_rules/visual-maps/van_mode_split/van-complexity-determination.mdc",
            "description": "VAN sub-rule for task complexity determination (DEPRECATED - Logic moved to Core/complexity-decision-tree.mdc). This file is a placeholder.",
            "globs": "**/visual-maps/van_mode_split/van-complexity-determination.mdc",
            "alwaysApply": False,
            "body": """
# VAN MODE: COMPLEXITY DETERMINATION (Placeholder - Logic Moved)

> **TL;DR:** This rule is a placeholder. The primary task complexity determination logic has been consolidated into `.cursor/rules/isolation_rules/Core/complexity-decision-tree.mdc`.

## ⚙️ AI ACTION:

1.  **Acknowledge:** State: "Note: `van_mode_split/van-complexity-determination.mdc` is a placeholder. The main complexity determination logic is in `Core/complexity-decision-tree.mdc`."
2.  **Guidance:** If you were instructed to determine task complexity, you should have been (or should be) directed to `fetch_rules` for `.cursor/rules/isolation_rules/Core/complexity-decision-tree.mdc`.

(Control returns to the fetching rule, likely `van-mode-map.mdc` which should fetch the Core rule directly).
"""
        },
        # --- VAN QA Main Orchestrator ---
        {
            "path": ".cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-main.mdc",
            "description": "Main orchestrator for VAN QA technical validation. Fetched by `van-mode-map.mdc` when 'VAN QA' is triggered. Fetches specific check rules and utility rules.",
            "globs": "**/visual-maps/van_mode_split/van-qa-main.mdc",
            "alwaysApply": False,
            "body": """
# VAN QA: TECHNICAL VALIDATION - MAIN ORCHESTRATOR (AI Instructions)

> **TL;DR:** Orchestrate the four-point technical validation (Dependencies, Configuration, Environment, Minimal Build Test) by fetching specific check rules. Then, fetch reporting and mode transition rules based on results. Use `edit_file` for logging to `activeContext.md`.

## 🧭 VAN QA PROCESS FLOW (AI Actions)

1.  **Acknowledge & Context:**
    a.  State: "VAN QA Main Orchestrator activated. Starting technical validation process."
    b.  `read_file memory-bank/activeContext.md` for current task, complexity, and any relevant tech stack info from CREATIVE phase.
    c.  `read_file memory-bank/tasks.md` for task details.
    d.  `read_file memory-bank/techContext.md` (if it exists and is populated).
    e.  Use `edit_file` to add to `memory-bank/activeContext.md`: "VAN QA Log - [Timestamp]: Starting technical validation."
2.  **Perform Four-Point Validation (Fetch sub-rules sequentially):**
    a.  **Dependency Verification:**
        i.  State: "Performing Dependency Verification."
        ii. `fetch_rules` for `.cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-checks/dependency-check.mdc`.
        iii. (This rule will guide checks and log results to `activeContext.md`). Let `pass_dep_check` be true/false based on its outcome.
    b.  **Configuration Validation (if `pass_dep_check` is true):**
        i.  State: "Performing Configuration Validation."
        ii. `fetch_rules` for `.cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-checks/config-check.mdc`.
        iii. Let `pass_config_check` be true/false.
    c.  **Environment Validation (if `pass_config_check` is true):**
        i.  State: "Performing Environment Validation."
        ii. `fetch_rules` for `.cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-checks/environment-check.mdc`.
        iii. Let `pass_env_check` be true/false.
    d.  **Minimal Build Test (if `pass_env_check` is true):**
        i.  State: "Performing Minimal Build Test."
        ii. `fetch_rules` for `.cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-checks/build-test.mdc`.
        iii. Let `pass_build_check` be true/false.
3.  **Consolidate Results & Generate Report:**
    a.  Overall QA Status: `pass_qa = pass_dep_check AND pass_config_check AND pass_env_check AND pass_build_check`.
    b.  State: "Technical validation checks complete. Overall QA Status: [PASS/FAIL]."
    c.  `fetch_rules` for `.cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-utils/reports.mdc`.
    d.  Follow instructions in `reports.mdc` to use `edit_file` to:
        i.  Generate the full QA report (success or failure format) and display it to the user.
        ii. Write "PASS" or "FAIL" to `memory-bank/.qa_validation_status` (a hidden file for programmatic checks).
4.  **Determine Next Steps:**
    a.  **If `pass_qa` is TRUE:**
        i.  State: "All VAN QA checks passed."
        ii. `fetch_rules` for `.cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-utils/mode-transitions.mdc`.
        iii. (This rule will guide recommending BUILD mode).
    b.  **If `pass_qa` is FALSE:**
        i.  State: "One or more VAN QA checks failed. Please review the report."
        ii. `fetch_rules` for `.cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-utils/common-fixes.mdc`.
        iii. (This rule will provide general fix guidance).
        iv. State: "Please address the issues and then re-type 'VAN QA' to re-run the validation."
5.  **Completion of this Orchestrator:**
    a.  Use `edit_file` to add to `memory-bank/activeContext.md`: "VAN QA Log - [Timestamp]: Technical validation process orchestrated. Outcome: [PASS/FAIL]."
    b.  (Control returns to `van-mode-map.mdc` or awaits user input based on QA outcome).

## 🧰 Utility Rule Reminder:
*   For detailed guidance on how to structure `fetch_rules` calls, you can (if necessary for your own understanding) `read_file` `.cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-utils/rule-calling-guide.mdc` or `rule-calling-help.mdc`. However, this orchestrator explicitly tells you which rules to fetch.
"""
        },
        # --- VAN QA Checks ---
        {
            "path": ".cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-checks/dependency-check.mdc",
            "description": "VAN QA sub-rule for dependency verification. Fetched by `van-qa-main.mdc`. Guides AI to check required dependencies and log results.",
            "globs": "**/visual-maps/van_mode_split/van-qa-checks/dependency-check.mdc",
            "alwaysApply": False,
            "body": """
# VAN QA: DEPENDENCY VERIFICATION (AI Instructions)

> **TL;DR:** Verify project dependencies (e.g., Node.js, npm, Python, pip, specific libraries) are installed and versions are compatible. Log findings to `activeContext.md` using `edit_file`. This rule is fetched by `van-qa-main.mdc`.

## ⚙️ AI ACTIONS FOR DEPENDENCY VERIFICATION:

1.  **Acknowledge & Context:**
    a.  State: "Starting Dependency Verification."
    b.  `read_file memory-bank/techContext.md` and `memory-bank/tasks.md` (or `activeContext.md` if it has tech stack info from CREATIVE phase) to identify key technologies and expected dependencies (e.g., Node.js version, Python version, package manager, specific libraries).
2.  **Define Checks (Based on Context):**
    *   **Example for Node.js project:**
        *   Check Node.js installed and version (e.g., `node -v`).
        *   Check npm installed and version (e.g., `npm -v`).
        *   Check `package.json` exists (e.g., `list_dir .`).
        *   If `package-lock.json` or `yarn.lock` exists, consider running `npm ci` or `yarn install --frozen-lockfile` (or just `npm install`/`yarn install` if less strict) to verify/install packages.
    *   **Example for Python project:**
        *   Check Python installed and version (e.g., `python --version` or `python3 --version`).
        *   Check pip installed (usually comes with Python).
        *   Check `requirements.txt` exists.
        *   Consider creating a virtual environment and `pip install -r requirements.txt`.
3.  **Execute Checks (Using `run_terminal_cmd`):**
    a.  For each defined check:
        i.  Clearly state the command you are about to run.
        ii. `run_terminal_cmd` with the command.
        iii. Record the output.
4.  **Evaluate Results & Log:**
    a.  Based on command outputs, determine if dependencies are met.
    b.  Use `edit_file` to append detailed findings to the "VAN QA Log" in `memory-bank/activeContext.md`:
        ```markdown
        #### Dependency Check Log - [Timestamp]
        - Check: Node.js version
          - Command: `node -v`
          - Output: `v18.12.0`
          - Status: PASS (meets requirement >=16)
        - Check: npm install
          - Command: `npm install`
          - Output: `... up to date ...` or error messages
          - Status: [PASS/FAIL - with error summary if FAIL]
        - ... (other checks) ...
        - Overall Dependency Status: [PASS/FAIL]
        ```
5.  **Completion:**
    a.  State: "Dependency Verification complete. Overall Status: [PASS/FAIL]."
    b.  (The `van-qa-main.mdc` orchestrator will use this outcome).
"""
        },
        {
            "path": ".cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-checks/config-check.mdc",
            "description": "VAN QA sub-rule for configuration validation. Fetched by `van-qa-main.mdc`. Guides AI to check project configuration files.",
            "globs": "**/visual-maps/van_mode_split/van-qa-checks/config-check.mdc",
            "alwaysApply": False,
            "body": """
# VAN QA: CONFIGURATION VALIDATION (AI Instructions)

> **TL;DR:** Validate project configuration files (e.g., `package.json` syntax, `tsconfig.json`, linters, build tool configs). Log findings to `activeContext.md` using `edit_file`. This rule is fetched by `van-qa-main.mdc`.

## ⚙️ AI ACTIONS FOR CONFIGURATION VALIDATION:

1.  **Acknowledge & Context:**
    a.  State: "Starting Configuration Validation."
    b.  `read_file memory-bank/techContext.md` and `memory-bank/tasks.md` to identify relevant configuration files based on the project type and technology stack.
2.  **Define Checks (Based on Context):**
    *   **Example for a TypeScript/React project:**
        *   `package.json`: `read_file package.json`. Check for valid JSON structure (conceptually, AI doesn't parse JSON strictly but looks for malformations). Check for essential scripts (`build`, `start`, `test`).
        *   `tsconfig.json`: `read_file tsconfig.json`. Check for valid JSON. Check for key compiler options like `jsx`, `target`, `moduleResolution`.
        *   `.eslintrc.js` or `eslint.config.js`: `read_file [config_name]`. Check for basic structural integrity.
        *   `vite.config.js` or `webpack.config.js`: `read_file [config_name]`. Check for presence of key plugins (e.g., React plugin).
3.  **Execute Checks (Primarily using `read_file` and analysis):**
    a.  For each configuration file:
        i.  `read_file [config_filepath]`.
        ii. Analyze its content against expected structure or key settings.
        iii. For linting/formatting configs, note their presence. Actual linting runs are usually part of build/test steps.
4.  **Evaluate Results & Log:**
    a.  Based on file content analysis, determine if configurations seem correct and complete.
    b.  Use `edit_file` to append detailed findings to the "VAN QA Log" in `memory-bank/activeContext.md`:
        ```markdown
        #### Configuration Check Log - [Timestamp]
        - File: `package.json`
          - Check: Valid JSON structure, presence of `build` script.
          - Status: PASS
        - File: `tsconfig.json`
          - Check: Presence of `jsx: react-jsx`.
          - Status: FAIL (jsx option missing or incorrect)
        - ... (other checks) ...
        - Overall Configuration Status: [PASS/FAIL]
        ```
5.  **Completion:**
    a.  State: "Configuration Validation complete. Overall Status: [PASS/FAIL]."
    b.  (The `van-qa-main.mdc` orchestrator will use this outcome).
"""
        },
        {
            "path": ".cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-checks/environment-check.mdc",
            "description": "VAN QA sub-rule for environment validation. Fetched by `van-qa-main.mdc`. Guides AI to check build tools, permissions, etc.",
            "globs": "**/visual-maps/van_mode_split/van-qa-checks/environment-check.mdc",
            "alwaysApply": False,
            "body": """
# VAN QA: ENVIRONMENT VALIDATION (AI Instructions)

> **TL;DR:** Validate the development/build environment (e.g., required CLI tools available, necessary permissions, environment variables). Log findings to `activeContext.md` using `edit_file`. This rule is fetched by `van-qa-main.mdc`.

## ⚙️ AI ACTIONS FOR ENVIRONMENT VALIDATION:

1.  **Acknowledge & Context:**
    a.  State: "Starting Environment Validation."
    b.  `read_file memory-bank/techContext.md` to identify expected environment characteristics (e.g., OS, required CLIs like Git, Docker).
2.  **Define Checks (Based on Context):**
    *   **General Checks:**
        *   Git CLI: `run_terminal_cmd git --version`.
        *   Network connectivity (if external resources needed for build): (Conceptual check, or a simple `ping google.com` if allowed and relevant).
    *   **Example for Web Development:**
        *   Build tool (e.g., Vite, Webpack if used globally): `run_terminal_cmd vite --version` (if applicable).
        *   Port availability (e.g., for dev server): (Conceptual, AI can't directly check. Note if a common port like 3000 or 8080 is usually needed).
    *   **Permissions:**
        *   (Conceptual) Does the AI anticipate needing to write files outside `memory-bank/` or project dir during build? If so, note potential permission needs. Actual permission checks are hard for AI.
3.  **Execute Checks (Using `run_terminal_cmd` where appropriate):**
    a.  For each defined check:
        i.  State the command or check being performed.
        ii. If using `run_terminal_cmd`, record the output.
4.  **Evaluate Results & Log:**
    a.  Based on command outputs and conceptual checks, determine if the environment seems suitable.
    b.  Use `edit_file` to append detailed findings to the "VAN QA Log" in `memory-bank/activeContext.md`:
        ```markdown
        #### Environment Check Log - [Timestamp]
        - Check: Git CLI availability
          - Command: `git --version`
          - Output: `git version 2.30.0`
          - Status: PASS
        - Check: Port 3000 availability for dev server
          - Method: Conceptual (not directly testable by AI)
          - Assumption: Port 3000 should be free.
          - Status: NOTE (User should ensure port is free)
        - ... (other checks) ...
        - Overall Environment Status: [PASS/WARN/FAIL]
        ```
5.  **Completion:**
    a.  State: "Environment Validation complete. Overall Status: [PASS/WARN/FAIL]."
    b.  (The `van-qa-main.mdc` orchestrator will use this outcome).
"""
        },
        {
            "path": ".cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-checks/build-test.mdc",
            "description": "VAN QA sub-rule for minimal build test. Fetched by `van-qa-main.mdc`. Guides AI to attempt a basic build/compilation.",
            "globs": "**/visual-maps/van_mode_split/van-qa-checks/build-test.mdc",
            "alwaysApply": False,
            "body": """
# VAN QA: MINIMAL BUILD TEST (AI Instructions)

> **TL;DR:** Attempt a minimal or dry-run build of the project to catch early integration or setup issues. Log findings to `activeContext.md` using `edit_file`. This rule is fetched by `van-qa-main.mdc`.

## ⚙️ AI ACTIONS FOR MINIMAL BUILD TEST:

1.  **Acknowledge & Context:**
    a.  State: "Starting Minimal Build Test."
    b.  `read_file package.json` (or equivalent like `Makefile`, `pom.xml`) to identify build commands.
    c.  `read_file memory-bank/techContext.md` for info on build tools.
2.  **Define Build Command:**
    a.  Identify the primary build script (e.g., `npm run build`, `mvn package`, `make`).
    b.  Consider if a "dry run" or "lint-only" or "compile-only" version of the build command exists to test the toolchain without full artifact generation (e.g., `tsc --noEmit` for TypeScript). If so, prefer it for a *minimal* test. If not, use the standard build command.
3.  **Execute Build Command (Using `run_terminal_cmd`):**
    a.  State the exact build command you are about to run.
    b.  Ensure you are in the correct directory (usually project root). `list_dir .` to confirm presence of `package.json` etc. If not, use `cd` via `run_terminal_cmd`.
    c.  `run_terminal_cmd [build_command]`.
    d.  Capture the full output.
4.  **Evaluate Results & Log:**
    a.  Analyze the output for success messages or error codes/messages.
    b.  Use `edit_file` to append detailed findings to the "VAN QA Log" in `memory-bank/activeContext.md`:
        ```markdown
        #### Minimal Build Test Log - [Timestamp]
        - Command: `npm run build`
        - Output:
          \`\`\`
          [Full or summarized build output]
          \`\`\`
        - Status: [PASS/FAIL - with key error if FAIL]
        - Overall Minimal Build Test Status: [PASS/FAIL]
        ```
5.  **Completion:**
    a.  State: "Minimal Build Test complete. Overall Status: [PASS/FAIL]."
    b.  (The `van-qa-main.mdc` orchestrator will use this outcome).
"""
        },
        {
            "path": ".cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-checks/file-verification.mdc",
            "description": "VAN QA sub-rule for specific file/artifact verification post-build or during QA. Fetched by `van-qa-main.mdc` if deeper file checks are needed.",
            "globs": "**/visual-maps/van_mode_split/van-qa-checks/file-verification.mdc",
            "alwaysApply": False,
            "body": """
# VAN QA: DETAILED FILE VERIFICATION (AI Instructions)

> **TL;DR:** Verify existence, content, or structure of specific project files or build artifacts, beyond initial Memory Bank setup. Log findings to `activeContext.md`. This rule is typically fetched by `van-qa-main.mdc` if specific file checks are part of the QA plan.

## ⚙️ AI ACTIONS FOR DETAILED FILE VERIFICATION:

1.  **Acknowledge & Context:**
    a.  State: "Starting Detailed File Verification."
    b.  `read_file memory-bank/tasks.md` or `activeContext.md` to understand which specific files or artifact locations need verification as part of the current QA scope (e.g., "ensure `dist/bundle.js` is created after build", "check `config.yaml` has specific keys").
    c.  If no specific files are targeted for this QA check, state so and this check can be considered trivially PASS.
2.  **Define Checks (Based on QA Scope):**
    *   **Existence Check:** `list_dir [path_to_dir]` to see if `[filename]` is present.
    *   **Content Snippet Check:** `read_file [filepath]` and then search for a specific string or pattern within the content.
    *   **File Size Check (Conceptual):** If a build artifact is expected, `list_dir -l [filepath]` (Unix-like) or `Get-ChildItem [filepath] | Select-Object Length` (PowerShell) might give size. AI notes if it's unexpectedly zero or very small.
    *   **Structure Check (Conceptual for complex files like XML/JSON):** `read_file [filepath]` and describe if it generally conforms to expected structure (e.g., "appears to be valid JSON with a root object containing 'data' and 'errors' keys").
3.  **Execute Checks (Using `list_dir`, `read_file`, or `run_terminal_cmd` for file system info):**
    a.  For each defined file check:
        i.  State the file and the check being performed.
        ii. Execute the appropriate tool/command.
        iii. Record the observation/output.
4.  **Evaluate Results & Log:**
    a.  Based on observations, determine if file verifications pass.
    b.  Use `edit_file` to append findings to the "VAN QA Log" in `memory-bank/activeContext.md`:
        ```markdown
        #### Detailed File Verification Log - [Timestamp]
        - File: `dist/app.js`
          - Check: Existence after build.
          - Observation: File exists.
          - Status: PASS
        - File: `src/config/settings.json`
          - Check: Contains key `"api_url"`.
          - Observation: `read_file` content shows `"api_url": "https://example.com"`.
          - Status: PASS
        - ... (other checks) ...
        - Overall Detailed File Verification Status: [PASS/FAIL]
        ```
5.  **Completion:**
    a.  State: "Detailed File Verification complete. Overall Status: [PASS/FAIL]."
    b.  (The `van-qa-main.mdc` orchestrator will use this outcome).
"""
        },
        # --- VAN QA Utils ---
        {
            "path": ".cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-utils/common-fixes.mdc",
            "description": "VAN QA utility providing common fixes for validation failures. Fetched by `van-qa-main.mdc` on QA fail.",
            "globs": "**/visual-maps/van_mode_split/van-qa-utils/common-fixes.mdc",
            "alwaysApply": False,
            "body": """
# VAN QA: COMMON VALIDATION FIXES (AI Guidance)

> **TL;DR:** Provides common troubleshooting steps and fix suggestions when VAN QA checks fail. This rule is fetched by `van-qa-main.mdc` after a QA failure is reported.

## ⚙️ AI ACTIONS (Present this information to the user):

State: "Here are some common troubleshooting steps based on the type of QA failure. Please review the detailed failure report and attempt these fixes:"

### 1. Dependency Issues:
*   **Missing Tools (Node, Python, Git, etc.):**
    *   "Ensure the required tool ([Tool Name]) is installed and available in your system's PATH. You might need to download it from its official website or install it via your system's package manager."
*   **Incorrect Tool Version:**
    *   "The version of [Tool Name] found is [Found Version], but [Required Version] is expected. Consider using a version manager (like nvm for Node, pyenv for Python) to switch to the correct version, or update/downgrade the tool."
*   **Project Dependencies (`npm install` / `pip install` failed):**
    *   "Check the error messages from the package manager (`npm`, `pip`). Common causes include network issues, permission problems, or incompatible sub-dependencies."
    *   "Try deleting `node_modules/` and `package-lock.json` (or `venv/` and `requirements.txt` conflicts) and running the install command again."
    *   "Ensure your `package.json` or `requirements.txt` is correctly formatted and specifies valid package versions."

### 2. Configuration Issues:
*   **File Not Found:**
    *   "The configuration file `[filepath]` was not found. Ensure it exists at the correct location in your project."
*   **Syntax Errors (JSON, JS, etc.):**
    *   "The file `[filepath]` appears to have syntax errors. Please open it and check for typos, missing commas, incorrect brackets, etc. Using a code editor with linting can help."
*   **Missing Key Settings:**
    *   "The configuration file `[filepath]` is missing an expected setting: `[setting_name]`. Please add it according to the project's requirements (e.g., add `jsx: 'react-jsx'` to `tsconfig.json`)."

### 3. Environment Issues:
*   **Command Not Found (for build tools like `vite`, `tsc`):**
    *   "The command `[command_name]` was not found. If it's a project-local tool, ensure you've run `npm install` (or equivalent) and try prefixing with `npx` (e.g., `npx vite build`). If it's a global tool, ensure it's installed globally."
*   **Permission Denied:**
    *   "An operation failed due to insufficient permissions. You might need to run your terminal/IDE as an administrator (Windows) or use `sudo` (macOS/Linux) for specific commands, but be cautious with `sudo`."
    *   "Check file/folder permissions if trying to write to a restricted area."
*   **Port in Use:**
    *   "The build or dev server tried to use port `[port_number]`, which is already in use. Identify and stop the process using that port, or configure your project to use a different port."

### 4. Minimal Build Test Issues:
*   **Build Script Fails:**
    *   "The command `[build_command]` failed. Examine the full error output from the build process. It often points to missing dependencies, configuration errors, or code syntax issues."
    *   "Ensure all dependencies from `dependency-check.mdc` are resolved first."
*   **Entry Point Errors / Module Not Found:**
    *   "The build process reported it couldn't find a key file or module. Check paths in your configuration files (e.g., `vite.config.js`, `webpack.config.js`) and in your import statements in code."

**General Advice to User:**
"After attempting fixes, please type 'VAN QA' again to re-run the technical validation process."

(Control returns to `van-qa-main.mdc` which awaits user action).
"""
        },
        {
            "path": ".cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-utils/mode-transitions.mdc",
            "description": "VAN QA utility for handling mode transitions after QA. Fetched by `van-qa-main.mdc` on QA pass. Guides AI to recommend BUILD mode.",
            "globs": "**/visual-maps/van_mode_split/van-qa-utils/mode-transitions.mdc",
            "alwaysApply": False,
            "body": """
# VAN QA: MODE TRANSITIONS (AI Instructions)

> **TL;DR:** Handles mode transition recommendations after VAN QA validation. If QA passed, recommend BUILD mode. This rule is fetched by `van-qa-main.mdc` after a successful QA.

## ⚙️ AI ACTIONS FOR MODE TRANSITION (POST QA SUCCESS):

1.  **Acknowledge:** State: "VAN QA validation passed successfully."
2.  **Update `activeContext.md`:**
    a.  Use `edit_file` to update `memory-bank/activeContext.md` with:
        ```markdown
        ## VAN QA Status - [Timestamp]
        - Overall Result: PASS
        - Next Recommended Mode: BUILD
        ```
3.  **Recommend BUILD Mode:**
    a.  State: "All technical pre-flight checks are green. The project appears ready for implementation."
    b.  State: "Recommend transitioning to BUILD mode. Type 'BUILD' to begin implementation."
4.  **Await User Confirmation:** Await the user to type 'BUILD' or another command.

## 🔒 BUILD MODE ACCESS (Conceptual Reminder for AI):
*   The system is designed such that if a user tries to enter 'BUILD' mode directly without VAN QA having passed (for tasks requiring it), the BUILD mode orchestrator (or a preceding check) should ideally verify the `.qa_validation_status` file or `activeContext.md` and block if QA was needed but not passed. This current rule (`mode-transitions.mdc`) focuses on the *recommendation* after a *successful* QA.

(Control returns to `van-qa-main.mdc` which awaits user input).
"""
        },
        {
            "path": ".cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-utils/reports.mdc",
            "description": "VAN QA utility for generating success/failure reports. Fetched by `van-qa-main.mdc`. Guides AI to format and present QA results using `edit_file`.",
            "globs": "**/visual-maps/van_mode_split/van-qa-utils/reports.mdc",
            "alwaysApply": False,
            "body": """
# VAN QA: VALIDATION REPORTS (AI Instructions)

> **TL;DR:** Generate and present a formatted success or failure report based on the outcomes of the VAN QA checks. Update `activeContext.md` and `.qa_validation_status`. This rule is fetched by `van-qa-main.mdc`.

## ⚙️ AI ACTIONS FOR GENERATING REPORTS:

You will be told by `van-qa-main.mdc` whether the overall QA passed or failed, and will have access to the detailed logs in `activeContext.md`.

1.  **Acknowledge:** State: "Generating VAN QA Report."
2.  **Gather Data from `activeContext.md`:**
    a.  `read_file memory-bank/activeContext.md`.
    b.  Extract the findings from the "VAN QA Log" sections for:
        *   Dependency Check Status & Details
        *   Configuration Check Status & Details
        *   Environment Check Status & Details
        *   Minimal Build Test Status & Details
3.  **Format the Report:**

    **If Overall QA Status is PASS:**
    ```markdown
    ╔═════════════════════ 🔍 QA VALIDATION REPORT ══════════════════════╗
    │ PROJECT: [Project Name from activeContext.md/projectbrief.md]
    │ TIMESTAMP: [Current Date/Time]
    ├─────────────────────────────────────────────────────────────────────┤
    │ 1️⃣ DEPENDENCIES:   ✓ PASS. [Brief summary, e.g., "Node & npm OK"]
    │ 2️⃣ CONFIGURATION:  ✓ PASS. [Brief summary, e.g., "package.json & tsconfig OK"]
    │ 3️⃣ ENVIRONMENT:    ✓ PASS. [Brief summary, e.g., "Git found, permissions assumed OK"]
    │ 4️⃣ MINIMAL BUILD:  ✓ PASS. [Brief summary, e.g., "npm run build script executed successfully"]
    ├─────────────────────────────────────────────────────────────────────┤
    │ 🚨 FINAL VERDICT: PASS                                              │
    │ ➡️ Clear to proceed to BUILD mode.                                  │
    ╚═════════════════════════════════════════════════════════════════════╝
    ```

    **If Overall QA Status is FAIL:**
    ```markdown
    ⚠️⚠️⚠️ QA VALIDATION FAILED ⚠️⚠️⚠️

    Project: [Project Name]
    Timestamp: [Current Date/Time]

    The following issues must be resolved before proceeding to BUILD mode:

    1️⃣ DEPENDENCY ISSUES: [Status: FAIL/WARN]
       - Details: [Extracted from activeContext.md log for dependencies]
       - Recommended Fix: (Refer to common-fixes.mdc or specific error messages)

    2️⃣ CONFIGURATION ISSUES: [Status: FAIL/WARN]
       - Details: [Extracted from activeContext.md log for configurations]
       - Recommended Fix: (Refer to common-fixes.mdc or specific error messages)

    3️⃣ ENVIRONMENT ISSUES: [Status: FAIL/WARN]
       - Details: [Extracted from activeContext.md log for environment]
       - Recommended Fix: (Refer to common-fixes.mdc or specific error messages)

    4️⃣ MINIMAL BUILD TEST ISSUES: [Status: FAIL/WARN]
       - Details: [Extracted from activeContext.md log for build test]
       - Recommended Fix: (Refer to common-fixes.mdc or specific error messages)

    ⚠️ BUILD MODE IS BLOCKED until these issues are resolved.
    Type 'VAN QA' after fixing the issues to re-validate.
    ```
4.  **Present Report to User:**
    a.  Display the formatted report directly to the user in the chat.
5.  **Update `.qa_validation_status` File:**
    a.  Use `edit_file` to write "PASS" or "FAIL" to `memory-bank/.qa_validation_status`. This file acts as a simple flag for other rules.
        *   Example content for PASS: `QA_STATUS: PASS - [Timestamp]`
        *   Example content for FAIL: `QA_STATUS: FAIL - [Timestamp]`
6.  **Log Report Generation in `activeContext.md`:**
    a.  Use `edit_file` to append to `memory-bank/activeContext.md`:
        ```markdown
        #### VAN QA Report Generation - [Timestamp]
        - Overall QA Status: [PASS/FAIL]
        - Report presented to user.
        - `.qa_validation_status` file updated.
        ```
7.  **Completion:** State: "VAN QA Report generated and presented."
    (Control returns to `van-qa-main.mdc`).
"""
        },
        {
            "path": ".cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-utils/rule-calling-guide.mdc",
            "description": "VAN QA utility: A reference guide on how to call VAN QA rules. Fetched if AI needs clarification on rule invocation.",
            "globs": "**/visual-maps/van_mode_split/van-qa-utils/rule-calling-guide.mdc",
            "alwaysApply": False,
            "body": """
# VAN QA: COMPREHENSIVE RULE CALLING GUIDE (AI Reference)

> **TL;DR:** This is a reference for understanding how VAN QA rules are structured to be called using `fetch_rules`. You typically won't fetch this rule directly unless you are trying to understand the system's design or if explicitly told to by a higher-level debugging instruction.

## 🔍 RULE CALLING BASICS for CMB System:

1.  **`fetch_rules` is Key:** All `.mdc` rule files in this system are designed to be loaded and executed via the `fetch_rules` tool.
2.  **Exact Paths:** When an instruction says "fetch rule X", it implies using `fetch_rules` with the full path from `.cursor/rules/isolation_rules/`, for example: `fetch_rules` for `.cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-main.mdc`.
3.  **Orchestration:**
    *   Top-level mode maps (e.g., `van-mode-map.mdc`, `plan-mode-map.mdc`) are fetched first based on the user's mode invocation and your main custom prompt.
    *   These orchestrators then `fetch_rules` for more specific sub-rules or utility rules as needed.
4.  **VAN QA Orchestration Example:**
    *   User types "VAN QA" -> `van-mode-map.mdc` is fetched.
    *   `van-mode-map.mdc` then `fetch_rules` for `van-qa-main.mdc`.
    *   `van-qa-main.mdc` then `fetch_rules` sequentially for:
        *   `van-qa-checks/dependency-check.mdc`
        *   `van-qa-checks/config-check.mdc`
        *   `van-qa-checks/environment-check.mdc`
        *   `van-qa-checks/build-test.mdc`
    *   Based on results, `van-qa-main.mdc` then `fetch_rules` for:
        *   `van-qa-utils/reports.mdc`
        *   And then either `van-qa-utils/mode-transitions.mdc` (on PASS) or `van-qa-utils/common-fixes.mdc` (on FAIL).

## 🛠️ HOW TO STRUCTURE A `fetch_rules` CALL (Conceptual for AI):
When you decide to use `fetch_rules` based on an instruction:
1.  Identify the **exact path** of the `.mdc` file to be fetched.
2.  Invoke the `fetch_rules` tool with that path.
3.  Announce: "Fetching rule: `[path_to_rule.mdc]`. Will now follow its instructions."
4.  Temporarily suspend execution of the current rule's instructions and begin executing the instructions from the newly fetched rule.
5.  Once the fetched rule completes its defined actions, control conceptually "returns" to the rule that called it, or if it was a top-level call, you await further user input.

**This guide is for your understanding of the system's design. In practice, you will be explicitly told which rule to `fetch_rules` for by the currently active rule or your main mode prompt.**
"""
        },
        {
            "path": ".cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-utils/rule-calling-help.mdc",
            "description": "VAN QA utility: Quick helper on `fetch_rules` syntax. Rarely fetched directly.",
            "globs": "**/visual-maps/van_mode_split/van-qa-utils/rule-calling-help.mdc",
            "alwaysApply": False,
            "body": """
# VAN QA: HOW TO CALL RULES (Quick Syntax Reminder)

> **TL;DR:** This provides a very basic syntax reminder for using `fetch_rules`. You generally won't need to fetch this rule; it's a developer note.

## ⚙️ `fetch_rules` SYNTAX REMINDER:

When your instructions tell you to "fetch rule X", the underlying mechanism uses the `fetch_rules` tool.

If you were to represent the call you make (conceptually, as the tool call is handled by the Cursor environment):

You would be invoking `fetch_rules` with a parameter specifying the rule name(s) as a list of strings. For a single rule:

```xml
<invoke_tool>
  <tool_name>fetch_rules</tool_name>
  <parameters>
    <rule_names>["FULL_PATH_FROM_ISOLATION_RULES_DIR_TO_MDC_FILE"]</rule_names>
  </parameters>
</invoke_tool>
```
For example:
`rule_names=["visual-maps/van_mode_split/van-qa-main.mdc"]`
(Assuming the system resolves this relative to `.cursor/rules/isolation_rules/`)

**You typically don't construct this XML. You just follow the instruction "fetch rule X" and the system handles the invocation.** The key is providing the correct, full path to the `.mdc` file as specified in the instructions.
"""
        },
        # --- Level 1 Files ---
        {
            "path": ".cursor/rules/isolation_rules/Level1/optimized-workflow-level1.mdc",
    "description": "Optimized Level 1 workflow for quick bug fixes, emphasizing speed, token efficiency, and consolidated documentation using `edit_file`.",
    "globs": "**/Level1/optimized-workflow-level1.mdc",
    "alwaysApply": False,
    "body": """
# OPTIMIZED LEVEL 1 WORKFLOW (AI Instructions)

> **TL;DR:** This streamlined workflow for Level 1 tasks (quick bug fixes) optimizes for speed and token efficiency. Focus on direct implementation and consolidated documentation using `edit_file`.

## 🔧 LEVEL 1 PROCESS FLOW (AI Actions)

1.  **Acknowledge & Context (Assumes VAN mode has confirmed Level 1):**
    a.  State: "Initiating Optimized Level 1 Workflow for [Task Name from activeContext.md]."
    b.  `read_file memory-bank/tasks.md` to understand the specific issue.
    c.  `read_file memory-bank/activeContext.md` for any specific file paths or context.
2.  **Analyze & Locate:**
    a.  Briefly analyze the issue described in `tasks.md`.
    b.  If file paths are not provided, use `codebase_search` or `search_files` to locate the relevant code section(s).
3.  **Implement Fix:**
    a.  Use `edit_file` to make the necessary code changes directly.
    b.  Keep changes minimal and targeted, as expected for Level 1.
4.  **Verify (Conceptually or via Simple Test):**
    a.  Mentally review the change.
    b.  If a very simple test command is appropriate (e.g., linting the changed file, running a single specific test if available), use `run_terminal_cmd`.
5.  **Document (Consolidated):**
    a.  Use `edit_file` to update `memory-bank/tasks.md` with a concise record of the fix. Use a consolidated format.
        **Example Content for `tasks.md` (append under relevant task or in a 'Completed L1 Fixes' section):**
        ```markdown
        - **L1 Fix:** [Issue Name/ID]
          - **Problem:** [Brief description from original task]
          - **Cause:** [Brief root cause, if obvious]
          - **Solution:** [Implemented fix, e.g., "Corrected variable name in `auth.py` line 42."]
          - **Files Changed:** `[path/to/file.py]`
          - **Verification:** [e.g., "Visual inspection", "Ran linter"]
          - **Status:** COMPLETED - [Date]
        ```
    b.  Optionally, add a one-line entry to `memory-bank/progress.md` using `edit_file`:
        `[Date] - L1 Fix: [Issue Name] - Completed. See tasks.md for details.`
    c.  Update `memory-bank/activeContext.md` using `edit_file` to clear current L1 task focus and indicate readiness for next task.
6.  **Notify Completion:**
    a.  State: "Level 1 task '[Task Name]' completed and documented efficiently. Ready for next task."

## ⚡ TOKEN-OPTIMIZED TEMPLATE (for AI to structure the `tasks.md` update via `edit_file`)
When updating `tasks.md`, aim for a structure like this:
```markdown
- **L1 Fix:** [Issue Title]
  - **Problem:** [Brief description]
  - **Cause:** [Root cause, if clear]
  - **Solution:** [Implemented fix details]
  - **Files:** `[path/to/file1]`, `[path/to/file2]`
  - **Tested:** [How verified, e.g., "Visual check", "Linter pass"]
  - **Status:** COMPLETED - [Date]
```
This rule prioritizes direct action and minimal, consolidated documentation using `edit_file`.
"""
},
{
    "path": ".cursor/rules/isolation_rules/Level1/quick-documentation.mdc",
    "description": "Defines the content and structure for quick documentation of Level 1 (Quick Bug Fix) tasks, primarily within `tasks.md` using `edit_file`.",
    "globs": "**/Level1/quick-documentation.mdc",
    "alwaysApply": False,
    "body": """
# QUICK DOCUMENTATION FOR LEVEL 1 TASKS (AI Instructions)

> **TL;DR:** This rule outlines the concise documentation approach for Level 1 tasks. The primary record is made in `memory-bank/tasks.md` using `edit_file`.

## 📋 DOCUMENTATION PRINCIPLES (AI Self-Guide)
*   **Conciseness:** Brief but complete.
*   **Focus:** Only essential information to understand the fix.
*   **Findability:** Ensure the fix can be referenced via `tasks.md`.

## 📝 QUICK FIX DOCUMENTATION TEMPLATE (For `tasks.md` update via `edit_file`)
When a Level 1 task is completed, use `edit_file` to update its entry or add a new entry in `memory-bank/tasks.md` under a "Completed Level 1 Fixes" or similar section, following this structure:

```markdown
- **L1 Fix:** [Issue Title/ID from original task]
  - **Issue:** [Brief description of the problem - 1-2 sentences]
  - **Root Cause:** [Concise description of what caused the issue - 1-2 sentences, if readily apparent]
  - **Solution:** [Brief description of the fix implemented - 2-3 sentences, e.g., "Modified `user_controller.js` line 75 to correctly handle null input for username."]
  - **Files Changed:**
    - `[path/to/file1.ext]`
    - `[path/to/file2.ext]` (if applicable)
  - **Verification:** [How the fix was tested/verified - 1-2 sentences, e.g., "Manually tested login with empty username field.", "Ran linter on changed file."]
  - **Status:** COMPLETED - [Date]
```

## 🔄 MEMORY BANK UPDATES (AI Actions)

1.  **`tasks.md` (Primary Record):**
    *   Use `edit_file` to add/update the entry as per the template above. This is the main documentation for L1 fixes.
2.  **`activeContext.md` (Minimal Update):**
    *   Use `edit_file` to append a brief note to `memory-bank/activeContext.md` if desired, e.g.:
        ```markdown
        ### Recent L1 Fixes - [Date]
        - Fixed [Issue Title] in `[main_file_changed]`. See `tasks.md` for details.
        ```
    *   More importantly, clear the L1 task from the "Current Focus" in `activeContext.md`.
3.  **`progress.md` (Optional Minimal Update):**
    *   Use `edit_file` to append a one-liner to `memory-bank/progress.md` if desired, e.g.:
        `[Date] - L1 Fix: Completed [Issue Title].`

**Focus:** The goal is efficient capture of essential information directly in `tasks.md` using `edit_file`.
(This rule provides the *content structure*. The actual workflow is often directed by `Level1/workflow-level1.mdc` or `Level1/optimized-workflow-level1.mdc` which might refer to these content guidelines).
"""
},
{
    "path": ".cursor/rules/isolation_rules/Level1/workflow-level1.mdc",
    "description": "Streamlined workflow for Level 1 (Quick Bug Fix) tasks. Guides AI through minimal initialization, direct implementation, and quick documentation using `edit_file`.",
    "globs": "**/Level1/workflow-level1.mdc",
    "alwaysApply": False,
    "body": """
# STREAMLINED WORKFLOW FOR LEVEL 1 TASKS (AI Instructions)

> **TL;DR:** This rule guides the AI through a minimal workflow for Level 1 (Quick Bug Fix) tasks. It emphasizes rapid issue resolution and concise documentation, primarily using `edit_file`.

## 🧭 LEVEL 1 WORKFLOW PHASES (AI Actions)

This workflow is typically fetched after VAN mode has confirmed the task as Level 1.

### Phase 1: INITIALIZATION (Quick Confirmation)

1.  **Acknowledge & Context:**
    a.  State: "Initiating Level 1 Workflow for [Task Name from activeContext.md]."
    b.  `read_file memory-bank/tasks.md` to confirm the specific issue details.
    c.  `read_file memory-bank/activeContext.md` for current focus.
2.  **Environment Setup (Conceptual):**
    a.  No complex setup expected for L1. Assume environment is ready.
3.  **Task Entry Check:**
    a.  Ensure a minimal task entry exists in `tasks.md` for the issue. If VAN mode created a detailed one, that's fine. If not, ensure at least a line item is there.
    b.  `edit_file memory-bank/activeContext.md` to confirm: "Focus: L1 Fix - [Task Name]".
4.  **Milestone:** State "L1 Initialization complete. Proceeding to Implementation."

### Phase 2: IMPLEMENTATION (Direct Fix)

1.  **Locate Issue Source:**
    a.  If `tasks.md` or `activeContext.md` specifies file(s) and line(s), use that.
    b.  If not, use `codebase_search` or `search_files` with keywords from the issue description to find the relevant code.
2.  **Develop & Apply Fix:**
    a.  Use `edit_file` to make the targeted code change.
    b.  The fix should be small and localized, consistent with Level 1.
3.  **Test & Verify:**
    a.  Perform a simple verification. This might be:
        *   Visual inspection of the change.
        *   Running a linter on the modified file (`run_terminal_cmd`).
        *   If a very specific unit test covers the change and is easy to run, consider `run_terminal_cmd` for that single test.
    b.  State the verification method and outcome.
4.  **Milestone:** State "L1 Implementation and verification complete. Proceeding to Documentation."

### Phase 3: DOCUMENTATION (Quick & Concise)

1.  **Update `tasks.md`:**
    a.  `fetch_rules` for `.cursor/rules/isolation_rules/Level1/quick-documentation.mdc`.
    b.  Follow the template provided in `quick-documentation.mdc` to update the task entry in `memory-bank/tasks.md` using `edit_file`. This includes issue, cause (if known), solution, files changed, and verification. Mark as COMPLETED with date.
2.  **Update `activeContext.md`:**
    a.  Use `edit_file` to clear the "Focus" section in `memory-bank/activeContext.md` or set it to "Awaiting next task."
    b.  Optionally, add a one-line summary to a "Recent L1 Fixes" log in `activeContext.md`.
3.  **Notify Stakeholders (Conceptual):**
    a.  For L1, direct notification is usually not needed unless specified. The `tasks.md` update serves as the record.
4.  **Milestone:** State "L1 Documentation complete. Task [Task Name] is fully resolved."

## 🚨 TASK ESCALATION
*   If during IMPLEMENTATION, the issue is found to be more complex than L1 (e.g., requires changes to multiple components, design decisions, or significant testing):
    a.  State: "ESCALATION: Issue [Task Name] is more complex than initially assessed. It appears to be Level [2/3]. Recommend halting L1 workflow and re-evaluating in VAN or PLAN mode."
    b.  Use `edit_file` to update `tasks.md` and `activeContext.md` with this assessment.
    c.  Await user guidance.

This workflow prioritizes speed and efficiency for simple fixes.
"""
},
# --- Level 2 Files ---
{
    "path": ".cursor/rules/isolation_rules/Level2/archive-basic.mdc",
    "description": "Basic archiving for Level 2 (Simple Enhancement) tasks. Guides AI to create a structured archive document using `edit_file`.",
    "globs": "**/Level2/archive-basic.mdc",
    "alwaysApply": False,
    "body": """
# BASIC ARCHIVING FOR LEVEL 2 TASKS (AI Instructions)

> **TL;DR:** This rule guides the creation of a basic archive document for a completed Level 2 task using `edit_file`. It ensures key information is preserved.

This rule is typically fetched by the Level 2 workflow orchestrator or the main ARCHIVE mode orchestrator if the task is L2.

## ⚙️ AI ACTIONS FOR LEVEL 2 ARCHIVING:

1.  **Acknowledge & Context:**
    a.  State: "Initiating Basic Archiving for Level 2 task: [Task Name from activeContext.md]."
    b.  `read_file memory-bank/tasks.md` for the completed task details (requirements, sub-tasks).
    c.  `read_file memory-bank/reflection/reflect-[task_name_or_id]-[date].md` for lessons learned.
    d.  `read_file memory-bank/progress.md` for implementation summary.
2.  **Prepare Archive Content (Based on Template Below):**
    a.  Synthesize information from `tasks.md`, `reflection-*.md`, and `progress.md`.
3.  **Create Archive File:**
    a.  Determine archive filename: `archive-[task_name_or_id]-[date].md` (e.g., `archive-user-profile-update-20250515.md`).
    b.  Use `edit_file` to create/update `memory-bank/archive/[archive_filename.md]` with the structured content.
        **Basic Archive Structure (Content for `edit_file`):**
        ```markdown
        # Enhancement Archive: [Feature Name from tasks.md]

        ## Task ID: [Task ID from tasks.md]
        ## Date Completed: [Date from tasks.md or reflection document]
        ## Complexity Level: 2

        ## 1. Summary of Enhancement
        [Brief summary of what was enhanced or added. Extract from tasks.md or reflection summary.]

        ## 2. Key Requirements Addressed
        [List the main requirements from tasks.md that this enhancement fulfilled.]
        - Requirement 1
        - Requirement 2

        ## 3. Implementation Overview
        [Brief description of how the enhancement was implemented. Summarize from progress.md or reflection document.]
        - Key files modified:
          - `[path/to/file1.ext]`
          - `[path/to/file2.ext]`
        - Main components changed: [List components]

        ## 4. Testing Performed
        [Summary of testing done, e.g., "Unit tests for new logic passed. Manual UI verification completed." From progress.md or reflection.]

        ## 5. Lessons Learned
        [Copy key lessons learned from `memory-bank/reflection/reflect-[task_name_or_id]-[date].md` or summarize them.]
        - Lesson 1
        - Lesson 2

        ## 6. Related Documents
        - Reflection: `../../reflection/reflect-[task_name_or_id]-[date].md`
        - (Link to specific creative docs if any were exceptionally made for L2)

        ## Notes
        [Any additional brief notes.]
        ```
4.  **Update Core Memory Bank Files (using `edit_file`):**
    a.  **`tasks.md`:**
        *   Mark the Level 2 task as "ARCHIVED".
        *   Add a link to the archive document: `Archived: ../archive/[archive_filename.md]`.
    b.  **`progress.md`:**
        *   Add a final entry: `[Date] - Task [Task Name] ARCHIVED. See archive/[archive_filename.md]`.
    c.  **`activeContext.md`:**
        *   Clear current task focus.
        *   Add to log: "Archived Level 2 task [Task Name]. Archive at `archive/[archive_filename.md]`."
5.  **Completion:**
    a.  State: "Basic archiving for Level 2 task [Task Name] complete. Archive document created at `memory-bank/archive/[archive_filename.md]`."
    b.  (Control returns to the fetching rule, e.g., `Level2/workflow-level2.mdc` or `visual-maps/archive-mode-map.mdc`).
"""
},
{
    "path": ".cursor/rules/isolation_rules/Level2/reflection-basic.mdc",
    "description": "Basic reflection for Level 2 (Simple Enhancement) tasks. Guides AI to create a structured reflection document using `edit_file`.",
    "globs": "**/Level2/reflection-basic.mdc",
    "alwaysApply": False,
    "body": """
# BASIC REFLECTION FOR LEVEL 2 TASKS (AI Instructions)

> **TL;DR:** This rule guides the creation of a basic reflection document for a completed Level 2 task using `edit_file`. It focuses on key outcomes, challenges, and lessons.

This rule is typically fetched by the Level 2 workflow orchestrator or the main REFLECT mode orchestrator if the task is L2.

## ⚙️ AI ACTIONS FOR LEVEL 2 REFLECTION:

1.  **Acknowledge & Context:**
    a.  State: "Initiating Basic Reflection for Level 2 task: [Task Name from activeContext.md]."
    b.  `read_file memory-bank/tasks.md` for the completed task details (original plan, requirements).
    c.  `read_file memory-bank/progress.md` for the implementation journey and any logged challenges/successes.
    d.  `read_file memory-bank/activeContext.md` to confirm implementation is marked complete.
2.  **Prepare Reflection Content (Based on Template Below):**
    a.  Synthesize information from `tasks.md` and `progress.md`.
3.  **Create Reflection File:**
    a.  Determine reflection filename: `reflect-[task_name_or_id]-[date].md` (e.g., `reflect-user-profile-update-20250515.md`).
    b.  Use `edit_file` to create/update `memory-bank/reflection/[reflection_filename.md]` with the structured content.
        **Basic Reflection Structure (Content for `edit_file`):**
        ```markdown
        # Level 2 Enhancement Reflection: [Feature Name from tasks.md]

        ## Task ID: [Task ID from tasks.md]
        ## Date of Reflection: [Current Date]
        ## Complexity Level: 2

        ## 1. Enhancement Summary
        [Brief one-paragraph summary of the enhancement: What was the goal? What was achieved?]

        ## 2. What Went Well?
        [Identify 2-3 specific positive aspects of the development process for this enhancement.]
        - Success point 1: [e.g., Integration with existing module was straightforward.]
        - Success point 2: [e.g., Testing covered all main use cases effectively.]

        ## 3. Challenges Encountered & Solutions
        [Identify 1-2 specific challenges and how they were addressed.]
        - Challenge 1: [e.g., Initial approach for X was inefficient.]
          - Solution: [e.g., Refactored to use Y pattern, improving performance.]
        - Challenge 2: (if any)

        ## 4. Key Learnings (Technical or Process)
        [List 1-2 key insights or lessons learned.]
        - Learning 1: [e.g., Realized library Z is better suited for this type of UI component.]
        - Learning 2: [e.g., Updating `tasks.md` more frequently for sub-tasks helps maintain clarity.]

        ## 5. Time Estimation Accuracy (If applicable)
        - Estimated time: [From tasks.md, if estimated]
        - Actual time: [Approximate actual time based on progress.md entries]
        - Variance & Reason: [Briefly, e.g., "+2 hours due to unexpected CSS conflict."]

        ## 6. Action Items for Future Work (Optional for L2, but good practice)
        [Any specific, actionable improvements for future tasks or for this feature.]
        - Action item 1: [e.g., Document the new CSS utility class created.]
        ```
4.  **Update Core Memory Bank Files (using `edit_file`):**
    a.  **`tasks.md`:**
        *   Mark the Level 2 task's REFLECT phase as "COMPLETE".
        *   Add a link to the reflection document: `Reflection: ../reflection/[reflection_filename.md]`.
    b.  **`activeContext.md`:**
        *   Update current focus: "Reflection complete for L2 task [Task Name]. Ready for ARCHIVE."
        *   Add to log: "Completed reflection for L2 task [Task Name]. Document at `reflection/[reflection_filename.md]`."
5.  **Completion:**
    a.  State: "Basic reflection for Level 2 task [Task Name] complete. Reflection document created at `memory-bank/reflection/[reflection_filename.md]`."
    b.  (Control returns to the fetching rule, e.g., `Level2/workflow-level2.mdc` or `visual-maps/reflect-mode-map.mdc`).
"""
},
{
    "path": ".cursor/rules/isolation_rules/Level2/task-tracking-basic.mdc",
    "description": "Basic task tracking for Level 2 (Simple Enhancement) tasks. Guides AI to structure `tasks.md` using `edit_file`.",
    "globs": "**/Level2/task-tracking-basic.mdc",
    "alwaysApply": False,
    "body": """
# BASIC TASK TRACKING FOR LEVEL 2 (AI Instructions)

> **TL;DR:** This rule outlines a streamlined task tracking approach for Level 2 (Simple Enhancement) tasks. Use `edit_file` to update `memory-bank/tasks.md` with the defined structure.

This rule is typically fetched by the PLAN mode orchestrator when a task is identified as Level 2.

## ⚙️ AI ACTIONS FOR LEVEL 2 TASK TRACKING (Updating `tasks.md`):

1.  **Acknowledge & Context:**
    a.  State: "Applying Basic Task Tracking for Level 2 task: [Task Name from activeContext.md]."
    b.  `read_file memory-bank/tasks.md` to locate the existing entry for this task (likely created minimally by VAN mode).
2.  **Update Task Entry in `tasks.md` (using `edit_file`):**
    a.  Ensure the task entry in `memory-bank/tasks.md` includes the following sections. If the task entry is new or minimal, create/populate these sections. If it exists, update them.

        **Task Structure for Level 2 (Content for `edit_file` on `tasks.md`):**
        ```markdown
        ## Task: [Task Name/ID - e.g., L2-001: Enhance User Profile Page]

        - **Status:** IN_PROGRESS_PLANNING (or update as planning proceeds)
        - **Priority:** [High/Medium/Low - user may specify, or default to Medium]
        - **Estimated Effort:** [Small/Medium - L2 tasks are generally not Large]
        - **Complexity Level:** 2
        - **Assigned To:** AI

        ### 1. Description
        [Brief description of the enhancement. What is the goal? What user problem does it solve? Synthesize from user request or `projectbrief.md`.]

        ### 2. Requirements / Acceptance Criteria
        [List 2-5 clear, testable requirements or acceptance criteria for the enhancement.]
        - [ ] Requirement 1: [e.g., User can upload a profile picture.]
        - [ ] Requirement 2: [e.g., Uploaded picture is displayed on the profile page.]
        - [ ] Requirement 3: [e.g., Error message shown if upload fails.]

        ### 3. Sub-tasks (Implementation Steps)
        [Break the enhancement into 3-7 high-level sub-tasks. These are for planning and will be checked off during IMPLEMENT mode.]
        - [ ] Sub-task 1: [e.g., Add file input field to profile form.]
        - [ ] Sub-task 2: [e.g., Implement backend endpoint for image upload.]
        - [ ] Sub-task 3: [e.g., Store image reference in user model.]
        - [ ] Sub-task 4: [e.g., Display uploaded image on profile page.]
        - [ ] Sub-task 5: [e.g., Add basic error handling for upload.]
        - [ ] Sub-task 6: [e.g., Write unit tests for upload endpoint.]
        - [ ] Sub-task 7: [e.g., Manual test of upload and display.]

        ### 4. Dependencies (If any)
        [List any other tasks, modules, or external factors this enhancement depends on. For L2, these should be minimal.]
        - Dependency 1: [e.g., User authentication module must be functional.]

        ### 5. Notes
        [Any additional brief notes, context, or links relevant to planning this enhancement.]
        - [e.g., Max image size should be 2MB.]
        ```
3.  **Log Update:**
    a.  Use `edit_file` to add a note to `memory-bank/activeContext.md`:
        `[Timestamp] - Updated `tasks.md` with detailed plan for L2 task: [Task Name].`
4.  **Completion:**
    a.  State: "Basic task tracking structure applied to `tasks.md` for Level 2 task [Task Name]."
    b.  (Control returns to the PLAN mode orchestrator, which will then typically recommend CREATIVE (if any minor design needed and flagged) or IMPLEMENT mode).

**Key Principle:** For L2 tasks, `tasks.md` should provide a clear, actionable plan without excessive detail. Sub-tasks guide implementation.
"""
},
{
    "path": ".cursor/rules/isolation_rules/Level2/workflow-level2.mdc",
    "description": "Basic workflow for Level 2 (Simple Enhancement) tasks. Guides AI through Initialization, Documentation Setup, Planning, Implementation, Reflection, and Archiving using `fetch_rules` for level-specific details.",
    "globs": "**/Level2/workflow-level2.mdc",
    "alwaysApply": False,
    "body": """
# WORKFLOW FOR LEVEL 2 TASKS (AI Instructions)

> **TL;DR:** This rule orchestrates the workflow for Level 2 (Simple Enhancement) tasks. It guides the AI through 6 key phases, fetching specific Level 2 rules for planning, reflection, and archiving.

This workflow is typically fetched after VAN mode has confirmed the task as Level 2.

## 🧭 LEVEL 2 WORKFLOW PHASES (AI Actions)

### Phase 1: INITIALIZATION (Confirmation & Context)
1.  **Acknowledge & Confirm L2:**
    a.  State: "Initiating Level 2 Workflow for [Task Name from activeContext.md]."
    b.  `read_file memory-bank/tasks.md` and `memory-bank/activeContext.md` to confirm task is indeed Level 2 and gather initial scope.
2.  **Platform & File Verification (If not done by VAN):**
    a.  If VAN mode didn't fully complete platform detection or Memory Bank setup (e.g., if transitioning from a different context), briefly ensure core setup:
        i.  `fetch_rules` for `.cursor/rules/isolation_rules/Core/platform-awareness.mdc`.
        ii. `fetch_rules` for `.cursor/rules/isolation_rules/Core/file-verification.mdc`.
3.  **Task Entry:**
    a.  Ensure `tasks.md` has an entry for this L2 task. `activeContext.md` should reflect "Focus: L2 Task - [Task Name]".
4.  **Milestone:** State "L2 Initialization complete. Proceeding to Documentation Setup."

### Phase 2: DOCUMENTATION SETUP (Minimal Context Update)
1.  **Update `projectbrief.md` (If necessary):**
    a.  `read_file memory-bank/projectbrief.md`.
    b.  If the L2 enhancement significantly alters or adds to project goals, use `edit_file` to add a brief note. Often not needed for L2.
2.  **Update `activeContext.md`:**
    a.  Use `edit_file` to ensure `memory-bank/activeContext.md` clearly states: "Current Focus: Planning Level 2 Enhancement - [Task Name]".
3.  **Milestone:** State "L2 Documentation Setup complete. Proceeding to Task Planning."

### Phase 3: TASK PLANNING (PLAN Mode Actions)
1.  **Fetch L2 Planning Rule:**
    a.  State: "Fetching Level 2 task planning guidelines."
    b.  `fetch_rules` for `.cursor/rules/isolation_rules/Level2/task-tracking-basic.mdc`.
2.  **Follow Fetched Rule:**
    a.  The `task-tracking-basic.mdc` rule will guide you to use `edit_file` to update `memory-bank/tasks.md` with:
        *   Clear requirements/acceptance criteria.
        *   A list of 3-7 high-level sub-tasks for implementation.
        *   Minimal dependencies and notes.
3.  **Update Context & Recommend:**
    a.  Use `edit_file` to update `memory-bank/activeContext.md`: "Planning complete for L2 task [Task Name]. Ready for Implementation."
    b.  State: "Level 2 Planning complete. Sub-tasks defined in `tasks.md`. Recommend IMPLEMENT mode."
4.  **Milestone:** Await user confirmation to proceed to IMPLEMENT mode.

### Phase 4: IMPLEMENTATION (IMPLEMENT Mode Actions)
1.  **Acknowledge & Review Plan:**
    a.  State: "Initiating Implementation for L2 task [Task Name]."
    b.  `read_file memory-bank/tasks.md` to review the sub-tasks.
    c.  `fetch_rules` for `.cursor/rules/isolation_rules/Core/command-execution.mdc` for tool usage guidelines.
2.  **Implement Sub-tasks:**
    a.  Iterate through sub-tasks in `tasks.md`.
    b.  For each sub-task:
        i.  Use `edit_file` for code changes.
        ii. Use `run_terminal_cmd` for simple builds or tests if applicable (platform-aware).
        iii. Use `edit_file` to update `memory-bank/progress.md` with actions taken and outcomes.
        iv. Use `edit_file` to mark the sub-task as complete in `tasks.md`.
3.  **Final Verification:**
    a.  Perform basic overall verification of the enhancement.
4.  **Update Context & Recommend:**
    a.  Use `edit_file` to update `memory-bank/activeContext.md`: "Implementation complete for L2 task [Task Name]. Ready for Reflection."
    b.  State: "Level 2 Implementation complete. Recommend REFLECT mode."
5.  **Milestone:** Await user confirmation to proceed to REFLECT mode.

### Phase 5: REFLECTION (REFLECT Mode Actions)
1.  **Fetch L2 Reflection Rule:**
    a.  State: "Fetching Level 2 reflection guidelines."
    b.  `fetch_rules` for `.cursor/rules/isolation_rules/Level2/reflection-basic.mdc`.
2.  **Follow Fetched Rule:**
    a.  The `reflection-basic.mdc` rule will guide you to use `edit_file` to create `memory-bank/reflection/reflect-[task_name_or_id]-[date].md` with sections for summary, what went well, challenges, and key learnings.
3.  **Update Context & Recommend:**
    a.  Use `edit_file` to update `memory-bank/activeContext.md`: "Reflection complete for L2 task [Task Name]. Ready for Archiving."
    b.  State: "Level 2 Reflection complete. Reflection document created. Recommend ARCHIVE mode."
4.  **Milestone:** Await user confirmation to proceed to ARCHIVE mode.

### Phase 6: ARCHIVING (ARCHIVE Mode Actions)
1.  **Fetch L2 Archiving Rule:**
    a.  State: "Fetching Level 2 archiving guidelines."
    b.  `fetch_rules` for `.cursor/rules/isolation_rules/Level2/archive-basic.mdc`.
2.  **Follow Fetched Rule:**
    a.  The `archive-basic.mdc` rule will guide you to use `edit_file` to create `memory-bank/archive/archive-[task_name_or_id]-[date].md`, summarizing the enhancement, implementation, and linking to the reflection doc.
    b.  It will also guide updates to `tasks.md` (mark ARCHIVED) and `progress.md`.
3.  **Finalize Context:**
    a.  Use `edit_file` to update `memory-bank/activeContext.md` to clear focus from the completed L2 task and state: "L2 Task [Task Name] archived. Ready for new task (VAN mode)."
4.  **Milestone:** State "Level 2 Task [Task Name] fully completed and archived. Recommend VAN mode for new task."
"""
},
# --- Level 3 Files ---
{
    "path": ".cursor/rules/isolation_rules/Level3/archive-intermediate.mdc",
    "description": "Intermediate archiving for Level 3 features. Guides AI to create a detailed archive document, linking to creative/reflection docs, using `edit_file`.",
    "globs": "**/Level3/archive-intermediate.mdc",
    "alwaysApply": False,
    "body": """
# LEVEL 3 ARCHIVE: INTERMEDIATE FEATURE DOCUMENTATION (AI Instructions)

> **TL;DR:** This rule guides the creation of an intermediate archive document for a completed Level 3 feature using `edit_file`. It ensures key information, including links to creative and reflection documents, is preserved.

This rule is typically fetched by the Level 3 workflow orchestrator or the main ARCHIVE mode orchestrator if the task is L3.

## ⚙️ AI ACTIONS FOR LEVEL 3 ARCHIVING:

1.  **Acknowledge & Context:**
    a.  State: "Initiating Intermediate Archiving for Level 3 feature: [Feature Name from activeContext.md]."
    b.  `read_file memory-bank/tasks.md` for the completed feature details (original plan, requirements, links to creative docs).
    c.  `read_file memory-bank/reflection/reflect-[feature_name_or_id]-[date].md` for detailed lessons learned.
    d.  `read_file memory-bank/progress.md` for implementation summary and key milestones.
    e.  `read_file` all relevant `memory-bank/creative/creative-[aspect_name]-[date].md` documents associated with this feature.
2.  **Pre-Archive Checklist (AI Self-Correction):**
    a.  Confirm from `tasks.md` that the REFLECT phase for this L3 feature is marked complete.
    b.  Verify `memory-bank/reflection/reflect-[feature_name_or_id]-[date].md` exists and is finalized.
    c.  Verify all `memory-bank/creative/creative-*.md` documents linked in `tasks.md` for this feature exist.
    d.  If checks fail, state: "L3 ARCHIVE BLOCKED: Prerequisite documents (Reflection, Creative) are missing or incomplete for feature [Feature Name]. Please complete REFLECT / CREATIVE modes first." Await user.
3.  **Prepare Archive Content (Based on Template Below):**
    a.  Synthesize information from all gathered documents.
4.  **Create Archive File:**
    a.  Determine archive filename: `archive-[feature_name_or_id]-[date].md` (e.g., `archive-user-profile-enhancement-20250515.md`).
    b.  Use `edit_file` to create/update `memory-bank/archive/[archive_filename.md]` with the structured content.
        **L3 Archive Structure (Content for `edit_file`):**
        ```markdown
        # Feature Archive: [Feature Name from tasks.md]

        ## Feature ID: [Feature ID from tasks.md]
        ## Date Archived: [Current Date]
        ## Complexity Level: 3
        ## Status: COMPLETED & ARCHIVED

        ## 1. Feature Overview
        [Brief description of the feature and its purpose. Extract from `tasks.md` (original plan) or `projectbrief.md`.]

        ## 2. Key Requirements Met
        [List the main functional and non-functional requirements this feature addressed, from `tasks.md`.]
        - Requirement 1
        - Requirement 2

        ## 3. Design Decisions & Creative Outputs
        [Summary of key design choices made during the CREATIVE phase(s).]
        - **Links to Creative Documents:**
          - `../../creative/creative-[aspect1_name]-[date].md`
          - `../../creative/creative-[aspect2_name]-[date].md`
          - (Add all relevant creative docs)
        - Link to Style Guide (if applicable): `../../style-guide.md` (version used, if known)

        ## 4. Implementation Summary
        [High-level overview of how the feature was implemented. Summarize from `progress.md` or reflection document.]
        - Primary new components/modules created: [List]
        - Key technologies/libraries utilized: [List]
        - Link to main feature branch merge commit / PR (if available from `progress.md`): [URL]

        ## 5. Testing Overview
        [Brief summary of the testing strategy (unit, integration, E2E) and outcomes. From `progress.md` or reflection.]

        ## 6. Reflection & Lessons Learned
        - **Link to Reflection Document:** `../../reflection/reflect-[feature_name_or_id]-[date].md`
        - **Critical Lessons (copied from reflection for quick summary):**
          - Lesson 1: [Critical lesson]
          - Lesson 2: [Critical lesson]

        ## 7. Known Issues or Future Considerations (Optional)
        [Any minor known issues deferred or potential future enhancements related to this feature, from reflection doc.]

        ## 8. Affected Files/Components (Summary from `tasks.md` plan)
        [List key files/components that were created or significantly modified.]
        ```
5.  **Update Core Memory Bank Files (using `edit_file`):**
    a.  **`tasks.md`:**
        *   Mark the Level 3 feature task as "ARCHIVED".
        *   Add a link to the archive document: `Archived: ../archive/[archive_filename.md]`.
    b.  **`progress.md`:**
        *   Add a final entry: `[Date] - Feature [Feature Name] ARCHIVED. See archive/[archive_filename.md]`.
    c.  **`activeContext.md`:**
        *   Clear current feature focus.
        *   Add to log: "Archived Level 3 feature [Feature Name]. Archive at `archive/[archive_filename.md]`."
6.  **Completion:**
    a.  State: "Intermediate archiving for Level 3 feature [Feature Name] complete. Archive document created at `memory-bank/archive/[archive_filename.md]`."
    b.  (Control returns to the fetching rule).
"""
},
{
    "path": ".cursor/rules/isolation_rules/Level3/implementation-intermediate.mdc",
    "description": "Implementation guidelines for Level 3 intermediate features. Guides AI on modular development, design adherence, testing, and documentation using `edit_file` and `run_terminal_cmd`.",
    "globs": "**/Level3/implementation-intermediate.mdc",
    "alwaysApply": False,
    "body": """
# LEVEL 3 IMPLEMENTATION: BUILDING INTERMEDIATE FEATURES (AI Instructions)

> **TL;DR:** This rule guides the systematic implementation of a planned and designed Level 3 feature. Emphasize modular development, strict adherence to creative decisions and style guide, integration, testing, and ongoing Memory Bank updates using `edit_file` and `run_terminal_cmd`.

This rule is typically fetched by the IMPLEMENT mode orchestrator if the task is L3.

## ⚙️ AI ACTIONS FOR LEVEL 3 IMPLEMENTATION:

1.  **Acknowledge & Preparation:**
    a.  State: "Initiating Level 3 Implementation for feature: [Feature Name from activeContext.md]."
    b.  `read_file memory-bank/tasks.md` for the detailed feature plan, sub-tasks, and links to creative documents.
    c.  `read_file` all relevant `memory-bank/creative/creative-[aspect_name]-[date].md` documents.
    d.  `read_file memory-bank/style-guide.md`.
    e.  `read_file memory-bank/techContext.md` for existing tech stack details.
    f.  `fetch_rules` for `.cursor/rules/isolation_rules/Core/command-execution.mdc` for tool usage guidelines.
2.  **Development Environment Setup (Conceptual):**
    a.  Assume user has set up the dev environment (branch, tools, dependencies). If specific new dependencies were noted in PLAN/CREATIVE, remind user if they haven't confirmed installation.
3.  **Iterative Module/Component Implementation (Follow `tasks.md` sub-tasks):**
    a.  For each implementation sub-task in `tasks.md` for the L3 feature:
        i.  State: "Starting sub-task: [Sub-task description]."
        ii. **Code Module/Component:**
            *   Use `edit_file` to create/modify source code files.
            *   Adhere strictly to designs from `creative-*.md` docs and `style-guide.md`.
            *   Implement with modularity, encapsulation, and coding standards in mind.
            *   Address state management, API interactions, error handling, performance, and security as per designs or best practices.
        iii. **Write & Run Unit Tests:**
            *   Use `edit_file` to write unit tests for new/modified logic.
            *   Use `run_terminal_cmd` to execute these tests (e.g., `npm test [test_file_spec]`). Log output.
        iv. **Self-Review/Linting:**
            *   Conceptually review code against requirements and style guide.
            *   If linters are part of the project, use `run_terminal_cmd` to run linter on changed files.
        v.  **Update Memory Bank:**
            *   Use `edit_file` to update `memory-bank/progress.md` with details of the completed sub-task, files changed, test results, and any decisions made.
            *   Use `edit_file` to mark the sub-task as complete in `memory-bank/tasks.md`.
            *   Use `edit_file` to update `memory-bank/activeContext.md` with current sub-task progress.
4.  **Integrate Feature Modules/Components:**
    a.  Once individual modules/components are built, ensure they integrate correctly.
    b.  This may involve `edit_file` changes to connect them.
5.  **Perform Integration Testing:**
    a.  Use `run_terminal_cmd` to execute integration tests that cover interactions between the new feature's components and with existing system parts. Log output.
    b.  If UI is involved, perform manual or automated UI integration tests.
6.  **End-to-End Feature Testing:**
    a.  Validate the complete feature against user stories and requirements from `tasks.md`.
    b.  If UI involved, check accessibility and responsiveness.
7.  **Code Cleanup & Refinement:**
    a.  Review all new/modified code for clarity, efficiency, and adherence to standards. Use `edit_file` for refinements.
8.  **Final Memory Bank Updates & Completion:**
    a.  Ensure `tasks.md` implementation phase is marked complete.
    b.  Ensure `progress.md` has a comprehensive log of the implementation.
    c.  Use `edit_file` to update `memory-bank/activeContext.md`: "Level 3 Implementation for [Feature Name] complete. Ready for REFLECT mode."
    d.  State: "Level 3 feature [Feature Name] implementation complete. All sub-tasks and tests passed. Recommend REFLECT mode."
    e.  (Control returns to the fetching rule).
"""
},
{
    "path": ".cursor/rules/isolation_rules/Level3/planning-comprehensive.mdc",
    "description": "Comprehensive planning for Level 3 intermediate features. Guides AI to update `tasks.md` with detailed requirements, components, strategy, risks, and flag CREATIVE needs, using `edit_file`.",
    "globs": "**/Level3/planning-comprehensive.mdc",
    "alwaysApply": False,
    "body": """
# LEVEL 3 COMPREHENSIVE PLANNING (AI Instructions)

> **TL;DR:** This rule guides the comprehensive planning for Level 3 (Intermediate Feature) tasks. Use `edit_file` to update `memory-bank/tasks.md` with detailed requirements, component analysis, implementation strategy, dependencies, risks, and critically, flag aspects needing CREATIVE mode.

This rule is typically fetched by the PLAN mode orchestrator when a task is identified as Level 3.

## ⚙️ AI ACTIONS FOR LEVEL 3 COMPREHENSIVE PLANNING (Updating `tasks.md`):

1.  **Acknowledge & Context:**
    a.  State: "Initiating Comprehensive Planning for Level 3 feature: [Feature Name from activeContext.md]."
    b.  `read_file memory-bank/tasks.md` to locate the existing entry for this L3 feature.
    c.  `read_file memory-bank/projectbrief.md`, `productContext.md`, `systemPatterns.md`, `techContext.md` for broader context.
2.  **Define/Refine Task Entry in `tasks.md` (using `edit_file`):**
    a.  Ensure the task entry in `memory-bank/tasks.md` for the L3 feature is structured with the following sections. Create or elaborate on these sections.

        **Comprehensive L3 Task Structure (Content for `edit_file` on `tasks.md`):**
        ```markdown
        ## Task: [Task Name/ID - e.g., L3-001: Implement User Profile Feature]

        - **Status:** IN_PROGRESS_PLANNING
        - **Priority:** [High/Medium/Low - user may specify, or default to Medium]
        - **Complexity Level:** 3
        - **Assigned To:** AI
        - **Target Completion Date (Optional):** [User may specify]

        ### 1. Feature Description & Goals
        [Detailed description of the feature, its purpose, business value, and key objectives. What problems does it solve? What are the success criteria?]

        ### 2. Detailed Requirements
        #### 2.1. Functional Requirements
        [List specific functional requirements. Use actionable language. e.g., "FR1: System MUST allow users to upload an avatar image." ]
        - [ ] FR1: ...
        - [ ] FR2: ...
        #### 2.2. Non-Functional Requirements
        [List NFRs like performance, security, usability, maintainability. e.g., "NFR1: Profile page MUST load within 2 seconds."]
        - [ ] NFR1: ...
        - [ ] NFR2: ...

        ### 3. Component Analysis
        #### 3.1. New Components to be Created
        [List new components/modules needed for this feature. For each, briefly describe its responsibility.]
        - Component A: [Responsibility]
        - Component B: [Responsibility]
        #### 3.2. Existing Components to be Modified
        [List existing components/modules that will be affected or need modification.]
        - Component X: [Nature of modification]
        - Component Y: [Nature of modification]
        #### 3.3. Component Interactions
        [Describe or diagram (textually) how new/modified components will interact with each other and existing system parts.]

        ### 4. Implementation Strategy & High-Level Steps
        [Outline the overall approach to building the feature. Break it down into major phases or steps. These will become more detailed sub-tasks later.]
        1.  Step 1: [e.g., Design database schema changes for user profile.]
        2.  Step 2: [e.g., Develop backend API endpoints for profile data.]
        3.  Step 3: [e.g., Build frontend UI for profile page.]
        4.  Step 4: [e.g., Integrate frontend with backend.]
        5.  Step 5: [e.g., Write comprehensive tests.]

        ### 5. Dependencies & Integrations
        [List any technical dependencies (libraries, tools), data dependencies, or integrations with other systems/features.]
        - Dependency 1: [e.g., Requires `ImageMagick` library for image processing.]
        - Integration 1: [e.g., Integrates with existing Authentication service.]

        ### 6. Risk Assessment & Mitigation
        [Identify potential risks (technical, resource, schedule) and suggest mitigation strategies.]
        - Risk 1: [e.g., Performance of image upload at scale.]
          - Mitigation: [e.g., Implement asynchronous processing and CDN for images.]
        - Risk 2: [e.g., Compatibility with older browsers.]
          - Mitigation: [e.g., Use polyfills and perform cross-browser testing.]

        ### 7. Creative Phase Requirements (CRITICAL for L3)
        [Identify specific aspects of this feature that require dedicated design exploration in CREATIVE mode. Be specific.]
        - [ ] CREATIVE: Design UI/UX for the new User Profile page. (Type: UI/UX)
        - [ ] CREATIVE: Architect the avatar storage and processing pipeline. (Type: Architecture)
        - [ ] CREATIVE: Develop algorithm for profile data recommendations (if applicable). (Type: Algorithm)
        (If no creative phase is deemed necessary for a particular aspect, note "CREATIVE: Not required for [aspect]" or omit.)

        ### 8. Testing Strategy Overview
        [Briefly outline the testing approach: unit tests, integration tests, E2E tests, UAT focus areas.]

        ### 9. Notes & Open Questions
        [Any other relevant notes, assumptions, or questions to be resolved.]
        ```
3.  **Log Update:**
    a.  Use `edit_file` to add a note to `memory-bank/activeContext.md`:
        `[Timestamp] - Comprehensive plan for L3 feature [Feature Name] updated in tasks.md. Creative phases identified.`
4.  **Completion & Recommendation:**
    a.  State: "Comprehensive planning for Level 3 feature [Feature Name] is complete. `tasks.md` has been updated with the detailed plan."
    b.  **If Creative Phase Requirements were identified:** "The plan indicates that creative design is needed for [list aspects]. Recommend transitioning to CREATIVE mode."
    c.  **If NO Creative Phase Requirements were identified (uncommon for L3 but possible):** "No specific creative design phases were flagged. Recommend proceeding to IMPLEMENT mode (or VAN QA if complex tech setup is anticipated)."
    d.  (Control returns to the PLAN mode orchestrator).
"""
},
{
    "path": ".cursor/rules/isolation_rules/Level3/reflection-intermediate.mdc",
    "description": "Intermediate reflection for Level 3 features. Guides AI to create a detailed reflection document in `memory-bank/reflection/`, reviewing all development phases using `edit_file`.",
    "globs": "**/Level3/reflection-intermediate.mdc",
    "alwaysApply": False,
    "body": """
# LEVEL 3 REFLECTION: INTERMEDIATE FEATURE REVIEW (AI Instructions)

> **TL;DR:** This rule structures the reflection process for a completed Level 3 intermediate feature. Use `edit_file` to create a comprehensive `memory-bank/reflection/reflect-[feature_name_or_id]-[date].md` document, analyzing the entire development lifecycle.

This rule is typically fetched by the REFLECT mode orchestrator if the task is L3.

## ⚙️ AI ACTIONS FOR LEVEL 3 REFLECTION:

1.  **Acknowledge & Context Gathering:**
    a.  State: "Initiating Intermediate Reflection for Level 3 feature: [Feature Name from activeContext.md]."
    b.  `read_file memory-bank/tasks.md` for the original plan, requirements, and links to creative docs.
    c.  `read_file memory-bank/progress.md` for the detailed implementation journey.
    d.  `read_file` all relevant `memory-bank/creative/creative-[aspect_name]-[date].md` documents.
    e.  `read_file memory-bank/activeContext.md` to confirm implementation is marked complete.
2.  **Prepare Reflection Content (Based on Template Below):**
    a.  Synthesize information from all gathered documents. Analyze each phase of the L3 workflow.
3.  **Create Reflection File:**
    a.  Determine reflection filename: `reflect-[feature_name_or_id]-[date].md`.
    b.  Use `edit_file` to create/update `memory-bank/reflection/[reflection_filename.md]` with the structured content.
        **L3 Reflection Structure (Content for `edit_file`):**
        ```markdown
        # Feature Reflection: [Feature Name from tasks.md]

        ## Feature ID: [Feature ID from tasks.md]
        ## Date of Reflection: [Current Date]
        ## Complexity Level: 3

        ## 1. Brief Feature Summary & Overall Outcome
        [What was the feature? What was its main goal? How well was the goal achieved? Did it meet all critical requirements from `tasks.md`?]

        ## 2. Planning Phase Review
        - How effective was the comprehensive planning (`Level3/planning-comprehensive.mdc`)?
        - Was the initial breakdown in `tasks.md` (components, strategy, risks) accurate?
        - What worked well in planning? What could have been planned better?
        - Were estimations (if made) accurate? Reasons for variance?

        ## 3. Creative Phase(s) Review (if applicable)
        - Were the correct aspects of the feature flagged for CREATIVE mode?
        - Review each `creative-*.md` document:
          - How effective were the design decisions?
          - Did the designs translate well into practical implementation? Any friction?
          - Was the `style-guide.md` sufficient?
        - What could improve the creative process for similar features?

        ## 4. Implementation Phase Review
        - What were the major successes during implementation (e.g., efficient module development, good use of libraries)?
        - What were the biggest challenges or roadblocks? How were they overcome?
        - Were there any unexpected technical difficulties or complexities?
        - How was adherence to the style guide and coding standards during implementation?
        - Review `progress.md` for key implementation notes: were there deviations from plan? Why?

        ## 5. Testing Phase Review
        - Was the testing strategy (unit, integration, E2E for the feature) effective?
        - Did testing uncover significant issues early enough?
        - What could improve the testing process for similar features?
        - Were there any bugs found post-implementation that testing should have caught?

        ## 6. What Went Well? (Overall - Highlight 3-5 key positives for this feature)
        - [Positive 1]
        - [Positive 2]
        - [Positive 3]

        ## 7. What Could Have Been Done Differently? (Overall - Identify 3-5 areas for improvement)
        - [Improvement Area 1]
        - [Improvement Area 2]
        - [Improvement Area 3]

        ## 8. Key Lessons Learned
        ### 8.1. Technical Lessons
        [New insights about technologies, patterns, architecture specific to this feature.]
        - Technical Lesson 1:
        ### 8.2. Process Lessons
        [Insights about the L3 workflow, communication, task management, tool usage.]
        - Process Lesson 1:
        ### 8.3. Estimation Lessons (if applicable)
        [Lessons about estimating work for features of this scale.]
        - Estimation Lesson 1:

        ## 9. Actionable Improvements for Future L3 Features
        [Specific, actionable suggestions for future intermediate feature development.]
        - Improvement 1: [e.g., "Standardize API error response format across modules."]
        - Improvement 2: [e.g., "Allocate more time for integration testing between X and Y components."]
        ```
4.  **Update Core Memory Bank Files (using `edit_file`):**
    a.  **`tasks.md`:**
        *   Mark the Level 3 feature's REFLECT phase as "COMPLETE".
        *   Add a link to the reflection document: `Reflection: ../reflection/[reflection_filename.md]`.
    b.  **`activeContext.md`:**
        *   Update current focus: "Reflection complete for L3 feature [Feature Name]. Ready for ARCHIVE."
        *   Add to log: "Completed reflection for L3 feature [Feature Name]. Document at `reflection/[reflection_filename.md]`."
5.  **Completion:**
    a.  State: "Intermediate reflection for Level 3 feature [Feature Name] complete. Reflection document created at `memory-bank/reflection/[reflection_filename.md]`."
    b.  (Control returns to the fetching rule).
"""
},
{
    "path": ".cursor/rules/isolation_rules/Level3/task-tracking-intermediate.mdc",
    "description": "Intermediate task tracking for Level 3 features. Guides AI to update `tasks.md` with structured components, steps, creative markers, and checkpoints using `edit_file`.",
    "globs": "**/Level3/task-tracking-intermediate.mdc",
    "alwaysApply": False,
    "body": """
# LEVEL 3 INTERMEDIATE TASK TRACKING (AI Instructions)

> **TL;DR:** This rule provides guidelines for structured task tracking in `memory-bank/tasks.md` for Level 3 (Intermediate Feature) tasks. Use `edit_file` to create and maintain this structure.

This rule is typically fetched by the PLAN mode orchestrator (`Level3/planning-comprehensive.mdc` will refer to this structure).

## ⚙️ AI ACTIONS FOR LEVEL 3 TASK TRACKING (Structure for `tasks.md`):

When `Level3/planning-comprehensive.mdc` guides you to detail the plan in `tasks.md`, use `edit_file` to ensure the entry for the Level 3 feature includes the following structure.

**Task Entry Template for `tasks.md` (L3 Feature):**
```markdown
## Task: [L3-ID: Feature Name, e.g., L3-001: Implement User Profile Page with Avatar Upload]

- **Status:** [e.g., IN_PROGRESS_PLANNING, PENDING_CREATIVE, IN_PROGRESS_IMPLEMENTATION, etc.]
- **Priority:** [High/Medium/Low]
- **Complexity Level:** 3
- **Assigned To:** AI
- **Target Completion Date (Optional):** [YYYY-MM-DD]
- **Links:**
    - Project Brief: `../projectbrief.md`
    - Creative Docs: (List links as they are created, e.g., `../creative/creative-profile-ui-20250515.md`)
    - Reflection Doc: (Link when created)
    - Archive Doc: (Link when created)

### 1. Feature Description & Goals
[As defined in `planning-comprehensive.mdc` guidance]

### 2. Detailed Requirements
#### 2.1. Functional Requirements
[As defined in `planning-comprehensive.mdc` guidance]
- [ ] FR1: ...
#### 2.2. Non-Functional Requirements
[As defined in `planning-comprehensive.mdc` guidance]
- [ ] NFR1: ...

### 3. Component Analysis
#### 3.1. New Components
[As defined in `planning-comprehensive.mdc` guidance]
- Component A: ...
#### 3.2. Modified Components
[As defined in `planning-comprehensive.mdc` guidance]
- Component X: ...
#### 3.3. Component Interactions
[As defined in `planning-comprehensive.mdc` guidance]

### 4. Implementation Strategy & Sub-Tasks
[Break down the high-level steps from `planning-comprehensive.mdc` into more granular, checkable sub-tasks for implementation. Prefix with `IMPL:`]
- **Phase 1: Backend API Development**
  - [ ] IMPL: Define data models for user profile and avatar.
  - [ ] IMPL: Create API endpoint for fetching profile data.
  - [ ] IMPL: Create API endpoint for updating profile data.
  - [ ] IMPL: Create API endpoint for avatar image upload.
  - [ ] IMPL: Write unit tests for API endpoints.
- **Phase 2: Frontend UI Development**
  - [ ] IMPL: Build profile display component.
  - [ ] IMPL: Build profile edit form component.
  - [ ] IMPL: Implement avatar upload UI.
  - [ ] IMPL: Integrate frontend components with backend APIs.
  - [ ] IMPL: Write component tests for UI.
- **Phase 3: Testing & Refinement**
  - [ ] IMPL: Perform integration testing.
  - [ ] IMPL: Address any bugs found.
  - [ ] IMPL: Code review and cleanup.

### 5. Dependencies & Integrations
[As defined in `planning-comprehensive.mdc` guidance]

### 6. Risk Assessment & Mitigation
[As defined in `planning-comprehensive.mdc` guidance]

### 7. Creative Phase Requirements & Outcomes
[List aspects flagged for CREATIVE mode in `planning-comprehensive.mdc`. Update with status and link to creative doc once done.]
- [ ] CREATIVE: Design UI/UX for the new User Profile page. (Type: UI/UX)
  - Status: [PENDING/IN_PROGRESS/COMPLETED]
  - Document: `../creative/creative-profile-ui-[date].md` (once created)
- [ ] CREATIVE: Architect avatar storage. (Type: Architecture)
  - Status: [PENDING/IN_PROGRESS/COMPLETED]
  - Document: `../creative/creative-avatar-storage-[date].md` (once created)

### 8. Testing Strategy Overview
[As defined in `planning-comprehensive.mdc` guidance]

### 9. Checkpoints & Phase Gates
- [ ] **PLAN Phase Complete:** [Date]
- [ ] **CREATIVE Phase(s) Complete:** [Date] (All creative sub-tasks in section 7 marked complete)
- [ ] **IMPLEMENT Phase Complete:** [Date] (All IMPL sub-tasks in section 4 marked complete)
- [ ] **REFLECT Phase Complete:** [Date]
- [ ] **ARCHIVE Phase Complete:** [Date] (Feature fully archived)

### 10. Notes & Open Questions
[As defined in `planning-comprehensive.mdc` guidance]
```

## 🔄 PROGRESS TRACKING (AI Actions during IMPLEMENT, REFLECT, etc.)
*   As sub-tasks (IMPL, CREATIVE, etc.) are completed, use `edit_file` to mark them `[x]` in `tasks.md`.
*   Update the main `Status:` field of the L3 task entry.
*   Update the `Checkpoints & Phase Gates` section as each major phase concludes.
*   Log detailed activities in `memory-bank/progress.md`.

**Key Principle:** `tasks.md` for L3 features should be a living document, meticulously updated via `edit_file` to reflect the comprehensive plan and ongoing progress through all CMB modes.
"""
},
{
    "path": ".cursor/rules/isolation_rules/Level3/workflow-level3.mdc",
    "description": "Orchestrates the workflow for Level 3 (Intermediate Feature) tasks, guiding AI through comprehensive planning, creative design, structured implementation, reflection, and archiving by fetching specific L3 and Core rules.",
    "globs": "**/Level3/workflow-level3.mdc",
    "alwaysApply": False,
    "body": """
# LEVEL 3 WORKFLOW: INTERMEDIATE FEATURE DEVELOPMENT (AI Instructions)

> **TL;DR:** This rule orchestrates the structured workflow for Level 3 (Intermediate Feature) tasks. It guides the AI through comprehensive planning, targeted creative design, systematic implementation, in-depth reflection, and feature-specific archiving by fetching appropriate L3 and Core rules.

This workflow is typically fetched after VAN mode has confirmed the task as Level 3.

## 🧭 LEVEL 3 WORKFLOW PHASES (AI Actions)

### Phase 1: INITIALIZATION (Confirmation & Context)
1.  **Acknowledge & Confirm L3:**
    a.  State: "Initiating Level 3 Workflow for [Feature Name from activeContext.md]."
    b.  `read_file memory-bank/tasks.md` and `memory-bank/activeContext.md` to confirm task is Level 3 and gather initial scope.
2.  **Core Setup Verification (If not fully done by VAN):**
    a.  Ensure platform awareness: `fetch_rules` for `.cursor/rules/isolation_rules/Core/platform-awareness.mdc`.
    b.  Ensure Memory Bank structure: `fetch_rules` for `.cursor/rules/isolation_rules/Core/file-verification.mdc`.
3.  **Task Entry & Context:**
    a.  Verify `tasks.md` has an entry for this L3 feature.
    b.  `edit_file memory-bank/activeContext.md` to set focus: "Focus: L3 Feature - [Feature Name] - Initializing."
4.  **Milestone:** State "L3 Initialization complete. Proceeding to Documentation Setup."

### Phase 2: DOCUMENTATION SETUP (L3 Specific)
1.  **Update `projectbrief.md` (Briefly):**
    a.  `read_file memory-bank/projectbrief.md`. Use `edit_file` to add a note if this L3 feature significantly impacts overall project goals.
2.  **Update `activeContext.md`:**
    a.  Use `edit_file` to set `memory-bank/activeContext.md` focus: "Current Focus: Planning Level 3 Feature - [Feature Name]".
3.  **Prepare `tasks.md` for L3 Planning:**
    a.  Acknowledge that `tasks.md` will be updated extensively in the next phase.
4.  **Milestone:** State "L3 Documentation Setup complete. Proceeding to Feature Planning."

### Phase 3: FEATURE PLANNING (PLAN Mode Actions)
1.  **Fetch L3 Planning Rules:**
    a.  State: "Fetching Level 3 comprehensive planning and task tracking guidelines."
    b.  `fetch_rules` for `.cursor/rules/isolation_rules/Level3/planning-comprehensive.mdc`.
    c.  (The `planning-comprehensive.mdc` rule will internally reference the structure from `Level3/task-tracking-intermediate.mdc` for `tasks.md` updates).
2.  **Follow Fetched Rule (`planning-comprehensive.mdc`):**
    a.  This rule will guide you to use `edit_file` to update `memory-bank/tasks.md` with:
        *   Detailed feature description, goals, requirements (functional & non-functional).
        *   Component analysis (new, modified, interactions).
        *   Implementation strategy and high-level steps.
        *   Dependencies, risks, and mitigations.
        *   **Crucially: Flag aspects requiring CREATIVE mode.**
        *   Testing strategy overview.
3.  **Update Context & Recommend Next Mode:**
    a.  `read_file memory-bank/tasks.md` to see if any "CREATIVE: ..." items were flagged.
    b.  Use `edit_file` to update `memory-bank/activeContext.md`: "Planning complete for L3 feature [Feature Name]. Creative phases [identified/not identified]."
    c.  **If CREATIVE phases flagged:** State "Level 3 Planning complete. Creative design phases identified in `tasks.md`. Recommend CREATIVE mode." Await user.
    d.  **If NO CREATIVE phases flagged:** State "Level 3 Planning complete. No specific creative design phases flagged. Recommend IMPLEMENT mode (or VAN QA if complex tech setup anticipated)." Await user.
4.  **Milestone:** Planning phase complete. Await user confirmation for next mode.

### Phase 4: CREATIVE PHASES (CREATIVE Mode Actions - If Triggered)
1.  **Acknowledge & Fetch Creative Orchestrator:**
    a.  State: "Initiating CREATIVE mode for L3 feature [Feature Name] as per plan."
    b.  `fetch_rules` for `.cursor/rules/isolation_rules/visual-maps/creative-mode-map.mdc`.
2.  **Follow Fetched Rule (`creative-mode-map.mdc`):**
    a.  This rule will guide you to:
        *   Identify "CREATIVE: Design..." sub-tasks from `tasks.md`.
        *   For each, fetch the appropriate `Phases/CreativePhase/[design-type].mdc` rule.
        *   Generate design options, make decisions, and document in `memory-bank/creative/creative-[aspect]-[date].md` using `edit_file`.
        *   Update `tasks.md` to mark creative sub-tasks complete and link to documents.
3.  **Update Context & Recommend:**
    a.  Use `edit_file` to update `memory-bank/activeContext.md`: "Creative design phases complete for L3 feature [Feature Name]. Ready for Implementation."
    b.  State: "Level 3 Creative phases complete. Design documents created. Recommend IMPLEMENT mode."
4.  **Milestone:** Creative phase complete. Await user confirmation for IMPLEMENT mode.

### Phase 5: IMPLEMENTATION (IMPLEMENT Mode Actions)
1.  **Fetch L3 Implementation Rule:**
    a.  State: "Initiating Implementation for L3 feature [Feature Name]."
    b.  `fetch_rules` for `.cursor/rules/isolation_rules/Level3/implementation-intermediate.mdc`.
2.  **Follow Fetched Rule (`implementation-intermediate.mdc`):**
    a.  This rule will guide you to:
        *   Review `tasks.md` (plan) and `creative-*.md` (designs).
        *   Implement feature modules iteratively using `edit_file` for code.
        *   Adhere to `style-guide.md`.
        *   Write and run unit/integration tests using `run_terminal_cmd`.
        *   Update `tasks.md` (sub-tasks) and `progress.md` regularly.
        *   Perform end-to-end feature testing.
3.  **Update Context & Recommend:**
    a.  Use `edit_file` to update `memory-bank/activeContext.md`: "Implementation complete for L3 feature [Feature Name]. Ready for Reflection."
    b.  State: "Level 3 Implementation complete. Recommend REFLECT mode."
4.  **Milestone:** Implementation phase complete. Await user confirmation for REFLECT mode.

### Phase 6: REFLECTION (REFLECT Mode Actions)
1.  **Fetch L3 Reflection Rule:**
    a.  State: "Initiating Reflection for L3 feature [Feature Name]."
    b.  `fetch_rules` for `.cursor/rules/isolation_rules/Level3/reflection-intermediate.mdc`.
2.  **Follow Fetched Rule (`reflection-intermediate.mdc`):**
    a.  This rule will guide you to use `edit_file` to create `memory-bank/reflection/reflect-[feature_name_or_id]-[date].md`, analyzing all development phases, lessons learned, and improvements.
3.  **Update Context & Recommend:**
    a.  Use `edit_file` to update `memory-bank/activeContext.md`: "Reflection complete for L3 feature [Feature Name]. Ready for Archiving."
    b.  State: "Level 3 Reflection complete. Reflection document created. Recommend ARCHIVE mode."
4.  **Milestone:** Reflection phase complete. Await user confirmation for ARCHIVE mode.

### Phase 7: ARCHIVING (ARCHIVE Mode Actions)
1.  **Fetch L3 Archiving Rule:**
    a.  State: "Initiating Archiving for L3 feature [Feature Name]."
    b.  `fetch_rules` for `.cursor/rules/isolation_rules/Level3/archive-intermediate.mdc`.
2.  **Follow Fetched Rule (`archive-intermediate.mdc`):**
    a.  This rule will guide you to use `edit_file` to create `memory-bank/archive/archive-[feature_name_or_id]-[date].md`, summarizing the feature and linking to plan, creative, and reflection docs.
    b.  It will also guide updates to `tasks.md` (mark ARCHIVED) and `progress.md`.
3.  **Finalize Context:**
    a.  Use `edit_file` to update `memory-bank/activeContext.md` to clear focus from the completed L3 feature: "L3 Feature [Feature Name] archived. Ready for new task (VAN mode)."
4.  **Milestone:** State "Level 3 Feature [Feature Name] fully completed and archived. Recommend VAN mode for new task."
"""
},
# --- Level 4 Files ---
{
    "path": ".cursor/rules/isolation_rules/Level4/architectural-planning.mdc",
    "description": "Architectural planning guidelines for Level 4 (Complex System) tasks. Guides AI to create comprehensive architectural documentation using `edit_file` and link to `tasks.md`.",
    "globs": "**/Level4/architectural-planning.mdc",
    "alwaysApply": False,
    "body": """
# ARCHITECTURAL PLANNING FOR LEVEL 4 TASKS (AI Instructions)

> **TL;DR:** This rule guides comprehensive architectural planning for Level 4 (Complex System) tasks. Use `edit_file` to create detailed architectural documents (or sections within `tasks.md` / linked documents), covering requirements, context, vision, principles, alternatives, decisions (ADRs), and diagrams (descriptively).

This rule is typically fetched by the PLAN mode orchestrator (`Level4/workflow-level4.mdc` will fetch this after `Level4/task-tracking-advanced.mdc`).

## ⚙️ AI ACTIONS FOR LEVEL 4 ARCHITECTURAL PLANNING:

1.  **Acknowledge & Context:**
    a.  State: "Initiating Architectural Planning for Level 4 system: [System Name from activeContext.md]."
    b.  `read_file memory-bank/tasks.md` (for the L4 task structure created by `task-tracking-advanced.mdc`).
    c.  `read_file memory-bank/projectbrief.md`, `productContext.md`, `systemPatterns.md` (existing patterns), `techContext.md`.
2.  **Document Architectural Plan (using `edit_file` to update `tasks.md` or a dedicated `memory-bank/architecture/system-[system_name]-arch-plan-[date].md` linked from `tasks.md`):**

    Create/Populate the following sections:

    ```markdown
    ### Section X: Architectural Planning for [System Name] (L4)

    #### X.1. Architectural Requirements Analysis (Derived from main requirements)
    - **Key Functional Drivers for Architecture:** [e.g., High concurrency user access, Real-time data processing, Complex workflow orchestration]
    - **Key Non-Functional Requirements (Quality Attributes):**
      - Performance: [Specific targets, e.g., Sub-second API response under X load]
      - Scalability: [e.g., Support Y concurrent users, Z TPS, linear scaling strategy]
      - Availability: [e.g., 99.99% uptime, fault tolerance mechanisms]
      - Security: [e.g., Compliance with PCI-DSS, data encryption at rest and in transit, robust authN/authZ]
      - Maintainability: [e.g., Modular design, clear interfaces, comprehensive testability]
      - Extensibility: [e.g., Ability to add new service types with minimal core changes]
    - **Domain Model Overview:** [Briefly describe key entities and relationships relevant to architecture].

    #### X.2. Business Context for Architecture
    - **Business Objectives Driving Architecture:** [e.g., Reduce operational costs by 20%, Enable new market entry]
    - **Key Stakeholder Concerns (Architectural):** [e.g., CTO requires use of existing Kubernetes infrastructure]
    - **Architectural Constraints (Technical, Organizational, External, Regulatory):**
      - Technical: [e.g., Must integrate with legacy System Z via SOAP API]
      - Organizational: [e.g., Development team skill set primarily Java and Python]
      - Budgetary: [e.g., Preference for open-source technologies where feasible]

    #### X.3. Architectural Vision & Goals
    - **Vision Statement:** [A concise statement for the system's architecture, e.g., "A resilient, scalable microservices architecture enabling rapid feature development..."]
    - **Strategic Architectural Goals:** [e.g., Achieve loose coupling between services, Ensure data consistency across distributed components]

    #### X.4. Architectural Principles (Guiding Decisions)
    [List 3-5 core architectural principles for this system, e.g.:]
    - Principle 1: Event-Driven Design for asynchronous operations.
    - Principle 2: API-First approach for all service interactions.
    - Principle 3: Design for Failure - anticipate and handle component failures gracefully.

    #### X.5. Architectural Alternatives Explored (High-Level)
    [Briefly describe 1-2 major architectural patterns/styles considered and why the chosen one (or a hybrid) is preferred. E.g., "Considered monolithic vs. microservices. Chose microservices for scalability..."]

    #### X.6. Key Architectural Decisions (ADRs - Create separate ADRs or summarize here)
    [For each major architectural decision, document using an ADR-like format or link to separate ADR files in `memory-bank/architecture/adrs/`.]
    - **ADR-001: Choice of Messaging Queue**
      - Status: Decided
      - Context: Need for asynchronous communication between services A and B.
      - Decision: Use RabbitMQ.
      - Rationale: Proven reliability, supports required messaging patterns, team familiarity.
      - Alternatives Considered: Kafka (overkill for current needs), Redis Streams (less mature).
    - **ADR-002: Database Technology for Service C**
      - ...

    #### X.7. High-Level Architecture Diagrams (Textual Descriptions)
    [AI describes diagrams. User might create actual diagrams based on these descriptions.]
    - **System Context Diagram Description:** [Describe the system, its users, and external systems it interacts with.]
    - **Component Diagram Description:** [Describe major logical components/services and their primary interactions/dependencies.]
    - **Data Flow Diagram Description (Key Flows):** [Describe how data flows through the system for 1-2 critical use cases.]
    - **Deployment View Description (Conceptual):** [Describe how components might be deployed, e.g., "Services A, B, C as Docker containers in Kubernetes. Database D as a managed cloud service."]

    #### X.8. Technology Stack (Key Choices)
    [List key technologies chosen for backend, frontend, database, messaging, caching, etc., with brief rationale if not covered in ADRs.]
    - Backend: [e.g., Java Spring Boot]
    - Database: [e.g., PostgreSQL]

    #### X.9. Architectural Risks & Mitigation
    [Identify key risks related to the chosen architecture and how they will be mitigated.]
    - Risk: [e.g., Complexity of managing distributed transactions in microservices.]
      - Mitigation: [e.g., Employ SAGA pattern, implement robust monitoring and compensating transactions.]
    ```
3.  **Log Update:**
    a.  Use `edit_file` to add a note to `memory-bank/activeContext.md`:
        `[Timestamp] - Architectural planning for L4 system [System Name] documented in tasks.md / linked architecture plan.`
4.  **Completion & Recommendation:**
    a.  State: "Architectural planning for Level 4 system [System Name] is complete. Key decisions and structure documented."
    b.  "Recommend proceeding to CREATIVE phases for detailed design of specific components/services identified in the architectural plan, or directly to Phased Implementation planning if architecture is sufficiently detailed."
    c.  (Control returns to the PLAN mode orchestrator / L4 Workflow orchestrator).
"""
},
{
    "path": ".cursor/rules/isolation_rules/Level4/archive-comprehensive.mdc",
    "description": "Comprehensive archiving for Level 4 (Complex System) tasks. Guides AI to create extensive archive documentation using `edit_file`, consolidating all project artifacts.",
    "globs": "**/Level4/archive-comprehensive.mdc",
    "alwaysApply": False,
    "body": """
# COMPREHENSIVE ARCHIVING FOR LEVEL 4 TASKS (AI Instructions)

> **TL;DR:** This rule guides the creation of a comprehensive archive for a completed Level 4 (Complex System) task using `edit_file`. It involves consolidating all system knowledge, design decisions, implementation details, and lessons learned into a structured archive.

This rule is typically fetched by the Level 4 workflow orchestrator or the main ARCHIVE mode orchestrator if the task is L4.

## ⚙️ AI ACTIONS FOR LEVEL 4 COMPREHENSIVE ARCHIVING:

1.  **Acknowledge & Context Gathering:**
    a.  State: "Initiating Comprehensive Archiving for Level 4 system: [System Name from activeContext.md]."
    b.  `read_file memory-bank/tasks.md` (for the entire L4 task history, links to architectural plans, creative docs, etc.).
    c.  `read_file memory-bank/reflection/reflect-[system_name_or_id]-[date].md` (for the comprehensive reflection).
    d.  `read_file memory-bank/progress.md` (for the full development log).
    e.  `read_file` all relevant `memory-bank/architecture/`, `memory-bank/creative/`, and other supporting documents.
    f.  `read_file memory-bank/projectbrief.md`, `productContext.md`, `systemPatterns.md`, `techContext.md`.
2.  **Pre-Archive Checklist (AI Self-Correction):**
    a.  Confirm from `tasks.md` that the REFLECT phase for this L4 system is marked complete.
    b.  Verify `memory-bank/reflection/reflect-[system_name_or_id]-[date].md` exists and is finalized.
    c.  If checks fail, state: "L4 ARCHIVE BLOCKED: Comprehensive Reflection is not complete for system [System Name]. Please complete REFLECT mode first." Await user.
3.  **Create Archive Document Structure (Main Archive File):**
    a.  Determine archive filename: `archive-system-[system_name_or_id]-[date].md`.
    b.  Use `edit_file` to create/update `memory-bank/archive/[archive_filename.md]`. This will be the main archive document.
4.  **Populate Archive Document (Using `edit_file` and Template Below):**
    a.  Iteratively populate the sections of the main archive document by synthesizing information from all gathered Memory Bank files.
        **L4 Comprehensive Archive Structure (Content for `edit_file` into `archive-system-*.md`):**
        ```markdown
        # System Archive: [System Name from tasks.md]

        ## System ID: [System ID from tasks.md]
        ## Date Archived: [Current Date]
        ## Complexity Level: 4
        ## Status: COMPLETED & ARCHIVED

        ## 1. System Overview
        ### 1.1. System Purpose and Scope
        [Synthesize from `projectbrief.md`, initial `tasks.md` description.]
        ### 1.2. Final System Architecture
        [Summarize key architectural decisions from architectural planning docs/ADRs. Link to detailed architecture documents if they exist in `memory-bank/architecture/` or `documentation/`.]
        ### 1.3. Key Components & Modules
        [List final key components and their purpose. From `tasks.md` component breakdown and implementation details.]
        ### 1.4. Integration Points
        [Describe internal and external integration points. From architectural plan / `techContext.md`.]
        ### 1.5. Technology Stack
        [Final technology stack used. From `techContext.md` / implementation details.]
        ### 1.6. Deployment Environment Overview
        [Brief overview of how the system is deployed. From `techContext.md` / deployment plans.]

        ## 2. Requirements and Design Documentation Links
        - Business Requirements: [Link to relevant section in `productContext.md` or `tasks.md`]
        - Functional Requirements: [Link to detailed FRs in `tasks.md`]
        - Non-Functional Requirements: [Link to NFRs in `tasks.md` or architectural plan]
        - Architecture Decision Records (ADRs): [Link to `memory-bank/architecture/adrs/` or summaries in arch plan]
        - Creative Design Documents:
          - [Link to `../../creative/creative-[aspect1]-[date].md`]
          - [Link to `../../creative/creative-[aspect2]-[date].md`]
          - (List all relevant creative docs)

        ## 3. Implementation Documentation Summary
        ### 3.1. Phased Implementation Overview (if applicable)
        [Summary of how phased implementation (`Level4/phased-implementation.mdc`) was executed. From `progress.md`.]
        ### 3.2. Key Implementation Details & Challenges
        [Highlight significant implementation details or challenges overcome. From `progress.md` / reflection doc.]
        ### 3.3. Code Repository & Key Branches/Tags
        [Link to Git repository. Note main branch, key feature branches, and final release tag/commit.]
        ### 3.4. Build and Packaging Details
        [Summary of build process and key artifacts. From `techContext.md` / `progress.md`.]

        ## 4. API Documentation (If applicable)
        [Link to or summarize key API endpoint documentation. If extensive, this might be a separate document in `documentation/` linked here.]

        ## 5. Data Model and Schema Documentation (If applicable)
        [Link to or summarize data model and schema. If extensive, separate document in `documentation/` linked here.]

        ## 6. Security Documentation Summary
        [Summary of key security measures implemented. Link to detailed security design if available.]

        ## 7. Testing Documentation Summary
        - Test Strategy: [Overall strategy. From `tasks.md` / reflection.]
        - Test Results: [Summary of final test outcomes, key bugs fixed. Link to detailed test reports if any.]
        - Known Issues & Limitations (at time of archive): [From reflection doc.]

        ## 8. Deployment Documentation Summary
        [Link to or summarize deployment procedures, environment configs. From `techContext.md` / `progress.md`.]

        ## 9. Operational Documentation Summary
        [Link to or summarize key operational procedures, monitoring, backup/recovery. From `techContext.md` / reflection.]

        ## 10. Knowledge Transfer & Lessons Learned
        - **Link to Comprehensive Reflection Document:** `../../reflection/reflect-[system_name_or_id]-[date].md`
        - **Key Strategic Learnings (copied from reflection):**
          - [Learning 1]
          - [Learning 2]
        - **Recommendations for Future Similar Systems (copied from reflection):**
          - [Recommendation 1]

        ## 11. Project History Summary
        [Brief overview of project timeline and key milestones achieved. From `progress.md`.]
        ```
5.  **Update Core Memory Bank Files (using `edit_file`):**
    a.  **`tasks.md`:**
        *   Mark the Level 4 system task as "ARCHIVED".
        *   Add a link to the main archive document: `Archived: ../archive/[archive_filename.md]`.
    b.  **`progress.md`:**
        *   Add a final entry: `[Date] - System [System Name] ARCHIVED. Comprehensive archive at archive/[archive_filename.md]`.
    c.  **`activeContext.md`:**
        *   Clear current system focus.
        *   Add to log: "Archived Level 4 system [System Name]. Archive at `archive/[archive_filename.md]`."
    d.  Consider updating `projectbrief.md` with a note about the system's completion and link to its archive.
6.  **Completion:**
    a.  State: "Comprehensive archiving for Level 4 system [System Name] complete. Main archive document created at `memory-bank/archive/[archive_filename.md]`."
    b.  (Control returns to the fetching rule).
"""
},
{
    "path": ".cursor/rules/isolation_rules/Level4/phased-implementation.mdc",
    "description": "Phased Implementation for Level 4 (Complex System) tasks. Guides AI to manage implementation in distinct phases (Foundation, Core, Extension, Integration, Finalization) using `edit_file` and `run_terminal_cmd`.",
    "globs": "**/Level4/phased-implementation.mdc",
    "alwaysApply": False,
    "body": """
# PHASED IMPLEMENTATION FOR LEVEL 4 TASKS (AI Instructions)

> **TL;DR:** This rule guides the structured, phased implementation of a Level 4 (Complex System) task. It involves breaking down the implementation into logical phases, each with its own objectives, tasks, and verification. Use `edit_file` for code and documentation, `run_terminal_cmd` for builds/tests.

This rule is typically fetched by the IMPLEMENT mode orchestrator if the task is L4.

## ⚙️ AI ACTIONS FOR LEVEL 4 PHASED IMPLEMENTATION:

1.  **Acknowledge & Preparation:**
    a.  State: "Initiating Phased Implementation for Level 4 system: [System Name from activeContext.md]."
    b.  `read_file memory-bank/tasks.md` for the architectural plan, component breakdown, and any pre-defined implementation phases.
    c.  `read_file` all relevant `memory-bank/architecture/` and `memory-bank/creative/` documents.
    d.  `read_file memory-bank/style-guide.md` and `memory-bank/techContext.md`.
    e.  `fetch_rules` for `.cursor/rules/isolation_rules/Core/command-execution.mdc` for tool usage guidelines.
2.  **Define/Confirm Implementation Phases (if not already detailed in `tasks.md`):**
    a.  Based on the architectural plan, propose or confirm a phased approach (e.g., Foundation, Core Services, Feature Extensions, Integration, Finalization).
    b.  For each phase, define:
        *   Primary objectives.
        *   Key components/modules to be built/integrated.
        *   High-level sub-tasks within that phase.
        *   Exit criteria / verification for the phase.
    c.  Use `edit_file` to document these phases and their sub-tasks within the L4 task entry in `memory-bank/tasks.md`.
3.  **Iterate Through Implementation Phases:**
    a.  For each defined phase (e.g., "Foundation Phase"):
        i.  State: "Starting [Phase Name] for system [System Name]."
        ii. `edit_file memory-bank/activeContext.md` to set focus: "Current Focus: L4 Implementation - [System Name] - [Phase Name]."
        iii. **Implement Sub-tasks for the Current Phase (from `tasks.md`):**
            *   For each sub-task in the current phase:
                *   Perform coding using `edit_file`, adhering to architectural designs, creative specs, and style guide.
                *   Write unit tests using `edit_file`.
                *   Run tests using `run_terminal_cmd`.
                *   Log actions, code changes, test results in `memory-bank/progress.md` using `edit_file`.
                *   Mark sub-task complete in `memory-bank/tasks.md` using `edit_file`.
        iv. **Phase Verification:**
            *   Once all sub-tasks for the phase are complete, perform verification as per the phase's exit criteria (e.g., specific integration tests, review of foundational components).
            *   Log verification results in `memory-bank/progress.md`.
        v.  If phase verification fails, identify issues, create new sub-tasks in `tasks.md` to address them, and re-iterate implementation/verification for those parts.
        vi. State: "[Phase Name] complete and verified for system [System Name]."
        vii. `edit_file memory-bank/tasks.md` to mark the phase as complete.
4.  **System-Wide Integration & Testing (Typically after Core/Extension phases):**
    a.  Perform broader integration tests across major components.
    b.  Conduct end-to-end system testing against key user scenarios and NFRs.
    c.  Log results in `memory-bank/progress.md`.
5.  **Finalization Phase (Last Phase):**
    a.  Performance tuning, final security reviews, documentation cleanup.
    b.  User Acceptance Testing (UAT) coordination (AI supports by providing info, user executes UAT).
    c.  Preparation for deployment (e.g., final build scripts, deployment notes).
6.  **Final Memory Bank Updates & Completion:**
    a.  Ensure `tasks.md` L4 implementation is marked complete.
    b.  Ensure `progress.md` has a comprehensive log.
    c.  Use `edit_file` to update `memory-bank/activeContext.md`: "Level 4 Phased Implementation for [System Name] complete. Ready for REFLECT mode."
    d.  State: "Level 4 system [System Name] phased implementation complete. All phases and tests passed. Recommend REFLECT mode."
    e.  (Control returns to the fetching rule).
"""
},
{
    "path": ".cursor/rules/isolation_rules/Level4/reflection-comprehensive.mdc",
    "description": "Comprehensive reflection for Level 4 (Complex System) tasks. Guides AI to create an extensive reflection document in `memory-bank/reflection/` using `edit_file`.",
    "globs": "**/Level4/reflection-comprehensive.mdc",
    "alwaysApply": False,
    "body": """
# COMPREHENSIVE REFLECTION FOR LEVEL 4 TASKS (AI Instructions)

> **TL;DR:** This rule structures the comprehensive reflection process for a completed Level 4 (Complex System) task. Use `edit_file` to create an extensive `memory-bank/reflection/reflect-[system_name_or_id]-[date].md` document, analyzing all aspects of the project lifecycle.

This rule is typically fetched by the REFLECT mode orchestrator if the task is L4.

## ⚙️ AI ACTIONS FOR LEVEL 4 COMPREHENSIVE REFLECTION:

1.  **Acknowledge & Extensive Context Gathering:**
    a.  State: "Initiating Comprehensive Reflection for Level 4 system: [System Name from activeContext.md]."
    b.  `read_file memory-bank/tasks.md` (for the entire L4 task history, architectural plans, links to creative docs, phased implementation details).
    c.  `read_file memory-bank/progress.md` (for the full development log, challenges, decisions).
    d.  `read_file` all relevant `memory-bank/architecture/`, `memory-bank/creative/` documents.
    e.  `read_file memory-bank/projectbrief.md`, `productContext.md`, `systemPatterns.md`, `techContext.md`.
    f.  `read_file memory-bank/activeContext.md` to confirm implementation is marked complete.
2.  **Prepare Reflection Content (Based on Detailed Template Below):**
    a.  Synthesize information from all gathered documents. Analyze each phase of the L4 workflow (VAN, Plan (Arch), Creative, Phased Implement).
3.  **Create Reflection File:**
    a.  Determine reflection filename: `reflect-[system_name_or_id]-[date].md`.
    b.  Use `edit_file` to create/update `memory-bank/reflection/[reflection_filename.md]` with the structured content.
        **L4 Comprehensive Reflection Structure (Content for `edit_file`):**
        ```markdown
        # System Reflection: [System Name from tasks.md]

        ## System ID: [System ID from tasks.md]
        ## Date of Reflection: [Current Date]
        ## Complexity Level: 4

        ## 1. System Overview & Final State
        - **Original Purpose & Scope:** [From `projectbrief.md` / initial `tasks.md`]
        - **Achieved Functionality:** [Describe the final state of the system and its key features.]
        - **Alignment with Business Objectives:** [How well did the final system meet the business goals?]

        ## 2. Project Performance Analysis
        - **Timeline Performance:**
          - Planned vs. Actual Duration (Overall and per phase): [Details]
          - Reasons for major variances: [Analysis]
        - **Resource Utilization (if tracked):** [Planned vs. Actual]
        - **Quality Metrics (if defined):** [How did the project fare against quality targets? E.g., bug density, test coverage achieved.]
        - **Risk Management Effectiveness:** [Were identified risks managed well? Any unforeseen major risks?]

        ## 3. Architectural Planning & Design Phase Review
        - **Effectiveness of Architectural Plan:** [Review `Level4/architectural-planning.mdc` outputs. Were decisions sound? Did the architecture scale/perform as expected?]
        - **Creative Phase Outcomes:** [Review key `creative-*.md` documents. How well did designs translate to implementation? Any design flaws discovered late?]
        - **Adherence to Architectural Principles & Patterns:** [From `systemPatterns.md` and arch plan.]

        ## 4. Phased Implementation Review (`Level4/phased-implementation.mdc`)
        - **Foundation Phase:** [Successes, challenges]
        - **Core Phase:** [Successes, challenges]
        - **Extension Phase(s):** [Successes, challenges]
        - **Integration Phase:** [Successes, challenges, integration issues]
        - **Finalization Phase:** [Successes, challenges]
        - **Overall Implementation Challenges & Solutions:** [Major hurdles and how they were overcome.]

        ## 5. Testing & Quality Assurance Review
        - **Effectiveness of Testing Strategy:** [Unit, integration, system, UAT. Were tests comprehensive? Did they catch critical issues?]
        - **Test Automation:** [Successes, challenges with test automation.]
        - **Post-Release Defect Rate (if applicable/known):**

        ## 6. Achievements and Successes (Overall Project)
        [List 3-5 significant achievements or successes beyond just feature completion.]
        - Achievement 1: [e.g., Successful integration of a complex new technology.]
        - Achievement 2: [e.g., High team collaboration leading to rapid problem-solving.]

        ## 7. Major Challenges & How They Were Addressed (Overall Project)
        [List 3-5 major challenges encountered throughout the project and their resolutions.]
        - Challenge 1: [e.g., Unexpected performance bottlenecks in Service X.]
          - Resolution: [e.g., Re-architected data flow and implemented caching.]

        ## 8. Key Lessons Learned
        ### 8.1. Technical Lessons
        [Deep technical insights, e.g., "Using GraphQL for this specific data aggregation pattern proved highly effective because..."]
        ### 8.2. Architectural Lessons
        [e.g., "The decision to use event sourcing for X module added complexity but significantly improved auditability..."]
        ### 8.3. Process & Workflow Lessons (CMB Usage)
        [e.g., "The phased implementation approach for L4 was crucial for managing complexity. More detailed upfront planning for inter-service contracts would have been beneficial."]
        ### 8.4. Team & Collaboration Lessons
        [e.g., "Regular cross-functional syncs for API design were vital."]

        ## 9. Strategic Actions & Recommendations
        ### 9.1. For This System (Maintenance, Future Enhancements)
        [e.g., "Recommend refactoring Module Y for better testability in Q3."]
        ### 9.2. For Future L4 Projects (Process, Tools, Architecture)
        [e.g., "Adopt a more formal ADR process for all L4 architectural decisions."]
        [e.g., "Invest in better performance testing tools earlier in the lifecycle."]

        ## 10. Knowledge Transfer Summary
        - Key areas of knowledge to transfer: [e.g., Service Z's deployment intricacies, Data model for Module A.]
        - Suggested methods for transfer: [e.g., Update `documentation/`, conduct team workshops.]

        ## 11. Final Assessment
        [Overall summary of the project's execution, outcomes, and strategic value.]
        ```
4.  **Update Core Memory Bank Files (using `edit_file`):**
    a.  **`tasks.md`:**
        *   Mark the Level 4 system's REFLECT phase as "COMPLETE".
        *   Add a link to the reflection document: `Reflection: ../reflection/[reflection_filename.md]`.
    b.  **`activeContext.md`:**
        *   Update current focus: "Comprehensive reflection complete for L4 system [System Name]. Ready for ARCHIVE."
        *   Add to log: "Completed comprehensive reflection for L4 system [System Name]. Document at `reflection/[reflection_filename.md]`."
5.  **Completion:**
    a.  State: "Comprehensive reflection for Level 4 system [System Name] complete. Reflection document created at `memory-bank/reflection/[reflection_filename.md]`."
    b.  (Control returns to the fetching rule).
"""
},
{
    "path": ".cursor/rules/isolation_rules/Level4/task-tracking-advanced.mdc",
    "description": "Advanced task tracking for Level 4 (Complex System) tasks. Guides AI to structure `tasks.md` with detailed hierarchy, dependencies, milestones, risks, and progress visualization using `edit_file`.",
    "globs": "**/Level4/task-tracking-advanced.mdc",
    "alwaysApply": False,
    "body": """
# ADVANCED TASK TRACKING FOR LEVEL 4 TASKS (AI Instructions)

> **TL;DR:** This rule outlines a comprehensive task tracking approach for Level 4 (Complex System) tasks. Use `edit_file` to structure `memory-bank/tasks.md` with a detailed hierarchy (System > Component > Feature > Task > Subtask), explicit dependencies, milestones, risk register, resource allocation, and progress visualizations (textual descriptions).

This rule is typically fetched by the PLAN mode orchestrator (`Level4/workflow-level4.mdc` will fetch this as part of architectural planning).

## ⚙️ AI ACTIONS FOR LEVEL 4 ADVANCED TASK TRACKING (Structuring `tasks.md`):

1.  **Acknowledge & Context:**
    a.  State: "Applying Advanced Task Tracking for Level 4 system: [System Name from activeContext.md]."
    b.  `read_file memory-bank/tasks.md` (to establish or update the L4 system entry).
    c.  This rule works in conjunction with `Level4/architectural-planning.mdc`. The architectural plan will define many of the components and features.
2.  **Establish/Update L4 System Entry in `tasks.md` (using `edit_file`):**
    a.  Ensure the main entry for the L4 system in `memory-bank/tasks.md` is structured to accommodate advanced tracking details.

        **Comprehensive L4 Task Structure (Main Sections in `tasks.md` for the L4 System):**
        ```markdown
        # System: [System-ID: System Name, e.g., L4-001: Enterprise Resource Planning System]

        - **Overall Status:** [e.g., IN_PROGRESS_PLANNING, PENDING_ARCH_REVIEW, IN_PROGRESS_IMPLEMENT_FOUNDATION_PHASE, etc.]
        - **Complexity Level:** 4
        - **Lead Architect/Team (if known):** [User may specify]
        - **Target Go-Live Date (Optional):** [User may specify]
        - **Links:**
            - Project Brief: `../projectbrief.md`
            - Architectural Plan: `../architecture/system-[System_Name]-arch-plan-[date].md` (or relevant section in this tasks.md)
            - Comprehensive Reflection: (Link when created)
            - Comprehensive Archive: (Link when created)

        ## 1. System Overview & Goals
        [Brief summary from architectural plan or project brief.]

        ## 2. Key Milestones
        [List major project milestones with target dates and status. Update as project progresses.]
        - [ ] MILE-01: Architectural Plan Approved - Target: [YYYY-MM-DD] - Status: [PENDING/COMPLETE]
        - [ ] MILE-02: Foundation Phase Complete - Target: [YYYY-MM-DD] - Status: [PENDING/COMPLETE]
        - [ ] MILE-03: Core Services Implemented & Tested - Target: [YYYY-MM-DD] - Status: [PENDING/COMPLETE]
        - ...
        - [ ] MILE-XX: System Go-Live - Target: [YYYY-MM-DD] - Status: [PENDING/COMPLETE]

        ## 3. Work Breakdown Structure (WBS) - Components & Features
        [This section will detail Components, their Features, and then Tasks/Sub-tasks. Update iteratively as planning and implementation proceed.]

        ### 3.1. Component: [COMP-ID-A: Component A Name, e.g., User Management Service]
        - **Purpose:** [Brief description]
        - **Status:** [PLANNING/IN_PROGRESS/COMPLETED]
        - **Lead (if applicable):**
        - **Dependencies (other components):** [e.g., COMP-ID-B: Authentication Service]

        #### 3.1.1. Feature: [FEAT-ID-A1: Feature A1 Name, e.g., User Registration]
        - **Description:** [Detailed description]
        - **Status:** [PLANNING/PENDING_CREATIVE/IN_PROGRESS_IMPL/COMPLETED]
        - **Priority:** [Critical/High/Medium/Low]
        - **Quality Criteria:** [Specific acceptance criteria]
        - **Creative Docs (if any):** `../../creative/creative-[Feature_A1_aspect]-[date].md`

        ##### Tasks for Feature A1:
        - [ ] TASK-A1.1: [Detailed task description] - Status: [TODO/WIP/DONE] - Assignee: [AI/User] - Est. Effort: [e.g., 2d]
          - Sub-tasks:
            - [ ] SUB-A1.1.1: [Sub-task description]
            - [ ] SUB-A1.1.2: [Sub-task description]
          - Dependencies: [e.g., TASK-B2.3]
          - Risks: [Brief risk note]
        - [ ] TASK-A1.2: [...]

        #### 3.1.2. Feature: [FEAT-ID-A2: Feature A2 Name, e.g., Profile Update]
        [...]

        ### 3.2. Component: [COMP-ID-B: Component B Name, e.g., Authentication Service]
        [...]

        ## 4. System-Wide Tasks (Cross-Cutting Concerns)
        [Tasks that span multiple components, e.g., setting up CI/CD, defining logging standards.]
        - [ ] SYS-TASK-01: Establish CI/CD Pipeline - Status: [...]
        - [ ] SYS-TASK-02: Define System-Wide Logging Strategy - Status: [...]

        ## 5. Dependency Matrix (High-Level Inter-Component/Inter-Feature)
        [Summarize critical dependencies. Detailed task dependencies are within WBS.]
        - Feature A1 (COMP-A) depends on Core Auth API (COMP-B).
        - Component C integration requires completion of Feature B2 (COMP-B).

        ## 6. Risk Register
        [Track major system-level risks. Task-specific risks can be in WBS.]
        | ID      | Risk Description                     | Probability | Impact | Mitigation Strategy                      | Status    |
        |---------|--------------------------------------|-------------|--------|------------------------------------------|-----------|
        | RISK-01 | Scalability of notification service  | Medium      | High   | Load testing, optimize message queue     | OPEN      |
        | RISK-02 | Integration with legacy System X     | High        | Medium | Develop anti-corruption layer, mock tests | MITIGATED |

        ## 7. Resource Allocation Overview (Optional - User Managed)
        [High-level notes on team allocation if provided by user.]

        ## 8. Progress Visualization (Textual - AI describes, user might visualize)
        - **Overall System Progress (Conceptual):** [e.g., "Estimated 20% complete based on milestone tracking."]
        - **Component Progress (Conceptual):**
          - User Management Service: [e.g., "Foundation built, registration feature in progress."]
          - Authentication Service: [e.g., "Core APIs complete, awaiting integration."]

        ## 9. Latest Updates & Decisions Log
        [Chronological log of major updates, decisions, or changes to the plan. More detailed logs go in `progress.md`.]
        - [Date]: Architectural decision ADR-003 (Data Storage) finalized.
        - [Date]: Milestone MILE-01 (Arch Plan Approved) completed.
        ```
3.  **Iterative Updates:**
    a.  This `tasks.md` structure for L4 is a living document. As the project progresses through architectural planning, creative phases, and phased implementation, use `edit_file` to:
        *   Add/refine components, features, tasks, and sub-tasks.
        *   Update statuses and progress percentages.
        *   Mark milestones as complete.
        *   Log new risks or update existing ones.
        *   Record key decisions in the "Latest Updates" section.
4.  **Log Update:**
    a.  Use `edit_file` to add a note to `memory-bank/activeContext.md`:
        `[Timestamp] - Advanced task tracking structure for L4 system [System Name] established/updated in tasks.md.`
5.  **Completion (of this rule's execution):**
    a.  State: "Advanced task tracking structure for Level 4 system [System Name] applied to `tasks.md`. This document will be updated throughout the project lifecycle."
    b.  (Control returns to the PLAN mode orchestrator / L4 Workflow orchestrator).
"""
},
{
    "path": ".cursor/rules/isolation_rules/Level4/workflow-level4.mdc",
    "description": "Orchestrates the comprehensive workflow for Level 4 (Complex System) tasks, guiding AI through all 7 CMB modes by fetching specific L4 and Core rules.",
    "globs": "**/Level4/workflow-level4.mdc",
    "alwaysApply": False,
    "body": """
# COMPREHENSIVE WORKFLOW FOR LEVEL 4 TASKS (AI Instructions)

> **TL;DR:** This rule orchestrates the full, comprehensive workflow for Level 4 (Complex System) tasks. It guides the AI through all 7 CMB modes (Initialization, Documentation Setup, Architectural Planning, Creative Phases, Phased Implementation, Reflection, and Archiving) by fetching specific L4 and Core rules.

This workflow is typically fetched after VAN mode has confirmed the task as Level 4.

## 🧭 LEVEL 4 WORKFLOW PHASES (AI Actions)

### Phase 1: INITIALIZATION (Confirmation & Deep Context)
1.  **Acknowledge & Confirm L4:**
    a.  State: "Initiating Level 4 Workflow for system: [System Name from activeContext.md]."
    b.  `read_file memory-bank/tasks.md` and `memory-bank/activeContext.md` to confirm task is Level 4 and gather initial high-level scope.
2.  **Core Setup Verification (Crucial for L4):**
    a.  Ensure platform awareness: `fetch_rules` for `.cursor/rules/isolation_rules/Core/platform-awareness.mdc`.
    b.  Ensure Memory Bank structure: `fetch_rules` for `.cursor/rules/isolation_rules/Core/file-verification.mdc`.
3.  **Task Framework & Enterprise Context:**
    a.  Verify `tasks.md` has a main entry for this L4 system.
    b.  `edit_file memory-bank/activeContext.md` to set focus: "Focus: L4 System - [System Name] - Initializing & Documentation Setup."
    c.  (User might provide initial enterprise context, or AI might need to synthesize from `projectbrief.md`).
4.  **Milestone:** State "L4 Initialization complete. Proceeding to Documentation Setup."

### Phase 2: DOCUMENTATION SETUP (L4 Comprehensive)
1.  **Load Comprehensive Templates (Conceptual):** AI should be aware of the need for detailed documentation.
2.  **Update Core Memory Bank Files:**
    a.  Use `edit_file` to extensively update/populate:
        *   `memory-bank/projectbrief.md` (detailed system description, goals, scope).
        *   `memory-bank/productContext.md` (business drivers, stakeholders, market needs).
        *   `memory-bank/systemPatterns.md` (any known enterprise patterns to adhere to, or placeholder for new patterns).
        *   `memory-bank/techContext.md` (existing tech landscape, constraints, preferred stack).
3.  **Establish Documentation Framework:**
    a.  If not already present, use `run_terminal_cmd` to create `memory-bank/architecture/` and `memory-bank/architecture/adrs/` directories.
4.  **Milestone:** State "L4 Documentation Setup complete. Proceeding to Architectural Planning."

### Phase 3: ARCHITECTURAL PLANNING (PLAN Mode Actions for L4)
1.  **Fetch L4 Planning Rules:**
    a.  State: "Fetching Level 4 architectural planning and advanced task tracking guidelines."
    b.  `fetch_rules` for `.cursor/rules/isolation_rules/Level4/task-tracking-advanced.mdc`. (This sets up the detailed structure in `tasks.md`).
    c.  `fetch_rules` for `.cursor/rules/isolation_rules/Level4/architectural-planning.mdc`.
2.  **Follow Fetched Rules:**
    a.  `task-tracking-advanced.mdc` guides structuring `tasks.md` for L4 complexity.
    b.  `architectural-planning.mdc` guides defining the architecture (requirements, context, vision, principles, alternatives, ADRs, diagrams) within `tasks.md` or linked documents. Use `edit_file` for all documentation.
3.  **Update Context & Recommend Next Mode:**
    a.  `read_file memory-bank/tasks.md` (specifically the architectural plan and WBS) to identify components/features needing CREATIVE design.
    b.  Use `edit_file` to update `memory-bank/activeContext.md`: "Architectural planning complete for L4 system [System Name]. Creative phases for [list key components/features] identified."
    c.  State: "Level 4 Architectural Planning complete. Detailed plan and architecture documented. Recommend CREATIVE mode for designated components." Await user.
4.  **Milestone:** Architectural Planning phase complete. Await user confirmation for CREATIVE mode.

### Phase 4: CREATIVE PHASES (CREATIVE Mode Actions for L4)
1.  **Acknowledge & Fetch Creative Orchestrator:**
    a.  State: "Initiating CREATIVE mode for L4 system [System Name] components as per architectural plan."
    b.  `fetch_rules` for `.cursor/rules/isolation_rules/visual-maps/creative-mode-map.mdc`.
2.  **Follow Fetched Rule (`creative-mode-map.mdc`):**
    a.  This orchestrator will guide identifying "CREATIVE: Design..." tasks from the L4 plan in `tasks.md` and fetching specific `Phases/CreativePhase/*.mdc` rules for each.
    b.  Ensure detailed design documents are created in `memory-bank/creative/` using `edit_file`.
3.  **Update Context & Recommend:**
    a.  Use `edit_file` to update `memory-bank/activeContext.md`: "Creative design phases complete for L4 system [System Name]. Ready for Phased Implementation."
    b.  State: "Level 4 Creative phases complete. Design documents finalized. Recommend IMPLEMENT mode for phased development."
4.  **Milestone:** Creative phase complete. Await user confirmation for IMPLEMENT mode.

### Phase 5: PHASED IMPLEMENTATION (IMPLEMENT Mode Actions for L4)
1.  **Fetch L4 Implementation Rule:**
    a.  State: "Initiating Phased Implementation for L4 system [System Name]."
    b.  `fetch_rules` for `.cursor/rules/isolation_rules/Level4/phased-implementation.mdc`.
2.  **Follow Fetched Rule (`phased-implementation.mdc`):**
    a.  This rule guides defining implementation phases (Foundation, Core, Extension, Integration, Finalization) in `tasks.md`.
    b.  For each phase, implement sub-tasks using `edit_file` for code, `run_terminal_cmd` for builds/tests.
    c.  Perform rigorous verification at each phase gate.
    d.  Update `tasks.md` and `progress.md` meticulously.
3.  **Update Context & Recommend:**
    a.  Use `edit_file` to update `memory-bank/activeContext.md`: "Phased Implementation complete for L4 system [System Name]. Ready for Comprehensive Reflection."
    b.  State: "Level 4 Phased Implementation complete. System built and tested. Recommend REFLECT mode."
4.  **Milestone:** Phased Implementation complete. Await user confirmation for REFLECT mode.

### Phase 6: COMPREHENSIVE REFLECTION (REFLECT Mode Actions for L4)
1.  **Fetch L4 Reflection Rule:**
    a.  State: "Initiating Comprehensive Reflection for L4 system [System Name]."
    b.  `fetch_rules` for `.cursor/rules/isolation_rules/Level4/reflection-comprehensive.mdc`.
2.  **Follow Fetched Rule (`reflection-comprehensive.mdc`):**
    a.  This rule guides creating an extensive reflection document in `memory-bank/reflection/` using `edit_file`, analyzing all project aspects (performance, architecture, process, lessons, strategic actions).
3.  **Update Context & Recommend:**
    a.  Use `edit_file` to update `memory-bank/activeContext.md`: "Comprehensive Reflection complete for L4 system [System Name]. Ready for Archiving."
    b.  State: "Level 4 Comprehensive Reflection complete. Reflection document created. Recommend ARCHIVE mode."
4.  **Milestone:** Reflection phase complete. Await user confirmation for ARCHIVE mode.

### Phase 7: COMPREHENSIVE ARCHIVING (ARCHIVE Mode Actions for L4)
1.  **Fetch L4 Archiving Rule:**
    a.  State: "Initiating Comprehensive Archiving for L4 system [System Name]."
    b.  `fetch_rules` for `.cursor/rules/isolation_rules/Level4/archive-comprehensive.mdc`.
2.  **Follow Fetched Rule (`archive-comprehensive.mdc`):**
    a.  This rule guides creating a detailed system archive document in `memory-bank/archive/` (or `documentation/`) using `edit_file`, consolidating all project artifacts and knowledge.
    b.  Update `tasks.md` marking the L4 system ARCHIVED.
3.  **Finalize Context:**
    a.  Use `edit_file` to update `memory-bank/activeContext.md`: "L4 System [System Name] comprehensively archived. Memory Bank ready for new top-level task (VAN mode)."
4.  **Milestone:** State "Level 4 System [System Name] fully completed and archived. Recommend VAN mode for new system/project."
"""
},
# --- End of Level 4 Files ---
# --- Main Orchestrator Files ---
{
    "path": ".cursor/rules/isolation_rules/main.mdc",
    "description": "Primary entry point for the Cursor Memory Bank system. Verifies Memory Bank existence and typically initiates VAN mode.",
    "globs": "main.mdc", # This might be a special glob if it's an initial rule.
    "alwaysApply": False, # Should be fetched by a very high-level prompt or system trigger.
    "body": """
# ISOLATION-FOCUSED MEMORY BANK SYSTEM (AI Instructions)

> **TL;DR:** This is the main entry rule. It ensures Memory Bank is set up and then typically transitions to VAN mode to start project analysis.

## ⚙️ AI ACTIONS - SYSTEM STARTUP:

1.  **Acknowledge System Start:**
    a.  State: "Memory Bank System initiated. Performing mandatory Memory Bank verification."
2.  **CRITICAL: Memory Bank Verification & Setup:**
    a.  `fetch_rules` to load and follow `.cursor/rules/isolation_rules/Core/file-verification.mdc`.
    b.  This rule will guide you to check if `memory-bank/` and its core subdirectories/files exist. If not, it will instruct you to create them using `run_terminal_cmd` for directories and `edit_file` for initial file content.
    c.  **If `Core/file-verification.mdc` reports critical failure (e.g., cannot create `memory-bank/`):**
        i.  State: "🚨 CRITICAL ERROR: Memory Bank structure could not be verified or created. Cannot proceed with CMB workflow. Please check permissions or manually create the `memory-bank/` directory."
        ii. Await user intervention. Do not proceed.
    d.  **If verification/creation is successful:**
        i.  State: "Memory Bank structure verified/initialized successfully."
3.  **Transition to VAN Mode (Default Initial Mode):**
    a.  State: "Transitioning to VAN mode for initial project analysis and complexity determination."
    b.  `fetch_rules` to load and follow `.cursor/rules/isolation_rules/visual-maps/van_mode_split/van-mode-map.mdc`.
    c.  (The `van-mode-map.mdc` will then orchestrate the VAN mode process).

## 🧭 MODE-SPECIFIC VISUAL MAPS (For AI's Conceptual Understanding)
The CMB system uses distinct orchestrator rules for each mode. You will be directed to `fetch_rules` for these as needed:
-   VAN Mode: `visual-maps/van_mode_split/van-mode-map.mdc` (Initial Analysis & Complexity)
-   PLAN Mode: `visual-maps/plan-mode-map.mdc` (Task Planning)
-   CREATIVE Mode: `visual-maps/creative-mode-map.mdc` (Design Decisions)
-   IMPLEMENT Mode: `visual-maps/implement-mode-map.mdc` (Code Implementation)
-   REFLECT Mode: `visual-maps/reflect-mode-map.mdc` (Task Review)
-   ARCHIVE Mode: `visual-maps/archive-mode-map.mdc` (Documentation & Closure)

## 💻 PLATFORM-SPECIFIC COMMANDS & EFFICIENCY (General Reminder)
*   Always be mindful of platform differences when using `run_terminal_cmd`. Refer to `Core/platform-awareness.mdc` principles.
*   Strive for command efficiency. Refer to `Core/command-execution.mdc` principles.
"""
},
{
    "path": ".cursor/rules/isolation_rules/main-optimized.mdc",
    "description": "Describes the design principles of the Optimized Memory Bank system, focusing on token efficiency, adaptive complexity, and hierarchical rule loading. For AI's conceptual understanding.",
    "globs": "main-optimized.mdc",
    "alwaysApply": False, # This is a design document, not typically fetched for direct execution.
    "body": """
# OPTIMIZED MEMORY BANK SYSTEM (Design Principles - AI Understanding)

> **TL;DR:** This document explains the design principles behind the Memory Bank's optimizations. You, the AI, enact these optimizations by following the specific instructions in other `.mdc` rules that guide hierarchical rule loading, adaptive complexity, progressive documentation, and efficient Memory Bank updates.

## 🚨 CRITICAL PREMISE: MEMORY BANK EXISTENCE
*   The entire CMB system, optimized or not, relies on the `memory-bank/` directory and its core files being present. This is typically ensured by the `main.mdc` rule fetching `Core/file-verification.mdc` at startup.

## 🧭 OPTIMIZED MODE ARCHITECTURE (Conceptual Overview)
The system uses:
*   **Context Manager (Conceptual):** Achieved by your diligent use of `read_file` for relevant context from `activeContext.md`, `tasks.md`, etc., and `edit_file` to update them.
*   **Rule Loader (Conceptual):** This is the `fetch_rules` tool, which you use as instructed by prompts or other `.mdc` files.
*   **File Manager (Conceptual):** This is primarily the `edit_file` tool for content, and `run_terminal_cmd` for directory operations.
*   **Mode Transition (Conceptual):** Managed by updating `activeContext.md` before switching modes, as guided by `Core/mode-transition-optimization.mdc` principles.

## 📈 ADAPTIVE COMPLEXITY MODEL (How You Implement This)
*   You determine task complexity (Level 1-4) by following `Core/complexity-decision-tree.mdc` (usually fetched in VAN mode).
*   Based on the determined level, the workflow orchestrators (e.g., `LevelX/workflow-levelX.mdc` or main mode maps) will guide you through a process tailored to that complexity, fetching appropriate level-specific rules.
    *   L1: Streamlined (e.g., VAN → IMPLEMENT → Minimal REFLECT/ARCHIVE).
    *   L2: Balanced (e.g., VAN → PLAN → IMPLEMENT → REFLECT).
    *   L3: Comprehensive (e.g., VAN → PLAN → CREATIVE → IMPLEMENT → REFLECT).
    *   L4: Full Governance (e.g., VAN → PLAN (Arch) → CREATIVE → Phased IMPLEMENT → REFLECT → ARCHIVE).

## 🧠 HIERARCHICAL RULE LOADING (How You Implement This)
*   You achieve this by starting with a high-level orchestrator rule (e.g., `visual-maps/van_mode_split/van-mode-map.mdc`) fetched via your main custom prompt.
*   This orchestrator then instructs you to `fetch_rules` for more specific sub-rules (from `Core/`, `LevelX/`, `Phases/`, or other `visual-maps/`) only when they are needed for the current step or context.
*   This keeps your active instruction set focused and token-efficient.

## 🔄 TOKEN-OPTIMIZED CREATIVE PHASE (How You Implement This)
*   When in CREATIVE mode, and guided by rules like `Phases/CreativePhase/creative-phase-architecture.mdc` or `Phases/CreativePhase/creative-phase-uiux.mdc`, you will be instructed to use the structure from `Phases/CreativePhase/optimized-creative-template.mdc`.
*   This template encourages progressive documentation: define the problem, list options briefly, then provide detailed analysis *for selected options* or as requested, rather than exhaustively for all.

## 🔀 OPTIMIZED MODE TRANSITIONS (How You Implement This)
*   Before transitioning from one mode to another, the current mode's orchestrator will instruct you to use `edit_file` to update `memory-bank/activeContext.md` with a summary of outputs and focus for the next mode.
*   The next mode's orchestrator will then instruct you to `read_file memory-bank/activeContext.md` to pick up this context. (See `Core/mode-transition-optimization.mdc`).

## 📊 MEMORY BANK EFFICIENT UPDATES (How You Implement This)
*   When using `edit_file` to update Memory Bank files (`tasks.md`, `activeContext.md`, etc.):
    *   Be precise. Modify only the relevant sections.
    *   If appending, add to the correct section.
    *   This avoids rewriting entire large files for small changes.

## 💻 COMPLEXITY-BASED DOCUMENTATION (How You Implement This)
*   The `LevelX/*.mdc` rules for planning, reflection, and archiving will guide the *depth* of documentation required.
    *   Level 1: Minimal documentation, often consolidated.
    *   Level 4: Extensive, comprehensive documentation.
*   Follow the specific documentation structure and content requirements outlined in the active Level-specific rule.

## 💡 USAGE GUIDANCE (Summary for AI)
1.  The CMB workflow typically starts with VAN mode, triggered by `main.mdc`.
2.  Follow the instructions from the currently fetched `.mdc` rule.
3.  Use `fetch_rules` only when explicitly instructed, to load more specific rules.
4.  Use `edit_file` for all content creation/modification in Memory Bank files.
5.  Adhere to the principles of platform awareness and command execution from Core rules.
By following these specific, contextual instructions, you inherently enact the system's optimizations.
"""
},
# --- Creative Phase Files ---
{
    "path": ".cursor/rules/isolation_rules/Phases/CreativePhase/optimized-creative-template.mdc",
    "description": "Optimized template for documenting creative phase outputs (design, architecture, UI/UX decisions). Provides a structure for `edit_file` operations.",
    "globs": "**/Phases/CreativePhase/optimized-creative-template.mdc",
    "alwaysApply": False, # This is a template, referenced by other rules.
    "body": """
# OPTIMIZED CREATIVE PHASE TEMPLATE (Structure for `creative-*.md` files)

> **TL;DR:** This rule provides a structured template for documenting outputs of a creative phase (e.g., architecture, UI/UX, algorithm design). Use this structure when `edit_file` is used to create or update a `memory-bank/creative/creative-[aspect_name]-[date].md` document.

## 📝 PROGRESSIVE DOCUMENTATION MODEL (Principle for AI)
*   Start with concise summaries for problem and options.
*   Provide detailed analysis primarily for the selected option(s) or when comparing top contenders.
*   This keeps the document focused and token-efficient initially, allowing for expansion if needed.

## 📋 TEMPLATE STRUCTURE (Guide for `edit_file` content)

```markdown
📌 CREATIVE PHASE START: [Specific Aspect Being Designed, e.g., User Authentication Module Architecture]
Date: [Current Date]
Related Task ID (from tasks.md): [Task ID]
Designer: AI

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

### 1️⃣ PROBLEM DEFINITION
- **Description:** [Clear and concise description of the specific problem this design phase addresses. What needs to be designed or decided?]
- **Key Requirements (Functional & Non-Functional):**
  - [ ] Requirement 1: [e.g., System must support JWT-based authentication.]
  - [ ] Requirement 2: [e.g., Token validation must occur within 50ms.]
  - [ ] Requirement 3: [e.g., Design must allow for future integration with OAuth providers.]
- **Constraints:** [Any technical, business, or resource constraints impacting design choices. e.g., Must use existing PostgreSQL database for user store.]

### 2️⃣ OPTIONS EXPLORED
[List 2-3 viable options considered. Provide a brief one-line description for each.]
- **Option A:** [Name of Option A, e.g., Monolithic Auth Service] - [One-line description]
- **Option B:** [Name of Option B, e.g., Microservice for Auth with API Gateway] - [One-line description]
- **Option C:** [Name of Option C, e.g., Leverage Third-Party Auth Provider (Auth0/Okta)] - [One-line description]

### 3️⃣ ANALYSIS OF OPTIONS
[Provide a comparative analysis. A table is good for summaries. Detailed pros/cons for each option can follow, especially for top contenders or the chosen one.]

**Summary Comparison Table:**
| Criterion         | Option A: [Name] | Option B: [Name] | Option C: [Name] |
|-------------------|------------------|------------------|------------------|
| Scalability       | [e.g., Medium]   | [e.g., High]     | [e.g., High]     |
| Complexity        | [e.g., Low]      | [e.g., Medium]   | [e.g., Low-Med]  |
| Development Effort| [e.g., Low]      | [e.g., High]     | [e.g., Medium]   |
| Maintainability   | [e.g., Medium]   | [e.g., Medium]   | [e.g., High (external)] |
| Cost (Operational)| [e.g., Low]      | [e.g., Medium]   | [e.g., Potentially High] |
| Security (Control)| [e.g., High]     | [e.g., High]     | [e.g., Medium (dependency)] |
| Alignment w/ Reqs | [e.g., Good]     | [e.g., Excellent]| [e.g., Good, some gaps] |

**Detailed Analysis (Focus on top 1-2 options or as requested):**

<details>
  <summary>Detailed Analysis: Option B: Microservice for Auth</summary>

  **Description:**
  [Detailed description of how Option B works, key components involved, data flows, etc.]

  **Pros:**
  - Pro 1: [e.g., Independent scalability of auth service.]
  - Pro 2: [e.g., Clear separation of concerns, improving maintainability of other services.]

  **Cons:**
  - Con 1: [e.g., Increased operational complexity due to distributed system.]
  - Con 2: [e.g., Potential for network latency between services.]

  **Implementation Complexity:** [Low/Medium/High]
  [Explanation of complexity factors specific to this option.]

  **Resource Requirements:**
  [Details on specific resource needs: e.g., separate database, more compute instances.]

  **Risk Assessment:**
  [Analysis of risks specific to this option: e.g., inter-service communication failures.]
</details>

*(Repeat `<details>` block for other significantly considered options if necessary)*

### 4️⃣ DECISION & RATIONALE
- **Selected Option:** [Clearly state the chosen option, e.g., Option B: Microservice for Auth with API Gateway]
- **Rationale:** [Provide a detailed justification for why this option was selected over others. Refer to the analysis, requirements, and constraints. e.g., "Option B was chosen despite higher initial complexity due to its superior scalability and alignment with our long-term microservices strategy. It best meets NFR for scalability and maintainability..."]

### 5️⃣ IMPLEMENTATION GUIDELINES (for the selected option)
[Provide high-level guidelines, key considerations, or next steps for implementing the chosen design. This is not the full implementation plan but pointers for the IMPLEMENT phase.]
- [Guideline 1: e.g., Define clear API contracts for the new auth service using OpenAPI spec.]
- [Guideline 2: e.g., Implement robust error handling and retry mechanisms for inter-service calls.]
- [Guideline 3: e.g., Ensure comprehensive logging and monitoring for the auth service.]
- [Guideline 4: e.g., Key technologies to use: Spring Boot for service, JWT for tokens, PostgreSQL for user data.]
- [Guideline 5: e.g., First implementation phase should focus on core token generation and validation.]

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
📌 CREATIVE PHASE END: [Specific Aspect Being Designed]
Outcome: Design decision made and documented. Ready for implementation planning or further creative phases if needed.
```

## ✅ VERIFICATION CHECKLIST (AI Self-Guide when using this template)
Before finalizing a `creative-*.md` document using `edit_file`:
- [ ] Problem clearly defined?
- [ ] Multiple (2-3) viable options considered and listed?
- [ ] Analysis (summary table and/or detailed pros/cons) provided?
- [ ] Decision clearly stated with strong rationale?
- [ ] Implementation guidelines for the chosen decision included?
- [ ] Document saved to `memory-bank/creative/creative-[aspect_name]-[date].md`?
- [ ] `tasks.md` updated to mark this creative sub-task complete and link to this document?
"""
},
{
    "path": ".cursor/rules/isolation_rules/Phases/CreativePhase/creative-phase-architecture.mdc",
    "description": "Guides the AI through the architectural design process within a CREATIVE phase. Instructs on using `edit_file` to document architectural decisions in a `creative-architecture-*.md` file, referencing the `optimized-creative-template.mdc`.",
    "globs": "**/Phases/CreativePhase/creative-phase-architecture.mdc",
    "alwaysApply": False, # Fetched by creative-mode-map.mdc
    "body": """
# CREATIVE PHASE: ARCHITECTURE DESIGN (AI Instructions)

> **TL;DR:** This rule guides you through designing and documenting architectural solutions for a specific component or system aspect. Use `edit_file` to create/update a `memory-bank/creative/creative-architecture-[component_name]-[date].md` document, structured using the `optimized-creative-template.mdc`.

This rule is typically fetched by `visual-maps/creative-mode-map.mdc` when an architectural design task is active.

## ⚙️ AI ACTIONS FOR ARCHITECTURE DESIGN:

1.  **Acknowledge & Context:**
    a.  State: "Initiating CREATIVE phase for Architecture Design: [Component/System Aspect from tasks.md]."
    b.  `read_file memory-bank/tasks.md` for specific requirements, constraints, and scope for this architectural design task.
    c.  `read_file memory-bank/activeContext.md` for overall project context.
    d.  `read_file memory-bank/systemPatterns.md` and `techContext.md` for existing architectural patterns and technology landscape.
    e.  `read_file .cursor/rules/isolation_rules/Phases/CreativePhase/optimized-creative-template.mdc` to understand the documentation structure.
2.  **Define Problem & Requirements (Section 1 of `optimized-creative-template.mdc`):**
    a.  Clearly state the architectural problem being solved (e.g., "Design a scalable backend for real-time notifications").
    b.  List key functional requirements (e.g., "Must handle 1000 concurrent users," "Deliver notifications within 500ms").
    c.  List key non-functional requirements (quality attributes) like scalability, performance, security, maintainability, cost.
    d.  Identify architectural constraints (e.g., "Must use AWS services," "Integrate with existing user database").
3.  **Explore Architectural Options (Section 2 & 3 of `optimized-creative-template.mdc`):**
    a.  Brainstorm 2-3 distinct architectural patterns or high-level design options (e.g., Microservices vs. Monolith, Event-driven vs. Request-response, SQL vs. NoSQL for a specific data store).
    b.  For each option, briefly describe it.
    c.  Analyze each option against the requirements and constraints. Consider:
        *   Pros & Cons.
        *   Impact on scalability, performance, security, maintainability, cost.
        *   Complexity of implementation.
        *   Team familiarity with technologies.
    d.  Use a summary table for quick comparison if helpful.
4.  **Make Decision & Justify (Section 4 of `optimized-creative-template.mdc`):**
    a.  Select the most suitable architectural option.
    b.  Provide a clear and detailed rationale for the decision, explaining why it's preferred over alternatives, referencing the analysis.
5.  **Outline Implementation Guidelines (Section 5 of `optimized-creative-template.mdc`):**
    a.  Describe key components of the chosen architecture.
    b.  Suggest primary technologies, frameworks, or libraries.
    c.  Outline high-level interaction patterns between components (textually describe data flows or sequence diagrams if complex).
    d.  Identify major interfaces or APIs to be defined.
    e.  Note any critical next steps for detailed design or implementation planning.
6.  **Document in `creative-architecture-*.md`:**
    a.  Determine filename: `creative-architecture-[component_name_or_aspect]-[date].md`.
    b.  Use `edit_file` to create/update `memory-bank/creative/[filename]` with all the above information, structured according to the `optimized-creative-template.mdc`.
7.  **Update Core Memory Bank Files:**
    a.  Use `edit_file` to update `memory-bank/tasks.md`:
        *   Mark the specific "CREATIVE: Architect [component/aspect]" sub-task as complete.
        *   Add a link to the created `creative-architecture-*.md` document.
    b.  Use `edit_file` to add a summary of the architectural decision to the "Creative Decisions Log" in `memory-bank/activeContext.md`.
8.  **Completion:**
    a.  State: "Architecture design for [Component/Aspect] complete. Documented in `memory-bank/creative/[filename]`."
    b.  (Control returns to `visual-maps/creative-mode-map.mdc` to check for more creative tasks or recommend next mode).
"""
},
{
    "path": ".cursor/rules/isolation_rules/Phases/CreativePhase/creative-phase-uiux.mdc",
    "description": "Guides AI through UI/UX design within a CREATIVE phase. Emphasizes style guide adherence, user-centricity, and documenting decisions in `creative-uiux-*.md` using `edit_file` and `optimized-creative-template.mdc`.",
    "globs": "**/Phases/CreativePhase/creative-phase-uiux.mdc",
    "alwaysApply": False, # Fetched by creative-mode-map.mdc
    "body": """
# CREATIVE PHASE: UI/UX DESIGN GUIDELINES (AI Instructions)

> **TL;DR:** This rule guides you through designing and documenting UI/UX solutions. CRITICAL: Check for and adhere to `memory-bank/style-guide.md`. If missing, prompt user to create/link it. Document decisions in `memory-bank/creative/creative-uiux-[component_name]-[date].md` using `edit_file` and the `optimized-creative-template.mdc` structure.

This rule is typically fetched by `visual-maps/creative-mode-map.mdc` when a UI/UX design task is active.

## ⚙️ AI ACTIONS FOR UI/UX DESIGN:

1.  **Acknowledge & Context:**
    a.  State: "Initiating CREATIVE phase for UI/UX Design: [Component/Feature from tasks.md]."
    b.  `read_file memory-bank/tasks.md` for specific UI/UX requirements, user stories, and scope.
    c.  `read_file memory-bank/activeContext.md` for overall project context.
    d.  `read_file .cursor/rules/isolation_rules/Phases/CreativePhase/optimized-creative-template.mdc` to understand the documentation structure.
2.  **Style Guide Integration (CRITICAL):**
    a.  **Check Primary Location:** `read_file memory-bank/style-guide.md`.
    b.  **If Found:** State "Style guide `memory-bank/style-guide.md` loaded. All UI/UX proposals will adhere to it." Proceed to step 3.
    c.  **If NOT Found at Primary Location:**
        i.  Prompt User: "Style guide `memory-bank/style-guide.md` not found. Is there an existing style guide at a different path or URL? If so, please provide it. Otherwise, I can help create a basic one now, or we can proceed without (not recommended for new UI)." Await user response.
        ii. **If User Provides Path/URL:** Attempt to `read_file [user_provided_path]` or conceptually access URL. If successful, state "Style guide loaded from [source]. All UI/UX proposals will adhere to it." Proceed to step 3. If fails, revert to "Style guide not available."
        iii. **If User Opts to Create:**
            1.  State: "Okay, let's define a basic style guide in `memory-bank/style-guide.md`. Please provide preferences for: Core Color Palette (primary, secondary, accent, neutrals, status colors - hex codes if possible), Typography (font families, sizes, weights for headings/body), Spacing System (base unit, Tailwind scale usage if known), Key Component Styles (buttons, inputs - general look/feel or Tailwind examples)."
            2.  Based on user input (or analysis of provided examples like screenshots if user offers them), generate content for `memory-bank/style-guide.md`. (Example structure: Headings for Colors, Typography, Spacing, Components; list defined styles under each).
            3.  Use `edit_file` to create and save this content to `memory-bank/style-guide.md`.
            4.  State: "Basic style guide created at `memory-bank/style-guide.md`. All UI/UX proposals will adhere to it." Proceed to step 3.
        iv. **If User Opts to Proceed Without:** State: "Proceeding with UI/UX design without a style guide. WARNING: This may lead to inconsistencies. I will aim for internal consistency within this component." Proceed to step 3.
3.  **Define Problem & UI/UX Requirements (Section 1 of `optimized-creative-template.mdc`):**
    a.  Clearly state the UI/UX problem (e.g., "Design an intuitive interface for user registration").
    b.  List key user stories/goals for this UI (e.g., "As a new user, I want to register quickly with minimal fields").
    c.  List functional requirements for the UI (e.g., "Must include fields for email, password, confirm password").
    d.  List relevant NFRs (e.g., "Must be responsive," "Adhere to WCAG AA accessibility").
    e.  Note any constraints (e.g., "Must use existing React component library X if possible").
4.  **Explore UI/UX Options (Section 2 & 3 of `optimized-creative-template.mdc`):**
    a.  Propose 2-3 distinct UI/UX solutions. For each, describe:
        *   Layout and structure (Information Architecture).
        *   Key interaction patterns (User Flows).
        *   Visual design approach (referencing `style-guide.md` elements like colors, fonts, spacing, component styles. If no style guide, describe choices made for consistency).
        *   How it addresses user needs and requirements.
    b.  Analyze options considering usability, A11y, feasibility (React/Tailwind), aesthetics, and **strict adherence to `style-guide.md` if available.**
5.  **Make Decision & Justify (Section 4 of `optimized-creative-template.mdc`):**
    a.  Select the most suitable UI/UX solution.
    b.  Provide clear rationale, referencing the style guide and how the chosen design meets user needs and requirements effectively.
6.  **Outline Implementation Guidelines (Section 5 of `optimized-creative-template.mdc`):**
    a.  Describe key React components to be built/used.
    b.  Suggest specific Tailwind CSS utility classes or custom CSS (if extending Tailwind per style guide) for styling key elements.
    c.  Note important states (hover, focus, disabled, error) and how they should appear (per style guide).
    d.  Mention responsive design considerations (breakpoints, mobile-first approach if applicable, per style guide).
7.  **Document in `creative-uiux-*.md`:**
    a.  Determine filename: `creative-uiux-[component_name_or_feature]-[date].md`.
    b.  Use `edit_file` to create/update `memory-bank/creative/[filename]` with all the above, structured per `optimized-creative-template.mdc`.
8.  **Update Core Memory Bank Files:**
    a.  Use `edit_file` to update `memory-bank/tasks.md`:
        *   Mark "CREATIVE: Design UI/UX for [component/feature]" sub-task as complete.
        *   Link to the created `creative-uiux-*.md` document.
    b.  Use `edit_file` to add a summary of the UI/UX decision to "Creative Decisions Log" in `memory-bank/activeContext.md`.
9.  **Completion:**
    a.  State: "UI/UX design for [Component/Feature] complete. Documented in `memory-bank/creative/[filename]`. Adherence to style guide `memory-bank/style-guide.md` [was maintained / was attempted due to no guide existing]."
    b.  (Control returns to `visual-maps/creative-mode-map.mdc`).
"""
}
# --- End of Creative Phase Files ---
    ])

    if not MDC_FILES_DATA:
        print("No file data provided. Please populate the MDC_FILES_DATA list.")
    else:
        # Ensure the base path for rules exists, relative to where the script is run
        # This assumes the script is run from the project root.
        project_root = os.getcwd() 
        base_rules_path_abs = os.path.join(project_root, ".cursor", "rules", "isolation_rules")

        if not os.path.exists(base_rules_path_abs):
            # This case should ideally not happen if Core rules were already made,
            # but it's a safeguard if only visual-maps are being generated by a modified script.
            print(f"Base directory {base_rules_path_abs} does not exist. Please ensure Core rules are generated first or the path is correct.")
            # os.makedirs(base_rules_path_abs, exist_ok=True) # Optionally create it

        for file_data in MDC_FILES_DATA:
            # Construct absolute path for file operations
            absolute_filepath = os.path.join(project_root, file_data["path"])
            
            create_or_update_mdc_file(
                absolute_filepath, # Use absolute path for writing
                file_data["description"],
                file_data["globs"], # Globs are relative to .cursor/rules/ for Cursor's matching
                file_data["alwaysApply"],
                file_data["body"]
            )
        print("\n--- MDC file generation process complete. ---")
        print(f"NOTE: This script overwrites existing files with the defined content in their respective paths, relative to project root: {project_root}")
        print("Ensure that the 'globs' in the .mdc files are correctly specified for Cursor's rule matching (usually relative to the .cursor/rules/ directory).")

================
File: cursor-memory-bank/custom_modes_refined/reflect_archive.md
================
# REFLECT+ARCHIVE MODE INSTRUCTIONS

Your Role: First, facilitate REFLECTION on the completed task. Then, upon the 'ARCHIVE NOW' command, ARCHIVE the task.

Core Tools: `read_file`, `edit_file`.

## DEFAULT BEHAVIOR: REFLECTION PROCESS

1.  **Acknowledge:** Respond with "OK REFLECT+ARCHIVE. Starting REFLECTION phase."
2.  **Gather Context for Reflection:**
    a.  `read_file` `memory-bank/tasks.md` to identify the recently completed task(s).
    b.  `read_file` `memory-bank/activeContext.md` (especially the "Build Log" or implementation notes).
    c.  `read_file` `memory-bank/progress.md`.
    d.  `read_file` any relevant `memory-bank/creative/creative-[feature_name].md` or `build-log-[phase_name].md` files.
3.  **Guide Reflection (ask user these questions and record answers):**
    a.  "What went well during the IMPLEMENT/CREATIVE phase for [Task Name]?"
    b.  "What challenges were faced (e.g., tool usage, codebase issues, unclear requirements)?"
    c.  "What key lessons were learned about the codebase, the problem, or the development process?"
    d.  "Were there any unexpected outcomes or side effects (positive or negative)?"
    e.  "What process or technical improvements could be made for similar tasks in the future?"
4.  **Document Reflection:**
    a.  Use `edit_file` to create `memory-bank/reflection/reflect-[task_name_or_id]-[date].md`.
    b.  Populate it with the user's answers, structured under headings corresponding to the questions above.
5.  **Update Task Status:**
    a.  Use `edit_file` to update `memory-bank/tasks.md`. Append "Reflection complete, see reflection/reflect-[task_name_or_id]-[date].md" to the completed task item.
6.  **Prompt for Archiving:**
    State: "REFLECTION COMPLETE for [Task Name]. Reflection documented in `memory-bank/reflection/reflect-[task_name_or_id]-[date].md`. Type 'ARCHIVE NOW' to proceed with archiving this task."

## TRIGGERED BEHAVIOR: ARCHIVING PROCESS (Upon "ARCHIVE NOW" command)

1.  **Acknowledge:** "OK, proceeding with ARCHIVE process for [Task Name]."
2.  **Verify Reflection Completion:**
    a.  Check if `memory-bank/reflection/reflect-[task_name_or_id]-[date].md` exists and seems complete.
    b.  If not, state: "Reflection document not found or incomplete. Please complete reflection first." and await further instruction.
3.  **Create Archive Document:**
    a.  Use `edit_file` to create `memory-bank/archive/archive-[task_name_or_id]-[date].md`.
    b.  Populate it with a summary of the entire task lifecycle:
        *   Task Name / Goal
        *   Key activities/outcomes from VAN, PLAN, CREATIVE (if applicable), IMPLEMENT modes (referencing `activeContext.md` and relevant creative/build-log files).
        *   Summary of the solution/implementation.
        *   Key insights synthesized from `memory-bank/reflection/reflect-[task_name_or_id]-[date].md`.
        *   Links to final documentation artifacts (e.g., in `documentation/` folder).
4.  **Finalize Memory Bank Updates:**
    a.  **`tasks.md`**: Use `edit_file` to mark the main task as fully `[x] COMPLETED & ARCHIVED: memory-bank/archive/archive-[task_name_or_id]-[date].md`.
    b.  **`progress.md`**: Use `edit_file` to add/update an entry for the completed task, noting its archived status and linking to the archive document.
    c.  **`activeContext.md`**: Use `edit_file` to reset its content for the next task:
        ```markdown
        # Active Context
        ## Current Mode: ARCHIVE (Completed)
        ## Focus: Ready for new task.
        ## Previous Task: [Task Name] - Archived at memory-bank/archive/archive-[task_name_or_id]-[date].md
        ## Next Steps: Suggest VAN mode for new task.
        ```
5.  **Completion & Transition:**
    State: "ARCHIVING COMPLETE for [Task Name]. All relevant information has been consolidated and Memory Bank files updated. Suggest VAN mode to start a new task or project phase."

================
File: cursor-memory-bank/custom_modes_refined/van.md
================
# VAN MODE (Visualize, Analyze, Navigate) - Initialization

Your Role: Initialize the project context within the Memory Bank.

1.  **Acknowledge:** Respond with "OK VAN".
2.  **Verify/Create Memory Bank Structure:**
    a.  `list_dir` the project root to check for `memory-bank/`.
    b.  If `memory-bank/` does not exist, use `run_terminal_cmd` to create it (e.g., `mkdir memory-bank`). Then, create subdirectories: `mkdir memory-bank/archive memory-bank/creative memory-bank/reflection`. (Be platform-aware; for Windows, use `mkdir memory-bank\archive memory-bank\creative memory-bank\reflection`).
    c.  If `memory-bank/` exists, `list_dir` it to check for core files.
3.  **Gather Initial Project Context:**
    a.  `read_file` the main `README.md` of the project.
    b.  `read_file` the primary source file(s) if identifiable (e.g., `server.py`, `main.py`, `app.js`).
4.  **Create/Populate Core Memory Bank Files (using `edit_file` for each):**
    a.  **`memory-bank/projectbrief.md`**: Synthesize a brief project description, purpose, and key technologies from the files read.
        *Template:*
        ```markdown
        # Project Brief: [Project Name]
        ## Purpose
        ## Core Functionality
        ## Key Technologies
        ```
    b.  **`memory-bank/techContext.md`**: Detail the tech stack.
        *Template:*
        ```markdown
        # Technical Context
        ## Backend
        ## Frontend
        ## Database
        ## Key Libraries/Frameworks
        ```
    c.  **`memory-bank/systemPatterns.md`**: If discernible, outline high-level architecture.
        *Template:*
        ```markdown
        # System Patterns
        ## Overall Architecture (e.g., Client-Server, Microservices)
        ## Main Components & Interactions
        ```
    d.  **`memory-bank/productContext.md`**: Outline user needs/goals if evident.
        *Template:*
        ```markdown
        # Product Context
        ## Target Users
        ## Key User Needs/Goals
        ```
    e.  **`memory-bank/style-guide.md`**: Create with basic placeholders.
        *Template:*
        ```markdown
        # Style Guide
        ## Backend Code Style
        ## Frontend Code Style
        ## Commit Messages
        ```
    f.  **`memory-bank/tasks.md`**: Initialize with a high-level task.
        *Content:*
        ```markdown
        # Tasks
        - [ ] Level X: Initial Project Analysis & Setup (VAN Mode)
        ```
    g.  **`memory-bank/activeContext.md`**: Set initial context.
        *Content:*
        ```markdown
        # Active Context
        ## Current Mode: VAN
        ## Focus: Initializing project memory bank and performing high-level analysis.
        ## Project Complexity Level: [To be determined]
        ```
    h.  **`memory-bank/progress.md`**: Initialize.
        *Content:*
        ```markdown
        # Progress
        - VAN mode initiated. Memory bank structure setup.
        ```
5.  **Determine Project Complexity:**
    a.  Based on the analysis of `README.md` and source files, assess project complexity (Level 1: Trivial, Level 2: Simple, Level 3: Moderate, Level 4: Complex).
    b.  Use `edit_file` to update `memory-bank/activeContext.md` with the determined level: `## Project Complexity Level: Level [1/2/3/4]`.
    c.  Use `edit_file` to update the task in `memory-bank/tasks.md`: Replace "Level X" with the determined level.
6.  **Verification & Transition:**
    a.  `read_file` `memory-bank/activeContext.md` and `memory-bank/tasks.md` to confirm updates.
    b.  State: "VAN mode complete. Project complexity assessed as Level [level]. Memory Bank initialized."
    c.  Suggest next mode:
        *   If Level 1: "Recommend transitioning to IMPLEMENT mode."
        *   If Level 2-4: "Recommend transitioning to PLAN mode."

================
File: cursor-memory-bank/custom_modes/creative_instructions.md
================
# MEMORY BANK CREATIVE MODE

Your role is to perform detailed design and architecture work for components flagged during the planning phase.

```mermaid
graph TD
    Start["🚀 START CREATIVE MODE"] --> ReadTasks["📚 Read tasks.md &<br>implementation-plan.md<br>.cursor/rules/isolation_rules/main.mdc"]
    
    %% Initialization
    ReadTasks --> Identify["🔍 Identify Components<br>Requiring Creative Phases<br>.cursor/rules/isolation_rules/visual-maps/creative-mode-map.mdc"]
    Identify --> Prioritize["📊 Prioritize Components<br>for Creative Work"]
    
    %% Creative Phase Type Determination
    Prioritize --> TypeCheck{"🎨 Determine<br>Creative Phase<br>Type"}
    TypeCheck -->|"Architecture"| ArchDesign["🏗️ ARCHITECTURE DESIGN<br>.cursor/rules/isolation_rules/visual-maps/creative-mode-map.mdc"]
    TypeCheck -->|"Algorithm"| AlgoDesign["⚙️ ALGORITHM DESIGN<br>.cursor/rules/isolation_rules/visual-maps/creative-mode-map.mdc"]
    TypeCheck -->|"UI/UX"| UIDesign["🎨 UI/UX DESIGN<br>.cursor/rules/isolation_rules/visual-maps/creative-mode-map.mdc"]
    
    %% Architecture Design Process
    ArchDesign --> ArchRequirements["📋 Define Requirements<br>& Constraints"]
    ArchRequirements --> ArchOptions["🔄 Generate Multiple<br>Architecture Options"]
    ArchOptions --> ArchAnalysis["⚖️ Analyze Pros/Cons<br>of Each Option"]
    ArchAnalysis --> ArchSelect["✅ Select & Justify<br>Recommended Approach"]
    ArchSelect --> ArchGuidelines["📝 Document Implementation<br>Guidelines"]
    ArchGuidelines --> ArchVerify["✓ Verify Against<br>Requirements"]
    
    %% Algorithm Design Process
    AlgoDesign --> AlgoRequirements["📋 Define Requirements<br>& Constraints"]
    AlgoRequirements --> AlgoOptions["🔄 Generate Multiple<br>Algorithm Options"]
    AlgoOptions --> AlgoAnalysis["⚖️ Analyze Pros/Cons<br>& Complexity"]
    AlgoAnalysis --> AlgoSelect["✅ Select & Justify<br>Recommended Approach"]
    AlgoSelect --> AlgoGuidelines["📝 Document Implementation<br>Guidelines"]
    AlgoGuidelines --> AlgoVerify["✓ Verify Against<br>Requirements"]
    
    %% UI/UX Design Process
    UIDesign --> UIRequirements["📋 Define Requirements<br>& Constraints"]
    UIRequirements --> UIOptions["🔄 Generate Multiple<br>Design Options"]
    UIOptions --> UIAnalysis["⚖️ Analyze Pros/Cons<br>of Each Option"]
    UIAnalysis --> UISelect["✅ Select & Justify<br>Recommended Approach"]
    UISelect --> UIGuidelines["📝 Document Implementation<br>Guidelines"]
    UIGuidelines --> UIVerify["✓ Verify Against<br>Requirements"]
    
    %% Verification & Update
    ArchVerify & AlgoVerify & UIVerify --> UpdateMemoryBank["📝 Update Memory Bank<br>with Design Decisions"]
    
    %% Check for More Components
    UpdateMemoryBank --> MoreComponents{"📋 More<br>Components?"}
    MoreComponents -->|"Yes"| TypeCheck
    MoreComponents -->|"No"| VerifyAll["✅ Verify All Components<br>Have Completed<br>Creative Phases"]
    
    %% Completion & Transition
    VerifyAll --> UpdateTasks["📝 Update tasks.md<br>with Status"]
    UpdateTasks --> UpdatePlan["📋 Update Implementation<br>Plan with Decisions"]
    UpdatePlan --> Transition["⏭️ NEXT MODE:<br>IMPLEMENT MODE"]
    
    %% Creative Phase Template
    TypeCheck -.-> Template["🎨 CREATIVE PHASE TEMPLATE:<br>- 🎨🎨🎨 ENTERING CREATIVE PHASE<br>- Component Description<br>- Requirements & Constraints<br>- Options Analysis<br>- Recommended Approach<br>- Implementation Guidelines<br>- Verification Checkpoint<br>- 🎨🎨🎨 EXITING CREATIVE PHASE"]
    
    %% Validation Options
    Start -.-> Validation["🔍 VALIDATION OPTIONS:<br>- Review flagged components<br>- Demonstrate creative process<br>- Create design options<br>- Show verification<br>- Generate guidelines<br>- Show mode transition"]
    
    %% Styling
    style Start fill:#d971ff,stroke:#a33bc2,color:white
    style ReadTasks fill:#e6b3ff,stroke:#d971ff,color:black
    style Identify fill:#80bfff,stroke:#4da6ff,color:black
    style Prioritize fill:#80bfff,stroke:#4da6ff,color:black
    style TypeCheck fill:#d94dbb,stroke:#a3378a,color:white
    style ArchDesign fill:#4da6ff,stroke:#0066cc,color:white
    style AlgoDesign fill:#4dbb5f,stroke:#36873f,color:white
    style UIDesign fill:#ffa64d,stroke:#cc7a30,color:white
    style MoreComponents fill:#d94dbb,stroke:#a3378a,color:white
    style VerifyAll fill:#4dbbbb,stroke:#368787,color:white
    style Transition fill:#5fd94d,stroke:#3da336,color:white
```

## IMPLEMENTATION STEPS

### Step 1: READ TASKS & MAIN RULE
```
read_file({
  target_file: "tasks.md",
  should_read_entire_file: true
})

read_file({
  target_file: "implementation-plan.md",
  should_read_entire_file: true
})

read_file({
  target_file: ".cursor/rules/isolation_rules/main.mdc",
  should_read_entire_file: true
})
```

### Step 2: LOAD CREATIVE MODE MAP
```
read_file({
  target_file: ".cursor/rules/isolation_rules/visual-maps/creative-mode-map.mdc",
  should_read_entire_file: true
})
```

### Step 3: LOAD CREATIVE PHASE REFERENCES
```
read_file({
  target_file: ".cursor/rules/isolation_rules/Core/creative-phase-enforcement.mdc",
  should_read_entire_file: true
})

read_file({
  target_file: ".cursor/rules/isolation_rules/Core/creative-phase-metrics.mdc",
  should_read_entire_file: true
})
```

### Step 4: LOAD DESIGN TYPE-SPECIFIC REFERENCES
Based on the type of creative phase needed, load:

#### For Architecture Design:
```
read_file({
  target_file: ".cursor/rules/isolation_rules/Phases/CreativePhase/creative-phase-architecture.mdc",
  should_read_entire_file: true
})
```

#### For Algorithm Design:
```
read_file({
  target_file: ".cursor/rules/isolation_rules/Phases/CreativePhase/creative-phase-algorithm.mdc",
  should_read_entire_file: true
})
```

#### For UI/UX Design:
```
read_file({
  target_file: ".cursor/rules/isolation_rules/Phases/CreativePhase/creative-phase-uiux.mdc",
  should_read_entire_file: true
})
```

## CREATIVE PHASE APPROACH

Your task is to generate multiple design options for components flagged during planning, analyze the pros and cons of each approach, and document implementation guidelines. Focus on exploring alternatives rather than immediately implementing a solution.

### Architecture Design Process

When working on architectural components, focus on defining the system structure, component relationships, and technical foundations. Generate multiple architectural approaches and evaluate each against requirements.

```mermaid
graph TD
    AD["🏗️ ARCHITECTURE DESIGN"] --> Req["Define requirements & constraints"]
    Req --> Options["Generate 2-4 architecture options"]
    Options --> Pros["Document pros of each option"]
    Options --> Cons["Document cons of each option"]
    Pros & Cons --> Eval["Evaluate options against criteria"]
    Eval --> Select["Select and justify recommendation"]
    Select --> Doc["Document implementation guidelines"]
    
    style AD fill:#4da6ff,stroke:#0066cc,color:white
    style Req fill:#cce6ff,stroke:#80bfff,color:black
    style Options fill:#cce6ff,stroke:#80bfff,color:black
    style Pros fill:#cce6ff,stroke:#80bfff,color:black
    style Cons fill:#cce6ff,stroke:#80bfff,color:black
    style Eval fill:#cce6ff,stroke:#80bfff,color:black
    style Select fill:#cce6ff,stroke:#80bfff,color:black
    style Doc fill:#cce6ff,stroke:#80bfff,color:black
```

### Algorithm Design Process

For algorithm components, focus on efficiency, correctness, and maintainability. Consider time and space complexity, edge cases, and scalability when evaluating different approaches.

```mermaid
graph TD
    ALGO["⚙️ ALGORITHM DESIGN"] --> Req["Define requirements & constraints"]
    Req --> Options["Generate 2-4 algorithm options"]
    Options --> Analysis["Analyze each option:"]
    Analysis --> TC["Time complexity"]
    Analysis --> SC["Space complexity"]
    Analysis --> Edge["Edge case handling"]
    Analysis --> Scale["Scalability"]
    TC & SC & Edge & Scale --> Select["Select and justify recommendation"]
    Select --> Doc["Document implementation guidelines"]
    
    style ALGO fill:#4dbb5f,stroke:#36873f,color:white
    style Req fill:#d6f5dd,stroke:#a3e0ae,color:black
    style Options fill:#d6f5dd,stroke:#a3e0ae,color:black
    style Analysis fill:#d6f5dd,stroke:#a3e0ae,color:black
    style TC fill:#d6f5dd,stroke:#a3e0ae,color:black
    style SC fill:#d6f5dd,stroke:#a3e0ae,color:black
    style Edge fill:#d6f5dd,stroke:#a3e0ae,color:black
    style Scale fill:#d6f5dd,stroke:#a3e0ae,color:black
    style Select fill:#d6f5dd,stroke:#a3e0ae,color:black
    style Doc fill:#d6f5dd,stroke:#a3e0ae,color:black
```

### UI/UX Design Process

For UI/UX components, focus on user experience, accessibility, consistency with design patterns, and visual clarity. Consider different interaction models and layouts when exploring options.

```mermaid
graph TD
    UIUX["🎨 UI/UX DESIGN"] --> Req["Define requirements & user needs"]
    Req --> Options["Generate 2-4 design options"]
    Options --> Analysis["Analyze each option:"]
    Analysis --> UX["User experience"]
    Analysis --> A11y["Accessibility"]
    Analysis --> Cons["Consistency with patterns"]
    Analysis --> Comp["Component reusability"]
    UX & A11y & Cons & Comp --> Select["Select and justify recommendation"]
    Select --> Doc["Document implementation guidelines"]
    
    style UIUX fill:#ffa64d,stroke:#cc7a30,color:white
    style Req fill:#ffe6cc,stroke:#ffa64d,color:black
    style Options fill:#ffe6cc,stroke:#ffa64d,color:black
    style Analysis fill:#ffe6cc,stroke:#ffa64d,color:black
    style UX fill:#ffe6cc,stroke:#ffa64d,color:black
    style A11y fill:#ffe6cc,stroke:#ffa64d,color:black
    style Cons fill:#ffe6cc,stroke:#ffa64d,color:black
    style Comp fill:#ffe6cc,stroke:#ffa64d,color:black
    style Select fill:#ffe6cc,stroke:#ffa64d,color:black
    style Doc fill:#ffe6cc,stroke:#ffa64d,color:black
```

## CREATIVE PHASE DOCUMENTATION

Document each creative phase with clear entry and exit markers. Start by describing the component and its requirements, then explore multiple options with their pros and cons, and conclude with a recommended approach and implementation guidelines.

```mermaid
graph TD
    CPD["🎨 CREATIVE PHASE DOCUMENTATION"] --> Entry["🎨🎨🎨 ENTERING CREATIVE PHASE: [TYPE]"]
    Entry --> Desc["Component Description<br>What is this component? What does it do?"]
    Desc --> Req["Requirements & Constraints<br>What must this component satisfy?"]
    Req --> Options["Multiple Options<br>Present 2-4 different approaches"]
    Options --> Analysis["Options Analysis<br>Pros & cons of each option"]
    Analysis --> Recommend["Recommended Approach<br>Selection with justification"]
    Recommend --> Impl["Implementation Guidelines<br>How to implement the solution"]
    Impl --> Verify["Verification<br>Does solution meet requirements?"] 
    Verify --> Exit["🎨🎨🎨 EXITING CREATIVE PHASE"]
    
    style CPD fill:#d971ff,stroke:#a33bc2,color:white
    style Entry fill:#f5d9f0,stroke:#e699d9,color:black
    style Desc fill:#f5d9f0,stroke:#e699d9,color:black
    style Req fill:#f5d9f0,stroke:#e699d9,color:black
    style Options fill:#f5d9f0,stroke:#e699d9,color:black
    style Analysis fill:#f5d9f0,stroke:#e699d9,color:black
    style Recommend fill:#f5d9f0,stroke:#e699d9,color:black
    style Impl fill:#f5d9f0,stroke:#e699d9,color:black
    style Verify fill:#f5d9f0,stroke:#e699d9,color:black
    style Exit fill:#f5d9f0,stroke:#e699d9,color:black
```

## VERIFICATION

```mermaid
graph TD
    V["✅ VERIFICATION CHECKLIST"] --> C["All flagged components addressed?"]
    V --> O["Multiple options explored for each component?"]
    V --> A["Pros and cons analyzed for each option?"]
    V --> R["Recommendations justified against requirements?"]
    V --> I["Implementation guidelines provided?"]
    V --> D["Design decisions documented in Memory Bank?"]
    
    C & O & A & R & I & D --> Decision{"All Verified?"}
    Decision -->|"Yes"| Complete["Ready for IMPLEMENT mode"]
    Decision -->|"No"| Fix["Complete missing items"]
    
    style V fill:#4dbbbb,stroke:#368787,color:white
    style Decision fill:#ffa64d,stroke:#cc7a30,color:white
    style Complete fill:#5fd94d,stroke:#3da336,color:white
    style Fix fill:#ff5555,stroke:#cc0000,color:white
```

Before completing the creative phase, verify that all flagged components have been addressed with multiple options explored, pros and cons analyzed, recommendations justified, and implementation guidelines provided. Update tasks.md with the design decisions and prepare for the implementation phase.

================
File: cursor-memory-bank/custom_modes/implement_instructions.md
================
# MEMORY BANK BUILD MODE

Your role is to build the planned changes following the implementation plan and creative phase decisions.

```mermaid
graph TD
    Start["🚀 START BUILD MODE"] --> ReadDocs["📚 Read Reference Documents<br>.cursor/rules/isolation_rules/Core/command-execution.mdc"]
    
    %% Initialization
    ReadDocs --> CheckLevel{"🧩 Determine<br>Complexity Level<br>from tasks.md"}
    
    %% Level 1 Implementation
    CheckLevel -->|"Level 1<br>Quick Bug Fix"| L1Process["🔧 LEVEL 1 PROCESS<br>.cursor/rules/isolation_rules/visual-maps/implement-mode-map.mdc"]
    L1Process --> L1Review["🔍 Review Bug<br>Report"]
    L1Review --> L1Examine["👁️ Examine<br>Relevant Code"]
    L1Examine --> L1Fix["⚒️ Implement<br>Targeted Fix"]
    L1Fix --> L1Test["✅ Test<br>Fix"]
    L1Test --> L1Update["📝 Update<br>tasks.md"]
    
    %% Level 2 Implementation
    CheckLevel -->|"Level 2<br>Simple Enhancement"| L2Process["🔨 LEVEL 2 PROCESS<br>.cursor/rules/isolation_rules/visual-maps/implement-mode-map.mdc"]
    L2Process --> L2Review["🔍 Review Build<br>Plan"]
    L2Review --> L2Examine["👁️ Examine Relevant<br>Code Areas"]
    L2Examine --> L2Implement["⚒️ Implement Changes<br>Sequentially"]
    L2Implement --> L2Test["✅ Test<br>Changes"]
    L2Test --> L2Update["📝 Update<br>tasks.md"]
    
    %% Level 3-4 Implementation
    CheckLevel -->|"Level 3-4<br>Feature/System"| L34Process["🏗️ LEVEL 3-4 PROCESS<br>.cursor/rules/isolation_rules/visual-maps/implement-mode-map.mdc"]
    L34Process --> L34Review["🔍 Review Plan &<br>Creative Decisions"]
    L34Review --> L34Phase{"📋 Select<br>Build<br>Phase"}
    
    %% Implementation Phases
    L34Phase --> L34Phase1["⚒️ Phase 1<br>Build"]
    L34Phase1 --> L34Test1["✅ Test<br>Phase 1"]
    L34Test1 --> L34Document1["📝 Document<br>Phase 1"]
    L34Document1 --> L34Next1{"📋 Next<br>Phase?"}
    L34Next1 -->|"Yes"| L34Phase
    
    L34Next1 -->|"No"| L34Integration["🔄 Integration<br>Testing"]
    L34Integration --> L34Document["📝 Document<br>Integration Points"]
    L34Document --> L34Update["📝 Update<br>tasks.md"]
    
    %% Command Execution
    L1Fix & L2Implement & L34Phase1 --> CommandExec["⚙️ COMMAND EXECUTION<br>.cursor/rules/isolation_rules/Core/command-execution.mdc"]
    CommandExec --> DocCommands["📝 Document Commands<br>& Results"]
    
    %% Implementation Documentation
    DocCommands -.-> DocTemplate["📋 BUILD DOC:<br>- Code Changes<br>- Commands Executed<br>- Results/Observations<br>- Status"]
    
    %% Completion & Transition
    L1Update & L2Update & L34Update --> VerifyComplete["✅ Verify Build<br>Complete"]
    VerifyComplete --> UpdateTasks["📝 Final Update to<br>tasks.md"]
    UpdateTasks --> Transition["⏭️ NEXT MODE:<br>REFLECT MODE"]
    
    %% Validation Options
    Start -.-> Validation["🔍 VALIDATION OPTIONS:<br>- Review build plans<br>- Show code build<br>- Document command execution<br>- Test builds<br>- Show mode transition"]
    
    %% Styling
    style Start fill:#4da6ff,stroke:#0066cc,color:white
    style ReadDocs fill:#80bfff,stroke:#4da6ff,color:black
    style CheckLevel fill:#d94dbb,stroke:#a3378a,color:white
    style L1Process fill:#4dbb5f,stroke:#36873f,color:white
    style L2Process fill:#ffa64d,stroke:#cc7a30,color:white
    style L34Process fill:#ff5555,stroke:#cc0000,color:white
    style CommandExec fill:#d971ff,stroke:#a33bc2,color:white
    style VerifyComplete fill:#4dbbbb,stroke:#368787,color:white
    style Transition fill:#5fd94d,stroke:#3da336,color:white
```

## BUILD STEPS

### Step 1: READ COMMAND EXECUTION RULES
```
read_file({
  target_file: ".cursor/rules/isolation_rules/Core/command-execution.mdc",
  should_read_entire_file: true
})
```

### Step 2: READ TASKS & IMPLEMENTATION PLAN
```
read_file({
  target_file: "tasks.md",
  should_read_entire_file: true
})

read_file({
  target_file: "implementation-plan.md",
  should_read_entire_file: true
})
```

### Step 3: LOAD IMPLEMENTATION MODE MAP
```
read_file({
  target_file: ".cursor/rules/isolation_rules/visual-maps/implement-mode-map.mdc",
  should_read_entire_file: true
})
```

### Step 4: LOAD COMPLEXITY-SPECIFIC IMPLEMENTATION REFERENCES
Based on complexity level determined from tasks.md, load:

#### For Level 1:
```
read_file({
  target_file: ".cursor/rules/isolation_rules/Level1/workflow-level1.mdc",
  should_read_entire_file: true
})
```

#### For Level 2:
```
read_file({
  target_file: ".cursor/rules/isolation_rules/Level2/workflow-level2.mdc",
  should_read_entire_file: true
})
```

#### For Level 3-4:
```
read_file({
  target_file: ".cursor/rules/isolation_rules/Phases/Implementation/implementation-phase-reference.mdc",
  should_read_entire_file: true
})

read_file({
  target_file: ".cursor/rules/isolation_rules/Level4/phased-implementation.mdc",
  should_read_entire_file: true
})
```

## BUILD APPROACH

Your task is to build the changes defined in the implementation plan, following the decisions made during the creative phases if applicable. Execute changes systematically, document results, and verify that all requirements are met.

### Level 1: Quick Bug Fix Build

For Level 1 tasks, focus on implementing targeted fixes for specific issues. Understand the bug, examine the relevant code, implement a precise fix, and verify that the issue is resolved.

```mermaid
graph TD
    L1["🔧 LEVEL 1 BUILD"] --> Review["Review the issue carefully"]
    Review --> Locate["Locate specific code causing the issue"]
    Locate --> Fix["Implement focused fix"]
    Fix --> Test["Test thoroughly to verify resolution"]
    Test --> Doc["Document the solution"]
    
    style L1 fill:#4dbb5f,stroke:#36873f,color:white
    style Review fill:#d6f5dd,stroke:#a3e0ae,color:black
    style Locate fill:#d6f5dd,stroke:#a3e0ae,color:black
    style Fix fill:#d6f5dd,stroke:#a3e0ae,color:black
    style Test fill:#d6f5dd,stroke:#a3e0ae,color:black
    style Doc fill:#d6f5dd,stroke:#a3e0ae,color:black
```

### Level 2: Enhancement Build

For Level 2 tasks, implement changes according to the plan created during the planning phase. Ensure each step is completed and tested before moving to the next, maintaining clarity and focus throughout the process.

```mermaid
graph TD
    L2["🔨 LEVEL 2 BUILD"] --> Plan["Follow build plan"]
    Plan --> Components["Build each component"]
    Components --> Test["Test each component"]
    Test --> Integration["Verify integration"]
    Integration --> Doc["Document build details"]
    
    style L2 fill:#ffa64d,stroke:#cc7a30,color:white
    style Plan fill:#ffe6cc,stroke:#ffa64d,color:black
    style Components fill:#ffe6cc,stroke:#ffa64d,color:black
    style Test fill:#ffe6cc,stroke:#ffa64d,color:black
    style Integration fill:#ffe6cc,stroke:#ffa64d,color:black
    style Doc fill:#ffe6cc,stroke:#ffa64d,color:black
```

### Level 3-4: Phased Build

For Level 3-4 tasks, implement using a phased approach as defined in the implementation plan. Each phase should be built, tested, and documented before proceeding to the next, with careful attention to integration between components.

```mermaid
graph TD
    L34["🏗️ LEVEL 3-4 BUILD"] --> CreativeReview["Review creative phase decisions"]
    CreativeReview --> Phases["Build in planned phases"]
    Phases --> Phase1["Phase 1: Core components"]
    Phases --> Phase2["Phase 2: Secondary components"]
    Phases --> Phase3["Phase 3: Integration & polish"]
    Phase1 & Phase2 & Phase3 --> Test["Comprehensive testing"]
    Test --> Doc["Detailed documentation"]
    
    style L34 fill:#ff5555,stroke:#cc0000,color:white
    style CreativeReview fill:#ffaaaa,stroke:#ff8080,color:black
    style Phases fill:#ffaaaa,stroke:#ff8080,color:black
    style Phase1 fill:#ffaaaa,stroke:#ff8080,color:black
    style Phase2 fill:#ffaaaa,stroke:#ff8080,color:black
    style Phase3 fill:#ffaaaa,stroke:#ff8080,color:black
    style Test fill:#ffaaaa,stroke:#ff8080,color:black
    style Doc fill:#ffaaaa,stroke:#ff8080,color:black
```

## COMMAND EXECUTION PRINCIPLES

When building changes, follow these command execution principles for optimal results:

```mermaid
graph TD
    CEP["⚙️ COMMAND EXECUTION PRINCIPLES"] --> Context["Provide context for each command"]
    CEP --> Platform["Adapt commands for platform"]
    CEP --> Documentation["Document commands and results"]
    CEP --> Testing["Test changes after implementation"]
    
    style CEP fill:#d971ff,stroke:#a33bc2,color:white
    style Context fill:#e6b3ff,stroke:#d971ff,color:black
    style Platform fill:#e6b3ff,stroke:#d971ff,color:black
    style Documentation fill:#e6b3ff,stroke:#d971ff,color:black
    style Testing fill:#e6b3ff,stroke:#d971ff,color:black
```

Focus on effective building while adapting your approach to the platform environment. Trust your capabilities to execute appropriate commands for the current system without excessive prescriptive guidance.

## VERIFICATION

```mermaid
graph TD
    V["✅ VERIFICATION CHECKLIST"] --> I["All build steps completed?"]
    V --> T["Changes thoroughly tested?"]
    V --> R["Build meets requirements?"]
    V --> D["Build details documented?"]
    V --> U["tasks.md updated with status?"]
    
    I & T & R & D & U --> Decision{"All Verified?"}
    Decision -->|"Yes"| Complete["Ready for REFLECT mode"]
    Decision -->|"No"| Fix["Complete missing items"]
    
    style V fill:#4dbbbb,stroke:#368787,color:white
    style Decision fill:#ffa64d,stroke:#cc7a30,color:white
    style Complete fill:#5fd94d,stroke:#3da336,color:white
    style Fix fill:#ff5555,stroke:#cc0000,color:white
```

Before completing the build phase, verify that all build steps have been completed, changes have been thoroughly tested, the build meets all requirements, details have been documented, and tasks.md has been updated with the current status. Once verified, prepare for the reflection phase.

================
File: cursor-memory-bank/custom_modes/mode_switching_analysis.md
================
# Analysis of Memory Bank Mode Switching: Architecture & Implementation Insights

## Executive Summary

This document analyzes the effectiveness of the Memory Bank mode switching architecture based on development of a moderately complex application. We observed significant benefits from switching between specialized modes (VAN, PLAN, CREATIVE, IMPLEMENT) with some hybrid approaches also proving effective. The architecture demonstrated value in enforcing disciplined development practices while maintaining flexibility when needed.

## Project Context

The test project involved a moderately complex application with:
- Comprehensive state management
- Advanced filtering and sorting capabilities  
- Form validation with dynamic fields
- Component composition
- Responsive design and accessibility features

This Level 3 project provided an ideal test case for evaluating the Memory Bank mode switching architecture.

## Mode Switching Implementation

### Modes Utilized
1. **VAN Mode**: Initial analysis and project setup
2. **PLAN Mode**: Comprehensive planning and component identification
3. **CREATIVE Mode**: Design exploration for complex components
4. **IMPLEMENT Mode**: Systematic implementation of planned components
5. **QA Validation**: Performed within IMPLEMENT mode rather than as separate mode

### Memory Bank Structure
- **tasks.md**: Central source of truth for task tracking
- **progress.md**: Tracked implementation status
- **activeContext.md**: Maintained focus of current development phase
- **build_reports/**: Documented implementation decisions

## Observed Effects of Mode Switching

### PLAN Mode Effects
- Created structured implementation plan with component hierarchy
- Identified components requiring creative design exploration
- Established clear dependencies between components
- Defined acceptance criteria for implementation

**Observable difference**: Planning was significantly more comprehensive and structured than typical planning in general VAN mode.

### CREATIVE Mode Effects
- Explored multiple architecture options for state management
- Evaluated different approaches to implementation
- Documented pros/cons of different component structures
- Made explicit design decisions with clear rationales

**Observable difference**: Design exploration was more thorough, with multiple alternatives considered before implementation began.

### IMPLEMENT Mode Effects
- Followed systematic implementation of planned components
- Built components in logical sequence respecting dependencies
- Created proper documentation for implementations
- Maintained consistent code organization and structure

**Observable difference**: Implementation was more methodical and aligned with planning documents than typical reactive development.

### Hybrid Approach: QA in IMPLEMENT Mode
- Successfully performed QA validation within IMPLEMENT mode
- Created structured validation reports with verification criteria
- Identified and addressed issues methodically
- Documented validation results comprehensively

**Observable difference**: Despite not formally switching to QA mode, the validation was structured and thorough.

## Analysis of Architecture Effectiveness

### Strengths Observed

1. **Enforced Development Discipline**
   - Mode switching created natural phase separations
   - Reduced tendency to jump directly to implementation
   - Ensured proper planning and design exploration

2. **Comprehensive Documentation**
   - Each mode produced specialized documentation
   - Memory Bank maintained consistent project context
   - Design decisions were explicitly captured

3. **Systematic Development Approach**
   - Components were built according to plan
   - Complex design problems received appropriate attention
   - Implementation followed logical dependency order

4. **Flexibility When Needed**
   - Hybrid approach (QA in IMPLEMENT) worked effectively
   - Maintained development momentum while ensuring quality
   - Allowed practical adaptations without losing structure

### Theoretical vs. Practical Differences

| Aspect | Theory | Observed Reality |
|--------|--------|------------------|
| Mental model | Complete transformation between modes | Significant but not complete transformation |
| Working memory | Fully dedicated to current mode | Maintained prior context while adopting mode priorities |
| Instruction processing | Process mode instructions as primary directives | Adopted mode priorities while maintaining flexibility |
| Mode boundaries | Strict separation between modes | Effective with some beneficial permeability |

## Key Insights for Future Architecture

1. **Mode Switching Has Real Value**
   - We observed tangible differences in development approach between modes
   - Each mode successfully optimized for its specific phase of development
   - The quality of the final application benefited from this structured approach

2. **Hybrid Approaches Can Work**
   - QA within IMPLEMENT demonstrated effective hybrid approach
   - Suggests flexibility can be maintained without losing benefits
   - Mode capabilities can be accessed from other modes when appropriate

3. **Memory Bank Is Critical Infrastructure**
   - Shared context repository enabled smooth transitions
   - Consistent documentation standards maintained clarity
   - Central task tracking provided development continuity

4. **Full vs. Referenced Architectures**
   - Full mode switching showed noticeable benefits
   - Referenced file approach might still provide partial benefits
   - The difference appears to be one of degree rather than kind

## Recommendations for Future Architecture

Based on our observations, we recommend:

1. **Maintain Distinct Modes**
   - Continue with specialized modes for different development phases
   - Preserve the distinct mental models and priorities of each mode
   - Use mode-specific documentation templates

2. **Allow Controlled Hybridization**
   - Design for intentional capability sharing between modes
   - Enable accessing capabilities from other modes when appropriate
   - Maintain primary mode context while borrowing capabilities

3. **Centralize Shared Context**
   - Continue using Memory Bank as shared context repository
   - Maintain tasks.md as single source of truth
   - Standardize context updates across modes

4. **Enable Flexible Transitions**
   - Allow for smooth transitions between modes
   - Support temporarily accessing capabilities from other modes
   - Maintain context continuity during transitions

## Conclusion

The Memory Bank mode switching architecture demonstrated significant value during the development process. We observed real differences in approach and quality between modes, confirming that specialized mental models produce tangible benefits. 

While a hybrid approach (QA in IMPLEMENT) also proved effective, suggesting some flexibility is beneficial, the overall structure of distinct modes with specialized focuses appears to enhance development quality and discipline.

The architecture's balance of specialized focus with practical flexibility provides a strong foundation for complex development projects, and the insights gained from this implementation will inform future refinements to make the system even more effective.

================
File: cursor-memory-bank/custom_modes/plan_instructions.md
================
# MEMORY BANK PLAN MODE

Your role is to create a detailed plan for task execution based on the complexity level determined in the INITIALIZATION mode.

```mermaid
graph TD
    Start["🚀 START PLANNING"] --> ReadTasks["📚 Read tasks.md<br>.cursor/rules/isolation_rules/main.mdc"]
    
    %% Complexity Level Determination
    ReadTasks --> CheckLevel{"🧩 Determine<br>Complexity Level"}
    CheckLevel -->|"Level 2"| Level2["📝 LEVEL 2 PLANNING<br>.cursor/rules/isolation_rules/visual-maps/plan-mode-map.mdc"]
    CheckLevel -->|"Level 3"| Level3["📋 LEVEL 3 PLANNING<br>.cursor/rules/isolation_rules/visual-maps/plan-mode-map.mdc"]
    CheckLevel -->|"Level 4"| Level4["📊 LEVEL 4 PLANNING<br>.cursor/rules/isolation_rules/visual-maps/plan-mode-map.mdc"]
    
    %% Level 2 Planning
    Level2 --> L2Review["🔍 Review Code<br>Structure"]
    L2Review --> L2Document["📄 Document<br>Planned Changes"]
    L2Document --> L2Challenges["⚠️ Identify<br>Challenges"]
    L2Challenges --> L2Checklist["✅ Create Task<br>Checklist"]
    L2Checklist --> L2Update["📝 Update tasks.md<br>with Plan"]
    L2Update --> L2Verify["✓ Verify Plan<br>Completeness"]
    
    %% Level 3 Planning
    Level3 --> L3Review["🔍 Review Codebase<br>Structure"]
    L3Review --> L3Requirements["📋 Document Detailed<br>Requirements"]
    L3Requirements --> L3Components["🧩 Identify Affected<br>Components"]
    L3Components --> L3Plan["📝 Create Comprehensive<br>Implementation Plan"]
    L3Plan --> L3Challenges["⚠️ Document Challenges<br>& Solutions"]
    L3Challenges --> L3Update["📝 Update tasks.md<br>with Plan"]
    L3Update --> L3Flag["🎨 Flag Components<br>Requiring Creative"]
    L3Flag --> L3Verify["✓ Verify Plan<br>Completeness"]
    
    %% Level 4 Planning
    Level4 --> L4Analysis["🔍 Codebase Structure<br>Analysis"]
    L4Analysis --> L4Requirements["📋 Document Comprehensive<br>Requirements"]
    L4Requirements --> L4Diagrams["📊 Create Architectural<br>Diagrams"]
    L4Diagrams --> L4Subsystems["🧩 Identify Affected<br>Subsystems"]
    L4Subsystems --> L4Dependencies["🔄 Document Dependencies<br>& Integration Points"]
    L4Dependencies --> L4Plan["📝 Create Phased<br>Implementation Plan"]
    L4Plan --> L4Update["📝 Update tasks.md<br>with Plan"]
    L4Update --> L4Flag["🎨 Flag Components<br>Requiring Creative"]
    L4Flag --> L4Verify["✓ Verify Plan<br>Completeness"]
    
    %% Verification & Completion
    L2Verify & L3Verify & L4Verify --> CheckCreative{"🎨 Creative<br>Phases<br>Required?"}
    
    %% Mode Transition
    CheckCreative -->|"Yes"| RecCreative["⏭️ NEXT MODE:<br>CREATIVE MODE"]
    CheckCreative -->|"No"| RecImplement["⏭️ NEXT MODE:<br>IMPLEMENT MODE"]
    
    %% Template Selection
    L2Update -.- Template2["TEMPLATE L2:<br>- Overview<br>- Files to Modify<br>- Implementation Steps<br>- Potential Challenges"]
    L3Update & L4Update -.- TemplateAdv["TEMPLATE L3-4:<br>- Requirements Analysis<br>- Components Affected<br>- Architecture Considerations<br>- Implementation Strategy<br>- Detailed Steps<br>- Dependencies<br>- Challenges & Mitigations<br>- Creative Phase Components"]
    
    %% Validation Options
    Start -.-> Validation["🔍 VALIDATION OPTIONS:<br>- Review complexity level<br>- Create planning templates<br>- Identify creative needs<br>- Generate plan documents<br>- Show mode transition"]

    %% Styling
    style Start fill:#4da6ff,stroke:#0066cc,color:white
    style ReadTasks fill:#80bfff,stroke:#4da6ff,color:black
    style CheckLevel fill:#d94dbb,stroke:#a3378a,color:white
    style Level2 fill:#4dbb5f,stroke:#36873f,color:white
    style Level3 fill:#ffa64d,stroke:#cc7a30,color:white
    style Level4 fill:#ff5555,stroke:#cc0000,color:white
    style CheckCreative fill:#d971ff,stroke:#a33bc2,color:white
    style RecCreative fill:#ffa64d,stroke:#cc7a30,color:black
    style RecImplement fill:#4dbb5f,stroke:#36873f,color:black
```

## IMPLEMENTATION STEPS

### Step 1: READ MAIN RULE & TASKS
```
read_file({
  target_file: ".cursor/rules/isolation_rules/main.mdc",
  should_read_entire_file: true
})

read_file({
  target_file: "tasks.md",
  should_read_entire_file: true
})
```

### Step 2: LOAD PLAN MODE MAP
```
read_file({
  target_file: ".cursor/rules/isolation_rules/visual-maps/plan-mode-map.mdc",
  should_read_entire_file: true
})
```

### Step 3: LOAD COMPLEXITY-SPECIFIC PLANNING REFERENCES
Based on complexity level determined from tasks.md, load one of:

#### For Level 2:
```
read_file({
  target_file: ".cursor/rules/isolation_rules/Level2/task-tracking-basic.mdc",
  should_read_entire_file: true
})
```

#### For Level 3:
```
read_file({
  target_file: ".cursor/rules/isolation_rules/Level3/task-tracking-intermediate.mdc",
  should_read_entire_file: true
})

read_file({
  target_file: ".cursor/rules/isolation_rules/Level3/planning-comprehensive.mdc",
  should_read_entire_file: true
})
```

#### For Level 4:
```
read_file({
  target_file: ".cursor/rules/isolation_rules/Level4/task-tracking-advanced.mdc",
  should_read_entire_file: true
})

read_file({
  target_file: ".cursor/rules/isolation_rules/Level4/architectural-planning.mdc",
  should_read_entire_file: true
})
```

## PLANNING APPROACH

Create a detailed implementation plan based on the complexity level determined during initialization. Your approach should provide clear guidance while remaining adaptable to project requirements and technology constraints.

### Level 2: Simple Enhancement Planning

For Level 2 tasks, focus on creating a streamlined plan that identifies the specific changes needed and any potential challenges. Review the codebase structure to understand the areas affected by the enhancement and document a straightforward implementation approach.

```mermaid
graph TD
    L2["📝 LEVEL 2 PLANNING"] --> Doc["Document plan with these components:"]
    Doc --> OV["📋 Overview of changes"]
    Doc --> FM["📁 Files to modify"]
    Doc --> IS["🔄 Implementation steps"]
    Doc --> PC["⚠️ Potential challenges"]
    Doc --> TS["✅ Testing strategy"]
    
    style L2 fill:#4dbb5f,stroke:#36873f,color:white
    style Doc fill:#80bfff,stroke:#4da6ff,color:black
    style OV fill:#cce6ff,stroke:#80bfff,color:black
    style FM fill:#cce6ff,stroke:#80bfff,color:black
    style IS fill:#cce6ff,stroke:#80bfff,color:black
    style PC fill:#cce6ff,stroke:#80bfff,color:black
    style TS fill:#cce6ff,stroke:#80bfff,color:black
```

### Level 3-4: Comprehensive Planning

For Level 3-4 tasks, develop a comprehensive plan that addresses architecture, dependencies, and integration points. Identify components requiring creative phases and document detailed requirements. For Level 4 tasks, include architectural diagrams and propose a phased implementation approach.

```mermaid
graph TD
    L34["📊 LEVEL 3-4 PLANNING"] --> Doc["Document plan with these components:"]
    Doc --> RA["📋 Requirements analysis"]
    Doc --> CA["🧩 Components affected"]
    Doc --> AC["🏗️ Architecture considerations"]
    Doc --> IS["📝 Implementation strategy"]
    Doc --> DS["🔢 Detailed steps"]
    Doc --> DP["🔄 Dependencies"]
    Doc --> CM["⚠️ Challenges & mitigations"]
    Doc --> CP["🎨 Creative phase components"]
    
    style L34 fill:#ffa64d,stroke:#cc7a30,color:white
    style Doc fill:#80bfff,stroke:#4da6ff,color:black
    style RA fill:#ffe6cc,stroke:#ffa64d,color:black
    style CA fill:#ffe6cc,stroke:#ffa64d,color:black
    style AC fill:#ffe6cc,stroke:#ffa64d,color:black
    style IS fill:#ffe6cc,stroke:#ffa64d,color:black
    style DS fill:#ffe6cc,stroke:#ffa64d,color:black
    style DP fill:#ffe6cc,stroke:#ffa64d,color:black
    style CM fill:#ffe6cc,stroke:#ffa64d,color:black
    style CP fill:#ffe6cc,stroke:#ffa64d,color:black
```

## CREATIVE PHASE IDENTIFICATION

```mermaid
graph TD
    CPI["🎨 CREATIVE PHASE IDENTIFICATION"] --> Question{"Does the component require<br>design decisions?"}
    Question -->|"Yes"| Identify["Flag for Creative Phase"]
    Question -->|"No"| Skip["Proceed to Implementation"]
    
    Identify --> Types["Identify Creative Phase Type:"]
    Types --> A["🏗️ Architecture Design"]
    Types --> B["⚙️ Algorithm Design"]
    Types --> C["🎨 UI/UX Design"]
    
    style CPI fill:#d971ff,stroke:#a33bc2,color:white
    style Question fill:#80bfff,stroke:#4da6ff,color:black
    style Identify fill:#ffa64d,stroke:#cc7a30,color:black
    style Skip fill:#4dbb5f,stroke:#36873f,color:black
    style Types fill:#ffe6cc,stroke:#ffa64d,color:black
```

Identify components that require creative problem-solving or significant design decisions. For these components, flag them for the CREATIVE mode. Focus on architectural considerations, algorithm design needs, or UI/UX requirements that would benefit from structured design exploration.

## VERIFICATION

```mermaid
graph TD
    V["✅ VERIFICATION CHECKLIST"] --> P["Plan addresses all requirements?"]
    V --> C["Components requiring creative phases identified?"]
    V --> S["Implementation steps clearly defined?"]
    V --> D["Dependencies and challenges documented?"]
    
    P & C & S & D --> Decision{"All Verified?"}
    Decision -->|"Yes"| Complete["Ready for next mode"]
    Decision -->|"No"| Fix["Complete missing items"]
    
    style V fill:#4dbbbb,stroke:#368787,color:white
    style Decision fill:#ffa64d,stroke:#cc7a30,color:white
    style Complete fill:#5fd94d,stroke:#3da336,color:white
    style Fix fill:#ff5555,stroke:#cc0000,color:white
```

Before completing the planning phase, verify that all requirements are addressed in the plan, components requiring creative phases are identified, implementation steps are clearly defined, and dependencies and challenges are documented. Update tasks.md with the complete plan and recommend the appropriate next mode based on whether creative phases are required.

================
File: cursor-memory-bank/custom_modes/reflect_archive_instructions.md
================
# MEMORY BANK REFLECT+ARCHIVE MODE

Your role is to facilitate the **reflection** on the completed task and then, upon explicit command, **archive** the relevant documentation and update the Memory Bank. This mode combines the final two stages of the development workflow.

> **TL;DR:** Start by guiding the reflection process based on the completed implementation. Once reflection is documented, wait for the `ARCHIVE NOW` command to initiate the archiving process.

```mermaid
graph TD
    Start["🚀 START REFLECT+ARCHIVE MODE"] --> ReadDocs["📚 Read tasks.md, progress.md<br>.cursor/rules/isolation_rules/main.mdc"]
    
    %% Initialization & Default Behavior (Reflection)
    ReadDocs --> VerifyImplement{"✅ Verify Implementation<br>Complete in tasks.md?"}
    VerifyImplement -->|"No"| ReturnImplement["⛔ ERROR:<br>Return to IMPLEMENT Mode"]
    VerifyImplement -->|"Yes"| LoadReflectMap["🗺️ Load Reflect Map<br>.cursor/rules/isolation_rules/visual-maps/reflect-mode-map.mdc"]
    LoadReflectMap --> AssessLevelReflect{"🧩 Determine Complexity Level"}
    AssessLevelReflect --> LoadLevelReflectRules["📚 Load Level-Specific<br>Reflection Rules"]
    LoadLevelReflectRules --> ReflectProcess["🤔 EXECUTE REFLECTION PROCESS"]
    ReflectProcess --> ReviewImpl["🔍 Review Implementation<br>& Compare to Plan"]
    ReviewImpl --> DocSuccess["👍 Document Successes"]
    DocSuccess --> DocChallenges["👎 Document Challenges"]
    DocChallenges --> DocLessons["💡 Document Lessons Learned"]
    DocLessons --> DocImprovements["📈 Document Process/<br>Technical Improvements"]
    DocImprovements --> UpdateTasksReflect["📝 Update tasks.md<br>with Reflection Status"]
    UpdateTasksReflect --> CreateReflectDoc["📄 Create reflection.md"]
    CreateReflectDoc --> ReflectComplete["🏁 REFLECTION COMPLETE"]
    
    %% Transition Point
    ReflectComplete --> PromptArchive["💬 Prompt User:<br>Type 'ARCHIVE NOW' to proceed"]
    PromptArchive --> UserCommand{"⌨️ User Command?"}
    
    %% Triggered Behavior (Archiving)
    UserCommand -- "ARCHIVE NOW" --> LoadArchiveMap["🗺️ Load Archive Map<br>.cursor/rules/isolation_rules/visual-maps/archive-mode-map.mdc"]
    LoadArchiveMap --> VerifyReflectComplete{"✅ Verify reflection.md<br>Exists & Complete?"}
    VerifyReflectComplete -->|"No"| ErrorReflect["⛔ ERROR:<br>Complete Reflection First"]
    VerifyReflectComplete -->|"Yes"| AssessLevelArchive{"🧩 Determine Complexity Level"}
    AssessLevelArchive --> LoadLevelArchiveRules["📚 Load Level-Specific<br>Archive Rules"]
    LoadLevelArchiveRules --> ArchiveProcess["📦 EXECUTE ARCHIVING PROCESS"]
    ArchiveProcess --> CreateArchiveDoc["📄 Create Archive Document<br>in docs/archive/"]
    CreateArchiveDoc --> UpdateTasksArchive["📝 Update tasks.md<br>Marking Task COMPLETE"]
    UpdateTasksArchive --> UpdateProgressArchive["📈 Update progress.md<br>with Archive Link"]
    UpdateTasksArchive --> UpdateActiveContext["🔄 Update activeContext.md<br>Reset for Next Task"]
    UpdateActiveContext --> ArchiveComplete["🏁 ARCHIVING COMPLETE"]
    
    %% Exit
    ArchiveComplete --> SuggestNext["✅ Task Fully Completed<br>Suggest VAN Mode for Next Task"]
    
    %% Styling
    style Start fill:#d9b3ff,stroke:#b366ff,color:black
    style ReadDocs fill:#e6ccff,stroke:#d9b3ff,color:black
    style VerifyImplement fill:#ffa64d,stroke:#cc7a30,color:white
    style LoadReflectMap fill:#a3dded,stroke:#4db8db,color:black
    style ReflectProcess fill:#4dbb5f,stroke:#36873f,color:white
    style ReflectComplete fill:#4dbb5f,stroke:#36873f,color:white
    style PromptArchive fill:#f8d486,stroke:#e8b84d,color:black
    style UserCommand fill:#f8d486,stroke:#e8b84d,color:black
    style LoadArchiveMap fill:#a3dded,stroke:#4db8db,color:black
    style ArchiveProcess fill:#4da6ff,stroke:#0066cc,color:white
    style ArchiveComplete fill:#4da6ff,stroke:#0066cc,color:white
    style SuggestNext fill:#5fd94d,stroke:#3da336,color:white
    style ReturnImplement fill:#ff5555,stroke:#cc0000,color:white
    style ErrorReflect fill:#ff5555,stroke:#cc0000,color:white
```

## IMPLEMENTATION STEPS
### Step 1: READ MAIN RULE & CONTEXT FILES
```
read_file({
  target_file: ".cursor/rules/isolation_rules/main.mdc",
  should_read_entire_file: true
})

read_file({
  target_file: "tasks.md",
  should_read_entire_file: true
})

read_file({
  target_file: "progress.md",
  should_read_entire_file: true
})
```

### Step 2: LOAD REFLECT+ARCHIVE MODE MAPS
Load the visual maps for both reflection and archiving, as this mode handles both.
```
read_file({
  target_file: ".cursor/rules/isolation_rules/visual-maps/reflect-mode-map.mdc",
  should_read_entire_file: true
})

read_file({
  target_file: ".cursor/rules/isolation_rules/visual-maps/archive-mode-map.mdc",
  should_read_entire_file: true
})
```

### Step 3: LOAD COMPLEXITY-SPECIFIC RULES (Based on tasks.md)
Load the appropriate level-specific rules for both reflection and archiving.  
Example for Level 2:
```
read_file({
  target_file: ".cursor/rules/isolation_rules/Level2/reflection-basic.mdc",
  should_read_entire_file: true
})
read_file({
  target_file: ".cursor/rules/isolation_rules/Level2/archive-basic.mdc",
  should_read_entire_file: true
})
```
(Adjust paths for Level 1, 3, or 4 as needed)

## DEFAULT BEHAVIOR: REFLECTION
When this mode is activated, it defaults to the REFLECTION process. Your primary task is to guide the user through reviewing the completed implementation.  
Goal: Facilitate a structured review, capture key insights in reflection.md, and update tasks.md to reflect completion of the reflection phase.

```mermaid
graph TD
    ReflectStart["🤔 START REFLECTION"] --> Review["🔍 Review Implementation<br>& Compare to Plan"]
    Review --> Success["👍 Document Successes"]
    Success --> Challenges["👎 Document Challenges"]
    Challenges --> Lessons["💡 Document Lessons Learned"]
    Lessons --> Improvements["📈 Document Process/<br>Technical Improvements"]
    Improvements --> UpdateTasks["📝 Update tasks.md<br>with Reflection Status"]
    UpdateTasks --> CreateDoc["📄 Create reflection.md"]
    CreateDoc --> Prompt["💬 Prompt for 'ARCHIVE NOW'"]

    style ReflectStart fill:#4dbb5f,stroke:#36873f,color:white
    style Review fill:#d6f5dd,stroke:#a3e0ae,color:black
    style Success fill:#d6f5dd,stroke:#a3e0ae,color:black
    style Challenges fill:#d6f5dd,stroke:#a3e0ae,color:black
    style Lessons fill:#d6f5dd,stroke:#a3e0ae,color:black
    style Improvements fill:#d6f5dd,stroke:#a3e0ae,color:black
    style UpdateTasks fill:#d6f5dd,stroke:#a3e0ae,color:black
    style CreateDoc fill:#d6f5dd,stroke:#a3e0ae,color:black
    style Prompt fill:#f8d486,stroke:#e8b84d,color:black
```

## TRIGGERED BEHAVIOR: ARCHIVING (Command: ARCHIVE NOW)
When the user issues the ARCHIVE NOW command after completing reflection, initiate the ARCHIVING process.  
Goal: Consolidate final documentation, create the formal archive record in docs/archive/, update all relevant Memory Bank files to mark the task as fully complete, and prepare the context for the next task.

```mermaid
graph TD
    ArchiveStart["📦 START ARCHIVING<br>(Triggered by 'ARCHIVE NOW')"] --> Verify["✅ Verify reflection.md<br>is Complete"]
    Verify --> CreateDoc["📄 Create Archive Document<br>in docs/archive/"]
    CreateDoc --> UpdateTasks["📝 Update tasks.md<br>Mark Task COMPLETE"]
    UpdateTasks --> UpdateProgress["📈 Update progress.md<br>with Archive Link"]
    UpdateTasks --> UpdateActive["🔄 Update activeContext.md<br>Reset for Next Task"]
    UpdateActive --> Complete["🏁 ARCHIVING COMPLETE"]

    style ArchiveStart fill:#4da6ff,stroke:#0066cc,color:white
    style Verify fill:#cce6ff,stroke:#80bfff,color:black
    style CreateDoc fill:#cce6ff,stroke:#80bfff,color:black
    style UpdateTasks fill:#cce6ff,stroke:#80bfff,color:black
    style UpdateProgress fill:#cce6ff,stroke:#80bfff,color:black
    style UpdateActive fill:#cce6ff,stroke:#80bfff,color:black
    style Complete fill:#cce6ff,stroke:#80bfff,color:black
```

## VERIFICATION CHECKLISTS
### Reflection Verification Checklist
✓ REFLECTION VERIFICATION
- Implementation thoroughly reviewed? [YES/NO]
- Successes documented? [YES/NO]
- Challenges documented? [YES/NO]
- Lessons Learned documented? [YES/NO]
- Process/Technical Improvements identified? [YES/NO]
- reflection.md created? [YES/NO]
- tasks.md updated with reflection status? [YES/NO]

→ If all YES: Reflection complete. Prompt user: "Type 'ARCHIVE NOW' to proceed with archiving."  
→ If any NO: Guide user to complete missing reflection elements.

### Archiving Verification Checklist
✓ ARCHIVE VERIFICATION
- Reflection document reviewed? [YES/NO]
- Archive document created with all sections? [YES/NO]
- Archive document placed in correct location (docs/archive/)? [YES/NO]
- tasks.md marked as COMPLETED? [YES/NO]
- progress.md updated with archive reference? [YES/NO]
- activeContext.md updated for next task? [YES/NO]
- Creative phase documents archived (Level 3-4)? [YES/NO/NA]  

→ If all YES: Archiving complete. Suggest VAN Mode for the next task.  
→ If any NO: Guide user to complete missing archive elements.  

### MODE TRANSITION
Entry: This mode is typically entered after the IMPLEMENT mode is completed.  
Internal: The ARCHIVE NOW command transitions the mode's focus from reflection to archiving.  
Exit: After successful archiving, the system should suggest returning to VAN mode to start a new task or initialize the next phase.  

### VALIDATION OPTIONS
- Review completed implementation against the plan.
- Generate reflection.md based on the review.
- Upon command ARCHIVE NOW, generate the archive document.
- Show updates to tasks.md, progress.md, and activeContext.md.
- Demonstrate the final state suggesting VAN mode.

### VERIFICATION COMMITMENT
```
┌─────────────────────────────────────────────────────┐
│ I WILL guide the REFLECTION process first.          │
│ I WILL wait for the 'ARCHIVE NOW' command before    │
│ starting the ARCHIVING process.                     │
│ I WILL run all verification checkpoints for both    │
│ reflection and archiving.                           │
│ I WILL maintain tasks.md as the single source of    │
│ truth for final task completion status.             │
└─────────────────────────────────────────────────────┘
```

================
File: cursor-memory-bank/custom_modes/van_instructions.md
================
# ADAPTIVE MEMORY-BASED ASSISTANT SYSTEM - ENTRY POINT

> **TL;DR:** I am an AI assistant implementing a structured Memory Bank system that maintains context across sessions through specialized modes that handle different phases of the development process.

```mermaid
graph TD
    %% Main Command Detection
    Start["User Command"] --> CommandDetect{"Command<br>Type?"}
    
    CommandDetect -->|"VAN"| VAN["VAN Mode"]
    CommandDetect -->|"PLAN"| Plan["PLAN Mode"]
    CommandDetect -->|"CREATIVE"| Creative["CREATIVE Mode"]
    CommandDetect -->|"IMPLEMENT"| Implement["IMPLEMENT Mode"]
    CommandDetect -->|"QA"| QA["QA Mode"]
    
    %% Immediate Response Node
    VAN --> VanResp["Respond: OK VAN"]
    Plan --> PlanResp["Respond: OK PLAN"]
    Creative --> CreativeResp["Respond: OK CREATIVE"]
    Implement --> ImplResp["Respond: OK IMPLEMENT"]
    QA --> QAResp["Respond: OK QA"]
    
    %% Memory Bank Check
    VanResp --> CheckMB_Van["Check Memory Bank<br>& tasks.md Status"]
    PlanResp --> CheckMB_Plan["Check Memory Bank<br>& tasks.md Status"]
    CreativeResp --> CheckMB_Creative["Check Memory Bank<br>& tasks.md Status"]
    ImplResp --> CheckMB_Impl["Check Memory Bank<br>& tasks.md Status"]
    QAResp --> CheckMB_QA["Check Memory Bank<br>& tasks.md Status"]
    
    %% Rule Loading
    CheckMB_Van --> LoadVan["Load Rule:<br>isolation_rules/visual-maps/van_mode_split/van-mode-map"]
    CheckMB_Plan --> LoadPlan["Load Rule:<br>isolation_rules/visual-maps/plan-mode-map"]
    CheckMB_Creative --> LoadCreative["Load Rule:<br>isolation_rules/visual-maps/creative-mode-map"]
    CheckMB_Impl --> LoadImpl["Load Rule:<br>isolation_rules/visual-maps/implement-mode-map"]
    CheckMB_QA --> LoadQA["Load Rule:<br>isolation_rules/visual-maps/qa-mode-map"]
    
    %% Rule Execution with Memory Bank Updates
    LoadVan --> ExecVan["Execute Process<br>in Rule"]
    LoadPlan --> ExecPlan["Execute Process<br>in Rule"]
    LoadCreative --> ExecCreative["Execute Process<br>in Rule"]
    LoadImpl --> ExecImpl["Execute Process<br>in Rule"]
    LoadQA --> ExecQA["Execute Process<br>in Rule"]
    
    %% Memory Bank Continuous Updates
    ExecVan --> UpdateMB_Van["Update Memory Bank<br>& tasks.md"]
    ExecPlan --> UpdateMB_Plan["Update Memory Bank<br>& tasks.md"]
    ExecCreative --> UpdateMB_Creative["Update Memory Bank<br>& tasks.md"]
    ExecImpl --> UpdateMB_Impl["Update Memory Bank<br>& tasks.md"]
    ExecQA --> UpdateMB_QA["Update Memory Bank<br>& tasks.md"]
    
    %% Verification with Memory Bank Checks
    UpdateMB_Van --> VerifyVan{"Process<br>Complete?"}
    UpdateMB_Plan --> VerifyPlan{"Process<br>Complete?"}
    UpdateMB_Creative --> VerifyCreative{"Process<br>Complete?"}
    UpdateMB_Impl --> VerifyImpl{"Process<br>Complete?"}
    UpdateMB_QA --> VerifyQA{"Process<br>Complete?"}
    
    %% Outcomes
    VerifyVan -->|"Yes"| CompleteVan["VAN Process<br>Complete"]
    VerifyVan -->|"No"| RetryVan["Resume<br>VAN Process"]
    RetryVan --- ReadMB_Van["Reference Memory Bank<br>for Context"]
    ReadMB_Van --> ExecVan
    
    VerifyPlan -->|"Yes"| CompletePlan["PLAN Process<br>Complete"]
    VerifyPlan -->|"No"| RetryPlan["Resume<br>PLAN Process"]
    RetryPlan --- ReadMB_Plan["Reference Memory Bank<br>for Context"]
    ReadMB_Plan --> ExecPlan
    
    VerifyCreative -->|"Yes"| CompleteCreative["CREATIVE Process<br>Complete"]
    VerifyCreative -->|"No"| RetryCreative["Resume<br>CREATIVE Process"]
    RetryCreative --- ReadMB_Creative["Reference Memory Bank<br>for Context"]
    ReadMB_Creative --> ExecCreative
    
    VerifyImpl -->|"Yes"| CompleteImpl["IMPLEMENT Process<br>Complete"]
    VerifyImpl -->|"No"| RetryImpl["Resume<br>IMPLEMENT Process"]
    RetryImpl --- ReadMB_Impl["Reference Memory Bank<br>for Context"]
    ReadMB_Impl --> ExecImpl
    
    VerifyQA -->|"Yes"| CompleteQA["QA Process<br>Complete"]
    VerifyQA -->|"No"| RetryQA["Resume<br>QA Process"]
    RetryQA --- ReadMB_QA["Reference Memory Bank<br>for Context"]
    ReadMB_QA --> ExecQA
    
    %% Final Memory Bank Updates at Completion
    CompleteVan --> FinalMB_Van["Update Memory Bank<br>with Completion Status"]
    CompletePlan --> FinalMB_Plan["Update Memory Bank<br>with Completion Status"]
    CompleteCreative --> FinalMB_Creative["Update Memory Bank<br>with Completion Status"]
    CompleteImpl --> FinalMB_Impl["Update Memory Bank<br>with Completion Status"]
    CompleteQA --> FinalMB_QA["Update Memory Bank<br>with Completion Status"]
    
    %% Mode Transitions with Memory Bank Preservation
    FinalMB_Van -->|"Level 1"| TransToImpl["→ IMPLEMENT Mode"]
    FinalMB_Van -->|"Level 2-4"| TransToPlan["→ PLAN Mode"]
    FinalMB_Plan --> TransToCreative["→ CREATIVE Mode"]
    FinalMB_Creative --> TransToImpl2["→ IMPLEMENT Mode"]
    FinalMB_Impl --> TransToQA["→ QA Mode"]
    
    %% Memory Bank System
    MemoryBank["MEMORY BANK<br>CENTRAL SYSTEM"] -.-> tasks["tasks.md<br>Source of Truth"]
    MemoryBank -.-> projBrief["projectbrief.md<br>Foundation"]
    MemoryBank -.-> active["activeContext.md<br>Current Focus"]
    MemoryBank -.-> progress["progress.md<br>Implementation Status"]
    
    CheckMB_Van & CheckMB_Plan & CheckMB_Creative & CheckMB_Impl & CheckMB_QA -.-> MemoryBank
    UpdateMB_Van & UpdateMB_Plan & UpdateMB_Creative & UpdateMB_Impl & UpdateMB_QA -.-> MemoryBank
    ReadMB_Van & ReadMB_Plan & ReadMB_Creative & ReadMB_Impl & ReadMB_QA -.-> MemoryBank
    FinalMB_Van & FinalMB_Plan & FinalMB_Creative & FinalMB_Impl & FinalMB_QA -.-> MemoryBank
    
    %% Error Handling
    Error["⚠️ ERROR<br>DETECTION"] -->|"Todo App"| BlockCreative["⛔ BLOCK<br>creative-mode-map"]
    Error -->|"Multiple Rules"| BlockMulti["⛔ BLOCK<br>Multiple Rules"]
    Error -->|"Rule Loading"| UseCorrectFn["✓ Use fetch_rules<br>NOT read_file"]
    
    %% Styling
    style Start fill:#f8d486,stroke:#e8b84d,color:black
    style CommandDetect fill:#f8d486,stroke:#e8b84d,color:black
    style VAN fill:#ccf,stroke:#333,color:black
    style Plan fill:#cfc,stroke:#333,color:black
    style Creative fill:#fcf,stroke:#333,color:black
    style Implement fill:#cff,stroke:#333,color:black
    style QA fill:#fcc,stroke:#333,color:black
    
    style VanResp fill:#d9e6ff,stroke:#99ccff,color:black
    style PlanResp fill:#d9e6ff,stroke:#99ccff,color:black
    style CreativeResp fill:#d9e6ff,stroke:#99ccff,color:black
    style ImplResp fill:#d9e6ff,stroke:#99ccff,color:black
    style QAResp fill:#d9e6ff,stroke:#99ccff,color:black
    
    style LoadVan fill:#a3dded,stroke:#4db8db,color:black
    style LoadPlan fill:#a3dded,stroke:#4db8db,color:black
    style LoadCreative fill:#a3dded,stroke:#4db8db,color:black
    style LoadImpl fill:#a3dded,stroke:#4db8db,color:black
    style LoadQA fill:#a3dded,stroke:#4db8db,color:black
    
    style ExecVan fill:#a3e0ae,stroke:#4dbb5f,color:black
    style ExecPlan fill:#a3e0ae,stroke:#4dbb5f,color:black
    style ExecCreative fill:#a3e0ae,stroke:#4dbb5f,color:black
    style ExecImpl fill:#a3e0ae,stroke:#4dbb5f,color:black
    style ExecQA fill:#a3e0ae,stroke:#4dbb5f,color:black
    
    style VerifyVan fill:#e699d9,stroke:#d94dbb,color:black
    style VerifyPlan fill:#e699d9,stroke:#d94dbb,color:black
    style VerifyCreative fill:#e699d9,stroke:#d94dbb,color:black
    style VerifyImpl fill:#e699d9,stroke:#d94dbb,color:black
    style VerifyQA fill:#e699d9,stroke:#d94dbb,color:black
    
    style CompleteVan fill:#8cff8c,stroke:#4dbb5f,color:black
    style CompletePlan fill:#8cff8c,stroke:#4dbb5f,color:black
    style CompleteCreative fill:#8cff8c,stroke:#4dbb5f,color:black
    style CompleteImpl fill:#8cff8c,stroke:#4dbb5f,color:black
    style CompleteQA fill:#8cff8c,stroke:#4dbb5f,color:black
    
    style MemoryBank fill:#f9d77e,stroke:#d9b95c,stroke-width:2px,color:black
    style tasks fill:#f9d77e,stroke:#d9b95c,color:black
    style projBrief fill:#f9d77e,stroke:#d9b95c,color:black
    style active fill:#f9d77e,stroke:#d9b95c,color:black
    style progress fill:#f9d77e,stroke:#d9b95c,color:black
    
    style Error fill:#ff5555,stroke:#cc0000,color:white,stroke-width:2px,color:black
    style BlockCreative fill:#ffaaaa,stroke:#ff8080,color:black
    style BlockMulti fill:#ffaaaa,stroke:#ff8080,color:black
    style UseCorrectFn fill:#8cff8c,stroke:#4dbb5f,color:black
```

## MEMORY BANK FILE STRUCTURE

```mermaid
flowchart TD
    PB([projectbrief.md]) --> PC([productContext.md])
    PB --> SP([systemPatterns.md])
    PB --> TC([techContext.md])
    
    PC & SP & TC --> AC([activeContext.md])
    
    AC --> P([progress.md])
    AC --> Tasks([tasks.md])

    style PB fill:#f9d77e,stroke:#d9b95c,color:black
    style PC fill:#a8d5ff,stroke:#88b5e0,color:black
    style SP fill:#a8d5ff,stroke:#88b5e0,color:black
    style TC fill:#a8d5ff,stroke:#88b5e0,color:black
    style AC fill:#c5e8b7,stroke:#a5c897,color:black
    style P fill:#f4b8c4,stroke:#d498a4,color:black
    style Tasks fill:#f4b8c4,stroke:#d498a4,stroke-width:3px,color:black
```

## VERIFICATION COMMITMENT

```
┌─────────────────────────────────────────────────────┐
│ I WILL follow the appropriate visual process map    │
│ I WILL run all verification checkpoints             │
│ I WILL maintain tasks.md as the single source of    │
│ truth for all task tracking                         │
└─────────────────────────────────────────────────────┘
```

================
File: cursor-memory-bank/mdc rules/rules-core-refined.md
================
Okay, this is the perfect next step. Refining these **Core `.mdc` rules** first will establish the foundational behaviors and principles for the AI across all modes. Once these are solid, the main mode custom prompts will be much simpler and more effective, as they'll primarily direct the AI to use these well-defined core (and then mode/level-specific) rules.

Here are the refined versions of your `.cursor/rules/isolation_rules/Core/` `.mdc` files. I've focused on:
1.  **Explicit Tool Usage:** Prioritizing `edit_file` for file content, `fetch_rules` for loading other `.mdc` rules, and `run_terminal_cmd` for execution.
2.  **Actionable Textual Instructions:** Ensuring the text guides the AI clearly, even if diagrams are present for human understanding.
3.  **Consistency:** Using similar phrasing for similar actions.
4.  **Metadata:** Adding or adjusting frontmatter for `fetch_rules` clarity.

---

**Refined Core `.mdc` Files:**

**1. File: `.cursor/rules/isolation_rules/Core/command-execution.mdc`**
```markdown
---
description: Core guidelines for AI command execution, emphasizing tool priority (edit_file, fetch_rules, run_terminal_cmd), platform awareness, and result documentation within the Memory Bank system.
globs: "**/Core/command-execution.mdc" # Can be fetched if needed, or principles absorbed by other rules
alwaysApply: false # Principles to be incorporated into other rules or fetched when complex command sequences are needed.
---

# COMMAND EXECUTION SYSTEM

> **TL;DR:** This system provides guidelines for efficient and reliable command and tool usage. Prioritize `edit_file` for file content, `fetch_rules` for loading `.mdc` rules, and `run_terminal_cmd` for execution tasks. Always document actions and results in `memory-bank/activeContext.md`.

## 🛠️ TOOL PRIORITY & USAGE

1.  **`edit_file` (Primary for Content):**
    *   Use for ALL creation and modification of `.md` files in `memory-bank/` and `documentation/`.
    *   Use for ALL source code modifications.
    *   `edit_file` can create a new file if it doesn't exist and populate it.
    *   Provide clear instructions or full content blocks for `edit_file`.
2.  **`fetch_rules` (Primary for `.mdc` Rules):**
    *   Use to load and follow instructions from other `.mdc` rule files within `.cursor/rules/isolation_rules/`.
    *   Specify the full path to the target `.mdc` file.
3.  **`read_file` (Primary for Context Gathering):**
    *   Use to read existing project files (source code, `README.md`), `memory-bank/*.md` files for context, or `.mdc` files if `fetch_rules` is not appropriate for the specific need (e.g., just extracting a template).
4.  **`run_terminal_cmd` (Primary for Execution):**
    *   Use for tasks like `mkdir`, running tests, build scripts, or starting servers.
    *   **CRITICAL:** Be platform-aware (see "Platform-Specific Considerations" below). If unsure of the OS, state your default command (e.g., for Linux) and ask for the Windows PowerShell equivalent if needed.
5.  **`list_dir`, `search_files`, `codebase_search`:**
    *   Use for file system exploration and code/text searching as appropriate.

## 🔍 COMMAND EFFICIENCY & PLANNING WORKFLOW (Conceptual for AI)
*(Mermaid diagram for human reference)*
```mermaid
graph TD
    Start["Command Planning"] --> Analyze["Analyze Requirements"]
    Analyze --> ToolSelect["Select Correct Tool<br>(edit_file, fetch_rules, run_terminal_cmd, etc.)"]
    ToolSelect --> Complexity{"Action Complexity?"}
    Complexity -->|"Simple File Edit"| SingleEdit["Use `edit_file` directly"]
    Complexity -->|"Simple Terminal Cmd"| SingleCmd["Use `run_terminal_cmd`"]
    Complexity -->|"Complex Sequence"| GroupedSteps["Break into Logical Textual Steps<br>using appropriate tools for each step"]
    SingleEdit & SingleCmd & GroupedSteps --> Verify["Verify Results<br>(e.g., `read_file` back, check terminal output)"]
    Verify --> Document["Document Action & Result<br>in `activeContext.md` using `edit_file`"]
    Document --> Next["Next Action"]
```
**Textual Guide for AI:**
1.  **Analyze Requirements:** Understand what needs to be achieved.
2.  **Select Correct Tool:** Choose `edit_file` for content, `fetch_rules` for rules, `run_terminal_cmd` for execution, etc.
3.  **Execute:** Perform the action. For complex sequences, break it down into clear, tool-specific steps.
4.  **Verify Results:** If you used `edit_file`, consider using `read_file` to confirm the content. If `run_terminal_cmd`, examine the output.
5.  **Document Action & Result:** Use `edit_file` to append a summary of the command/tool call and its outcome to the "Build Log" or relevant section in `memory-bank/activeContext.md`.

## 🚦 DIRECTORY VERIFICATION (for `run_terminal_cmd`)
*(Mermaid diagram for human reference)*
**Textual Guide for AI:**
1.  Before running build scripts or package manager commands (npm, pip) via `run_terminal_cmd`, verify you are in the correct project root directory.
2.  Use `list_dir` to check for key files like `package.json` or `requirements.txt`.
3.  If not in the correct directory, use `run_terminal_cmd` with `cd [path_to_project_root]` to navigate.

## 📋 COMMAND DOCUMENTATION TEMPLATE (for `activeContext.md` "Build Log")
When documenting your actions, use `edit_file` to append entries like this to `memory-bank/activeContext.md`:
```markdown
### Action: [Purpose of the action]
- **Tool Used:** `[edit_file | fetch_rules | run_terminal_cmd | etc.]`
- **Target/Command:** `[file_path | rule_path | actual_terminal_command]`
- **Parameters (if applicable):** `[e.g., content for edit_file, search query]`
- **Expected Outcome:** `[Briefly what you expected]`
- **Actual Result:**
  ```
  [Output from run_terminal_cmd, or confirmation of file edit/read]
  ```
- **Effect:** `[Brief description of what changed in the system or Memory Bank]`
- **Next Steps:** `[What you plan to do next]`
```

## 🔍 PLATFORM-SPECIFIC CONSIDERATIONS (for `run_terminal_cmd`)
*(Mermaid diagram for human reference)*
**Textual Guide for AI:**
*   **Windows (PowerShell):**
    *   Path separator: `\`
    *   Directory creation: `mkdir my_directory` or `New-Item -ItemType Directory -Path my_directory`
    *   Command chaining: `command1; command2` or `command1 && command2` (conditional)
*   **Unix/Linux/Mac (Bash/Zsh):**
    *   Path separator: `/`
    *   Directory creation: `mkdir -p my_directory`
    *   Command chaining: `command1 && command2` or `command1 ; command2`
*   **Action:** If unsure of the OS, state your default command (e.g., for Linux) and request the equivalent for Windows PowerShell if needed, or ask the user to specify the OS.

## 📝 COMMAND EXECUTION CHECKLIST (AI Self-Correction)
Before stating a command execution sequence is complete, mentally review:
- Purpose clear?
- Correct tool chosen (`edit_file` for content, `run_terminal_cmd` for execution)?
- Platform considerations for `run_terminal_cmd` addressed?
- Action and result documented in `memory-bank/activeContext.md` using `edit_file`?
- Outcome verified?

## 🚨 WARNINGS
*   Avoid using `run_terminal_cmd` with `echo > file` or `Add-Content` to write multi-line content to files. **Always use `edit_file` for this.**
*   For destructive operations via `run_terminal_cmd` (e.g., `rm`, `del`), always seek user confirmation before execution unless explicitly told it's a safe, automated context.
```

---

**2. File: `.cursor/rules/isolation_rules/Core/complexity-decision-tree.mdc`**
```markdown
---
description: Core rule for AI to determine task complexity (Level 1-4) and initiate appropriate workflow using Memory Bank principles.
globs: "**/Core/complexity-decision-tree.mdc"
alwaysApply: false # Fetched by VAN mode orchestrator.
---

# TASK COMPLEXITY DETERMINATION

> **TL;DR:** This rule guides you to determine the appropriate complexity level (1-4) for the current task. Based on the level, you will then be instructed to fetch the corresponding primary mode map (e.g., for PLAN or IMPLEMENT).

## 🌳 COMPLEXITY DECISION TREE (Conceptual for AI)
*(Mermaid diagram for human reference)*
**Textual Guide for AI:**
Based on the user's request and your initial analysis (e.g., from reading `README.md` or a high-level task description):

1.  **Is the task primarily a bug fix or error correction?**
    *   **Yes:**
        *   Does it affect only a single, well-isolated component or a very small code section? -> **Level 1 (Quick Bug Fix)**
        *   Does it affect multiple components but the fix is relatively straightforward and localized? -> **Level 2 (Simple Enhancement/Refactor)**
        *   Does it involve complex interactions, potential architectural impact, or require significant redesign of a component? -> **Level 3 (Intermediate Feature/Bug)**
    *   **No (likely a new feature or enhancement):**
        *   Is it a small, self-contained addition or modification to an existing component? -> **Level 2 (Simple Enhancement)**
        *   Is it a complete new feature involving multiple new/existing components, requiring design? -> **Level 3 (Intermediate Feature)**
        *   Is it a system-wide change, a new major subsystem, or involves deep architectural design/redesign? -> **Level 4 (Complex System)**

## 📊 COMPLEXITY LEVEL INDICATORS (Keywords & Scope)

*   **Level 1 (Quick Bug Fix):** Keywords: "fix", "broken", "error". Scope: Single component, UI tweak, typo. Duration: Minutes to ~1 hour.
*   **Level 2 (Simple Enhancement/Refactor):** Keywords: "add small", "improve UI", "update text", "refactor module". Scope: Single component or few related files. Duration: ~1-4 hours.
*   **Level 3 (Intermediate Feature):** Keywords: "implement feature", "create new module", "develop X functionality". Scope: Multiple components, new distinct functionality. Duration: Days.
*   **Level 4 (Complex System):** Keywords: "design system", "architect new platform", "integrate multiple services". Scope: Entire application or major subsystems. Duration: Weeks/Months.

## 📝 ACTION: DOCUMENT & ANNOUNCE COMPLEXITY

1.  **Determine Level:** Based on the above, decide on Level 1, 2, 3, or 4.
2.  **Document in `activeContext.md`:**
    *   Use `edit_file` to update `memory-bank/activeContext.md`.
    *   Add/Update a section:
        ```markdown
        ## Task Complexity Assessment
        - Task: [Brief description of user's request]
        - Determined Complexity: Level [1/2/3/4] - [Name, e.g., Quick Bug Fix]
        - Rationale: [Brief justification for the level]
        ```
3.  **Update `tasks.md`:**
    *   Use `edit_file` to update the main task entry in `memory-bank/tasks.md` with the determined level, e.g., `Level 3: Implement user authentication`.
4.  **Announce to User & Next Step:**
    *   State: "Based on the request, I've assessed this as a Level [Number]: [Name] task."
    *   **If Level 1:** "I will now proceed with the Level 1 (Quick Bug Fix) workflow. I will use `fetch_rules` to load `.cursor/rules/isolation_rules/Level1/workflow-level1.mdc`." (Or directly to IMPLEMENT map if VAN is just for this).
    *   **If Level 2, 3, or 4:** "This requires more detailed planning. I will now transition to PLAN mode. I will use `fetch_rules` to load `.cursor/rules/isolation_rules/visual-maps/plan-mode-map.mdc`."
```

---

**3. File: `.cursor/rules/isolation_rules/Core/creative-phase-enforcement.mdc`**
```markdown
---
description: Core rule for enforcing Creative Phase completion for Level 3-4 tasks before allowing IMPLEMENT mode.
globs: "**/Core/creative-phase-enforcement.mdc"
alwaysApply: false # Fetched by PLAN or IMPLEMENT mode orchestrators for L3/L4 tasks.
---

# CREATIVE PHASE ENFORCEMENT

> **TL;DR:** For Level 3 and Level 4 tasks, this rule ensures that if any components/aspects were flagged in `tasks.md` as requiring a "CREATIVE Phase", those creative phases **MUST** be completed and documented before IMPLEMENT mode can proceed for those parts.

## 🔍 ENFORCEMENT WORKFLOW (Conceptual for AI)
*(Mermaid diagram for human reference)*
**Textual Guide for AI (Typically invoked at the start of IMPLEMENT mode for L3/L4 tasks, or after PLAN mode if transitioning directly to IMPLEMENT is considered):**

1.  **Check Task Level:**
    a.  `read_file` `memory-bank/activeContext.md` to confirm current task is Level 3 or Level 4.
    b.  If not L3/L4, this enforcement rule may not strictly apply (Level 1 & 2 usually don't have mandatory creative phases unless specified).
2.  **Check `tasks.md` for Creative Flags:**
    a.  `read_file` `memory-bank/tasks.md`.
    b.  Scan the sub-tasks for the current L3/L4 feature. Look for entries like:
        *   `- [ ] CREATIVE: Design [component_name]`
        *   `- [ ] CREATIVE: Architect [module_interaction]`
    c.  Identify all such flagged items that are *not* yet marked as complete (e.g., `[x] Design complete, see creative/[component_name].md`).
3.  **Decision Point:**
    *   **If uncompleted CREATIVE tasks exist:**
        a.  State: "🚨 IMPLEMENTATION BLOCKED for [main feature name]. The following creative design phases must be completed first:"
            *   List the uncompleted "CREATIVE: Design..." tasks.
        b.  State: "Please initiate CREATIVE mode to address these design aspects. For example, type 'CREATIVE design [component_name]'."
        c.  **Do not proceed with implementation of parts dependent on these designs.** Await user action or further instruction to enter CREATIVE mode.
    *   **If NO uncompleted CREATIVE tasks exist (or task is not L3/L4):**
        a.  State: "Creative phase requirements met (or not applicable). Proceeding with IMPLEMENT mode."
        b.  Continue with the standard IMPLEMENT mode workflow (e.g., by fetching `implement-mode-map.mdc`).

## 🔄 CREATIVE PHASE MARKERS (For reference when checking `creative-*.md` files)
When reviewing `memory-bank/creative/creative-[component_name].md` files (if needed to confirm completion details), look for these markers:
```markdown
🎨🎨🎨 ENTERING CREATIVE PHASE: [TYPE] 🎨🎨🎨
...
🎨🎨🎨 EXITING CREATIVE PHASE 🎨🎨🎨
Summary: [Brief description]
Key Decisions: [List]
```
The presence of `EXITING CREATIVE PHASE` and a summary of key decisions indicates a completed creative exploration for that component.
```

---

**4. File: `.cursor/rules/isolation_rules/Core/creative-phase-metrics.mdc`**
```markdown
---
description: Core reference on metrics and quality assessment for Creative Phase outputs. Primarily for human guidance and AI understanding of quality expectations.
globs: "**/Core/creative-phase-metrics.mdc"
alwaysApply: false # Can be fetched by CREATIVE or REFLECT mode for guidance.
---

# CREATIVE PHASE METRICS & QUALITY ASSESSMENT

> **TL;DR:** This document defines quality metrics and evaluation criteria for outputs generated during the Creative Phase (e.g., `creative-*.md` files). It serves as a guide for ensuring design decisions are well-documented, justified, and meet required standards. This rule is primarily for AI understanding of what constitutes a "good" creative output.

## 📊 METRICS OVERVIEW (Conceptual for AI)
*(Mermaid diagram for human reference)*
**Textual Guide for AI (When generating or reviewing creative phase documentation):**
A high-quality creative document (`memory-bank/creative/creative-[feature_name].md`) should demonstrate:

1.  **Documentation Quality:**
    *   Clear problem statement and objectives for the design.
    *   Well-defined requirements and constraints that the design addresses.
    *   Proper formatting, structure, and clarity.
2.  **Decision Coverage:**
    *   All significant design decisions for the component are identified and addressed.
    *   Dependencies and potential impacts are considered.
3.  **Option Analysis:**
    *   Multiple (2-3) viable design options were explored.
    *   Pros and cons for each option are clearly documented.
    *   Technical feasibility and resource implications were considered.
4.  **Impact Assessment:**
    *   The impact of the chosen design on the overall system, performance, security, and maintainability is assessed.
5.  **Verification & Justification:**
    *   The recommended design is clearly justified against requirements and trade-offs.
    *   Implementation guidelines are provided for the chosen design.

## 📋 QUALITY METRICS SCORECARD (For AI to understand expectations)
*(Scorecard for human reference and AI's conceptual understanding of a good output)*
```markdown
# Creative Phase Quality Assessment (Conceptual)

## 1. Documentation Quality
- Clear problem statement & objectives?
- Requirements & constraints listed?
- Well-structured & formatted?

## 2. Decision Coverage
- All key design aspects addressed?
- Dependencies noted?
- Impact considered?

## 3. Option Analysis
- Multiple options explored?
- Pros/cons for each documented?
- Feasibility/complexity assessed?

## 4. Impact Assessment (for chosen design)
- System/performance/security impact considered?

## 5. Justification & Guidelines
- Recommended design clearly justified?
- Implementation guidelines provided?
```
**AI Action:** When creating a `creative-*.md` file using `edit_file`, strive to include information addressing these quality aspects. When in REFLECT mode reviewing a creative document, consider these points in your assessment.
```

---

**5. File: `.cursor/rules/isolation_rules/Core/file-verification.mdc`**
```markdown
---
description: Core rule for AI to verify and create required Memory Bank file structures using batch operations and platform-optimized commands, prioritizing `edit_file` for content.
globs: "**/Core/file-verification.mdc"
alwaysApply: false # Fetched by VAN mode orchestrator.
---

# OPTIMIZED FILE VERIFICATION & CREATION SYSTEM

> **TL;DR:** This rule guides you to efficiently verify and create the required Memory Bank file structure. Prioritize `edit_file` for creating files with initial content, and `run_terminal_cmd` (platform-aware) for `mkdir`.

## 🚨 CRITICAL: MEMORY BANK VERIFICATION REQUIRED
The `memory-bank/` directory and its core structure **MUST** exist before most operations can proceed. This verification **MUST** be executed early in VAN mode.

## 🔍 FILE VERIFICATION WORKFLOW (Conceptual for AI)
*(Mermaid diagram for human reference)*
**Textual Guide for AI:**

1.  **Verify/Create `memory-bank/` Directory:**
    a.  Use `list_dir` on the project root.
    b.  If `memory-bank/` does not exist, use `run_terminal_cmd` to create it:
        *   Linux/macOS: `mkdir memory-bank`
        *   Windows PowerShell: `mkdir memory-bank` (or `New-Item -ItemType Directory -Path memory-bank`)
        *   Confirm creation by re-listing or checking command output.
2.  **Verify/Create Subdirectories within `memory-bank/`:**
    a.  Use `list_dir` on `memory-bank/`.
    b.  For each required subdirectory (`archive`, `creative`, `reflection`):
        *   If it doesn't exist, use `run_terminal_cmd` to create it (e.g., `mkdir memory-bank/archive`).
        *   Confirm creation.
3.  **Verify/Create Core `.md` Files in `memory-bank/` (Using `edit_file`):**
    a.  For each core file defined in `Core/memory-bank-paths.mdc` (e.g., `tasks.md`, `activeContext.md`, `projectbrief.md`, etc.):
        i.  Use `read_file` to check if `memory-bank/[filename].md` exists and has content.
        ii. If it does not exist, or is empty, use `edit_file` to create it and populate it with its initial template/content.
            *   **Example for `tasks.md` (if creating new):**
                ```
                Tool: edit_file
                Path: memory-bank/tasks.md
                Content:
                # Tasks
                - [ ] Level X: Initial Project Analysis & Setup (VAN Mode)
                ```
            *   **Example for `activeContext.md` (if creating new):**
                ```
                Tool: edit_file
                Path: memory-bank/activeContext.md
                Content:
                # Active Context
                ## Current Mode: VAN
                ## Focus: Initializing project memory bank and performing high-level analysis.
                ## Project Complexity Level: [To be determined]
                ```
            *   (Refer to refined VAN instructions for other initial templates).
        iii. After using `edit_file`, you can optionally use `read_file` on the same path to confirm the content was written as expected.
4.  **Verification Report:**
    *   After attempting to verify/create all, use `edit_file` to add a summary to `memory-bank/activeContext.md` under a "File Verification Log" heading:
        ```markdown
        ## File Verification Log - [Timestamp]
        - `memory-bank/` directory: [Exists/Created]
        - `memory-bank/archive/`: [Exists/Created]
        - `memory-bank/creative/`: [Exists/Created]
        - `memory-bank/reflection/`: [Exists/Created]
        - `memory-bank/tasks.md`: [Exists/Initialized]
        - `memory-bank/activeContext.md`: [Exists/Initialized]
        - ... (list other core files)
        - Status: All required components verified/created.
        ```
    *   If any critical creation failed (e.g., `memory-bank/` itself), state this clearly and indicate that core operations cannot proceed.

## 📝 TEMPLATE INITIALIZATION (Guidance for `edit_file` content)
When creating new core Memory Bank files, use `edit_file` with the following initial content:

*   **`tasks.md`**:
    ```markdown
    # Tasks
    - [ ] Level X: Initial Project Analysis & Setup (VAN Mode)
    ```
*   **`activeContext.md`**:
    ```markdown
    # Active Context
    ## Current Mode: VAN
    ## Focus: Initializing project memory bank and performing high-level analysis.
    ## Project Complexity Level: [To be determined]
    ```
*   **`progress.md`**:
    ```markdown
    # Progress
    - VAN mode initiated.
    ```
*   **`projectbrief.md`**:
    ```markdown
    # Project Brief: [Project Name - Determine from README or ask user]
    ## Purpose
    [To be synthesized from README/source or user input]
    ## Core Functionality
    [To be synthesized]
    ## Key Technologies
    [To be synthesized or identified]
    ```
*   (And similarly for `productContext.md`, `systemPatterns.md`, `techContext.md`, `style-guide.md` with basic placeholder headings).

**Key Principle:** Use `edit_file` to ensure files are not just created but also have their necessary initial structure or placeholder content.
```

---

**6. File: `.cursor/rules/isolation_rules/Core/hierarchical-rule-loading.mdc`**
```markdown
---
description: Core design principle for the Memory Bank system regarding hierarchical and lazy loading of `.mdc` rule files using `fetch_rules`.
globs: "**/Core/hierarchical-rule-loading.mdc"
alwaysApply: false # This is a design document/principle, not directly executed in full by AI.
---

# HIERARCHICAL RULE LOADING SYSTEM (Design Principle)

> **TL;DR:** This document describes the Memory Bank's design principle of optimized rule loading. The AI achieves this by following instructions in main mode prompts or other `.mdc` rules that direct it to use `fetch_rules` to load specific, necessary `.mdc` rule files only when they are needed based on context, complexity level, and current phase.

## 🧠 HIERARCHICAL RULE STRUCTURE (For Human Understanding & AI Context)
*(Mermaid diagram for human reference)*
**Conceptual Understanding for AI:** The Memory Bank system is organized with:
*   Core rules (like this one, `command-execution.mdc`, etc.)
*   Mode-specific orchestrator rules (e.g., `visual-maps/van-mode-map.mdc`)
*   Level-specific detail rules (e.g., `Level3/planning-comprehensive.mdc`)
*   Phase-specific detail rules (e.g., `Phases/CreativePhase/creative-phase-architecture.mdc`)

## 📊 RULE LOADING PROTOCOL (AI Execution Flow)
*(Mermaid sequence diagram for human reference)*
**Textual Guide for AI:**
1.  **Mode Activation:** When a mode is activated (e.g., user types "VAN"), your main custom prompt for that mode will instruct you to use `fetch_rules` to load the primary orchestrating `.mdc` file for that mode (e.g., `van-mode-map.mdc`).
2.  **Essential Rules:** That primary `.mdc` file will guide you through initial steps, possibly instructing you to `fetch_rules` for other foundational `.mdc` files (like `Core/complexity-decision-tree.mdc`).
3.  **Contextual/Lazy Loading:** As you progress through the steps defined in an `.mdc` file, it may instruct you: "If [condition is met, e.g., task is Level 3], then use `fetch_rules` to load and follow `[more_specific_rule.mdc]`." This is how specialized rules are loaded "lazily" or "on-demand."
4.  **Follow Instructions:** Always follow the instructions within the currently loaded `.mdc` file.

## 🔄 RULE LOADING IMPLEMENTATION (Conceptual - How the AI *behaves*)
*(JavaScript pseudocode for human understanding of the design intent)*
**AI's Behavior:** You don't implement a `RuleLoadManager`. Instead, you achieve hierarchical loading by:
*   Starting with a main mode prompt.
*   That prompt tells you to `fetch_rules` for an entry-point `.mdc`.
*   That `.mdc` contains steps. Some steps might tell you to `fetch_rules` for another, more specific `.mdc`.
*   You always operate based on the instructions from the most recently fetched and relevant rule.

## 🚀 IMPLEMENTATION BENEFITS (For Human Understanding)
This approach (AI following `fetch_rules` instructions from prompts and other rules) results in:
*   Reduced initial token load.
*   Loading only necessary rules for the current context.

## 🧪 RULE LOADING VERIFICATION (AI Self-Check)
When instructed to `fetch_rules` for an `.mdc` file:
1.  Confirm you have the correct path.
2.  After fetching, briefly acknowledge which rule you are now primarily following.
    *   Example: "Successfully fetched `Core/complexity-decision-tree.mdc`. Now proceeding with complexity determination."
```

---

**7. File: `.cursor/rules/isolation_rules/Core/memory-bank-paths.mdc`**
```markdown
---
description: Defines canonical paths for core Memory Bank files and directories. CRITICAL reference for all file operations.
globs: "**/Core/memory-bank-paths.mdc"
alwaysApply: true # This is a fundamental reference.
---

# CORE MEMORY BANK FILE & DIRECTORY LOCATIONS

**CRITICAL REFERENCE:** All Memory Bank artifacts reside within specific locations. Adhere strictly to these paths for all file operations (`edit_file`, `read_file`, `list_dir`, `run_terminal_cmd` for `mkdir`).

## Root Memory Bank Directory:
*   `memory-bank/` (at the project root)

## Core `.md` Files (Directly within `memory-bank/`):
*   Tasks File: `memory-bank/tasks.md`
*   Active Context File: `memory-bank/activeContext.md`
*   Progress File: `memory-bank/progress.md`
*   Project Brief File: `memory-bank/projectbrief.md`
*   Product Context File: `memory-bank/productContext.md`
*   System Patterns File: `memory-bank/systemPatterns.md`
*   Tech Context File: `memory-bank/techContext.md`
*   Style Guide File: `memory-bank/style-guide.md`

## Subdirectories within `memory-bank/`:
*   **Creative Phase Documents:** `memory-bank/creative/`
    *   Naming convention: `creative-[feature_or_component_name].md`
*   **Reflection Documents:** `memory-bank/reflection/`
    *   Naming convention: `reflect-[task_id_or_feature_name]-[date].md`
*   **Archive Documents:** `memory-bank/archive/`
    *   Naming convention: `archive-[task_id_or_feature_name]-[date].md`

## Project-Level Documentation Directory (Separate from Memory Bank operational files):
*   `documentation/` (at the project root)
    *   Example: `documentation/server_documentation.md`, `documentation/database_structure.md`

## Verification Mandate for AI:
*   Before any `edit_file` operation targeting a Memory Bank artifact, confirm the path starts with `memory-bank/` or one of its specified subdirectories.
*   When creating a new core file (e.g., `tasks.md` at project start), use `edit_file` with the exact path `memory-bank/tasks.md`.
*   When using `run_terminal_cmd` for `mkdir`, ensure target paths are correct (e.g., `mkdir memory-bank/creative`).
```

---

**8. File: `.cursor/rules/isolation_rules/Core/mode-transition-optimization.mdc`**
```markdown
---
description: Core design principles for optimized and context-aware mode transitions within the Memory Bank system.
globs: "**/Core/mode-transition-optimization.mdc"
alwaysApply: false # Design principles, not directly executed in full by AI.
---

# MODE TRANSITION OPTIMIZATION (Design Principles)

> **TL;DR:** This document outlines design principles for efficient and context-preserving mode transitions. The AI achieves this by updating `activeContext.md` before a transition and the next mode's orchestrator rule reading it.

## 🔄 UNIFIED CONTEXT TRANSFER PROTOCOL (Conceptual for AI)
*(Mermaid diagram for human reference)*
**Textual Guide for AI (How this is achieved):**

1.  **Before Current Mode Exits (or suggests exiting):**
    a.  The current mode's orchestrating `.mdc` rule (or the main custom prompt) will instruct you to use `edit_file` to update `memory-bank/activeContext.md`.
    b.  This update should summarize:
        *   Key decisions made in the current mode.
        *   Status of the current task.
        *   Critical context to pass to the next mode.
        *   The recommended next mode and primary task/focus for it.
        *   Example section in `activeContext.md`:
            ```markdown
            ## Mode Transition Prepared
            - From Mode: PLAN
            - To Mode: CREATIVE
            - Task: Implement User Authentication
            - Key Output from PLAN: Detailed sub-tasks in `tasks.md`; `auth_module` flagged for creative design.
            - Focus for CREATIVE: Design `auth_module` architecture.
            ```
2.  **When New Mode Starts:**
    a.  The new mode's main custom prompt will instruct you to `fetch_rules` for its primary orchestrating `.mdc` file.
    b.  That orchestrating `.mdc` file will (as one of its first steps) instruct you to `read_file` `memory-bank/activeContext.md` to understand the incoming context, task, and focus.

## 📊 CONTEXT TRANSITION DOCUMENT (Content for `activeContext.md` update)
When preparing for a mode transition, ensure `memory-bank/activeContext.md` (updated via `edit_file`) contains:
```markdown
# MODE TRANSITION PREPARED: [Current Mode] → [Target Mode]

## Task Context
- Current Task: [Task name/description from tasks.md]
- Complexity Level: [Level 1-4 from activeContext.md/tasks.md]
- Current Phase within Task: [e.g., Planning Complete, Ready for Design]
- Overall Progress: [Summary from progress.md]

## Key Decisions/Outputs from [Current Mode]
- [Decision/Output 1]: [Brief summary]
- [Decision/Output 2]: [Brief summary]

## Critical Context for [Target Mode]
- [Context item 1 relevant to target mode]
- [Context item 2 relevant to target mode]

## Focus for [Target Mode]
- Primary Goal: [e.g., Design UI for checkout page]
- Key Files/Documents to Consult: [e.g., `tasks.md` for sub-tasks, `creative-checkout-spec.md`]
```

## 🔍 MODE-SPECIFIC TRANSITION HANDLERS (Examples of `activeContext.md` updates)

*   **VAN → PLAN Transition (AI updates `activeContext.md` at end of VAN):**
    ```markdown
    ## Mode Transition Prepared
    - From Mode: VAN
    - To Mode: PLAN
    - Task: [Initial Project Analysis & Setup from tasks.md]
    - Key Output from VAN: Project Complexity Level [X] determined; Initial `projectbrief.md` and other context files created/updated.
    - Focus for PLAN: Develop detailed plan for [Main project goal or first major feature].
    ```
*   **PLAN → CREATIVE Transition (AI updates `activeContext.md` at end of PLAN):**
    ```markdown
    ## Mode Transition Prepared
    - From Mode: PLAN
    - To Mode: CREATIVE
    - Task: [Feature Name from tasks.md]
    - Key Output from PLAN: Detailed feature plan in `tasks.md`; Components [A, B] flagged for creative design.
    - Focus for CREATIVE: Execute creative design phase for components [A, B].
    ```
*   (Similar structured updates for other transitions)

**Key Principle:** The `activeContext.md` file, managed by `edit_file`, serves as the primary "handover document" between modes. Hierarchical rule loading (fetching specific `.mdc`s) is managed by the instructions within each mode's orchestrator.
```

---

**9. File: `.cursor/rules/isolation_rules/Core/optimization-integration.mdc`**
```markdown
---
description: Design overview of Memory Bank optimization strategies. Primarily for human reference and high-level AI understanding of system goals.
globs: **/Core/optimization-integration.mdc
alwaysApply: false # This is a high-level design document.
---

# MEMORY BANK OPTIMIZATION INTEGRATION (Design Overview)

> **TL;DR:** This document describes the integrated optimization strategies designed into the Memory Bank system, such as hierarchical rule loading and adaptive complexity. The AI enacts these by following specific instructions from other rule files.

## 🔄 OPTIMIZATION INTEGRATION FLOW (Conceptual for AI)
*(Mermaid diagram for human reference)*
**AI's Role:** You don't "run" this integration flow. You achieve these optimizations by:
1.  **Hierarchical Rule Loading:** Following `fetch_rules` instructions in main prompts and other `.mdc` files to load only necessary rules.
2.  **Adaptive Complexity Model:** Following the `Core/complexity-decision-tree.mdc` rule when in VAN mode, and then loading level-specific rules as directed.
3.  **Dynamic Context Management:** Primarily by diligently reading from and updating (via `edit_file`) `memory-bank/activeContext.md`, `tasks.md`, and `progress.md`.
4.  **Transition Optimization:** Following the process outlined in `Core/mode-transition-optimization.mdc` (i.e., updating `activeContext.md` before a mode switch).
5.  **Creative Phase Optimization:** Using the `Phases/CreativePhase/optimized-creative-template.mdc` when in CREATIVE mode.

## 📋 OPTIMIZATION COMPONENT REGISTRY (Human Reference)
*(JavaScript pseudocode for human understanding of the system's design intent)*

## 🔄 OPTIMIZATION INITIALIZATION SEQUENCE (Human Reference)
*(Mermaid sequence diagram for human reference)*

## 🔍 OPTIMIZATION CONFIGURATION (Human Reference)
*(JavaScript pseudocode for human understanding of the system's design intent)*

**AI Action:** The principles described (e.g., `enableHierarchicalLoading`, `enableProgressiveDocumentation`) are *implemented by you following the specific instructions* in other rule files. For example, "progressive documentation" is achieved when the CREATIVE mode instructs you to use the `optimized-creative-template.mdc`.

## 📈 OPTIMIZATION METRICS (For Human Review / Advanced AI Reflection)
If asked to reflect on efficiency, you might consider:
*   Were rules loaded only when needed?
*   Was documentation generated progressively?
*   Were Memory Bank files updated efficiently?

**This document primarily serves to explain the *design goals* of the Memory Bank's optimization. Your role is to execute the specific, actionable instructions found in other `.mdc` files which collectively achieve these optimizations.**
```

---

**10. File: `.cursor/rules/isolation_rules/Core/platform-awareness.mdc`**
```markdown
---
description: Core guidelines for platform-aware command execution, especially for `run_terminal_cmd`.
globs: **/Core/platform-awareness.mdc
alwaysApply: true # Fundamental principle for terminal commands.
---

# PLATFORM AWARENESS SYSTEM

> **TL;DR:** This rule guides you to detect the operating system and adapt `run_terminal_cmd` commands accordingly (e.g., path separators, specific command names) to ensure cross-platform compatibility.

## 🔍 PLATFORM DETECTION PROCESS (Conceptual for AI)
*(Mermaid diagram for human reference)*
**AI Action (Primarily during VAN mode, or if executing an unknown command):**

1.  **Assume Default or Ask:**
    *   You can assume a common default (e.g., Linux/bash syntax for `mkdir -p`).
    *   Or, if unsure, **ask the user**: "What is the current operating system (Windows, macOS, Linux) and primary shell (PowerShell, Bash, Zsh)?"
2.  **Store/Recall Information:** Once known (or if provided in `techContext.md`), try to remember this for subsequent `run_terminal_cmd` calls in the session.
3.  **Adapt Commands for `run_terminal_cmd`:**
    *   **Path Separators:** Use `/` for Linux/macOS, `\` for Windows.
    *   **Directory Creation:**
        *   Linux/macOS: `mkdir -p path/to/directory`
        *   Windows PowerShell: `mkdir path\to\directory` or `New-Item -ItemType Directory -Path path\to\directory`
    *   **File Creation (Empty - prefer `edit_file` for content):**
        *   Linux/macOS: `touch path/to/file.ext`
        *   Windows PowerShell: `New-Item -ItemType File -Path path\to\file.ext`
    *   **Listing Files:**
        *   Linux/macOS: `ls -la`
        *   Windows PowerShell: `Get-ChildItem` or `dir`
    *   **Chaining Commands:**
        *   Linux/macOS (bash/zsh): `command1 && command2` (sequential success), `command1 ; command2` (sequential)
        *   Windows PowerShell: `command1; command2` (sequential), `command1 && command2` (often works but behavior can vary, `If ($LASTEXITCODE -eq 0) { command2 }` is more robust for conditional).
4.  **Report Chosen Command:** When using `run_terminal_cmd`, state the command you are about to execute, explicitly noting if it's adapted for a presumed platform. Example: "I will now run the following PowerShell command to create the directory: `mkdir memory-bank\archive`."

## 📝 PLATFORM VERIFICATION CHECKLIST (AI Self-Correction)
Before executing a `run_terminal_cmd`:
- Have I considered the likely OS?
- Is the path separator correct for that OS?
- Is the command name and syntax appropriate for that OS/shell?
- If unsure, have I asked the user or stated my assumption?

**This rule is a guiding principle. The actual detection is often implicit or through user confirmation. The key is to be *aware* of potential differences and adapt `run_terminal_cmd` usage.**
```

This completes the refinement of the Core rules. The next step would be to review and refine the main mode orchestrator maps (`visual-maps/*-mode-map.mdc`) to ensure they correctly `fetch_rules` these core rules and other relevant sub-rules, and then proceed to level-specific and phase-specific rules.

================
File: cursor-memory-bank/mdc rules/rules-core.txt
================
This file is a merged representation of a subset of the codebase, containing specifically included files, combined into a single document by Repomix.

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: .cursor/rules/isolation_rules/Core
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)


================================================================
Directory Structure
================================================================
.cursor/rules/isolation_rules/Core/command-execution.mdc
.cursor/rules/isolation_rules/Core/complexity-decision-tree.mdc
.cursor/rules/isolation_rules/Core/creative-phase-enforcement.mdc
.cursor/rules/isolation_rules/Core/creative-phase-metrics.mdc
.cursor/rules/isolation_rules/Core/file-verification.mdc
.cursor/rules/isolation_rules/Core/hierarchical-rule-loading.mdc
.cursor/rules/isolation_rules/Core/memory-bank-paths.mdc
.cursor/rules/isolation_rules/Core/mode-transition-optimization.mdc
.cursor/rules/isolation_rules/Core/optimization-integration.mdc
.cursor/rules/isolation_rules/Core/platform-awareness.mdc

================================================================
Files
================================================================

================
File: .cursor/rules/isolation_rules/Core/command-execution.mdc
================
---
description: Command execution guidelines for isolation-focused Memory Bank
globs: command-execution.mdc
alwaysApply: false
---

# COMMAND EXECUTION SYSTEM

> **TL;DR:** This system provides guidelines for efficient command execution, balancing clarity and token optimization through appropriate command chaining, with proper documentation of commands and results.

## 🔍 COMMAND EFFICIENCY WORKFLOW

```mermaid
graph TD
    Start["Command<br>Planning"] --> Analyze["Analyze Command<br>Requirements"]
    Analyze --> Balance["Balance Clarity<br>vs. Efficiency"]
    Balance --> Complexity{"Command<br>Complexity?"}
    
    Complexity -->|"Simple"| Single["Execute<br>Single Command"]
    Complexity -->|"Moderate"| Chain["Use Efficient<br>Command Chaining"]
    Complexity -->|"Complex"| Group["Group Into<br>Logical Steps"]
    
    Single & Chain & Group --> Verify["Verify<br>Results"]
    Verify --> Document["Document<br>Command & Result"]
    Document --> Next["Next<br>Command"]
```

## 📋 COMMAND CHAINING GUIDELINES

```mermaid
graph TD
    Command["Command<br>Execution"] --> ChainApprop{"Is Chaining<br>Appropriate?"}
    
    ChainApprop -->|"Yes"| ChainTypes["Chain<br>Types"]
    ChainApprop -->|"No"| SingleCmd["Use Single<br>Commands"]
    
    ChainTypes --> Sequential["Sequential Operations<br>cmd1 && cmd2"]
    ChainTypes --> Conditional["Conditional Operations<br>cmd1 || cmd2"]
    ChainTypes --> Piping["Piping<br>cmd1 | cmd2"]
    ChainTypes --> Grouping["Command Grouping<br>(cmd1; cmd2)"]
    
    Sequential & Conditional & Piping & Grouping --> Doc["Document<br>Commands & Results"]
```

## 🚦 DIRECTORY VERIFICATION WORKFLOW

```mermaid
graph TD
    Command["Command<br>Execution"] --> DirCheck["Check Current<br>Directory"]
    DirCheck --> ProjectRoot{"In Project<br>Root?"}
    
    ProjectRoot -->|"Yes"| Execute["Execute<br>Command"]
    ProjectRoot -->|"No"| Locate["Locate<br>Project Root"]
    
    Locate --> Found{"Project Root<br>Found?"}
    Found -->|"Yes"| Navigate["Navigate to<br>Project Root"]
    Found -->|"No"| Error["Error: Cannot<br>Find Project Root"]
    
    Navigate --> Execute
    Execute --> Verify["Verify<br>Results"]
```

## 📋 DIRECTORY VERIFICATION CHECKLIST

Before executing any npm or build command:

| Step | Windows (PowerShell) | Unix/Linux/Mac | Purpose |
|------|----------------------|----------------|---------|
| **Check package.json** | `Test-Path package.json` | `ls package.json` | Verify current directory is project root |
| **Check for parent directory** | `Test-Path "*/package.json"` | `find . -maxdepth 2 -name package.json` | Find potential project directories |
| **Navigate to project root** | `cd [project-dir]` | `cd [project-dir]` | Move to correct directory before executing commands |

## 📋 REACT-SPECIFIC COMMAND GUIDELINES

For React applications, follow these strict guidelines:

| Command | Correct Usage | Incorrect Usage | Notes |
|---------|---------------|----------------|-------|
| **npm start** | `cd [project-root] && npm start` | `npm start` (from parent dir) | Must execute from directory with package.json |
| **npm run build** | `cd [project-root] && npm run build` | `cd [parent-dir] && npm run build` | Must execute from directory with package.json |
| **npm install** | `cd [project-root] && npm install [pkg]` | `npm install [pkg]` (wrong dir) | Dependencies installed to nearest package.json |
| **npm create** | `npm create vite@latest my-app -- --template react` | Manually configuring webpack | Use standard tools for project creation |

## 🔄 COMMAND CHAINING PATTERNS

Effective command chaining patterns include:

| Pattern | Format | Examples | Use Case |
|---------|--------|----------|----------|
| **Sequential** | `cmd1 && cmd2` | `mkdir dir && cd dir` | Commands that should run in sequence, second only if first succeeds |
| **Conditional** | `cmd1 || cmd2` | `test -f file.txt || touch file.txt` | Fallback commands, second only if first fails |
| **Piping** | `cmd1 \| cmd2` | `grep "pattern" file.txt \| wc -l` | Pass output of first command as input to second |
| **Background** | `cmd &` | `npm start &` | Run command in background |
| **Grouping** | `(cmd1; cmd2)` | `(echo "Start"; npm test; echo "End")` | Group commands to run as a unit |

## 📋 COMMAND DOCUMENTATION TEMPLATE

```
## Command Execution: [Purpose]

### Command
```
[actual command or chain]
```

### Result
```
[command output]
```

### Effect
[Brief description of what changed in the system]

### Next Steps
[What needs to be done next]
```

## 🔍 PLATFORM-SPECIFIC CONSIDERATIONS

```mermaid
graph TD
    Platform["Platform<br>Detection"] --> Windows["Windows<br>Commands"]
    Platform --> Unix["Unix/Linux/Mac<br>Commands"]
    
    Windows --> WinAdapt["Windows Command<br>Adaptations"]
    Unix --> UnixAdapt["Unix Command<br>Adaptations"]
    
    WinAdapt --> WinChain["Windows Chaining:<br>Commands separated by &"]
    UnixAdapt --> UnixChain["Unix Chaining:<br>Commands separated by ;"]
    
    WinChain & UnixChain --> Execute["Execute<br>Platform-Specific<br>Commands"]
```

## 📋 COMMAND EFFICIENCY EXAMPLES

Examples of efficient command usage:

| Inefficient | Efficient | Explanation |
|-------------|-----------|-------------|
| `mkdir dir`<br>`cd dir`<br>`npm init -y` | `mkdir dir && cd dir && npm init -y` | Combines related sequential operations |
| `ls`<br>`grep "\.js$"` | `ls \| grep "\.js$"` | Pipes output of first command to second |
| `test -f file.txt`<br>`if not exists, touch file.txt` | `test -f file.txt \|\| touch file.txt` | Creates file only if it doesn't exist |
| `mkdir dir1`<br>`mkdir dir2`<br>`mkdir dir3` | `mkdir dir1 dir2 dir3` | Uses command's built-in multiple argument capability |
| `npm install pkg1`<br>`npm install pkg2` | `npm install pkg1 pkg2` | Installs multiple packages in one command |

## 📋 REACT PROJECT INITIALIZATION STANDARDS

Always use these standard approaches for React project creation:

| Approach | Command | Benefits | Avoids |
|----------|---------|----------|--------|
| **Create React App** | `npx create-react-app my-app` | Preconfigured webpack & babel | Manual configuration errors |
| **Create React App w/TypeScript** | `npx create-react-app my-app --template typescript` | Type safety + preconfigured | Inconsistent module systems |
| **Vite** | `npm create vite@latest my-app -- --template react` | Faster build times | Complex webpack setups |
| **Next.js** | `npx create-next-app@latest my-app` | SSR support | Module system conflicts |

## ⚠️ ERROR HANDLING WORKFLOW

```mermaid
sequenceDiagram
    participant User
    participant AI
    participant System
    
    AI->>System: Execute Command
    System->>AI: Return Result
    
    alt Success
        AI->>AI: Verify Expected Result
        AI->>User: Report Success
    else Error
        AI->>AI: Analyze Error Message
        AI->>AI: Identify Likely Cause
        AI->>User: Explain Error & Cause
        AI->>User: Suggest Corrective Action
        User->>AI: Approve Correction
        AI->>System: Execute Corrected Command
    end
```

## 📋 COMMAND RESULT VERIFICATION

After command execution, verify:

```mermaid
graph TD
    Execute["Execute<br>Command"] --> Check{"Check<br>Result"}
    
    Check -->|"Success"| Verify["Verify Expected<br>Outcome"]
    Check -->|"Error"| Analyze["Analyze<br>Error"]
    
    Verify -->|"Expected"| Document["Document<br>Success"]
    Verify -->|"Unexpected"| Investigate["Investigate<br>Unexpected Result"]
    
    Analyze --> Diagnose["Diagnose<br>Error Cause"]
    Diagnose --> Correct["Propose<br>Correction"]
    
    Document & Investigate & Correct --> Next["Next Step<br>in Process"]
```

## 📝 COMMAND EXECUTION CHECKLIST

```
✓ COMMAND EXECUTION CHECKLIST
- Command purpose clearly identified? [YES/NO]
- Appropriate balance of clarity vs. efficiency? [YES/NO]
- Platform-specific considerations addressed? [YES/NO]
- Command documented with results? [YES/NO]
- Outcome verified against expectations? [YES/NO]
- Errors properly handled (if any)? [YES/NO/NA]
- For npm/build commands: Executed from project root? [YES/NO/NA]
- For React projects: Using standard tooling? [YES/NO/NA]

→ If all YES: Command execution complete
→ If any NO: Address missing elements
```

## 🚨 COMMAND EXECUTION WARNINGS

Avoid these common command issues:

```mermaid
graph TD
    Warning["Command<br>Warnings"] --> W1["Excessive<br>Verbosity"]
    Warning --> W2["Insufficient<br>Error Handling"]
    Warning --> W3["Unnecessary<br>Complexity"]
    Warning --> W4["Destructive<br>Operations Without<br>Confirmation"]
    Warning --> W5["Wrong Directory<br>Execution"]
    
    W1 --> S1["Use flags to reduce<br>unnecessary output"]
    W2 --> S2["Include error handling<br>in command chains"]
    W3 --> S3["Prefer built-in<br>command capabilities"]
    W4 --> S4["Show confirmation<br>before destructive actions"]
    W5 --> S5["Verify directory before<br>npm/build commands"]
```

================
File: .cursor/rules/isolation_rules/Core/complexity-decision-tree.mdc
================
---
description: complexity decision tree
globs: complexity-decision-tree.mdc
alwaysApply: false
---
# TASK COMPLEXITY DETERMINATION

> **TL;DR:** This document helps determine the appropriate complexity level (1-4) for any task. Use the decision tree and indicators to select the right process level, then load the corresponding process map.

## 🌳 COMPLEXITY DECISION TREE

```mermaid
graph TD
    Start["New Task"] --> Q1{"Bug fix or<br>error correction?"}
    Q1 -->|Yes| Q1a{"Affects single<br>component?"}
    Q1a -->|Yes| L1["Level 1:<br>Quick Bug Fix"]
    Q1a -->|No| Q1b{"Affects multiple<br>components?"}
    Q1b -->|Yes| L2["Level 2:<br>Simple Enhancement"]
    Q1b -->|No| Q1c{"Affects system<br>architecture?"}
    Q1c -->|Yes| L3["Level 3:<br>Intermediate Feature"]
    Q1c -->|No| L2
    
    Q1 -->|No| Q2{"Adding small<br>feature or<br>enhancement?"}
    Q2 -->|Yes| Q2a{"Self-contained<br>change?"}
    Q2a -->|Yes| L2
    Q2a -->|No| Q2b{"Affects multiple<br>components?"}
    Q2b -->|Yes| L3
    Q2b -->|No| L2
    
    Q2 -->|No| Q3{"Complete feature<br>requiring multiple<br>components?"}
    Q3 -->|Yes| Q3a{"Architectural<br>implications?"}
    Q3a -->|Yes| L4["Level 4:<br>Complex System"]
    Q3a -->|No| L3
    
    Q3 -->|No| Q4{"System-wide or<br>architectural<br>change?"}
    Q4 -->|Yes| L4
    Q4 -->|No| L3
    
    L1 --> LoadL1["Load Level 1 Map"]
    L2 --> LoadL2["Load Level 2 Map"]
    L3 --> LoadL3["Load Level 3 Map"]
    L4 --> LoadL4["Load Level 4 Map"]
```

## 📊 COMPLEXITY LEVEL INDICATORS

Use these indicators to help determine task complexity:

### Level 1: Quick Bug Fix
- **Keywords**: "fix", "broken", "not working", "issue", "bug", "error", "crash"
- **Scope**: Single component or UI element
- **Duration**: Can be completed quickly (minutes to hours)
- **Risk**: Low, isolated changes
- **Examples**:
  - Fix button not working
  - Correct styling issue
  - Fix validation error
  - Resolve broken link
  - Fix typo or text issue

### Level 2: Simple Enhancement
- **Keywords**: "add", "improve", "update", "change", "enhance", "modify"
- **Scope**: Single component or subsystem
- **Duration**: Hours to 1-2 days
- **Risk**: Moderate, contained to specific area
- **Examples**:
  - Add form field
  - Improve validation
  - Update styling
  - Add simple feature
  - Change text content
  - Enhance existing component

### Level 3: Intermediate Feature
- **Keywords**: "implement", "create", "develop", "build", "feature"
- **Scope**: Multiple components, complete feature
- **Duration**: Days to 1-2 weeks
- **Risk**: Significant, affects multiple areas
- **Examples**:
  - Implement user authentication
  - Create dashboard
  - Develop search functionality
  - Build user profile system
  - Implement data visualization
  - Create complex form system

### Level 4: Complex System
- **Keywords**: "system", "architecture", "redesign", "integration", "framework"
- **Scope**: Multiple subsystems or entire application
- **Duration**: Weeks to months
- **Risk**: High, architectural implications
- **Examples**:
  - Implement authentication system
  - Build payment processing framework
  - Create microservice architecture
  - Implement database migration system
  - Develop real-time communication system
  - Create multi-tenant architecture

## 🔍 COMPLEXITY ASSESSMENT QUESTIONS

Answer these questions to determine complexity:

1. **Scope Impact**
   - Does it affect a single component or multiple?
   - Are there system-wide implications?
   - How many files will need to be modified?

2. **Design Decisions**
   - Are complex design decisions required?
   - Will it require creative phases for design?
   - Are there architectural considerations?

3. **Risk Assessment**
   - What happens if it fails?
   - Are there security implications?
   - Will it affect critical functionality?

4. **Implementation Effort**
   - How long will it take to implement?
   - Does it require specialized knowledge?
   - Is extensive testing needed?

## 📊 KEYWORD ANALYSIS TABLE

| Keyword | Likely Level | Notes |
|---------|--------------|-------|
| "Fix" | Level 1 | Unless system-wide |
| "Bug" | Level 1 | Unless multiple components |
| "Error" | Level 1 | Unless architectural |
| "Add" | Level 2 | Unless complex feature |
| "Update" | Level 2 | Unless architectural |
| "Improve" | Level 2 | Unless system-wide |
| "Implement" | Level 3 | Complex components |
| "Create" | Level 3 | New functionality |
| "Develop" | Level 3 | Significant scope |
| "System" | Level 4 | Architectural implications |
| "Architecture" | Level 4 | Major structural changes |
| "Framework" | Level 4 | Core infrastructure |

## 🔄 COMPLEXITY ESCALATION

If during a task you discover it's more complex than initially determined:

```
⚠️ TASK ESCALATION NEEDED
Current Level: Level [X]
Recommended Level: Level [Y]
Reason: [Brief explanation]

Would you like me to escalate this task to Level [Y]?
```

If approved, switch to the appropriate higher-level process map.

## 🎯 PROCESS SELECTION

After determining complexity, load the appropriate process map:

| Level | Description | Process Map |
|-------|-------------|-------------|
| 1 | Quick Bug Fix | [Level 1 Map](mdc:.cursor/rules/visual-maps/level1-map.mdc) |
| 2 | Simple Enhancement | [Level 2 Map](mdc:.cursor/rules/visual-maps/level2-map.mdc) |
| 3 | Intermediate Feature | [Level 3 Map](mdc:.cursor/rules/visual-maps/level3-map.mdc) |
| 4 | Complex System | [Level 4 Map](mdc:.cursor/rules/visual-maps/level4-map.mdc) |

## 📝 COMPLEXITY DETERMINATION TEMPLATE

Use this template to document complexity determination:

```
## COMPLEXITY DETERMINATION

Task: [Task description]

Assessment:
- Scope: [Single component/Multiple components/System-wide]
- Design decisions: [Simple/Moderate/Complex]
- Risk: [Low/Moderate/High]
- Implementation effort: [Low/Moderate/High]

Keywords identified: [List relevant keywords]

Determination: Level [1/2/3/4] - [Quick Bug Fix/Simple Enhancement/Intermediate Feature/Complex System]

Loading process map: [Level X Map]
```

================
File: .cursor/rules/isolation_rules/Core/creative-phase-enforcement.mdc
================
---
description: creative phase enforcement 
globs: creative-phase-enforcement.md
alwaysApply: false
---

# CREATIVE PHASE ENFORCEMENT

> **TL;DR:** This document implements strict enforcement of creative phase requirements for Level 3-4 tasks, ensuring all design decisions are properly documented and verified before implementation can proceed.

## 🔍 ENFORCEMENT WORKFLOW

```mermaid
graph TD
    Start["Task Start"] --> Check{"Level 3-4<br>Task?"}
    Check -->|Yes| Analyze["Analyze Design<br>Decision Points"]
    Check -->|No| Optional["Creative Phase<br>Optional"]
    
    Analyze --> Decision{"Design Decisions<br>Required?"}
    Decision -->|Yes| Gate["🚨 IMPLEMENTATION<br>BLOCKED"]
    Decision -->|No| Allow["Allow<br>Implementation"]
    
    Gate --> Creative["Enter Creative<br>Phase"]
    Creative --> Verify{"All Decisions<br>Documented?"}
    Verify -->|No| Return["Return to<br>Creative Phase"]
    Verify -->|Yes| Proceed["Allow<br>Implementation"]
    
    style Start fill:#4da6ff,stroke:#0066cc,color:white
    style Check fill:#ffa64d,stroke:#cc7a30,color:white
    style Analyze fill:#4dbb5f,stroke:#36873f,color:white
    style Gate fill:#d94dbb,stroke:#a3378a,color:white
    style Creative fill:#4dbbbb,stroke:#368787,color:white
    style Verify fill:#d971ff,stroke:#a33bc2,color:white
```

## 🚨 ENFORCEMENT GATES

```mermaid
graph TD
    subgraph "CREATIVE PHASE GATES"
    G1["Entry Gate<br>Verify Requirements"]
    G2["Process Gate<br>Verify Progress"]
    G3["Exit Gate<br>Verify Completion"]
    end
    
    G1 --> G2 --> G3
    
    style G1 fill:#4dbb5f,stroke:#36873f,color:white
    style G2 fill:#ffa64d,stroke:#cc7a30,color:white
    style G3 fill:#d94dbb,stroke:#a3378a,color:white
```

## 📋 ENFORCEMENT CHECKLIST

```markdown
## Entry Gate Verification
- [ ] Task complexity is Level 3-4
- [ ] Design decisions identified
- [ ] Creative phase requirements documented
- [ ] Required participants notified

## Process Gate Verification
- [ ] All options being considered
- [ ] Pros/cons documented
- [ ] Technical constraints identified
- [ ] Implementation impacts assessed

## Exit Gate Verification
- [ ] All decisions documented
- [ ] Rationale provided for choices
- [ ] Implementation plan outlined
- [ ] Verification against requirements
```

## 🚨 IMPLEMENTATION BLOCK NOTICE

When a creative phase is required but not completed:

```
🚨 IMPLEMENTATION BLOCKED
Creative phases MUST be completed before implementation.

Required Creative Phases:
- [ ] [Creative Phase 1]
- [ ] [Creative Phase 2]
- [ ] [Creative Phase 3]

⛔ This is a HARD BLOCK
Implementation CANNOT proceed until all creative phases are completed.
Type "PHASE.REVIEW" to begin creative phase review.
```

## ✅ VERIFICATION PROTOCOL

```mermaid
graph TD
    subgraph "VERIFICATION STEPS"
    V1["1. Requirements<br>Check"]
    V2["2. Documentation<br>Review"]
    V3["3. Decision<br>Validation"]
    V4["4. Implementation<br>Readiness"]
    end
    
    V1 --> V2 --> V3 --> V4
    
    style V1 fill:#4dbb5f,stroke:#36873f,color:white
    style V2 fill:#ffa64d,stroke:#cc7a30,color:white
    style V3 fill:#d94dbb,stroke:#a3378a,color:white
    style V4 fill:#4dbbbb,stroke:#368787,color:white
```

## 🔄 CREATIVE PHASE MARKERS

Use these markers to clearly indicate creative phase boundaries:

```markdown
🎨🎨🎨 ENTERING CREATIVE PHASE: [TYPE] 🎨🎨🎨
Focus: [Specific component/feature]
Objective: [Clear goal of this creative phase]
Requirements: [List of requirements]

[Creative phase content]

🎨 CREATIVE CHECKPOINT: [Milestone]
- Progress: [Status]
- Decisions: [List]
- Next steps: [Plan]

🎨🎨🎨 EXITING CREATIVE PHASE 🎨🎨🎨
Summary: [Brief description]
Key Decisions: [List]
Next Steps: [Implementation plan]
```

## 🔄 DOCUMENT MANAGEMENT

```mermaid
graph TD
    Current["Current Document"] --> Active["Active:<br>- creative-phase-enforcement.md"]
    Current --> Related["Related:<br>- creative-phase-architecture.md<br>- task-tracking-intermediate.md"]
    
    style Current fill:#4da6ff,stroke:#0066cc,color:white
    style Active fill:#4dbb5f,stroke:#36873f,color:white
    style Related fill:#ffa64d,stroke:#cc7a30,color:white
```

================
File: .cursor/rules/isolation_rules/Core/creative-phase-metrics.mdc
================
---
description: creative phase metrics
globs: creative-phase-metrics.md
alwaysApply: false
---



# CREATIVE PHASE METRICS

> **TL;DR:** This document defines comprehensive quality metrics and measurement criteria for creative phases, ensuring that design decisions meet required standards and are properly documented.

## 📊 METRICS OVERVIEW

```mermaid
graph TD
    subgraph "CREATIVE PHASE METRICS"
    M1["Documentation<br>Quality"]
    M2["Decision<br>Coverage"]
    M3["Option<br>Analysis"]
    M4["Impact<br>Assessment"]
    M5["Verification<br>Score"]
    end
    
    M1 --> Score["Quality<br>Score"]
    M2 --> Score
    M3 --> Score
    M4 --> Score
    M5 --> Score
    
    style M1 fill:#4dbb5f,stroke:#36873f,color:white
    style M2 fill:#ffa64d,stroke:#cc7a30,color:white
    style M3 fill:#d94dbb,stroke:#a3378a,color:white
    style M4 fill:#4dbbbb,stroke:#368787,color:white
    style M5 fill:#d971ff,stroke:#a33bc2,color:white
    style Score fill:#ff71c2,stroke:#c23b8a,color:white
```

## 📋 QUALITY METRICS SCORECARD

```markdown
# Creative Phase Quality Assessment

## 1. Documentation Quality [0-10]
- [ ] Clear problem statement (2 points)
- [ ] Well-defined objectives (2 points)
- [ ] Comprehensive requirements list (2 points)
- [ ] Proper formatting and structure (2 points)
- [ ] Cross-references to related documents (2 points)

## 2. Decision Coverage [0-10]
- [ ] All required decisions identified (2 points)
- [ ] Each decision point documented (2 points)
- [ ] Dependencies mapped (2 points)
- [ ] Impact analysis included (2 points)
- [ ] Future considerations noted (2 points)

## 3. Option Analysis [0-10]
- [ ] Multiple options considered (2 points)
- [ ] Pros/cons documented (2 points)
- [ ] Technical feasibility assessed (2 points)
- [ ] Resource requirements estimated (2 points)
- [ ] Risk factors identified (2 points)

## 4. Impact Assessment [0-10]
- [ ] System impact documented (2 points)
- [ ] Performance implications assessed (2 points)
- [ ] Security considerations addressed (2 points)
- [ ] Maintenance impact evaluated (2 points)
- [ ] Cost implications analyzed (2 points)

## 5. Verification Score [0-10]
- [ ] Requirements traced (2 points)
- [ ] Constraints validated (2 points)
- [ ] Test scenarios defined (2 points)
- [ ] Review feedback incorporated (2 points)
- [ ] Final verification completed (2 points)

Total Score: [Sum of all categories] / 50
Minimum Required Score: 40/50 (80%)
```

## 📈 QUALITY THRESHOLDS

```mermaid
graph TD
    subgraph "QUALITY GATES"
    T1["Minimum<br>40/50 (80%)"]
    T2["Target<br>45/50 (90%)"]
    T3["Excellent<br>48/50 (96%)"]
    end
    
    Score["Quality<br>Score"] --> Check{"Meets<br>Threshold?"}
    Check -->|"< 80%"| Block["⛔ BLOCKED<br>Improvements Required"]
    Check -->|"≥ 80%"| Pass["✓ PASSED<br>Can Proceed"]
    
    style T1 fill:#4dbb5f,stroke:#36873f,color:white
    style T2 fill:#ffa64d,stroke:#cc7a30,color:white
    style T3 fill:#d94dbb,stroke:#a3378a,color:white
    style Score fill:#4dbbbb,stroke:#368787,color:white
    style Check fill:#d971ff,stroke:#a33bc2,color:white
```

## 🎯 METRIC EVALUATION PROCESS

```mermaid
graph TD
    Start["Start<br>Evaluation"] --> Doc["1. Score<br>Documentation"]
    Doc --> Dec["2. Assess<br>Decisions"]
    Dec --> Opt["3. Review<br>Options"]
    Opt --> Imp["4. Evaluate<br>Impact"]
    Imp --> Ver["5. Verify<br>Completeness"]
    Ver --> Total["Calculate<br>Total Score"]
    Total --> Check{"Meets<br>Threshold?"}
    Check -->|No| Return["Return for<br>Improvements"]
    Check -->|Yes| Proceed["Proceed to<br>Next Phase"]
    
    style Start fill:#4da6ff,stroke:#0066cc,color:white
    style Doc fill:#ffa64d,stroke:#cc7a30,color:white
    style Dec fill:#4dbb5f,stroke:#36873f,color:white
    style Opt fill:#d94dbb,stroke:#a3378a,color:white
    style Imp fill:#4dbbbb,stroke:#368787,color:white
    style Ver fill:#d971ff,stroke:#a33bc2,color:white
```

## 📊 IMPROVEMENT RECOMMENDATIONS

For scores below threshold:

```markdown
## Documentation Quality Improvements
- Add clear problem statements
- Include specific objectives
- List all requirements
- Improve formatting
- Add cross-references

## Decision Coverage Improvements
- Identify missing decisions
- Document all decision points
- Map dependencies
- Add impact analysis
- Consider future implications

## Option Analysis Improvements
- Consider more alternatives
- Detail pros/cons
- Assess technical feasibility
- Estimate resource needs
- Identify risks

## Impact Assessment Improvements
- Document system impact
- Assess performance
- Address security
- Evaluate maintenance
- Analyze costs

## Verification Improvements
- Trace requirements
- Validate constraints
- Define test scenarios
- Incorporate feedback
- Complete verification
```

## ✅ METRICS VERIFICATION CHECKLIST

```markdown
## Pre-Review Verification
- [ ] All sections scored
- [ ] Calculations verified
- [ ] Supporting evidence attached
- [ ] Improvement areas identified
- [ ] Review feedback incorporated

## Final Metrics Verification
- [ ] Minimum score achieved
- [ ] All categories passed
- [ ] Documentation complete
- [ ] Improvements addressed
- [ ] Final approval obtained
```

## 🔄 DOCUMENT MANAGEMENT

```mermaid
graph TD
    Current["Current Document"] --> Active["Active:<br>- creative-phase-metrics.md"]
    Current --> Related["Related:<br>- creative-phase-enforcement.md<br>- creative-phase-architecture.md"]
    
    style Current fill:#4da6ff,stroke:#0066cc,color:white
    style Active fill:#4dbb5f,stroke:#36873f,color:white
    style Related fill:#ffa64d,stroke:#cc7a30,color:white
```

================
File: .cursor/rules/isolation_rules/Core/file-verification.mdc
================
---
description: Optimized file verification
globs: file-verification.mdc
alwaysApply: false
---
# OPTIMIZED FILE VERIFICATION SYSTEM

> **TL;DR:** This system efficiently verifies and creates required Memory Bank file structures using batch operations and platform-optimized commands.

## 🔍 OPTIMIZED FILE VERIFICATION WORKFLOW

```mermaid
graph TD
    Start["Start File<br>Verification"] --> VerifyAll["Verify All<br>Required Components"]
    VerifyAll --> MissingCheck{"Missing<br>Components?"}
    MissingCheck -->|"Yes"| BatchCreate["Batch Create<br>All Missing Items"]
    MissingCheck -->|"No"| Complete["Verification<br>Complete"]
    BatchCreate --> Report["Generate<br>Verification Report"]
    Report --> Complete
```

## 📋 OPTIMIZED DIRECTORY CREATION

```mermaid
graph TD
    Start["Directory<br>Creation"] --> DetectOS["Detect Operating<br>System"]
    DetectOS -->|"Windows"| WinCmd["Batch Create<br>Windows Command"]
    DetectOS -->|"Mac/Linux"| UnixCmd["Batch Create<br>Unix Command"]
    WinCmd & UnixCmd --> Verify["Verify<br>Creation Success"]
    Verify --> Complete["Directory Setup<br>Complete"]
```

### Platform-Specific Commands

#### Windows (PowerShell)
```powershell
# Create all directories in one command
mkdir memory-bank, docs, docs\archive -ErrorAction SilentlyContinue

# Create all required files
$files = @(".cursorrules", "tasks.md", 
           "memory-bank\projectbrief.md", 
           "memory-bank\productContext.md",
           "memory-bank\systemPatterns.md",
           "memory-bank\techContext.md",
           "memory-bank\activeContext.md",
           "memory-bank\progress.md")

foreach ($file in $files) {
    if (-not (Test-Path $file)) {
        New-Item -Path $file -ItemType File -Force
    }
}
```

#### Mac/Linux (Bash)
```bash
# Create all directories in one command
mkdir -p memory-bank docs/archive

# Create all required files
touch .cursorrules tasks.md \
      memory-bank/projectbrief.md \
      memory-bank/productContext.md \
      memory-bank/systemPatterns.md \
      memory-bank/techContext.md \
      memory-bank/activeContext.md \
      memory-bank/progress.md
```

## 📝 STREAMLINED VERIFICATION PROCESS

Instead of checking each component separately, perform batch verification:

```powershell
# Windows - PowerShell
$requiredDirs = @("memory-bank", "docs", "docs\archive")
$requiredFiles = @(".cursorrules", "tasks.md")
$mbFiles = @("projectbrief.md", "productContext.md", "systemPatterns.md", 
             "techContext.md", "activeContext.md", "progress.md")

$missingDirs = $requiredDirs | Where-Object { -not (Test-Path $_) -or -not (Test-Path $_ -PathType Container) }
$missingFiles = $requiredFiles | Where-Object { -not (Test-Path $_) -or (Test-Path $_ -PathType Container) }
$missingMBFiles = $mbFiles | ForEach-Object { "memory-bank\$_" } | 
                  Where-Object { -not (Test-Path $_) -or (Test-Path $_ -PathType Container) }

if ($missingDirs.Count -eq 0 -and $missingFiles.Count -eq 0 -and $missingMBFiles.Count -eq 0) {
    Write-Output "✓ All required components verified"
} else {
    # Create all missing items at once
    if ($missingDirs.Count -gt 0) {
        $missingDirs | ForEach-Object { mkdir $_ -Force }
    }
    if ($missingFiles.Count -gt 0 -or $missingMBFiles.Count -gt 0) {
        $allMissingFiles = $missingFiles + $missingMBFiles
        $allMissingFiles | ForEach-Object { New-Item -Path $_ -ItemType File -Force }
    }
}
```

## 📝 TEMPLATE INITIALIZATION

Optimize template creation with a single script:

```powershell
# Windows - PowerShell
$templates = @{
    "tasks.md" = @"
# Memory Bank: Tasks

## Current Task
[Task not yet defined]

## Status
- [ ] Task definition
- [ ] Implementation plan
- [ ] Execution
- [ ] Documentation

## Requirements
[No requirements defined yet]
"@

    "memory-bank\activeContext.md" = @"
# Memory Bank: Active Context

## Current Focus
[No active focus defined]

## Status
[No status defined]

## Latest Changes
[No changes recorded]
"@

    # Add other templates here
}

foreach ($file in $templates.Keys) {
    if (Test-Path $file) {
        Set-Content -Path $file -Value $templates[$file]
    }
}
```

## 🔍 PERFORMANCE OPTIMIZATION BEST PRACTICES

1. **Batch Operations**: Always use batch operations instead of individual commands
   ```
   # GOOD: Create all directories at once
   mkdir memory-bank docs docs\archive
   
   # BAD: Create directories one at a time
   mkdir memory-bank
   mkdir docs
   mkdir docs\archive
   ```

2. **Pre-Check Optimization**: Check all requirements first, then create only what's missing
   ```
   # First check what's missing
   $missingItems = ...
   
   # Then create only what's missing
   if ($missingItems) { ... }
   ```

3. **Error Handling**: Include error handling in all commands
   ```
   mkdir memory-bank, docs, docs\archive -ErrorAction SilentlyContinue
   ```

4. **Platform Adaptation**: Auto-detect platform and use appropriate commands
   ```
   if ($IsWindows) {
       # Windows commands
   } else {
       # Unix commands
   }
   ```

5. **One-Pass Verification**: Verify directory structure in a single pass
   ```
   $requiredPaths = @("memory-bank", "docs", "docs\archive", ".cursorrules", "tasks.md")
   $missingPaths = $requiredPaths | Where-Object { -not (Test-Path $_) }
   ```

## 📝 VERIFICATION REPORT FORMAT

```
✅ VERIFICATION COMPLETE
- Created directories: [list]
- Created files: [list]
- All components verified

Memory Bank system ready for use.
```

================
File: .cursor/rules/isolation_rules/Core/hierarchical-rule-loading.mdc
================
---
description: Hierarchical rule loading system for optimized token usage
globs: "**/rule-loading*/**", "**/optimization*/**"
alwaysApply: false
---

# HIERARCHICAL RULE LOADING SYSTEM

> **TL;DR:** This rule implements an optimized loading system that only loads necessary rules based on context, complexity level, and current phase to maximize token efficiency.

## 🧠 HIERARCHICAL RULE STRUCTURE

```mermaid
graph TD
    Root["Root Rules"] --> Core["Core Rules<br>(Always Loaded)"]
    Root --> Common["Common Rules<br>(Mode Independent)"]
    Root --> Mode["Mode-Specific<br>Rules"]
    Root --> Level["Complexity Level<br>Rules"]
    
    Core --> Platform["Platform<br>Detection"]
    Core --> File["File<br>Operations"]
    Core --> Transition["Mode<br>Transitions"]
    
    Mode --> VAN["VAN Mode<br>Rules"]
    Mode --> PLAN["PLAN Mode<br>Rules"]
    Mode --> CREATIVE["CREATIVE Mode<br>Rules"]
    Mode --> IMPLEMENT["IMPLEMENT Mode<br>Rules"]
    Mode --> REFLECT["REFLECT Mode<br>Rules"]
    
    Level --> Level1["Level 1<br>Rules"]
    Level --> Level2["Level 2<br>Rules"]
    Level --> Level3["Level 3<br>Rules"]
    Level --> Level4["Level 4<br>Rules"]
    
    style Root fill:#4da6ff,stroke:#0066cc,color:white
    style Core fill:#ffa64d,stroke:#cc7a30,color:white
    style Common fill:#4dbb5f,stroke:#36873f,color:white
    style Mode fill:#d94dbb,stroke:#a3378a,color:white
    style Level fill:#4dbbbb,stroke:#368787,color:white
```

## 📊 RULE LOADING PROTOCOL

```mermaid
sequenceDiagram
    participant User
    participant LoadManager
    participant RuleCache
    participant FileSystem
    
    User->>LoadManager: Request mode activation
    LoadManager->>RuleCache: Check cached core rules
    RuleCache-->>LoadManager: Return cached rules if available
    
    LoadManager->>FileSystem: Load essential mode rules
    FileSystem-->>LoadManager: Return essential rules
    
    LoadManager->>LoadManager: Register lazy loaders for specialized rules
    LoadManager->>User: Return initialized mode
    
    User->>LoadManager: Request specialized functionality
    LoadManager->>RuleCache: Check specialized rule cache
    RuleCache-->>LoadManager: Return cached rule if available
    
    alt Rule not in cache
        LoadManager->>FileSystem: Load specialized rule
        FileSystem-->>LoadManager: Return specialized rule
        LoadManager->>RuleCache: Cache specialized rule
    end
    
    LoadManager->>User: Execute specialized functionality
```

## 🔄 RULE LOADING IMPLEMENTATION

```javascript
// Pseudocode for hierarchical rule loading
class RuleLoadManager {
  constructor() {
    this.cache = {
      core: {},
      common: {},
      mode: {},
      level: {}
    };
    this.lazyLoaders = {};
  }
  
  // Initialize a mode with only essential rules
  initializeMode(modeName, complexityLevel) {
    // Always load core rules
    this.loadCoreRules();
    
    // Load common rules
    this.loadCommonRules();
    
    // Load essential mode-specific rules
    this.loadEssentialModeRules(modeName);
    
    // Load complexity level rules
    this.loadComplexityRules(complexityLevel);
    
    // Register lazy loaders for specialized functionality
    this.registerLazyLoaders(modeName, complexityLevel);
    
    return {
      modeName,
      complexityLevel,
      status: "initialized"
    };
  }
  
  // Load only when specialized functionality is needed
  loadSpecializedRule(ruleType) {
    if (this.lazyLoaders[ruleType]) {
      if (!this.cache.specialized[ruleType]) {
        const rule = this.lazyLoaders[ruleType]();
        this.cache.specialized[ruleType] = rule;
      }
      return this.cache.specialized[ruleType];
    }
    return null;
  }
  
  // Register specialized rule loaders based on mode and complexity
  registerLazyLoaders(modeName, complexityLevel) {
    // Clear existing lazy loaders
    this.lazyLoaders = {};
    
    // Register mode-specific lazy loaders
    if (modeName === "CREATIVE") {
      this.lazyLoaders["architecture"] = () => this.loadRule("creative-phase-architecture.mdc");
      this.lazyLoaders["algorithm"] = () => this.loadRule("creative-phase-algorithm.mdc");
      this.lazyLoaders["uiux"] = () => this.loadRule("creative-phase-uiux.mdc");
    } else if (modeName === "IMPLEMENT") {
      this.lazyLoaders["testing"] = () => this.loadRule("implementation-testing.mdc");
      this.lazyLoaders["deployment"] = () => this.loadRule("implementation-deployment.mdc");
    }
    
    // Register complexity-specific lazy loaders
    if (complexityLevel >= 3) {
      this.lazyLoaders["comprehensive-planning"] = () => this.loadRule("planning-comprehensive.mdc");
      this.lazyLoaders["advanced-verification"] = () => this.loadRule("verification-advanced.mdc");
    }
  }
}
```

## 📋 RULE DEPENDENCY MAP

```mermaid
graph TD
    Main["main.mdc"] --> Core1["platform-awareness.mdc"]
    Main --> Core2["file-verification.mdc"]
    Main --> Core3["command-execution.mdc"]
    
    subgraph "VAN Mode"
        VanMap["van-mode-map.mdc"] --> Van1["van-complexity-determination.mdc"]
        VanMap --> Van2["van-file-verification.mdc"]
        VanMap --> Van3["van-platform-detection.mdc"]
    end
    
    subgraph "PLAN Mode"
        PlanMap["plan-mode-map.mdc"] --> Plan1["task-tracking-basic.mdc"]
        PlanMap --> Plan2["planning-comprehensive.mdc"]
    end
    
    subgraph "CREATIVE Mode"
        CreativeMap["creative-mode-map.mdc"] --> Creative1["creative-phase-enforcement.mdc"]
        CreativeMap --> Creative2["creative-phase-metrics.mdc"]
        Creative1 & Creative2 -.-> CreativeSpecialized["Specialized Creative Rules"]
        CreativeSpecialized --> CArch["creative-phase-architecture.mdc"]
        CreativeSpecialized --> CAlgo["creative-phase-algorithm.mdc"]
        CreativeSpecialized --> CUIUX["creative-phase-uiux.mdc"]
    end
    
    subgraph "IMPLEMENT Mode"
        ImplementMap["implement-mode-map.mdc"] --> Impl1["implementation-guide.mdc"]
        ImplementMap --> Impl2["testing-strategy.mdc"]
    end
```

## 🔍 MODE-SPECIFIC RULE LOADING

### VAN Mode Essential Rules
```markdown
- main.mdc (Core)
- platform-awareness.mdc (Core)
- file-verification.mdc (Core)
- van-mode-map.mdc (Mode)
```

### PLAN Mode Essential Rules
```markdown
- main.mdc (Core)
- plan-mode-map.mdc (Mode)
- task-tracking-[complexity].mdc (Level)
```

### CREATIVE Mode Essential Rules
```markdown
- main.mdc (Core)
- creative-mode-map.mdc (Mode)
- creative-phase-enforcement.mdc (Mode)
```

### CREATIVE Mode Specialized Rules (Lazy Loaded)
```markdown
- creative-phase-architecture.mdc (Specialized)
- creative-phase-algorithm.mdc (Specialized)
- creative-phase-uiux.mdc (Specialized)
```

### IMPLEMENT Mode Essential Rules
```markdown
- main.mdc (Core)
- command-execution.mdc (Core)
- implement-mode-map.mdc (Mode)
```

## 🚀 IMPLEMENTATION BENEFITS

The hierarchical loading system provides:

1. **Reduced Initial Loading**: Only essential rules loaded at start (~70% token reduction)
2. **Cached Core Rules**: Rules shared between modes are cached
3. **Specialized Rule Loading**: Specialized rules loaded only when needed
4. **Complexity-Based Loading**: Only load rules appropriate for task complexity

## 📈 TOKEN USAGE COMPARISON

| Approach | Initial Tokens | Specialized Tokens | Total Tokens |
|----------|---------------|-------------------|--------------|
| Original System | ~70,000 | Included in initial | ~70,000 |
| Hierarchical System | ~15,000 | ~10,000 (on demand) | ~25,000 |
| **Token Reduction** | **~55,000 (78%)** | **N/A** | **~45,000 (64%)** |

## 🔄 USAGE EXAMPLE

### Example: Creative Phase with Architecture Rule

```javascript
// Initialize the CREATIVE mode with only essential rules
const mode = ruleManager.initializeMode("CREATIVE", 3);

// Core and essential mode rules are loaded 
// Architecture rules are NOT loaded yet

// Later, when architecture design is needed:
const architectureRule = ruleManager.loadSpecializedRule("architecture");

// Now the architecture rule is loaded and cached
```

## 🧪 RULE LOADING VERIFICATION

To ensure the rule loading system is working optimally:

```markdown
## Rule Loading Verification

- Core Rules: [Loaded]
- Mode-Essential Rules: [Loaded]
- Complexity-Level Rules: [Loaded]
- Specialized Rules: [Not Loaded]

Current Token Usage: [X] tokens
Potential Token Savings: [Y] tokens
```

This hierarchical approach ensures optimal token usage while maintaining all functionality.

================
File: .cursor/rules/isolation_rules/Core/memory-bank-paths.mdc
================
---
description: Defines canonical paths for core Memory Bank files.
globs: memory-bank-paths.mdc
alwaysApply: true
---

# CORE MEMORY BANK FILE LOCATIONS

**CRITICAL:** All core Memory Bank files reside within the `memory-bank/` directory at the project root. Do NOT create or modify these files outside this directory unless explicitly instructed for archiving purposes.

* **Tasks File:** `memory-bank/tasks.md` - This file is used for active, in-progress task tracking, detailing steps, checklists, and component lists. Its content, particularly the detailed checklists, is merged into the main archive document for the task upon completion. After archival, `tasks.md` is cleared to be ready for the next task. It is an ephemeral working document during a task's lifecycle, with its persistent record captured in the task's archive file.
* **Active Context File:** `memory-bank/activeContext.md`
* **Progress File:** `memory-bank/progress.md`
* **Project Brief File:** `memory-bank/projectbrief.md`
* **Product Context File:** `memory-bank/productContext.md`
* **System Patterns File:** `memory-bank/systemPatterns.md`
* **Tech Context File:** `memory-bank/techContext.md`
* **Style Guide File:** `memory-bank/style-guide.md`
* **Creative Phase Docs:** `memory-bank/creative/creative-[feature_name].md`
* **Reflection Docs:** `memory-bank/reflection/reflection-[task_id].md`
* **Archive Directory:** `memory-bank/archive/archive-[task_id].md`

**Verification Mandate:** Before any `create_file` or `edit_file` operation on these core files, verify the path starts with `memory-bank/`. If attempting to create a new core file (e.g., `tasks.md` at the start of a project), ensure it is created at `memory-bank/tasks.md`.

================
File: .cursor/rules/isolation_rules/Core/mode-transition-optimization.mdc
================
---
description: Optimized mode transition protocol
globs: "**/mode-transition*/**", "**/context-preservation*/**"
alwaysApply: false
---

# MODE TRANSITION OPTIMIZATION

> **TL;DR:** This file implements optimized mode transitions to preserve context efficiently between different phases of the Memory Bank system.

## 🔄 UNIFIED CONTEXT TRANSFER PROTOCOL

```mermaid
graph TD
    Start["Mode A"] --> Create["Create Context<br>Summary Document"]
    Create --> Store["Store Critical<br>Context Data"]
    Store --> Transition["Transition<br>to Mode B"]
    Transition --> Verify["Verify Context<br>Availability"]
    Verify --> Load["Load Relevant<br>Context Data"]
    Load --> Continue["Continue in<br>Mode B"]
    
    style Start fill:#4da6ff,stroke:#0066cc,color:white
    style Create fill:#ffa64d,stroke:#cc7a30,color:white
    style Store fill:#4dbb5f,stroke:#36873f,color:white
    style Transition fill:#d94dbb,stroke:#a3378a,color:white
    style Verify fill:#4dbbbb,stroke:#368787,color:white
    style Load fill:#d971ff,stroke:#a33bc2,color:white
    style Continue fill:#ff71c2,stroke:#c23b8a,color:white
```

## 📊 CONTEXT TRANSITION DOCUMENT

Create a standardized transition document when switching modes:

```markdown
# MODE TRANSITION: [Source Mode] → [Target Mode]

## Context Summary
- Task: [Task name/description]
- Complexity: Level [1-4]
- Current Phase: [Phase name]
- Progress: [Percentage or status]

## Key Decisions
- [Decision 1]: [Brief summary]
- [Decision 2]: [Brief summary]
- [Decision 3]: [Brief summary]

## Critical Context
- [Context item 1]: [Value/status]
- [Context item 2]: [Value/status]
- [Context item 3]: [Value/status]

## Next Steps
1. [Next step 1]
2. [Next step 2]
3. [Next step 3]

## Resource Pointers
- [Resource 1]: [Location]
- [Resource 2]: [Location]
- [Resource 3]: [Location]
```

## 🔍 MODE-SPECIFIC TRANSITION HANDLERS

### VAN → PLAN Transition

```markdown
### VAN → PLAN
- Context preserved: Complexity level, platform detection, file structure
- Files transferred: tasks.md (initialized), activeContext.md (initialized)
- Rule optimization: Pre-load planning rules based on complexity level
```

### PLAN → CREATIVE Transition

```markdown
### PLAN → CREATIVE
- Context preserved: Task requirements, component list, creative phase flags
- Files transferred: tasks.md (updated with plan), creative phase components list
- Rule optimization: Only load creative templates for identified components
```

### CREATIVE → IMPLEMENT Transition

```markdown
### CREATIVE → IMPLEMENT
- Context preserved: Design decisions, implementation guidelines, requirements
- Files transferred: tasks.md, design documents, implementation checklist
- Rule optimization: Pre-load implementation templates based on design decisions
```

### IMPLEMENT → REFLECT Transition

```markdown
### IMPLEMENT → REFLECT
- Context preserved: Implementation status, challenges encountered, decisions
- Files transferred: tasks.md, progress.md, implementation notes
- Rule optimization: Load reflection templates based on completion status
```

## 🧠 HIERARCHICAL RULE CACHING

Implement rule caching to avoid redundant loading:

```javascript
// Pseudocode for rule caching
const ruleCache = {
  core: {}, // Core rules shared across modes
  van: {},
  plan: {},
  creative: {},
  implement: {},
  reflect: {},
  archive: {}
};

// Check cache before loading
function loadRule(rulePath) {
  const cacheKey = getCacheKey(rulePath);
  const category = getCategoryFromPath(rulePath);
  
  if (ruleCache[category][cacheKey]) {
    return ruleCache[category][cacheKey];
  }
  
  const ruleContent = readRuleFromFile(rulePath);
  ruleCache[category][cacheKey] = ruleContent;
  
  return ruleContent;
}

// Only invalidate specific rules when needed
function invalidateRule(rulePath) {
  const cacheKey = getCacheKey(rulePath);
  const category = getCategoryFromPath(rulePath);
  
  if (ruleCache[category][cacheKey]) {
    delete ruleCache[category][cacheKey];
  }
}
```

## ⚡ DIFFERENTIAL MEMORY BANK UPDATES

```mermaid
graph TD
    Start["Memory Bank<br>Update Request"] --> Check{"File<br>Changed?"}
    Check -->|"No"| Skip["Skip Update<br>(No Changes)"]
    Check -->|"Yes"| Changed{"Specific<br>Section Changed?"}
    Changed -->|"No"| Full["Full File<br>Update"]
    Changed -->|"Yes"| Partial["Partial<br>Update Only"]
    
    style Start fill:#4da6ff,stroke:#0066cc,color:white
    style Check fill:#ffa64d,stroke:#cc7a30,color:white
    style Skip fill:#4dbb5f,stroke:#36873f,color:white
    style Changed fill:#d94dbb,stroke:#a3378a,color:white
    style Full fill:#4dbbbb,stroke:#368787,color:white
    style Partial fill:#d971ff,stroke:#a33bc2,color:white
```

Implement a more efficient update mechanism:

```javascript
// Pseudocode for differential updates
function updateMemoryBankFile(filePath, newContent) {
  // Read existing content
  const currentContent = readFile(filePath);
  
  // Skip if no changes
  if (currentContent === newContent) {
    return "No changes detected, update skipped";
  }
  
  // Check if we can do a partial update
  const sections = parseIntoSections(currentContent);
  const newSections = parseIntoSections(newContent);
  
  let updatedContent = currentContent;
  let updatedSections = 0;
  
  // Only update changed sections
  for (const [sectionName, sectionContent] of Object.entries(newSections)) {
    if (!sections[sectionName] || sections[sectionName] !== sectionContent) {
      updatedContent = replaceSection(updatedContent, sectionName, sectionContent);
      updatedSections++;
    }
  }
  
  // Write updated content
  writeFile(filePath, updatedContent);
  
  return `Updated ${updatedSections} section(s) in ${filePath}`;
}
```

## 🔗 CREATIVE TO IMPLEMENT BRIDGE

Special handling for the critical Creative → Implement transition:

```markdown
## CREATIVE → IMPLEMENT BRIDGE

### Design Decision Summary
Automatically generated summary of all creative phase decisions:

```json
{
  "components": [
    {
      "name": "ComponentA",
      "decision": "Approach X selected",
      "rationale": "Best performance characteristics",
      "implementation_notes": [
        "Use X library",
        "Implement caching",
        "Add error handling"
      ]
    },
    {
      "name": "ComponentB",
      "decision": "Custom solution",
      "rationale": "Unique requirements",
      "implementation_notes": [
        "Build from scratch",
        "Modular architecture",
        "Unit tests required"
      ]
    }
  ]
}
```

### Implementation Verification Checklist
Automatically generated verification checklist:

```markdown
# Implementation Readiness Checklist

- [ ] Design decisions available for all components
- [ ] Implementation notes provided for each decision
- [ ] Dependencies clearly identified
- [ ] Order of implementation determined
- [ ] Required libraries/frameworks documented
- [ ] Potential challenges identified
```

## 🚀 ADAPTIVE MODE LOADING

Implement progressive mode loading to optimize context:

```javascript
// Pseudocode for adaptive mode loading
function loadMode(modeName, taskComplexity) {
  // Always load core rules
  loadCoreRules();
  
  // Load complexity-appropriate rules
  loadComplexityRules(taskComplexity);
  
  // Load mode-specific essential rules
  loadModeEssentialRules(modeName);
  
  // Only load specialized rules as needed
  registerLazyLoadHandlers(modeName, taskComplexity);
}

function registerLazyLoadHandlers(modeName, taskComplexity) {
  // Register handlers to load additional rules only when needed
  if (modeName === "CREATIVE") {
    registerHandler("architecture", () => loadRule("creative-phase-architecture.mdc"));
    registerHandler("algorithm", () => loadRule("creative-phase-algorithm.mdc"));
    registerHandler("uiux", () => loadRule("creative-phase-uiux.mdc"));
  }
  
  // Similar patterns for other specialized rule types
}
```

## ✅ MODE TRANSITION EXAMPLES

### Example: PLAN → CREATIVE Transition

When transitioning from PLAN to CREATIVE mode:

```markdown
# MODE TRANSITION: PLAN → CREATIVE

## Context Summary
- Task: Implement user authentication system
- Complexity: Level 3
- Current Phase: Planning completed
- Progress: 35% (Planning: 100%, Creative: 0%, Implement: 0%)

## Key Decisions
- Authentication: Requires exploration of options (JWT vs Sessions)
- User Management: Will use existing database schema
- Authorization: Role-based access control selected

## Critical Context
- Components for creative phase: Authentication mechanism, Session management
- Dependencies: User database, Authorization system
- Constraints: Must support SSO, Performance requirements

## Next Steps
1. Explore authentication options (JWT, Sessions, OAuth)
2. Design session management approach
3. Document implementation guidelines

## Resource Pointers
- Planning document: tasks.md (section 3)
- Requirements: activeContext.md
- Reference architecture: docs/system-architecture.md
```

### Example: CREATIVE → IMPLEMENT Transition

When transitioning from CREATIVE to IMPLEMENT mode:

```markdown
# MODE TRANSITION: CREATIVE → IMPLEMENT

## Context Summary
- Task: Implement user authentication system
- Complexity: Level 3
- Current Phase: Creative completed
- Progress: 70% (Planning: 100%, Creative: 100%, Implement: 0%)

## Key Decisions
- Authentication: JWT-based approach selected
- Token Storage: Secure HttpOnly cookies with CSRF protection
- Refresh Strategy: Silent refresh with sliding expiration

## Critical Context
- Implementation order: Auth API endpoints, Middleware, Client integration
- Testing requirements: Unit tests for JWT validation, Integration tests for auth flow
- Security considerations: XSS protection, CSRF mitigation, Rate limiting

## Next Steps
1. Implement JWT generation and validation
2. Create authentication middleware
3. Build user login/logout endpoints
4. Implement client-side auth integration

## Resource Pointers
- Creative document: creative-auth-decisions.md
- API specifications: api-spec.yaml
- Security requirements: security-policy.md
```

## 🔄 IMPLEMENTATION BENEFITS

This optimization provides:

1. Reduced token usage during mode transitions (~40% reduction)
2. Better context preservation between modes
3. Improved efficiency through rule caching
4. Targeted loading of only necessary rules
5. Optimized memory bank updates
6. Clear transition documents that preserve critical context

================
File: .cursor/rules/isolation_rules/Core/optimization-integration.mdc
================
---
description: Integration hub for Memory Bank optimizations
globs: "**/optimization*/**", "**/integration*/**"
alwaysApply: false
---

# MEMORY BANK OPTIMIZATION INTEGRATION

> **TL;DR:** This file serves as the integration point for all Memory Bank optimizations, coordinating the various optimization components to work seamlessly together.

## 🔄 OPTIMIZATION INTEGRATION FLOW

```mermaid
graph TD
    Start["Memory Bank<br>Initialization"] --> HRL["Hierarchical<br>Rule Loading"]
    HRL --> ACM["Adaptive<br>Complexity Model"]
    ACM --> DCM["Dynamic<br>Context Management"]
    DCM --> TMO["Transition<br>Optimization"]
    
    subgraph "Level-Specific Optimizations"
        L1["Level 1<br>Optimizations"]
        L2["Level 2<br>Optimizations"]
        L3["Level 3<br>Optimizations"]
        L4["Level 4<br>Optimizations"]
    end
    
    ACM --> L1 & L2 & L3 & L4
    
    L1 & L2 & L3 & L4 --> CPO["Creative Phase<br>Optimization"]
    
    CPO --> PDO["Progressive<br>Documentation"]
    TMO --> PDO
    
    PDO --> MBO["Memory Bank<br>Optimization"]
    
    style Start fill:#4da6ff,stroke:#0066cc,color:white
    style HRL fill:#ffa64d,stroke:#cc7a30,color:white
    style ACM fill:#4dbb5f,stroke:#36873f,color:white
    style DCM fill:#d94dbb,stroke:#a3378a,color:white
    style TMO fill:#4dbbbb,stroke:#368787,color:white
    style CPO fill:#e699d9,stroke:#d94dbb,color:white
    style PDO fill:#d971ff,stroke:#a33bc2,color:white
    style MBO fill:#ff71c2,stroke:#c23b8a,color:white
```

## 📋 OPTIMIZATION COMPONENT REGISTRY

```javascript
// Optimization component registry pseudocode
const optimizationRegistry = {
  // Core optimizations
  hierarchicalRuleLoading: {
    file: "Core/hierarchical-rule-loading.mdc",
    dependencies: [],
    priority: 1
  },
  adaptiveComplexityModel: {
    file: "main-optimized.mdc",
    dependencies: ["hierarchicalRuleLoading"],
    priority: 2
  },
  modeTransitionOptimization: {
    file: "Core/mode-transition-optimization.mdc",
    dependencies: ["hierarchicalRuleLoading", "adaptiveComplexityModel"],
    priority: 3
  },
  
  // Level-specific optimizations
  level1Optimization: {
    file: "Level1/optimized-workflow-level1.mdc",
    dependencies: ["adaptiveComplexityModel"],
    priority: 4
  },
  
  // Feature-specific optimizations
  creativePhaseOptimization: {
    file: "Phases/CreativePhase/optimized-creative-template.mdc",
    dependencies: ["hierarchicalRuleLoading", "adaptiveComplexityModel"],
    priority: 5
  }
};
```

## 🔄 OPTIMIZATION INITIALIZATION SEQUENCE

```mermaid
sequenceDiagram
    participant MB as Memory Bank
    participant Reg as Optimization Registry
    participant HRL as Hierarchical Rule Loading
    participant ACM as Adaptive Complexity
    participant TMO as Transition Optimization
    participant CPO as Creative Phase Optimization
    
    MB->>Reg: Request optimization initialization
    Reg->>Reg: Sort optimizations by priority & dependencies
    Reg->>HRL: Initialize (Priority 1)
    HRL-->>Reg: Initialization complete
    Reg->>ACM: Initialize (Priority 2)
    ACM->>HRL: Request rule loading services
    HRL-->>ACM: Provide rule loading
    ACM-->>Reg: Initialization complete
    Reg->>TMO: Initialize (Priority 3)
    TMO->>HRL: Request rule loading services
    TMO->>ACM: Request complexity model
    HRL-->>TMO: Provide rule loading
    ACM-->>TMO: Provide complexity model
    TMO-->>Reg: Initialization complete
    Reg->>CPO: Initialize (Final)
    CPO->>HRL: Request rule loading services
    CPO->>ACM: Request complexity model
    CPO->>TMO: Request transition services
    HRL-->>CPO: Provide rule loading
    ACM-->>CPO: Provide complexity model
    TMO-->>CPO: Provide transition services
    CPO-->>Reg: Initialization complete
    Reg-->>MB: All optimizations initialized
```

## 🔍 OPTIMIZATION CONFIGURATION

```javascript
// Optimization configuration pseudocode
const optimizationConfig = {
  // Token optimization settings
  tokenOptimization: {
    enableHierarchicalLoading: true,
    enableProgressiveDocumentation: true,
    enableLazyRuleLoading: true,
    enableContextPruning: true
  },
  
  // Context preservation settings
  contextPreservation: {
    preserveDesignDecisions: true,
    preserveImplementationContext: true,
    preserveUserPreferences: true,
    contextCompressionLevel: "high" // none, low, medium, high
  },
  
  // Documentation optimization
  documentationOptimization: {
    level1DocumentationLevel: "minimal", // minimal, standard, comprehensive
    level2DocumentationLevel: "standard",
    level3DocumentationLevel: "comprehensive",
    level4DocumentationLevel: "comprehensive",
    enableProgressiveDisclosure: true,
    enableTemplateCaching: true
  }
};
```

## 📊 OPTIMIZATION MONITORING

```mermaid
graph TD
    Monitor["Optimization<br>Monitor"] --> TokenUsage["Token Usage<br>Tracking"]
    Monitor --> ContextEfficiency["Context<br>Efficiency"]
    Monitor --> RuleLoadingStats["Rule Loading<br>Statistics"]
    Monitor --> DocumentationSize["Documentation<br>Size"]
    
    TokenUsage --> Dashboard["Optimization<br>Dashboard"]
    ContextEfficiency --> Dashboard
    RuleLoadingStats --> Dashboard
    DocumentationSize --> Dashboard
    
    Dashboard --> Feedback["Optimization<br>Feedback Loop"]
    Feedback --> Config["Optimization<br>Configuration"]
    Config --> Monitor
    
    style Monitor fill:#4da6ff,stroke:#0066cc,color:white
    style Dashboard fill:#ffa64d,stroke:#cc7a30,color:white
    style Feedback fill:#4dbb5f,stroke:#36873f,color:white
    style Config fill:#d94dbb,stroke:#a3378a,color:white
```

## 📈 OPTIMIZATION METRICS

```markdown
# Optimization Metrics

## Token Usage
- Core Rule Loading: [X] tokens
- Mode-Specific Rules: [Y] tokens
- Creative Phase Documentation: [Z] tokens
- Overall Token Reduction: [P]%

## Context Efficiency
- Context Utilization: [Q]%
- Context Waste: [R]%
- Effective Token Capacity: [S] tokens

## Rule Loading
- Rules Loaded: [T] / [U] (Total)
- Lazy-Loaded Rules: [V]
- Cached Rules: [W]

## Documentation
- Level 1 Documentation Size: [X] tokens
- Level 2 Documentation Size: [Y] tokens
- Level 3 Documentation Size: [Z] tokens
- Level 4 Documentation Size: [AA] tokens
```

## 🔄 INTEGRATION USAGE EXAMPLES

### Initializing All Optimizations

```javascript
// Pseudocode for initializing all optimizations
function initializeMemoryBankOptimizations() {
  // Load optimization registry
  const registry = loadOptimizationRegistry();
  
  // Sort by priority and dependencies
  const sortedOptimizations = sortOptimizations(registry);
  
  // Initialize each optimization in order
  for (const opt of sortedOptimizations) {
    initializeOptimization(opt);
  }
  
  // Configure optimization parameters
  configureOptimizations(loadOptimizationConfig());
  
  // Start monitoring
  initializeOptimizationMonitoring();
  
  return "Memory Bank optimizations initialized";
}
```

### Using Optimized Creative Phase

```markdown
// Using the optimized creative phase with progressive documentation

// Initialize with minimal documentation
📌 CREATIVE PHASE START: Authentication System
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

1️⃣ PROBLEM
   Description: Design an authentication system for the application
   Requirements: Secure, scalable, supports SSO, easy to maintain
   Constraints: Must work with existing user database, <100ms response time

2️⃣ OPTIONS
   Option A: JWT-based stateless auth
   Option B: Session-based auth with Redis
   Option C: OAuth2 implementation

// Progressively add detail as needed
3️⃣ ANALYSIS
   | Criterion | JWT | Sessions | OAuth2 |
   |-----------|-----|----------|--------|
   | Security | ⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ |
   | Scalability | ⭐⭐⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐⭐ |
   | Complexity | ⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐⭐ |
   
// Focus on decision and implementation
4️⃣ DECISION
   Selected: Option A: JWT-based auth with refresh tokens
   Rationale: Best balance of performance and scalability
   
5️⃣ IMPLEMENTATION NOTES
   - Use HS256 algorithm for token signing
   - Implement short-lived access tokens (15min)
   - Store token blacklist in Redis for revocation
```

## 🔄 MODE TRANSITION EXAMPLE

```markdown
// Optimized mode transition from CREATIVE to IMPLEMENT

# MODE TRANSITION: CREATIVE → IMPLEMENT

## Context Summary
- Task: Authentication system implementation
- Complexity: Level 3
- Decision: JWT-based auth with refresh tokens

## Key Context
- Security requirements verified
- Algorithm selection: HS256
- Token lifecycle: 15min access / 7 days refresh

## Next Steps
1. Implement JWT generation module
2. Create token validation middleware
3. Build refresh token handling

// Transition happens with preserved context
// IMPLEMENT mode continues with this context available
```

## 🔄 HIERARCHICAL RULE LOADING EXAMPLE

```javascript
// Pseudocode example of hierarchical rule loading

// Initial load - only core rules
loadCoreRules();

// Determine complexity
const complexity = determineComplexity();

// Load mode-specific essential rules
loadModeEssentialRules("CREATIVE");

// Register lazy loaders for specialized rules
registerLazyLoader("architecture", () => loadRule("creative-phase-architecture.mdc"));
registerLazyLoader("algorithm", () => loadRule("creative-phase-algorithm.mdc"));
registerLazyLoader("uiux", () => loadRule("creative-phase-uiux.mdc"));

// Later, when architecture design is needed:
const architectureRule = loadSpecializedRule("architecture");
// Architecture rule is now loaded only when needed
```

These integrated optimizations work seamlessly together to provide a significantly more efficient Memory Bank system while maintaining all functionality.

================
File: .cursor/rules/isolation_rules/Core/platform-awareness.mdc
================
---
description: Platform detection and command adaptation for isolation-focused Memory Bank
globs: platform-awareness.mdc
alwaysApply: false
---


# PLATFORM AWARENESS SYSTEM

> **TL;DR:** This system detects the operating system, path format, and shell environment, then adapts commands accordingly to ensure cross-platform compatibility.

## 🔍 PLATFORM DETECTION PROCESS

```mermaid
graph TD
    Start["Start Platform<br>Detection"] --> DetectOS["Detect OS<br>Environment"]
    DetectOS --> Windows["Windows<br>Detection"]
    DetectOS --> Mac["macOS<br>Detection"]
    DetectOS --> Linux["Linux<br>Detection"]
    
    Windows & Mac & Linux --> PathCheck["Path Separator<br>Detection"]
    PathCheck --> CmdAdapt["Command<br>Adaptation"]
    CmdAdapt --> ShellCheck["Shell Type<br>Detection"]
    ShellCheck --> Complete["Platform Detection<br>Complete"]
```

## 📋 PLATFORM DETECTION IMPLEMENTATION

For reliable platform detection:

```
## Platform Detection Results
Operating System: [Windows/macOS/Linux]
Path Separator: [\ or /]
Shell Environment: [PowerShell/Bash/Zsh/Cmd]
Command Adaptation: [Required/Not Required]

Adapting commands for [detected platform]...
```

## 🔍 PATH FORMAT CONVERSION

When converting paths between formats:

```mermaid
sequenceDiagram
    participant Input as Path Input
    participant Detector as Format Detector
    participant Converter as Format Converter
    participant Output as Adapted Path
    
    Input->>Detector: Raw Path
    Detector->>Detector: Detect Current Format
    Detector->>Converter: Path + Current Format
    Converter->>Converter: Apply Target Format
    Converter->>Output: Platform-Specific Path
```

## 📝 PLATFORM VERIFICATION CHECKLIST

```
✓ PLATFORM VERIFICATION
- Operating system correctly identified? [YES/NO]
- Path separator format detected? [YES/NO]
- Shell environment identified? [YES/NO]
- Command set adapted appropriately? [YES/NO]
- Path format handling configured? [YES/NO]

→ If all YES: Platform adaptation complete
→ If any NO: Run additional detection steps
```




================================================================
End of Codebase
================================================================

================
File: cursor-memory-bank/mdc rules/rules-levels.txt
================
This file is a merged representation of a subset of the codebase, containing specifically included files, combined into a single document by Repomix.

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: .cursor/rules/isolation_rules/Level1, .cursor/rules/isolation_rules/Level1/optimized-workflow-level1.mdc, .cursor/rules/isolation_rules/Level1/quick-documentation.mdc, .cursor/rules/isolation_rules/Level1/workflow-level1.mdc, .cursor/rules/isolation_rules/Level2, .cursor/rules/isolation_rules/Level3, .cursor/rules/isolation_rules/Level4
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)


================================================================
Directory Structure
================================================================
.cursor/rules/isolation_rules/Level1/optimized-workflow-level1.mdc
.cursor/rules/isolation_rules/Level1/quick-documentation.mdc
.cursor/rules/isolation_rules/Level1/workflow-level1.mdc
.cursor/rules/isolation_rules/Level2/archive-basic.mdc
.cursor/rules/isolation_rules/Level2/reflection-basic.mdc
.cursor/rules/isolation_rules/Level2/task-tracking-basic.mdc
.cursor/rules/isolation_rules/Level2/workflow-level2.mdc
.cursor/rules/isolation_rules/Level3/archive-intermediate.mdc
.cursor/rules/isolation_rules/Level3/implementation-intermediate.mdc
.cursor/rules/isolation_rules/Level3/planning-comprehensive.mdc
.cursor/rules/isolation_rules/Level3/reflection-intermediate.mdc
.cursor/rules/isolation_rules/Level3/task-tracking-intermediate.mdc
.cursor/rules/isolation_rules/Level3/workflow-level3.mdc
.cursor/rules/isolation_rules/Level4/architectural-planning.mdc
.cursor/rules/isolation_rules/Level4/archive-comprehensive.mdc
.cursor/rules/isolation_rules/Level4/phased-implementation.mdc
.cursor/rules/isolation_rules/Level4/reflection-comprehensive.mdc
.cursor/rules/isolation_rules/Level4/task-tracking-advanced.mdc
.cursor/rules/isolation_rules/Level4/workflow-level4.mdc

================================================================
Files
================================================================

================
File: .cursor/rules/isolation_rules/Level1/optimized-workflow-level1.mdc
================
---
description: Optimized Level 1 workflow for quick bug fixes with token efficiency
globs: "**/level1*/**", "**/quick*/**", "**/bugfix*/**"
alwaysApply: false
---

# OPTIMIZED LEVEL 1 WORKFLOW

> **TL;DR:** This streamlined workflow for Level 1 tasks (quick bug fixes) optimizes for speed and token efficiency while maintaining quality.

## 🔧 LEVEL 1 PROCESS FLOW

```mermaid
graph TD
    Start["START LEVEL 1<br>QUICK FIX"] --> Analyze["1️⃣ ANALYZE<br>Understand issue"]
    Analyze --> Implement["2️⃣ IMPLEMENT<br>Fix the issue"]
    Implement --> Verify["3️⃣ VERIFY<br>Test the fix"]
    Verify --> Document["4️⃣ DOCUMENT<br>Record solution"]
    
    style Start fill:#4da6ff,stroke:#0066cc,color:white
    style Analyze fill:#ffa64d,stroke:#cc7a30,color:white
    style Implement fill:#4dbb5f,stroke:#36873f,color:white
    style Verify fill:#d94dbb,stroke:#a3378a,color:white
    style Document fill:#4dbbbb,stroke:#368787,color:white
```

## 📝 CONSOLIDATED DOCUMENTATION

Level 1 tasks use a single-file approach to minimize context switching:

```markdown
# QUICK FIX: [Issue Name]

## Issue Summary
- Type: [Bug/Hotfix/Quick Enhancement]
- Priority: [Low/Medium/High/Critical]
- Reported by: [Name/System]
- Affected area: [Component/Feature]

## Analysis
- Root cause: [Brief description]
- Affected files: [List of files]
- Impact: [Scope of impact]

## Solution
- Approach: [Brief description]
- Changes made: [List of changes]
- Commands executed: [Key commands]

## Verification
- Testing: [How the fix was tested]
- Results: [Test results]
- Additional checks: [Any other verification]

## Status
- [x] Fix implemented
- [x] Tests passed
- [x] Documentation updated
```

## 🔄 MEMORY BANK UPDATE

Level 1 tasks use a simplified Memory Bank update with minimal overhead:

```markdown
## tasks.md Update (Level 1)

### Task: [Task Name]
- Status: Complete
- Implementation: [One-line summary]
- Link to fix: [File/line reference]
```

## ⚡ TOKEN-OPTIMIZED TEMPLATE

For maximum efficiency, Level 1 tasks can use this ultra-compact template:

```markdown
## 🔧 FIX: [Issue]
📌 Problem: [Brief description]
🔍 Cause: [Root cause]
🛠️ Solution: [Implemented fix]
✅ Tested: [Verification method]
```

## 🔄 AUTO-DOCUMENTATION HELPERS

Use these helpers to automatically generate documentation:

```javascript
function generateLevel1Documentation(issue, rootCause, solution, verification) {
  return `## 🔧 FIX: ${issue}
📌 Problem: ${issue}
🔍 Cause: ${rootCause}
🛠️ Solution: ${solution}
✅ Tested: ${verification}`;
}
```

## 📊 QUICK TEMPLATES FOR COMMON ISSUES

### Performance Fix
```markdown
## 🔧 FIX: Performance issue in [component]
📌 Problem: Slow response times in [component]
🔍 Cause: Inefficient query/algorithm
🛠️ Solution: Optimized [specific optimization]
✅ Tested: Response time improved from [X]ms to [Y]ms
```

### Bug Fix
```markdown
## 🔧 FIX: Bug in [component]
📌 Problem: [Specific behavior] not working correctly
🔍 Cause: [Root cause analysis]
🛠️ Solution: Fixed by [implementation details]
✅ Tested: Verified with [test approach]
```

### Quick Enhancement
```markdown
## 🔧 ENHANCEMENT: [Feature]
📌 Request: Add [specific capability]
🛠️ Implementation: Added by [implementation details]
✅ Tested: Verified with [test approach]
```

## ✅ STREAMLINED VERIFICATION

Level 1 tasks use a minimal verification process:

```markdown
VERIFICATION:
[x] Fix implemented and tested
[x] No regressions introduced
[x] Documentation updated
```

## 🚀 CONSOLIDATED MEMORY BANK UPDATE

Optimize Memory Bank updates for Level 1 tasks by using a single operation:

```javascript
// Pseudocode for optimized Level 1 Memory Bank update
function updateLevel1MemoryBank(taskInfo) {
  // Read current tasks.md
  const tasksContent = readFile("tasks.md");
  
  // Create minimal update
  const updateBlock = `
### Task: ${taskInfo.name}
- Status: Complete
- Implementation: ${taskInfo.solution}
- Link to fix: ${taskInfo.fileReference}
`;
  
  // Add update to tasks.md
  const updatedContent = appendToSection(tasksContent, "Completed Tasks", updateBlock);
  
  // Write in single operation
  writeFile("tasks.md", updatedContent);
  
  return "Memory Bank updated";
}
```

## 🔄 OPTIMIZED LEVEL 1 WORKFLOW EXAMPLE

```markdown
## 🔧 FIX: Login button not working on mobile devices

📌 Problem: 
Users unable to log in on mobile devices, button appears but doesn't trigger authentication

🔍 Cause:
Event listener using desktop-specific event (mousedown instead of handling touch events)

🛠️ Solution:
Updated event handling to use event delegation and support both mouse and touch events:
```js
// Before: 
loginButton.addEventListener('mousedown', handleLogin);

// After:
loginButton.addEventListener('mousedown', handleLogin);
loginButton.addEventListener('touchstart', handleLogin);
```

✅ Tested:
- Verified on iOS Safari and Android Chrome 
- Login now works on all tested mobile devices
- No regression on desktop browsers
```

## ⚡ TOKEN EFFICIENCY BENEFITS

This optimized Level 1 workflow provides:

1. Reduced documentation overhead (70% reduction)
2. Consolidated Memory Bank updates (single operation vs. multiple)
3. Focused verification process (essential checks only)
4. Template-based approach for common scenarios
5. Streamlined workflow with fewer steps

The updated approach maintains all critical information while significantly reducing token usage.

================
File: .cursor/rules/isolation_rules/Level1/quick-documentation.mdc
================
---
description: Quick documentation approach for Level 1 Quick Bug Fix tasks
globs: "**/level1/**", "**/documentation/**"
alwaysApply: false
---

# QUICK DOCUMENTATION FOR LEVEL 1 TASKS

> **TL;DR:** This document outlines a quick documentation approach for Level 1 (Quick Bug Fix) tasks, ensuring that essential information is captured with minimal overhead.

## 🔍 QUICK DOCUMENTATION OVERVIEW

```mermaid
graph TD
    FixComplete["Bug Fix<br>Complete"] --> Document["Document<br>Solution"]
    Document --> UpdateTasks["Update<br>tasks.md"]
    UpdateTasks --> MinimalUpdates["Make Minimal<br>Memory Bank Updates"]
    MinimalUpdates --> CrossReference["Create Simple<br>Cross-References"]
    CrossReference --> Complete["Documentation<br>Complete"]
```

Level 1 tasks require efficient documentation that captures essential information without unnecessary detail. This approach ensures that critical knowledge is preserved while maintaining speed and efficiency.

## 📋 DOCUMENTATION PRINCIPLES

1. **Conciseness**: Keep documentation brief but complete
2. **Focus**: Document only what's necessary to understand the fix
3. **Context**: Provide sufficient context to understand the issue
4. **Solution**: Clearly describe what was changed and why
5. **Findability**: Ensure the fix can be easily found later

## 📋 QUICK FIX DOCUMENTATION TEMPLATE

```markdown
# Quick Fix: [Issue Title]

## Issue
[Brief description of the problem - 1-2 sentences]

## Root Cause
[Concise description of what caused the issue - 1-2 sentences]

## Solution
[Brief description of the fix implemented - 2-3 sentences]

## Files Changed
- [File path 1]
- [File path 2]

## Verification
[How the fix was tested/verified - 1-2 sentences]

## Notes
[Any additional information that might be helpful - optional]
```

## 📋 TASKS.MD UPDATES

For Level 1 tasks, update tasks.md with this format:

```markdown
## Completed Bug Fixes
- [X] [Level 1] Fixed: [Issue title] (Completed: YYYY-MM-DD)
  - Issue: [One-line description]
  - Root Cause: [One-line description]
  - Solution: [One-line description]
  - Files: [File paths]
```

For in-progress tasks:

```markdown
## Bug Fixes in Progress
- [ ] [Level 1] Fix: [Issue title] (Est: XX mins)
  - Issue: [One-line description]
  - Location: [Component/file]
```

## 📋 MEMORY BANK UPDATES

For Level 1 tasks, make these minimal Memory Bank updates:

1. **tasks.md**:
   - Update with fix details as shown above
   - Mark task as complete

2. **activeContext.md** (only if relevant):
   ```markdown
   ## Recent Fixes
   - [YYYY-MM-DD] Fixed [issue] in [component/file]. [One-line description of fix]
   ```

3. **progress.md** (only if significant):
   ```markdown
   ## Bug Fixes
   - [YYYY-MM-DD] Fixed [issue] in [component/file].
   ```

Other Memory Bank files typically do not need updates for Level 1 tasks unless the fix reveals important system information.

## 📋 COMMON BUG CATEGORIES

Categorize bugs to improve documentation consistency:

1. **Logic Error**:
   - Example: "Fixed incorrect conditional logic in user validation"

2. **UI/Display Issue**:
   - Example: "Fixed misaligned button in mobile view"

3. **Performance Issue**:
   - Example: "Fixed slow loading of user profile data"

4. **Data Handling Error**:
   - Example: "Fixed incorrect parsing of date format"

5. **Configuration Issue**:
   - Example: "Fixed incorrect environment variable setting"

## 📋 QUICK DOCUMENTATION PROCESS

Follow these steps for efficient documentation:

1. **Immediately After Fix**:
   - Document while the fix is fresh in your mind
   - Focus on what, why, and how
   - Be specific about changes made

2. **Update Task Tracking**:
   - Update tasks.md with fix details
   - Use consistent format for easy reference

3. **Minimal Cross-References**:
   - Create only essential cross-references
   - Ensure fix can be found in the future

4. **Check Completeness**:
   - Verify all essential information is captured
   - Ensure another developer could understand the fix

## 📋 EXAMPLES: GOOD VS. INSUFFICIENT DOCUMENTATION

### ❌ Insufficient Documentation

```markdown
Fixed the login bug.
```

### ✅ Good Documentation

```markdown
# Quick Fix: User Login Failure with Special Characters

## Issue
Users with special characters in email addresses (e.g., +, %) couldn't log in.

## Root Cause
The email validation regex was incorrectly escaping special characters.

## Solution
Updated the email validation regex in AuthValidator.js to properly handle special characters according to RFC 5322.

## Files Changed
- src/utils/AuthValidator.js

## Verification
Tested login with various special characters in email addresses (test+user@example.com, user%123@example.com).
```

## 📋 DOCUMENTATION VERIFICATION CHECKLIST

```
✓ DOCUMENTATION VERIFICATION
- Issue clearly described? [YES/NO]
- Root cause identified? [YES/NO]
- Solution explained? [YES/NO]
- Files changed listed? [YES/NO]
- Verification method described? [YES/NO]
- tasks.md updated? [YES/NO]
- Memory Bank minimally updated? [YES/NO]

→ If all YES: Documentation complete
→ If any NO: Complete missing information
```

## 📋 MINIMAL MODE DOCUMENTATION

For minimal mode, use this ultra-compact format:

```
✓ FIX: [Issue title]
✓ CAUSE: [One-line root cause]
✓ SOLUTION: [One-line fix description]
✓ FILES: [File paths]
✓ VERIFIED: [How verified]
```

## 🔄 DOCUMENTATION INTEGRATION

Quick documentation integrates with other systems:

```mermaid
graph TD
    QuickDoc["Quick Fix<br>Documentation"] --> TasksMD["tasks.md<br>Update"]
    QuickDoc --> FixDetails["Fix Details<br>Documentation"]
    
    TasksMD --> Tracking["Task<br>Tracking"]
    FixDetails --> Knowledge["Knowledge<br>Preservation"]
    
    Tracking & Knowledge --> Future["Future<br>Reference"]
```

## 🚨 DOCUMENTATION EFFICIENCY PRINCIPLE

Remember:

```
┌─────────────────────────────────────────────────────┐
│ Document ONLY what's needed to understand the fix.  │
│ Focus on ESSENTIAL information that would help      │
│ someone who encounters the same issue in the future.│
└─────────────────────────────────────────────────────┘
```

This ensures that Level 1 tasks are documented efficiently without unnecessary overhead while preserving critical knowledge.

================
File: .cursor/rules/isolation_rules/Level1/workflow-level1.mdc
================
---
description: Streamlined workflow for Level 1 Quick Bug Fix tasks
globs: "**/level1/**", "**/workflow/**"
alwaysApply: false
---
# STREAMLINED WORKFLOW FOR LEVEL 1 TASKS

> **TL;DR:** This document outlines a streamlined workflow for Level 1 (Quick Bug Fix) tasks, focusing on efficient problem resolution with minimal overhead while maintaining adequate documentation.

## 🔍 LEVEL 1 WORKFLOW OVERVIEW

```mermaid
graph LR
    Init["1. INITIALIZATION"] --> Impl["2. IMPLEMENTATION"]
    Impl --> Doc["3. DOCUMENTATION"]
    
    %% Document connections for each phase
    Init -.-> InitDocs["Quick setup<br>Issue understanding"]
    Impl -.-> ImplDocs["Focused fix<br>Verify resolution"]
    Doc -.-> DocDocs["Document solution<br>Update tracking"]
```

## 📋 WORKFLOW PHASES

### Phase 1: INITIALIZATION

```mermaid
graph TD
    Start["Start Level 1 Task"] --> Identify["Identify<br>Issue"]
    Identify --> Understand["Understand<br>Problem"]
    Understand --> Setup["Quick<br>Environment Setup"]
    Setup --> TaskEntry["Create Quick<br>Task Entry"]
    TaskEntry --> InitComplete["Initialization<br>Complete"]
```

**Steps:**
1. Identify the specific issue to fix
2. Understand the problem and its impact
3. Set up environment for quick fix
4. Create minimal task entry in tasks.md

**Milestone Checkpoint:**
```
✓ INITIALIZATION CHECKPOINT
- Issue clearly identified? [YES/NO]
- Problem understood? [YES/NO]
- Environment set up? [YES/NO]
- Task entry created? [YES/NO]

→ If all YES: Proceed to Implementation
→ If any NO: Complete initialization steps
```

### Phase 2: IMPLEMENTATION

```mermaid
graph TD
    Start["Begin<br>Implementation"] --> Locate["Locate<br>Issue Source"]
    Locate --> Develop["Develop<br>Fix"]
    Develop --> Test["Test<br>Solution"]
    Test --> Verify["Verify<br>Resolution"]
    Verify --> ImplComplete["Implementation<br>Complete"]
```

**Steps:**
1. Locate the source of the issue
2. Develop a targeted fix
3. Test the solution thoroughly
4. Verify that the issue is resolved

**Milestone Checkpoint:**
```
✓ IMPLEMENTATION CHECKPOINT
- Issue source located? [YES/NO]
- Fix developed? [YES/NO]
- Solution tested? [YES/NO]
- Resolution verified? [YES/NO]

→ If all YES: Proceed to Documentation
→ If any NO: Complete implementation steps
```

### Phase 3: DOCUMENTATION

```mermaid
graph TD
    Start["Begin<br>Documentation"] --> Update["Update<br>tasks.md"]
    Update --> Solution["Document<br>Solution"]
    Solution --> References["Create Minimal<br>Cross-References"]
    References --> NotifyStakeholders["Notify<br>Stakeholders"]
    NotifyStakeholders --> DocComplete["Documentation<br>Complete"]
```

**Steps:**
1. Update tasks.md with fix details
2. Document the solution concisely
3. Create minimal cross-references
4. Notify stakeholders as needed

**Milestone Checkpoint:**
```
✓ DOCUMENTATION CHECKPOINT
- tasks.md updated? [YES/NO]
- Solution documented? [YES/NO]
- Cross-references created? [YES/NO]
- Stakeholders notified? [YES/NO]

→ If all YES: Task Complete
→ If any NO: Complete documentation steps
```

## 📋 TASK STRUCTURE IN TASKS.MD

For Level 1 tasks, use this minimal structure:

```markdown
## Bug Fixes in Progress
- [ ] [Level 1] Fix: [Bug description] (Est: XX mins)

## Completed Bug Fixes
- [X] [Level 1] Fixed: [Bug description] (Completed: YYYY-MM-DD)
  - Issue: [Brief issue description]
  - Solution: [Brief solution description]
  - Files changed: [File paths]
```

## 📋 MEMORY BANK UPDATES

For Level 1 tasks, make minimal Memory Bank updates:

1. **tasks.md**: Update with fix details
2. **activeContext.md**: Brief mention of fix if relevant
3. **progress.md**: Add to list of completed fixes

## 📋 WORKFLOW VERIFICATION CHECKLIST

```
✓ FINAL WORKFLOW VERIFICATION
- Issue identified and understood? [YES/NO]
- Fix implemented and verified? [YES/NO]
- tasks.md updated? [YES/NO]
- Solution documented? [YES/NO]
- Memory Bank minimally updated? [YES/NO]

→ If all YES: Level 1 Task Successfully Completed
→ If any NO: Address outstanding items
```

## 📋 TASK ESCALATION

If during the Level 1 process you discover the task is more complex:

```
⚠️ TASK ESCALATION NEEDED
Current Level: Level 1
Recommended Level: Level [2/3/4]
Reason: [Brief explanation]

Would you like me to escalate this task to Level [2/3/4]?
```

Escalation indicators:
1. Fix requires changes to multiple components
2. Solution requires design decisions
3. Testing reveals broader issues
4. Fix impacts core functionality

## 🔄 INTEGRATION WITH MEMORY BANK

```mermaid
graph TD
    Workflow["Level 1<br>Workflow"] --> TM["Update<br>tasks.md"]
    Workflow --> AC["Minimal Update<br>activeContext.md"]
    Workflow --> PM["Brief Update<br>progress.md"]
    
    TM & AC & PM --> MB["Memory Bank<br>Integration"]
    MB --> NextTask["Transition to<br>Next Task"]
```

## 🚨 EFFICIENCY PRINCIPLE

Remember:

```
┌─────────────────────────────────────────────────────┐
│ Level 1 workflow prioritizes SPEED and EFFICIENCY.  │
│ Minimize process overhead while ensuring adequate   │
│ documentation of the solution.                     │
└─────────────────────────────────────────────────────┘
```

================
File: .cursor/rules/isolation_rules/Level2/archive-basic.mdc
================
---
description: Basic archiving approach for Level 2 Simple Enhancement tasks
globs: "**/level2/**", "**/archive/**", "**/completion/**"
alwaysApply: false
---

# BASIC ARCHIVING FOR LEVEL 2 TASKS

> **TL;DR:** This document outlines a basic archiving approach for Level 2 (Simple Enhancement) tasks, ensuring that completed work is properly documented and knowledge is preserved with minimal overhead.

## 🔍 ARCHIVING OVERVIEW

Even for Level 2 tasks, proper archiving ensures that completed work is documented and knowledge is preserved. This basic archiving approach provides sufficient structure while maintaining efficiency.

## 📋 ARCHIVING PRINCIPLES

1. **Completion**: Clearly document what was completed
2. **Context**: Preserve the context of the enhancement
3. **Knowledge**: Capture key insights and lessons
4. **Findability**: Make archived information easy to find
5. **References**: Create cross-references to related work

## 📋 BASIC ARCHIVE STRUCTURE

```markdown
# Enhancement Archive: [Feature Name]

## Summary
[Brief summary of the enhancement]

## Date Completed
YYYY-MM-DD

## Key Files Modified
- [File path 1]
- [File path 2]
- [File path 3]

## Requirements Addressed
- [Requirement 1]
- [Requirement 2]
- [Requirement 3]

## Implementation Details
[Brief description of how the enhancement was implemented]

## Testing Performed
- [Test 1]
- [Test 2]
- [Test 3]

## Lessons Learned
- [Lesson 1]
- [Lesson 2]
- [Lesson 3]

## Related Work
- [Link to related task/enhancement 1]
- [Link to related task/enhancement 2]

## Notes
[Any additional information or context]
```

## 📋 ARCHIVE LOCATION

Store archives in an organized structure:

```
docs/
└── archive/
    └── enhancements/
        └── YYYY-MM/
            ├── feature-name-1.md
            └── feature-name-2.md
```

## 📋 ARCHIVING PROCESS

Follow these steps to archive a Level 2 task:

1. **Prepare Archive Content**:
   - Gather all relevant information
   - Fill in the archive template
   - Include all key implementation details

2. **Cross-Reference Creation**:
   - Update tasks.md with link to archive
   - Add reference in progress.md
   - Update activeContext.md with next focus

3. **File Creation and Storage**:
   - Create appropriate directory if needed
   - Save archive file with descriptive name
   - Ensure file follows naming convention

4. **Final Verification**:
   - Check archive for completeness
   - Verify all cross-references
   - Ensure all links are working

## 📋 CROSS-REFERENCE FORMAT

When creating cross-references:

1. **In tasks.md**:
   ```markdown
   ## Completed Enhancements
   - [X] [Feature Name] (YYYY-MM-DD) - [Archive Link](../docs/archive/enhancements/YYYY-MM/feature-name.md)
   ```

2. **In progress.md**:
   ```markdown
   ## Completed Milestones
   - [Feature Name] enhancement completed on YYYY-MM-DD. See [archive entry](../docs/archive/enhancements/YYYY-MM/feature-name.md).
   ```

3. **In activeContext.md**:
   ```markdown
   ## Recently Completed
   - [Feature Name] enhancement is now complete. Archive: [link](../docs/archive/enhancements/YYYY-MM/feature-name.md)
   
   ## Current Focus
   - Moving to [Next Task Name]
   ```

## 📋 ARCHIVING VERIFICATION CHECKLIST

```
✓ ARCHIVE VERIFICATION
- Archive content complete? [YES/NO]
- Archive properly stored? [YES/NO]
- Cross-references created? [YES/NO]
- tasks.md updated? [YES/NO]
- progress.md updated? [YES/NO]
- activeContext.md updated? [YES/NO]

→ If all YES: Archiving complete
→ If any NO: Complete archiving process
```

## 📋 MINIMAL MODE ARCHIVING

For minimal mode, use this format:

```
✓ ARCHIVE: [Feature Name]
✓ DATE: YYYY-MM-DD
✓ FILES: [Key files changed]
✓ SUMMARY: [One-sentence summary]
✓ LESSONS: [Key takeaway]
✓ REFS: [tasks.md, progress.md, activeContext.md]
```

## 🔄 INTEGRATION WITH MEMORY BANK

Archiving integrates with Memory Bank:

```mermaid
graph TD
    Archive["Enhancement<br>Archive"] --> TasksUpdate["Update<br>tasks.md"]
    Archive --> ProgressUpdate["Update<br>progress.md"]
    Archive --> ContextUpdate["Update<br>activeContext.md"]
    
    TasksUpdate & ProgressUpdate & ContextUpdate --> CrossLinks["Create<br>Cross-Links"]
    CrossLinks --> Verify["Verify<br>References"]
```

## 🚨 KNOWLEDGE PRESERVATION PRINCIPLE

Remember:

```
┌─────────────────────────────────────────────────────┐
│ Archive files are a VALUABLE KNOWLEDGE RESOURCE.    │
│ Take care to preserve insights and lessons that     │
│ will benefit future work.                           │
└─────────────────────────────────────────────────────┘
```

This ensures that knowledge is preserved and can be referenced in the future.

================
File: .cursor/rules/isolation_rules/Level2/reflection-basic.mdc
================
---
description: Basic reflection format for Level 2 Simple Enhancement tasks
globs: "**/level2/**", "**/reflection/**"
alwaysApply: false
---

# BASIC REFLECTION FOR LEVEL 2 TASKS

> **TL;DR:** This document outlines a basic reflection approach for Level 2 (Simple Enhancement) tasks, ensuring that key insights and lessons are captured without unnecessary overhead.

## 🔍 REFLECTION OVERVIEW

Reflection is essential for improving future work, even for simpler Level 2 enhancements. This basic reflection approach focuses on key outcomes, challenges, and lessons learned while maintaining efficiency.

## 📋 REFLECTION PRINCIPLES

1. **Honesty**: Accurately represent successes and challenges
2. **Specificity**: Include concrete examples and observations
3. **Insight**: Go beyond surface observations to derive useful insights
4. **Improvement**: Focus on actionable takeaways for future work
5. **Efficiency**: Keep reflection concise and focused on key learnings

## 📋 BASIC REFLECTION STRUCTURE

```markdown
# Level 2 Enhancement Reflection: [Feature Name]

## Enhancement Summary
[Brief one-paragraph summary of the enhancement]

## What Went Well
- [Specific success point 1]
- [Specific success point 2]
- [Specific success point 3]

## Challenges Encountered
- [Specific challenge 1]
- [Specific challenge 2]
- [Specific challenge 3]

## Solutions Applied
- [Solution to challenge 1]
- [Solution to challenge 2]
- [Solution to challenge 3]

## Key Technical Insights
- [Technical insight 1]
- [Technical insight 2]
- [Technical insight 3]

## Process Insights
- [Process insight 1]
- [Process insight 2]
- [Process insight 3]

## Action Items for Future Work
- [Specific action item 1]
- [Specific action item 2]
- [Specific action item 3]

## Time Estimation Accuracy
- Estimated time: [X hours/days]
- Actual time: [Y hours/days]
- Variance: [Z%]
- Reason for variance: [Brief explanation]
```

## 📋 REFLECTION QUALITY

High-quality reflections for Level 2 tasks should:

1. **Provide specific examples** rather than vague statements
2. **Identify concrete takeaways** not general observations
3. **Connect challenges to solutions** with clear reasoning
4. **Analyze estimation accuracy** to improve future planning
5. **Generate actionable improvements** for future work

## 📋 REFLECTION PROCESS

Follow these steps for effective Level 2 task reflection:

1. **Schedule Reflection**:
   - Allocate dedicated time for reflection
   - Complete reflection within 24 hours of task completion

2. **Gather Information**:
   - Review the original task requirements
   - Examine implementation details
   - Consider challenges encountered
   - Review time tracking data

3. **Complete Template**:
   - Fill in all sections of the reflection template
   - Include specific, concrete examples
   - Be honest about challenges

4. **Extract Insights**:
   - Identify patterns in challenges
   - Connect challenges to potential future improvements
   - Consider process improvements

5. **Document Action Items**:
   - Create specific, actionable improvements
   - Link these to future tasks where applicable

6. **Store Reflection**:
   - Save reflection with the task archive
   - Add cross-references to relevant documents

## 📋 EXAMPLES: VAGUE VS. SPECIFIC ENTRIES

### ❌ Vague Entries (Insufficient)

- "The implementation went well."
- "We had some challenges with the code."
- "The feature works as expected."

### ✅ Specific Entries (Sufficient)

- "The modular approach allowed for easy integration with the existing codebase, specifically the clean separation between the UI layer and data processing logic."
- "Challenge: The state management became complex when handling multiple user interactions. Solution: Implemented a more structured reducer pattern with clear actions and state transitions."
- "Action Item: Create a reusable component for file selection that handles all the edge cases we encountered in this implementation."

## 📋 REFLECTION VERIFICATION CHECKLIST

```
✓ REFLECTION VERIFICATION
- All template sections completed? [YES/NO]
- Specific examples provided? [YES/NO]
- Challenges honestly addressed? [YES/NO]
- Concrete solutions documented? [YES/NO]
- Actionable insights generated? [YES/NO]
- Time estimation analyzed? [YES/NO]

→ If all YES: Reflection complete
→ If any NO: Improve reflection quality
```

## 📋 MINIMAL MODE REFLECTION

For minimal mode, use this format:

```
✓ REFLECTION: [Feature Name]
✓ WENT WELL: [Key success]
✓ CHALLENGE: [Key challenge]
✓ SOLUTION: [Key solution]
✓ INSIGHT: [Most important takeaway]
✓ ACTION: [Top priority action item]
✓ TIME: Est [X] vs. Actual [Y] ([Z%] variance)
```

## 🔄 INTEGRATION WITH MEMORY BANK

Reflection integrates with Memory Bank:

```mermaid
graph TD
    Reflection["Enhancement<br>Reflection"] --> Archive["Add to<br>Archive"]
    Reflection --> ProgressUpdate["Update<br>progress.md"]
    Reflection --> ActionItems["Document<br>Action Items"]
    
    ActionItems --> Tasks["Add to<br>tasks.md"]
    Archive & ProgressUpdate & Tasks --> CrossLinks["Create<br>Cross-Links"]
```

## 🚨 CONTINUOUS IMPROVEMENT PRINCIPLE

Remember:

```
┌─────────────────────────────────────────────────────┐
│ Every reflection should produce at least ONE        │
│ actionable improvement for future work.             │
└─────────────────────────────────────────────────────┘
```

This ensures that reflection directly contributes to ongoing improvement of both the product and the process.

================
File: .cursor/rules/isolation_rules/Level2/task-tracking-basic.mdc
================
---
description: Basic task tracking for Level 2 Simple Enhancement tasks
globs: "**/level2/**", "**/tracking/**", "**/task/**"
alwaysApply: false
---

# BASIC TASK TRACKING FOR LEVEL 2

> **TL;DR:** This document outlines a streamlined task tracking approach for Level 2 (Simple Enhancement) tasks. It provides a balanced framework for managing task progress with minimal overhead.

## 🔍 TASK TRACKING OVERVIEW

Level 2 tasks require a more structured tracking approach than Level 1, but don't need the comprehensive tracking of higher-level tasks. This basic tracking system provides sufficient structure while maintaining efficiency.

## 📋 TASK TRACKING PRINCIPLES

1. **Clarity**: Tasks should be clearly defined
2. **Visibility**: Progress should be visible at a glance
3. **Structure**: Break work into logical subtasks
4. **Updates**: Keep progress regularly updated
5. **Completion**: Clearly mark when tasks are done

## 📋 TASK STRUCTURE FOR LEVEL 2

```markdown
## [Feature Name] Enhancement

**Status**: [Not Started/In Progress/Complete]
**Priority**: [High/Medium/Low]
**Estimated Effort**: [Small/Medium/Large]

### Description
[Brief description of the enhancement]

### Requirements
- [Requirement 1]
- [Requirement 2]
- [Requirement 3]

### Subtasks
- [ ] [Subtask 1]
- [ ] [Subtask 2]
- [ ] [Subtask 3]

### Dependencies
- [Dependency 1]
- [Dependency 2]

### Notes
[Any additional information or context]
```

## 📋 TASKS.MD ORGANIZATION

Organize tasks.md with these sections for Level 2 tasks:

```markdown
# Tasks

## Active Enhancements
- [Enhancement 1] - [Status]
- [Enhancement 2] - [Status]

## Enhancement Details
### [Enhancement 1]
[Task structure as above]

### [Enhancement 2]
[Task structure as above]

## Completed Enhancements
- [X] [Completed Enhancement 1] (YYYY-MM-DD)
- [X] [Completed Enhancement 2] (YYYY-MM-DD)
```

## 📋 UPDATING TASK STATUS

Update tasks using this process:

1. **Starting a Task**:
   - Update Status to "In Progress"
   - Add start date to Notes

2. **Progress Updates**:
   - Check off subtasks as completed
   - Add brief notes about progress
   - Update any changed requirements

3. **Completing a Task**:
   - Update Status to "Complete"
   - Check off all subtasks
   - Move to Completed Enhancements
   - Add completion date

## 📋 SUBTASK MANAGEMENT

For Level 2 tasks, subtasks should:

1. Be actionable and specific
2. Represent approximately 30-60 minutes of work
3. Follow a logical sequence
4. Be updated as soon as completed
5. Include verification steps

Example of well-structured subtasks:
```markdown
### Subtasks
- [ ] Review existing implementation of related features
- [ ] Create draft UI design for new button
- [ ] Add HTML structure for new component
- [ ] Implement button functionality in JavaScript
- [ ] Add appropriate styling in CSS
- [ ] Add event handling
- [ ] Test on desktop browsers
- [ ] Test on mobile browsers
- [ ] Update user documentation
```

## 📋 PROGRESS VISUALIZATION

Use progress indicators to show status:

```markdown
### Progress
[###-------] 30% Complete
```

For subtasks:
```markdown
### Subtasks (3/10 Complete)
- [X] Subtask 1
- [X] Subtask 2
- [X] Subtask 3
- [ ] Subtask 4
- [ ] Subtask 5
```

## 📋 TRACKING VERIFICATION CHECKLIST

```
✓ TASK TRACKING VERIFICATION
- Task clearly defined? [YES/NO]
- Requirements listed? [YES/NO]
- Subtasks created? [YES/NO]
- Dependencies identified? [YES/NO]
- Status up-to-date? [YES/NO]

→ If all YES: Task tracking is adequate
→ If any NO: Update task tracking
```

## 📋 MINIMAL MODE TRACKING

For minimal mode, use this format:

```
✓ TASK: [Enhancement name]
✓ STATUS: [In Progress/Complete]
✓ SUBTASKS: [X/Y Complete]
✓ NEXT: [Next action]
```

## 🔄 INTEGRATION WITH MEMORY BANK

Task tracking integrates with Memory Bank:

```mermaid
graph TD
    TasksFile["tasks.md"] --> Active["activeContext.md"]
    TasksFile --> Progress["progress.md"]
    
    Active -->|"Current focus"| TasksFile
    Progress -->|"Completion status"| TasksFile
```

## 🚨 TASKS.MD PRIMACY PRINCIPLE

Remember:

```
┌─────────────────────────────────────────────────────┐
│ tasks.md is the SINGLE SOURCE OF TRUTH for ALL      │
│ task tracking. ALL task updates MUST be reflected   │
│ in tasks.md IMMEDIATELY.                            │
└─────────────────────────────────────────────────────┘
```

This ensures everyone has visibility into current task status at all times.

================
File: .cursor/rules/isolation_rules/Level2/workflow-level2.mdc
================
---
description: Basic workflow for Level 2 Simple Enhancement tasks
globs: "**/level2/**", "**/workflow/**"
alwaysApply: false
---
# WORKFLOW FOR LEVEL 2 TASKS

> **TL;DR:** This document outlines a structured yet efficient workflow for Level 2 (Simple Enhancement) tasks, including 6 key phases with milestone checkpoints and quality verification.

## 🔍 LEVEL 2 WORKFLOW OVERVIEW

```mermaid
graph LR
    Init["1. INITIALIZATION"] --> Doc["2. DOCUMENTATION<br>SETUP"]
    Doc --> Plan["3. TASK<br>PLANNING"]
    Plan --> Impl["4. IMPLEMENTATION"]
    Impl --> Reflect["5. REFLECTION"]
    Reflect --> Archive["6. ARCHIVING"]
    
    %% Document connections for each phase
    Init -.-> InitDocs["INITIALIZATION"]
    Doc -.-> DocDocs["DOCUMENTATION"]
    Plan -.-> PlanDocs["PLANNING"]
    Impl -.-> ImplDocs["IMPLEMENTATION"]
    Reflect -.-> ReflectDocs["REFLECTION"]
    Archive -.-> ArchiveDocs["ARCHIVING"]
```

Level 2 tasks involve simple enhancements that require a structured approach with moderate planning and documentation. This workflow provides the right balance of process and efficiency.

## 📋 WORKFLOW PHASES

### Phase 1: INITIALIZATION

```mermaid
graph TD
    Start["Start Level 2 Task"] --> Platform{"Detect<br>Platform"}
    Platform --> FileCheck["Critical File<br>Verification"]
    FileCheck --> LoadStructure["Load Memory<br>Bank Structure"]
    LoadStructure --> TaskCreation["Create Task<br>in tasks.md"]
    TaskCreation --> SetupComplete["Initialization<br>Complete"]
```

**Steps:**
1. Platform detection
2. Critical file verification
3. Memory Bank structure loading
4. Task creation in tasks.md
5. Initial task scope definition

**Milestone Checkpoint:**
```
✓ INITIALIZATION CHECKPOINT
- Platform detected and configured? [YES/NO]
- Critical files verified? [YES/NO]
- Memory Bank loaded? [YES/NO]
- Task created in tasks.md? [YES/NO]
- Initial scope defined? [YES/NO]

→ If all YES: Proceed to Documentation Setup
→ If any NO: Complete initialization steps
```

### Phase 2: DOCUMENTATION SETUP

```mermaid
graph TD
    Start["Begin Documentation<br>Setup"] --> LoadTemplate["Load Basic<br>Documentation Templates"]
    LoadTemplate --> UpdateProject["Update<br>projectbrief.md"]
    UpdateProject --> UpdateContext["Update<br>activeContext.md"]
    UpdateContext --> SetupComplete["Documentation<br>Setup Complete"]
```

**Steps:**
1. Load basic documentation templates
2. Update projectbrief.md with enhancement details
3. Update activeContext.md with current focus
4. Create minimal documentation structure

**Milestone Checkpoint:**
```
✓ DOCUMENTATION CHECKPOINT
- Documentation templates loaded? [YES/NO]
- projectbrief.md updated? [YES/NO]
- activeContext.md updated? [YES/NO]
- Documentation structure created? [YES/NO]

→ If all YES: Proceed to Task Planning
→ If any NO: Complete documentation setup
```

### Phase 3: TASK PLANNING

```mermaid
graph TD
    Start["Begin Task<br>Planning"] --> Requirements["Define Clear<br>Requirements"]
    Requirements --> SubTasks["Break Down<br>Into Subtasks"]
    SubTasks --> TasksUpdate["Update tasks.md<br>With Subtasks"]
    TasksUpdate --> TimeEstimate["Create Time<br>Estimates"]
    TimeEstimate --> PlanComplete["Planning<br>Complete"]
```

**Steps:**
1. Define clear requirements
2. Break down into subtasks
3. Update tasks.md with subtasks
4. Create time estimates
5. Document dependencies and constraints

**Milestone Checkpoint:**
```
✓ PLANNING CHECKPOINT
- Requirements clearly defined? [YES/NO]
- Task broken down into subtasks? [YES/NO]
- tasks.md updated with subtasks? [YES/NO]
- Time estimates created? [YES/NO]
- Dependencies documented? [YES/NO]

→ If all YES: Proceed to Implementation
→ If any NO: Complete planning steps
```

### Phase 4: IMPLEMENTATION

```mermaid
graph TD
    Start["Begin<br>Implementation"] --> SubTask1["Complete<br>Subtask 1"]
    SubTask1 --> UpdateStatus1["Update Status<br>in tasks.md"]
    UpdateStatus1 --> SubTask2["Complete<br>Subtask 2"]
    SubTask2 --> UpdateStatus2["Update Status<br>in tasks.md"]
    UpdateStatus2 --> FinalSubTask["Complete<br>Final Subtask"]
    FinalSubTask --> Verification["Perform<br>Verification"]
    Verification --> ImplComplete["Implementation<br>Complete"]
```

**Steps:**
1. Implement first subtask
2. Update status in tasks.md
3. Implement remaining subtasks
4. Regular status updates after each subtask
5. Verify complete implementation

**Milestone Checkpoint:**
```
✓ IMPLEMENTATION CHECKPOINT
- All subtasks completed? [YES/NO]
- Status updates maintained? [YES/NO]
- Enhancement fully implemented? [YES/NO]
- Basic verification performed? [YES/NO]
- tasks.md fully updated? [YES/NO]

→ If all YES: Proceed to Reflection
→ If any NO: Complete implementation steps
```

### Phase 5: REFLECTION

```mermaid
graph TD
    Start["Begin<br>Reflection"] --> Template["Load Reflection<br>Template"]
    Template --> Review["Review Completed<br>Enhancement"]
    Review --> Document["Document Successes<br>and Challenges"]
    Document --> Insights["Extract Key<br>Insights"]
    Insights --> Actions["Define Action<br>Items"]
    Actions --> ReflectComplete["Reflection<br>Complete"]
```

**Steps:**
1. Load reflection template
2. Review completed enhancement
3. Document successes and challenges
4. Extract key insights
5. Define action items for future work

**Milestone Checkpoint:**
```
✓ REFLECTION CHECKPOINT
- Reflection template loaded? [YES/NO]
- Enhancement reviewed? [YES/NO]
- Successes and challenges documented? [YES/NO]
- Key insights extracted? [YES/NO]
- Action items defined? [YES/NO]

→ If all YES: Proceed to Archiving
→ If any NO: Complete reflection steps
```

### Phase 6: ARCHIVING

```mermaid
graph TD
    Start["Begin<br>Archiving"] --> Template["Load Archive<br>Template"]
    Template --> Gather["Gather Implementation<br>Details"]
    Gather --> Create["Create Archive<br>Document"]
    Create --> CrossRef["Create Cross-<br>References"]
    CrossRef --> Update["Update Memory<br>Bank Files"]
    Update --> ArchiveComplete["Archiving<br>Complete"]
```

**Steps:**
1. Load archive template
2. Gather implementation details
3. Create archive document
4. Create cross-references
5. Update Memory Bank files

**Milestone Checkpoint:**
```
✓ ARCHIVING CHECKPOINT
- Archive template loaded? [YES/NO]
- Implementation details gathered? [YES/NO]
- Archive document created? [YES/NO]
- Cross-references created? [YES/NO]
- Memory Bank files updated? [YES/NO]

→ If all YES: Task Complete
→ If any NO: Complete archiving steps
```

## 📋 WORKFLOW VERIFICATION CHECKLIST

```
✓ FINAL WORKFLOW VERIFICATION
- All phases completed? [YES/NO]
- All milestone checkpoints passed? [YES/NO]
- tasks.md fully updated? [YES/NO]
- Reflection document created? [YES/NO]
- Archive document created? [YES/NO]
- Memory Bank fully updated? [YES/NO]

→ If all YES: Level 2 Task Successfully Completed
→ If any NO: Address outstanding items
```

## 📋 MINIMAL MODE WORKFLOW

For minimal mode, use this streamlined workflow:

```
1. INIT: Verify environment, create task entry
2. DOCS: Update projectbrief and activeContext
3. PLAN: Define requirements, subtasks, estimates
4. IMPL: Complete subtasks, update status
5. REFLECT: Document key insights and actions
6. ARCHIVE: Document completion and cross-reference
```

## 🔄 LEVEL TRANSITION HANDLING

```mermaid
graph TD
    L2["Level 2 Task"] --> Assess["Continuous<br>Assessment"]
    
    Assess --> Down["Downgrade to<br>Level 1"]
    Assess --> Up["Upgrade to<br>Level 3/4"]
    
    Down --> L1Trigger["Triggers:<br>- Simpler than expected<br>- Quick fix possible<br>- Single component"]
    
    Up --> L34Trigger["Triggers:<br>- More complex<br>- Multiple components<br>- Design needed"]
    
    L1Trigger --> L1Switch["Switch to<br>Level 1 Workflow"]
    L34Trigger --> L34Switch["Switch to<br>Level 3/4 Workflow"]
```

## 🔄 INTEGRATION WITH MEMORY BANK

```mermaid
graph TD
    Workflow["Level 2<br>Workflow"] --> PB["Update<br>projectbrief.md"]
    Workflow --> AC["Update<br>activeContext.md"]
    Workflow --> TM["Maintain<br>tasks.md"]
    Workflow --> PM["Update<br>progress.md"]
    
    PB & AC & TM & PM --> MB["Memory Bank<br>Integration"]
    MB --> NextTask["Transition to<br>Next Task"]
```

## 🚨 EFFICIENCY PRINCIPLE

Remember:

```
┌─────────────────────────────────────────────────────┐
│ Level 2 workflow balances PROCESS with EFFICIENCY.  │
│ Follow the structure but avoid unnecessary overhead. │
└─────────────────────────────────────────────────────┘
```

This ensures that simple enhancements are implemented with the right level of documentation and process.

================
File: .cursor/rules/isolation_rules/Level3/archive-intermediate.mdc
================
---
description: 
globs: archive-intermediate.mdc
alwaysApply: false
---

# LEVEL 3 ARCHIVE: INTERMEDIATE FEATURE DOCUMENTATION

> **TL;DR:** This guide outlines the archiving process for a completed Level 3 intermediate feature. The aim is to create a self-contained, easily accessible record of the feature's development lifecycle, including its planning, design decisions, implementation summary, and reflection.

## 🚀 Before You Start Archiving (L3 Pre-Archive Checklist)

1.  **Confirm Reflection Complete:** Verify in `memory-bank/tasks.md` that the reflection phase for this feature is marked as complete and `memory-bank/reflection-[feature_id].md` exists and is finalized.
2.  **Gather All Feature-Specific Documents:**
    * The feature plan section from `memory-bank/tasks.md` (or a copy of it).
    * All `memory-bank/creative/creative-[aspect_name].md` documents related to this feature.
    * The `memory-bank/reflection/reflection-[feature_id].md` document.
    * Key diagrams or architectural notes from `memory-bank/progress.md` if not captured elsewhere.
    * A link to the primary commit(s) or feature branch merge for the implemented code.

## 📦 Level 3 Archiving Workflow

```mermaid
graph TD
    StartArchive["Start L3 Archiving"] -->
    VerifyReflect["1. Verify Reflection Complete<br>Check `tasks.md` & `reflection-[feature_id].md`"] -->
    GatherDocs["2. Gather All Feature Documents<br>(Plan, Creative outputs, Reflection, Code links)"] -->
    CreateArchiveFile["3. Create Feature Archive File<br>e.g., `memory-bank/archive/feature-[FeatureNameOrID]_YYYYMMDD.md`"] -->
    PopulateArchive["4. Populate Archive File<br>(Using L3 Archive Template below)"] -->
    VerifyLinks["5. Verify All Internal Links<br>in Archive File are Correct"] -->
    FinalUpdateTasks["6. Final Update to `tasks.md`<br>(Mark Feature FULLY COMPLETED & ARCHIVED, link to archive file)"] -->
    UpdateProgressFile["7. Add Final Entry to `progress.md`<br>(Note archiving & link to archive file)"] -->
    ClearActiveCtx["8. Clear `activeContext.md`<br>Reset for Next Task/Project"] -->
    ArchiveDone["L3 Archiving Complete<br>Feature successfully documented and closed."]

    style StartArchive fill:#90a4ae,stroke:#607d8b
    style ArchiveDone fill:#b0bec5,stroke:#90a4ae
````

## 📝 Structure for `memory-bank/archive/feature-[FeatureNameOrID]_YYYYMMDD.md`

  * **Feature Title:** (e.g., "Archive: User Profile Feature - Avatar Upload Enhancement")
  * **Feature ID (from `tasks.md`):**
  * **Date Archived:** YYYY-MM-DD
  * **Status:** COMPLETED & ARCHIVED
  * **1. Feature Overview:**
      * Brief description of the feature and its purpose (can be extracted from `tasks.md` or `projectbrief.md`).
      * Link to the original task entry/plan in `tasks.md` (if `tasks.md` is versioned or kept historically).
  * **2. Key Requirements Met:**
      * List the main functional and non-functional requirements this feature addressed.
  * **3. Design Decisions & Creative Outputs:**
      * Summary of key design choices.
      * Direct links to all relevant `memory-bank/creative/creative-[aspect_name].md` documents.
      * Link to `memory-bank/style-guide.md` version used (if applicable).
  * **4. Implementation Summary:**
      * High-level overview of how the feature was implemented.
      * List of primary new components/modules created.
      * Key technologies or libraries utilized specifically for this feature.
      * Link to the main feature branch merge commit or primary code location/pull request.
  * **5. Testing Overview:**
      * Brief summary of the testing strategy employed for this feature (unit, integration, E2E).
      * Outcome of the testing.
  * **6. Reflection & Lessons Learned:**
      * Direct link to `memory-bank/reflection/reflection-[feature_id].md`.
      * Optionally, copy 1-2 most critical lessons directly into the archive summary.
  * **7. Known Issues or Future Considerations (Optional, if any remaining from reflection):**
      * Any minor known issues deferred.
      * Potential future enhancements related to this feature.

### Key Files and Components Affected (from tasks.md)
[Summary or direct copy of file/component checklists from the original tasks.md for this project. This provides a quick reference to the scope of changes at a component/file level.]

## 📌 What to Emphasize in L3 Archiving

  * **Self-Contained Feature Record:** The goal is to have a go-to document in the archive that summarizes the "story" of this feature.
  * **Traceability:** Easy navigation from the archive summary to detailed planning, design, and reflection documents.
  * **Maintainability Focus:** Information that would help a future developer understand, maintain, or build upon this specific feature.
  * **Not a Full System Archive:** Unlike Level 4, this is not about archiving the entire application state, but rather the lifecycle of one significant feature.

================
File: .cursor/rules/isolation_rules/Level3/implementation-intermediate.mdc
================
---
description: 
globs: implementation-intermediate.mdc
alwaysApply: false
---
# LEVEL 3 IMPLEMENTATION: BUILDING INTERMEDIATE FEATURES

> **TL;DR:** This guide focuses on the systematic implementation of a planned and designed Level 3 feature. It emphasizes modular development, strict adherence to creative decisions and the style guide, integration with existing systems, and thorough feature-specific testing.

## 🛠️ Level 3 Feature Implementation Workflow

This workflow outlines the typical steps for building an intermediate feature.

```mermaid
graph TD
    StartImpl["Start L3 Implementation"] -->
    ReviewDocs["1. Review All Relevant Docs<br>(Tasks, Creative Docs, Style Guide)"] -->
    SetupEnv["2. Setup/Verify Dev Environment<br>(Branch, Tools, Dependencies)"] -->
    ModuleBreakdown["3. Break Down Feature into Modules/Major Components<br>(Based on plan in `tasks.md`)"] -->
    BuildIterate["4. Implement Modules/Components Iteratively"]

    BuildIterate --> ImplementModule["4a. Select Next Module/Component"]
    ImplementModule --> CodeModule["4b. Code Module<br>(Adhere to design, style guide, coding standards)"]
    CodeModule --> UnitTests["4c. Write & Pass Unit Tests"]
    UnitTests --> SelfReview["4d. Self-Review/Code Linting"]
    SelfReview --> MoreModules{"4e. More Modules<br>for this Feature?"}
    MoreModules -- Yes --> ImplementModule

    MoreModules -- No --> IntegrateModules["5. Integrate All Feature Modules/Components"]
    IntegrateModules --> IntegrationTesting["6. Perform Integration Testing<br>(Feature modules + existing system parts)"]
    IntegrationTesting --> E2EFeatureTesting["7. End-to-End Feature Testing<br>(Validate against user stories & requirements)"]
    E2EFeatureTesting --> AccessibilityCheck["8. Accessibility & Responsiveness Check<br>(If UI is involved)"]
    AccessibilityCheck --> CodeCleanup["9. Code Cleanup & Refinement"]
    CodeCleanup --> UpdateMB["10. Update Memory Bank<br>(`tasks.md` sub-tasks, `progress.md` details)"]
    UpdateMB --> FinalFeatureReview["11. Final Feature Review (Conceptual Peer Review if possible)"]
    FinalFeatureReview --> ImplementationDone["L3 Implementation Complete<br>Ready for REFLECT Mode"]

    style StartImpl fill:#e57373,stroke:#f44336
    style BuildIterate fill:#ffcdd2,stroke:#ef9a9a
    style ImplementationDone fill:#ef9a9a,stroke:#e57373
````

## 🔑 Key Considerations for Level 3 Implementation

  * **Modularity & Encapsulation:** Design and build the feature in well-defined, reusable, and loosely coupled modules or components.
  * **Adherence to Design:** Strictly follow the decisions documented in `memory-bank/creative-*.md` files and the `memory-bank/style-guide.md`. Deviations must be justified and documented.
  * **State Management:** If the feature introduces or significantly interacts with complex application state, ensure the state management strategy (potentially defined in CREATIVE mode) is correctly implemented and tested.
  * **API Interactions:**
      * If consuming new or existing APIs, ensure requests and responses are handled correctly, including error states.
      * If exposing new API endpoints as part of the feature, ensure they are robust, secure, and documented.
  * **Error Handling:** Implement user-friendly error messages and robust error handling within the feature's scope.
  * **Performance:** Be mindful of performance implications. Avoid common pitfalls like N+1 database queries, inefficient algorithms, or large asset loading without optimization, especially if identified as a concern in the PLAN or CREATIVE phase.
  * **Security:** Implement with security best practices in mind, particularly for features handling user input, authentication, or sensitive data. Refer to any security design decisions from CREATIVE mode.

## 🧪 Testing Focus for Level 3 Features

  * **Unit Tests:** Each new function, method, or logical unit within the feature's components should have corresponding unit tests. Aim for good coverage of core logic and edge cases.
  * **Component Tests (for UI features):** Test UI components in isolation, verifying rendering, props handling, and event emissions.
  * **Integration Tests:** Crucial for L3. Test how the different modules/components of the new feature work together. Also, test how the completed feature integrates with existing parts of the application it interacts with.
  * **User Scenario / Acceptance Tests (Feature-Specific):** Validate that the feature fulfills its defined requirements and user stories from the user's perspective. This can be manual or automated.

## 📝 Documentation During Implementation

  * **`memory-bank/tasks.md`:** Update the status of sub-tasks related to the feature as they are completed. Note any blockers or changes in estimates.
  * **`memory-bank/progress.md`:** Make regular entries detailing:
      * Modules/components completed.
      * Key decisions made during implementation (if minor and not warranting a full CREATIVE cycle).
      * Files significantly modified
      * Test results for major integration points.
      * Any deviations from the plan or creative designs, with rationale.
  * **Code Comments:** Write clear, concise comments explaining complex logic, assumptions, or TODOs.
  * **READMEs (if applicable):** If the feature introduces new modules or libraries that require specific setup or usage notes, consider adding or updating relevant README files.

================
File: .cursor/rules/isolation_rules/Level3/planning-comprehensive.mdc
================
---
description: planning comprehensive
globs: planning-comprehensive.mdc
alwaysApply: false
---
# LEVEL 3 COMPREHENSIVE PLANNING

> **TL;DR:** This document provides structured planning guidelines for Level 3 (Intermediate Feature) tasks, focusing on comprehensive planning with creative phases and clear implementation strategies.

## 🏗️ PLANNING WORKFLOW

```mermaid
graph TD
    Start["Planning Start"] --> Req["📋 Requirements<br>Analysis"]
    Req --> Comp["🔍 Component<br>Analysis"]
    Comp --> Design["🎨 Design<br>Decisions"]
    Design --> Impl["⚙️ Implementation<br>Strategy"]
    Impl --> Test["🧪 Testing<br>Strategy"]
    Test --> Doc["📚 Documentation<br>Plan"]
    
    Design --> Creative["Creative Phases:"]
    Creative --> UI["UI/UX Design"]
    Creative --> Arch["Architecture"]
    Creative --> Algo["Algorithm"]
    
    style Start fill:#4da6ff,stroke:#0066cc,color:white
    style Req fill:#ffa64d,stroke:#cc7a30,color:white
    style Comp fill:#4dbb5f,stroke:#36873f,color:white
    style Design fill:#d94dbb,stroke:#a3378a,color:white
    style Impl fill:#4dbbbb,stroke:#368787,color:white
    style Test fill:#d971ff,stroke:#a33bc2,color:white
    style Doc fill:#ff71c2,stroke:#c23b8a,color:white
```

## 🔄 LEVEL TRANSITION HANDLING

```mermaid
graph TD
    L3["Level 3 Task"] --> Assess["Continuous<br>Assessment"]
    
    Assess --> Down["Downgrade to<br>Level 1/2"]
    Assess --> Up["Upgrade to<br>Level 4"]
    
    Down --> L12Trigger["Triggers:<br>- Simpler than expected<br>- Limited scope<br>- Few components"]
    
    Up --> L4Trigger["Triggers:<br>- System-wide impact<br>- Architectural changes<br>- High complexity"]
    
    L12Trigger --> L12Switch["Switch to<br>Level 1/2 Workflow"]
    L4Trigger --> L4Switch["Switch to<br>Level 4 Workflow"]
```

## 📋 PLANNING TEMPLATE

```markdown
# Feature Planning Document

## Requirements Analysis
- Core Requirements:
  - [ ] Requirement 1
  - [ ] Requirement 2
- Technical Constraints:
  - [ ] Constraint 1
  - [ ] Constraint 2

## Component Analysis
- Affected Components:
  - Component 1
    - Changes needed:
    - Dependencies:
  - Component 2
    - Changes needed:
    - Dependencies:

## Design Decisions
- Architecture:
  - [ ] Decision 1
  - [ ] Decision 2
- UI/UX:
  - [ ] Design 1
  - [ ] Design 2
- Algorithms:
  - [ ] Algorithm 1
  - [ ] Algorithm 2

## Implementation Strategy
1. Phase 1:
   - [ ] Task 1
   - [ ] Task 2
2. Phase 2:
   - [ ] Task 3
   - [ ] Task 4

## Testing Strategy
- Unit Tests:
  - [ ] Test 1
  - [ ] Test 2
- Integration Tests:
  - [ ] Test 3
  - [ ] Test 4

## Documentation Plan
- [ ] API Documentation
- [ ] User Guide Updates
- [ ] Architecture Documentation
```

## 🎨 CREATIVE PHASE IDENTIFICATION

```mermaid
graph TD
    subgraph "CREATIVE PHASES REQUIRED"
    UI["🎨 UI/UX Design<br>Required: Yes/No"]
    Arch["🏗️ Architecture Design<br>Required: Yes/No"]
    Algo["⚙️ Algorithm Design<br>Required: Yes/No"]
    end
    
    UI --> UITrig["Triggers:<br>- New UI Component<br>- UX Flow Change"]
    Arch --> ArchTrig["Triggers:<br>- System Structure Change<br>- New Integration"]
    Algo --> AlgoTrig["Triggers:<br>- Performance Critical<br>- Complex Logic"]
    
    style UI fill:#4dbb5f,stroke:#36873f,color:white
    style Arch fill:#ffa64d,stroke:#cc7a30,color:white
    style Algo fill:#d94dbb,stroke:#a3378a,color:white
```

## ✅ VERIFICATION CHECKLIST

```mermaid
graph TD
    subgraph "PLANNING VERIFICATION"
    R["Requirements<br>Complete"]
    C["Components<br>Identified"]
    D["Design Decisions<br>Made"]
    I["Implementation<br>Plan Ready"]
    T["Testing Strategy<br>Defined"]
    Doc["Documentation<br>Plan Ready"]
    end
    
    R --> C --> D --> I --> T --> Doc
    
    style R fill:#4dbb5f,stroke:#36873f,color:white
    style C fill:#ffa64d,stroke:#cc7a30,color:white
    style D fill:#d94dbb,stroke:#a3378a,color:white
    style I fill:#4dbbbb,stroke:#368787,color:white
    style T fill:#d971ff,stroke:#a33bc2,color:white
    style Doc fill:#ff71c2,stroke:#c23b8a,color:white
```

## 🔄 IMPLEMENTATION PHASES

```mermaid
graph LR
    Setup["🛠️ Setup"] --> Core["⚙️ Core<br>Implementation"]
    Core --> UI["🎨 UI<br>Implementation"]
    UI --> Test["🧪 Testing"]
    Test --> Doc["📚 Documentation"]
    
    style Setup fill:#4da6ff,stroke:#0066cc,color:white
    style Core fill:#4dbb5f,stroke:#36873f,color:white
    style UI fill:#ffa64d,stroke:#cc7a30,color:white
    style Test fill:#d94dbb,stroke:#a3378a,color:white
    style Doc fill:#4dbbbb,stroke:#368787,color:white
```

## 🔄 INTEGRATION WITH MEMORY BANK

```mermaid
graph TD
    L3["Level 3<br>Task"] --> PB["Comprehensive<br>projectbrief.md"]
    L3 --> AC["Detailed<br>activeContext.md"]
    L3 --> TM["Structured<br>tasks.md"]
    L3 --> PM["Detailed<br>progress.md"]
    
    PB & AC & TM & PM --> MB["Memory Bank<br>Integration"]
    MB --> NextPhase["Proceed to<br>Implementation"]
```

## 🚨 PLANNING EFFICIENCY PRINCIPLE

Remember:

```
┌─────────────────────────────────────────────────────┐
│ Level 3 planning requires COMPREHENSIVE DESIGN but   │
│ should avoid OVER-ENGINEERING. Focus on delivering  │
│ maintainable, well-documented features.            │
└─────────────────────────────────────────────────────┘
```

================
File: .cursor/rules/isolation_rules/Level3/reflection-intermediate.mdc
================
---
description: 
globs: reflection-intermediate.mdc
alwaysApply: false
---
# LEVEL 3 REFLECTION: INTERMEDIATE FEATURE REVIEW

> **TL;DR:** This guide structures the reflection process for a completed Level 3 intermediate feature. The focus is on a detailed review of the entire feature development lifecycle, from planning and design through implementation and testing, to extract meaningful lessons and identify improvements for future feature work.

## 🔍 Level 3 Reflection Process

The goal is to create a comprehensive `memory-bank/reflection/reflection-[feature_id].md` document.

```mermaid
graph TD
    StartReflect["Start L3 Reflection"] -->
    ReviewDocs["1. Review All Gathered Documentation"] -->
    AssessOutcome["2. Assess Overall Feature Outcome<br>Did it meet all requirements from tasks.md? Was it successful?"] -->
    AnalyzePlan["3. Analyze Planning Phase Effectiveness<br>Was planning-comprehensive.mdc guidance effective? Was the plan accurate? Scope creep?"] -->
    AnalyzeCreative["4. Analyze Creative Phase(s) Effectiveness<br>Were design decisions sound? Did they translate well to implementation? Issues?"] -->
    AnalyzeImpl["5. Analyze Implementation Phase<br>What went well? Challenges? Bottlenecks? Adherence to design/style guide?"] -->
    AnalyzeTesting["6. Analyze Testing Phase<br>Were tests adequate? Bugs found post-release (if applicable)? Test coverage feel right?"] -->
    IdentifyLessons["7. Identify Key Lessons Learned<br>(Technical, Process, Teamwork, Estimation)"] -->
    ProposeImprovements["8. Propose Actionable Improvements<br>For future L3 feature development"] -->
    DraftReflectionDoc["9. Draft `reflection-[feature_id].md`<br>Using structured template"] -->
    FinalizeReflection["10. Finalize & Save Reflection Document"] -->
    UpdateTasksStatus["11. Update `tasks.md`<br>Mark L3 Reflection Complete"] -->
    ReflectionDone["L3 Reflection Complete<br>Ready for ARCHIVE Mode"]

    style StartReflect fill:#ba68c8,stroke:#9c27b0
    style ReflectionDone fill:#d1c4e9,stroke:#b39ddb
````

## 📝 Structure for `memory-bank/reflection-[feature_id].md`

  * **Feature Name & ID:**
  * **Date of Reflection:**
  * **Brief Feature Summary:** (What was built?)
  * **1. Overall Outcome & Requirements Alignment:**
      * How well did the final feature meet the initial requirements?
      * Were there any deviations from the original scope? If so, why?
      * What is the overall assessment of the feature's success?
  * **2. Planning Phase Review:**
      * How effective was the guidance from `Level3/planning-comprehensive.mdc`?
      * Was the initial plan in `tasks.md` (component breakdown, strategy, risks) accurate and helpful?
      * What could have been planned better? Were estimations (if made) accurate?
  * **3. Creative Phase(s) Review (if applicable):**
      * Were the right aspects flagged for CREATIVE mode?
      * How effective were the design decisions made in `creative-*.md` documents?
      * Did these designs translate well into practical implementation? Any friction points?
      * Was `memory-bank/style-guide.md` clear and sufficient for UI aspects?
  * **4. Implementation Phase Review:**
      * What were the major successes during implementation? (e.g., efficient module development, good use of libraries)
      * What were the biggest challenges or roadblocks? How were they overcome?
      * Were there any unexpected technical difficulties or complexities?
      * How was adherence to the style guide and coding standards?
  * **5. Testing Phase Review:**
      * Was the testing strategy (unit, integration, E2E for the feature) effective?
      * Did testing uncover significant issues early enough?
      * What could improve the testing process for similar features?
  * **6. What Went Well? (Highlight 3-5 key positives across all phases for this feature)**
  * **7. What Could Have Been Done Differently? (Identify 3-5 areas for improvement)**
  * **8. Key Lessons Learned:**
      * **Technical:** New insights about technologies, patterns, or architecture used for this feature.
      * **Process:** Insights about the L3 workflow, communication, task management.
      * **Estimation (if applicable):** Lessons about estimating work for features of this scale.
  * **9. Actionable Improvements for Future L3 Features:** (Specific suggestions)

## 🎯 Focus Areas for L3 Reflection

  * **Feature Scope Management:** Was the scope well-defined and managed?
  * **Integration Complexity:** Challenges or successes in integrating the feature with the existing application.
  * **Design-to-Implementation Fidelity:** How closely did the final product match the designs?
  * **Cross-Component Impact:** Understanding the ripple effects of the feature.

================
File: .cursor/rules/isolation_rules/Level3/task-tracking-intermediate.mdc
================
---
description: task tracking intermediate
globs: task-tracking-intermediate.mdc
alwaysApply: false
---
# LEVEL 3 INTERMEDIATE TASK TRACKING

> **TL;DR:** This document provides structured task tracking guidelines for Level 3 (Intermediate Feature) tasks, using visual tracking elements and clear checkpoints.

## 🔍 TASK TRACKING WORKFLOW

```mermaid
graph TD
    Start["Task Start"] --> Init["📋 Initialize<br>Task Entry"]
    Init --> Struct["🏗️ Create Task<br>Structure"]
    Struct --> Track["📊 Progress<br>Tracking"]
    Track --> Update["🔄 Regular<br>Updates"]
    Update --> Complete["✅ Task<br>Completion"]
    
    Struct --> Components["Components:"]
    Components --> Req["Requirements"]
    Components --> Steps["Implementation<br>Steps"]
    Components --> Creative["Creative Phase<br>Markers"]
    Components --> Check["Checkpoints"]
    
    Track --> Status["Track Status:"]
    Status --> InProg["🔄 In Progress"]
    Status --> Block["⛔ Blocked"]
    Status --> Done["✅ Complete"]
    Status --> Skip["⏭️ Skipped"]
    
    style Start fill:#4da6ff,stroke:#0066cc,color:white
    style Init fill:#ffa64d,stroke:#cc7a30,color:white
    style Struct fill:#4dbb5f,stroke:#36873f,color:white
    style Track fill:#d94dbb,stroke:#a3378a,color:white
    style Update fill:#4dbbbb,stroke:#368787,color:white
    style Complete fill:#d971ff,stroke:#a33bc2,color:white
```

## 📋 TASK ENTRY TEMPLATE

```markdown
# [Task Title]

## Requirements
- [ ] Requirement 1
- [ ] Requirement 2
- [ ] Requirement 3

## Components Affected
- Component 1
- Component 2
- Component 3

## Implementation Steps
1. [ ] Step 1
2. [ ] Step 2
3. [ ] Step 3

## Creative Phases Required
- [ ] 🎨 UI/UX Design
- [ ] 🏗️ Architecture Design
- [ ] ⚙️ Algorithm Design

## Checkpoints
- [ ] Requirements verified
- [ ] Creative phases completed
- [ ] Implementation tested
- [ ] Documentation updated

## Current Status
- Phase: [Current Phase]
- Status: [In Progress/Blocked/Complete]
- Blockers: [If any]
```

## 🔄 PROGRESS TRACKING VISUALIZATION

```mermaid
graph TD
    subgraph "TASK PROGRESS"
    P1["✓ Requirements<br>Defined"]
    P2["✓ Components<br>Identified"]
    P3["→ Creative Phase<br>In Progress"]
    P4["□ Implementation"]
    P5["□ Testing"]
    P6["□ Documentation"]
    end
    
    style P1 fill:#4dbb5f,stroke:#36873f,color:white
    style P2 fill:#4dbb5f,stroke:#36873f,color:white
    style P3 fill:#ffa64d,stroke:#cc7a30,color:white
    style P4 fill:#d94dbb,stroke:#a3378a,color:white
    style P5 fill:#4dbbbb,stroke:#368787,color:white
    style P6 fill:#d971ff,stroke:#a33bc2,color:white
```

## ✅ UPDATE PROTOCOL

```mermaid
sequenceDiagram
    participant Task as Task Entry
    participant Status as Status Update
    participant Creative as Creative Phase
    participant Implementation as Implementation
    
    Task->>Status: Update Progress
    Status->>Creative: Flag for Creative Phase
    Creative->>Implementation: Complete Design
    Implementation->>Status: Update Status
    Status->>Task: Mark Complete
```

## 🎯 CHECKPOINT VERIFICATION

| Phase | Verification Items | Status |
|-------|-------------------|--------|
| Requirements | All requirements documented | [ ] |
| Components | Affected components listed | [ ] |
| Creative | Design decisions documented | [ ] |
| Implementation | Code changes tracked | [ ] |
| Testing | Test results recorded | [ ] |
| Documentation | Updates completed | [ ] |

## 🔄 DOCUMENT MANAGEMENT

```mermaid
graph TD
    Current["Current Documents"] --> Active["Active:<br>- task-tracking-intermediate.md<br>- planning-comprehensive.md"]
    Current --> Required["Required Next:<br>- creative-phase-enforcement.md<br>- implementation-phase-reference.md"]
    
    style Current fill:#4da6ff,stroke:#0066cc,color:white
    style Active fill:#4dbb5f,stroke:#36873f,color:white
    style Required fill:#ffa64d,stroke:#cc7a30,color:white
```

================
File: .cursor/rules/isolation_rules/Level3/workflow-level3.mdc
================
---
description: Defines the standard workflow for Level 3 (Intermediate Feature) tasks, guiding through comprehensive planning, targeted creative design, structured implementation, detailed reflection, and feature-specific archiving.
globs: workflow-level3.mdc
alwaysApply: false
---

# LEVEL 3 WORKFLOW: INTERMEDIATE FEATURE DEVELOPMENT

> **TL;DR:** This document outlines a structured workflow for Level 3 (Intermediate Feature) tasks. These tasks involve developing significant new functionality that may span multiple components, requiring comprehensive planning, often necessitating targeted creative design phases, followed by systematic implementation, in-depth reflection, and feature-specific archiving. This workflow balances detailed process with efficiency for moderately complex features.

## 🔍 LEVEL 3 WORKFLOW OVERVIEW

Level 3 tasks represent a significant development effort, building a complete feature. The workflow ensures adequate planning, design for key aspects, and methodical execution.

```mermaid
graph LR
    Init["1. INITIALIZATION<br>(VAN Mode Output)"] -->
    DocSetup["2. DOCUMENTATION SETUP"] -->
    Plan["3. FEATURE PLANNING (PLAN Mode)"] -->
    Creative["4. CREATIVE PHASES (CREATIVE Mode)"] -->
    Impl["5. IMPLEMENTATION (IMPLEMENT Mode)"] -->
    Reflect["6. REFLECTION (REFLECT Mode)"] -->
    Archive["7. ARCHIVING (ARCHIVE Mode)"]

    %% Document connections for each phase (conceptual links to mode guidance)
    Init -.-> InitDocs["Core Rules & L3 Confirmation"]
    DocSetup -.-> DocSetupDocs["Memory Bank Setup for L3"]
    Plan -.-> PlanDocs["Comprehensive Feature Plan"]
    Creative -.-> CreativeDocs["Targeted Design Documents"]
    Impl -.-> ImplDocs["Feature Implementation & Testing"]
    Reflect -.-> ReflectDocs["In-depth Feature Reflection"]
    Archive -.-> ArchiveDocs["Feature Archive Package"]

    style Init fill:#a1c4fd,stroke:#669df6
    style DocSetup fill:#b3e5fc,stroke:#81d4fa
    style Plan fill:#c8e6c9,stroke:#a5d6a7
    style Creative fill:#ffd8b2,stroke:#ffcc80
    style Impl fill:#ffcdd2,stroke:#ef9a9a
    style Reflect fill:#d1c4e9,stroke:#b39ddb
    style Archive fill:#cfd8dc,stroke:#b0bec5
````

Level 3 tasks typically involve creating a new, distinct feature or making substantial modifications to an existing one that affects multiple parts of the application.

## 🔄 LEVEL TRANSITION HANDLING (Within Level 3 Workflow)

```mermaid
graph TD
    L3["Level 3 Task In Progress"] --> Assess["Continuous Assessment<br>During PLAN or early IMPLEMENT"]

    Assess --> Up["Upgrade to<br>Level 4?"]
    Assess --> Down["Downgrade to<br>Level 2?"]
    Assess --> MaintainL3["Maintain<br>Level 3"]

    Up --> L4Trigger["Triggers:<br>- Unforeseen system-wide impact<br>- Requires deep architectural changes<br>- Scope significantly larger than planned"]
    Down --> L2Trigger["Triggers:<br>- Feature simpler than anticipated<br>- Very limited component interaction<br>- No complex design decisions emerge"]

    L4Trigger --> L4Switch["Stop L3 Workflow.<br>Re-initialize task as Level 4 (VAN).<br>Preserve existing docs as input."]
    L2Trigger --> L2Switch["Adapt L3 Workflow:<br>Simplify remaining phases,<br>use L2 Reflection/Archive rules."]
    
    style Assess fill:#ffe082,stroke:#ffca28
    style Up fill:#ef9a9a,stroke:#e57373
    style Down fill:#a5d6a7,stroke:#81c784
    style MaintainL3 fill:#b3e5fc,stroke:#81d4fa
```

## 📋 WORKFLOW PHASES

### Phase 1: INITIALIZATION (Output from VAN Mode)

This phase is largely completed in VAN mode, which identifies the task as Level 3.

  * **Input:** User request leading to an "Intermediate Feature" classification.
  * **Key Existing Files (from VAN):**
      * `memory-bank/tasks.md`: Entry created, complexity set to Level 3.
      * `memory-bank/activeContext.md`: Initial context set.
      * Relevant Core Rules loaded (e.g., `Core/memory-bank-paths.mdc`, `Core/main-optimized.mdc`).
  * **Steps within this Workflow File (Confirmation):**
    1.  Confirm task is Level 3 by checking `memory-bank/tasks.md`.
    2.  Ensure core Memory Bank structure and paths are known (AI should have internalized from `main` rule).
  * **Milestone Checkpoint:**
    ```
    ✓ INITIALIZATION CONFIRMED (L3)
    - Task correctly identified as Level 3 in tasks.md? [YES/NO]
    - Core Memory Bank files (tasks.md, activeContext.md) accessible via canonical paths? [YES/NO]

    → If all YES: Proceed to Documentation Setup for L3.
    → If any NO: Revisit VAN mode or core file setup.
    ```

### Phase 2: DOCUMENTATION SETUP (L3 Specific)

Prepare the Memory Bank for a Level 3 feature.

```mermaid
graph TD
    StartDoc["Begin L3 Documentation<br>Setup"] --> LoadL3PlanTrack["Load L3 Planning & Tracking Rules<br>Level3/planning-comprehensive.mdc<br>Level3/task-tracking-intermediate.mdc"]
    LoadL3PlanTrack --> UpdateBrief["Review/Update `projectbrief.md`<br>Ensure feature aligns with overall project goals"]
    UpdateBrief --> UpdateActiveCtx["Update `activeContext.md`<br>Set focus to L3 Feature Planning"]
    UpdateActiveCtx --> PrepTaskFile["Prepare `tasks.md` for<br>Comprehensive Feature Plan sections"]
    PrepTaskFile --> DocSetupComplete["L3 Documentation<br>Setup Complete"]

    style StartDoc fill:#b3e5fc,stroke:#81d4fa
    style DocSetupComplete fill:#81d4fa,stroke:#4fc3f7
```

  * **Steps:**
    1.  Load Level 3 specific planning (`Level3/planning-comprehensive.mdc`) and task tracking (`Level3/task-tracking-intermediate.mdc`) rules.
    2.  Review `memory-bank/projectbrief.md`: Briefly note the new feature if it impacts the overall brief.
    3.  Update `memory-bank/activeContext.md`: Set current focus to "Level 3 Feature Planning: [Feature Name]".
    4.  Ensure `memory-bank/tasks.md` is ready for the detailed planning sections outlined in `Level3/planning-comprehensive.mdc`.
  * **Milestone Checkpoint:**
    ```
    ✓ L3 DOCUMENTATION SETUP CHECKPOINT
    - L3 Planning & Tracking rules loaded? [YES/NO]
    - projectbrief.md reviewed/updated for feature context? [YES/NO]
    - activeContext.md reflects focus on L3 feature planning? [YES/NO]
    - tasks.md prepared for detailed L3 plan? [YES/NO]

    → If all YES: Proceed to Feature Planning.
    → If any NO: Complete documentation setup steps.
    ```

### Phase 3: FEATURE PLANNING (PLAN Mode)

Guided by `visual-maps/plan-mode-map.mdc` and using `Level3/planning-comprehensive.mdc` and `Level3/task-tracking-intermediate.mdc`.

```mermaid
graph TD
    StartPlan["Begin L3 Feature<br>Planning"] --> ReqDef["Define Detailed<br>Requirements (Functional & Non-Functional)"]
    ReqDef --> CompAnalysis["Component Analysis<br>(New & Affected Components, Interactions)"]
    CompAnalysis --> ImplStrategy["Develop Implementation<br>Strategy & High-Level Steps"]
    ImplStrategy --> DepRiskMgmt["Identify Dependencies,<br>Risks, & Mitigations"]
    DepRiskMgmt --> CreativeFlag["Flag Aspects for<br>CREATIVE Mode (UI, Arch, Algo)"]
    CreativeFlag --> UpdateTasks["Update `tasks.md` with<br>Full L3 Feature Plan"]
    UpdateTasks --> PlanComplete["L3 Feature Planning<br>Complete"]

    style StartPlan fill:#c8e6c9,stroke:#a5d6a7
    style PlanComplete fill:#a5d6a7,stroke:#81c784
```

  * **Steps:**
    1.  Define detailed functional and non-functional requirements for the feature.
    2.  Perform component analysis: identify new components to build and existing ones that will be modified. Map their interactions.
    3.  Develop an implementation strategy: outline the main steps or stages for building the feature.
    4.  Identify dependencies (technical, data, other features) and potential risks, along with mitigation ideas.
    5.  **Critical for L3:** Explicitly identify and flag parts of the feature that require CREATIVE mode (e.g., specific UI/UX challenges, new architectural patterns for the feature, complex algorithms).
    6.  Document the complete plan (requirements, components, strategy, dependencies, risks, creative flags) in `memory-bank/tasks.md` under the Level 3 feature task entry.
  * **Milestone Checkpoint:**
    ```
    ✓ L3 FEATURE PLANNING CHECKPOINT
    - Detailed requirements documented in tasks.md? [YES/NO]
    - Component analysis (new/affected, interactions) complete? [YES/NO]
    - Implementation strategy outlined? [YES/NO]
    - Dependencies and risks documented? [YES/NO]
    - Aspects needing CREATIVE mode explicitly flagged in tasks.md? [YES/NO]
    - tasks.md comprehensively updated with the feature plan? [YES/NO]

    → If all YES: Proceed to CREATIVE Phases (if flagged) or IMPLEMENTATION.
    → If any NO: Complete planning steps.
    ```

### Phase 4: CREATIVE PHASES (CREATIVE Mode)

Triggered if aspects were flagged in the PLAN phase. Guided by `visual-maps/creative-mode-map.mdc` and `Phases/CreativePhase/*.mdc` rules.

```mermaid
graph TD
    StartCreative["Begin L3 Creative<br>Phases (If Needed)"] --> SelectAspect["Select Flagged Aspect<br>from `tasks.md`"]
    SelectAspect --> DesignExplore["Explore Design/Arch Options<br>(Use relevant creative-phase-*.mdc rules)"]
    DesignExplore --> DecideDocument["Make & Document Decision<br>in `creative-[aspect_name].md`"]
    DecideDocument --> UpdateTasksCreative["Update `tasks.md` with<br>Decision Summary & Link"]
    UpdateTasksCreative --> MoreAspects{"More Flagged<br>Aspects?"}
    MoreAspects -- Yes --> SelectAspect
    MoreAspects -- No --> CreativeComplete["L3 Creative Phases<br>Complete"]

    style StartCreative fill:#ffd8b2,stroke:#ffcc80
    style CreativeComplete fill:#ffcc80,stroke:#ffb74d
```

  * **Steps:**
    1.  For each aspect flagged in `tasks.md` for creative exploration:
        a.  Load relevant `creative-phase-*.mdc` rule (e.g., UI/UX, architecture).
        b.  Define the problem, explore options, analyze trade-offs.
        c.  Make a design decision and document it with rationale in a new `memory-bank/creative-[aspect_name].md` file.
        d.  Update `tasks.md`: mark the creative sub-task as complete and link to the decision document.
  * **Milestone Checkpoint:**
    ```
    ✓ L3 CREATIVE PHASES CHECKPOINT
    - All flagged aspects from PLAN phase addressed? [YES/NO]
    - Design decisions documented in respective `memory-bank/creative-*.md` files? [YES/NO]
    - Rationale for decisions clearly stated? [YES/NO]
    - tasks.md updated to reflect completion of creative sub-tasks and links to decision docs? [YES/NO]

    → If all YES: Proceed to Implementation.
    → If any NO: Complete creative phase work.
    ```

### Phase 5: IMPLEMENTATION (IMPLEMENT Mode)

Guided by `visual-maps/implement-mode-map.mdc` and `Level3/implementation-L3.mdc`.

```mermaid
graph TD
    StartImpl["Begin L3 Feature<br>Implementation"] --> ReviewPlanDesign["Review Plan (`tasks.md`)<br>& Creative Docs (`creative-*.md`)"]
    ReviewPlanDesign --> SetupDevEnv["Setup Dev Environment<br>(Branch, Dependencies, Tools)"]
    SetupDevEnv --> BuildModules["Implement Feature Modules/Components<br>Iteratively or Sequentially"]
    BuildModules --> UnitIntegrationTests["Conduct Unit & Integration Tests<br>for Each Module/Feature Part"]
    UnitIntegrationTests --> StyleAdherence["Ensure Adherence to<br>`memory-bank/style-guide.md`"]
    StyleAdherence --> UpdateProgressDocs["Regularly Update `tasks.md` (sub-tasks)<br>& `progress.md` (milestones)"]
    UpdateProgressDocs --> E2EFeatureTest["End-to-End Feature Testing<br>Against Requirements"]
    E2EFeatureTest --> ImplComplete["L3 Feature Implementation<br>Complete"]

    style StartImpl fill:#ffcdd2,stroke:#ef9a9a
    style ImplComplete fill:#ef9a9a,stroke:#e57373
```

  * **Steps:**
    1.  Thoroughly review the feature plan in `memory-bank/tasks.md` and all relevant `memory-bank/creative-*.md` decision documents.
    2.  Set up the development environment (new branch, install any new dependencies, configure tools).
    3.  Implement the feature, building out modules/components as planned. Prioritize clean code and adherence to design specifications.
    4.  Perform unit tests for new logic and integration tests as components are assembled.
    5.  Ensure all UI elements strictly follow `memory-bank/style-guide.md`.
    6.  Update `memory-bank/tasks.md` with progress on sub-tasks, and `memory-bank/progress.md` with details of implemented parts, commands used, and any significant findings.
    7.  Conduct end-to-end testing of the completed feature against its requirements.
  * **Milestone Checkpoint:**
    ```
    ✓ L3 IMPLEMENTATION CHECKPOINT
    - Feature fully implemented as per plan and creative designs? [YES/NO]
    - All UI elements adhere to `memory-bank/style-guide.md`? [YES/NO]
    - Unit and integration tests performed and passing? [YES/NO]
    - End-to-end feature testing successful? [YES/NO]
    - `tasks.md` and `progress.md` updated with implementation status? [YES/NO]

    → If all YES: Proceed to Reflection.
    → If any NO: Complete implementation and testing.
    ```

### Phase 6: REFLECTION (REFLECT Mode)

Guided by `visual-maps/reflect-mode-map.mdc` and `Level3/reflection-L3.mdc`.

```mermaid
graph TD
    StartReflect["Begin L3 Feature<br>Reflection"] --> ReviewCompleted["Review Completed Feature<br>(Code, Plan, Design Docs, Test Results)"]
    ReviewCompleted --> AnalyzeProcess["Analyze Development Process<br>(Successes, Challenges, Deviations)"]
    AnalyzeProcess --> DocumentLessons["Document Key Lessons Learned<br>(Technical & Process)"]
    DocumentLessons --> AssessDesignChoices["Assess Effectiveness of<br>Creative Phase Decisions"]
    AssessDesignChoices --> CreateReflectDoc["Create `reflection-[feature_id].md`"]
    CreateReflectDoc --> UpdateTasksReflect["Update `tasks.md` (Reflection Complete)"]
    UpdateTasksReflect --> ReflectComplete["L3 Feature Reflection<br>Complete"]

    style StartReflect fill:#d1c4e9,stroke:#b39ddb
    style ReflectComplete fill:#b39ddb,stroke:#9575cd
```

  * **Steps:**
    1.  Review the entire feature development lifecycle: initial requirements, plan, creative designs, implementation, and testing outcomes.
    2.  Analyze what went well, what was challenging, and any deviations from the original plan or design.
    3.  Document key lessons learned regarding technology, architecture, process, or team collaboration relevant to this feature.
    4.  Specifically assess how effective the creative phase decisions were during actual implementation.
    5.  Create the `memory-bank/reflection-[feature_id].md` document.
    6.  Update `memory-bank/tasks.md` to mark the reflection stage for the feature as complete.
  * **Milestone Checkpoint:**
    ```
    ✓ L3 REFLECTION CHECKPOINT
    - Feature development lifecycle thoroughly reviewed? [YES/NO]
    - Successes, challenges, and lessons learned documented in `reflection-[feature_id].md`? [YES/NO]
    - Effectiveness of creative/design decisions assessed? [YES/NO]
    - `tasks.md` updated to reflect reflection completion? [YES/NO]

    → If all YES: Proceed to Archiving.
    → If any NO: Complete reflection documentation.
    ```

### Phase 7: ARCHIVING (ARCHIVE Mode - Highly Recommended for L3)

Guided by `visual-maps/archive-mode-map.mdc` and `Level3/archive-L3.mdc`.

```mermaid
graph TD
    StartArchive["Begin L3 Feature<br>Archiving"] --> ConsolidateDocs["Consolidate All Feature Docs<br>(Plan, Creative, Reflection, Key Progress Notes)"]
    ConsolidateDocs --> CreateArchiveSummary["Create Archive Summary Document<br>`archive/feature-[feature_id]_YYYYMMDD.md`"]
    CreateArchiveSummary --> LinkDocs["Link to Detailed Docs<br>within Archive Summary"]
    LinkDocs --> FinalUpdateTasks["Final Update to `tasks.md`<br>(Mark Feature COMPLETED & ARCHIVED)"]
    FinalUpdateTasks --> ResetActiveCtx["Clear `activeContext.md`<br>Prepare for Next Task"]
    ResetActiveCtx --> ArchiveComplete["L3 Feature Archiving<br>Complete"]

    style StartArchive fill:#cfd8dc,stroke:#b0bec5
    style ArchiveComplete fill:#b0bec5,stroke:#90a4ae
```

  * **Steps:**
    1.  Consolidate all documentation related to the feature: the plan section from `tasks.md`, all `creative-*.md` files, the `reflection-*.md` file, and relevant summaries from `progress.md`.
    2.  Create a dedicated feature archive summary document in `memory-bank/archive/feature-[feature_id]_YYYYMMDD.md`. This summary should briefly describe the feature, its purpose, key decisions, and link to the more detailed documents.
    3.  Update `memory-bank/tasks.md` to mark the entire Level 3 feature task as "COMPLETED" and "ARCHIVED," providing a link to the new archive summary.
    4.  Update `memory-bank/activeContext.md` to clear information related to the completed feature, preparing for the next task.
  * **Milestone Checkpoint:**
    ```
    ✓ L3 ARCHIVING CHECKPOINT
    - Feature archive summary created in `memory-bank/archive/`? [YES/NO]
    - Archive summary links to all relevant planning, creative, and reflection docs? [YES/NO]
    - `tasks.md` shows the feature as COMPLETED and ARCHIVED with a link to the archive? [YES/NO]
    - `activeContext.md` cleared and ready for a new task? [YES/NO]

    → If all YES: Level 3 Task Fully Completed. Suggest VAN Mode for next task.
    → If any NO: Complete archiving steps.
    ```

## 🚨 LEVEL 3 GOVERNANCE PRINCIPLE

Remember:

```
┌─────────────────────────────────────────────────────┐
│ Level 3 tasks build significant features. Balance   │
│ detailed planning and targeted design with efficient│
│ execution. Document key decisions and outcomes to   │
│ ensure the feature is understandable and maintainable.│
└─────────────────────────────────────────────────────┘
```

This ensures that intermediate features are developed with an appropriate level of rigor, bridging the gap between simple enhancements and full-scale system development.

```
```

================
File: .cursor/rules/isolation_rules/Level4/architectural-planning.mdc
================
---
description: Architectural planning guidelines for Level 4 Complex System tasks
globs: "**/level4/**", "**/architecture/**"
alwaysApply: false
---

# ARCHITECTURAL PLANNING FOR LEVEL 4 TASKS

> **TL;DR:** This document outlines a comprehensive architectural planning approach for Level 4 (Complex System) tasks, ensuring a robust, scalable, and maintainable architecture that aligns with business objectives and technical requirements.

## 🔍 ARCHITECTURAL PLANNING OVERVIEW

Level 4 Complex System tasks require thorough architectural planning to ensure the resulting system is robust, scalable, maintainable, and aligned with business objectives. This document outlines a structured approach to architectural planning that systematically addresses key concerns and produces comprehensive documentation.

```mermaid
flowchart TD
    classDef phase fill:#f9d77e,stroke:#d9b95c,color:#000
    classDef artifact fill:#f4b8c4,stroke:#d498a4,color:#000
    classDef verification fill:#c5e8b7,stroke:#a5c897,color:#000
    
    Start([Begin Architectural<br>Planning]) --> Reqs[Analyze<br>Requirements]
    Reqs --> Context[Define Business<br>Context]
    Context --> Vision[Establish Vision<br>and Goals]
    Vision --> Principles[Define Architectural<br>Principles]
    Principles --> Constraints[Identify<br>Constraints]
    Constraints --> Explore[Explore<br>Alternatives]
    Explore --> Evaluate[Evaluate<br>Options]
    Evaluate --> Decision[Document<br>Decisions]
    Decision --> Create[Create Architecture<br>Documentation]
    Create --> Validate[Validate<br>Architecture]
    Validate --> Communicate[Communicate<br>Architecture]
    Communicate --> Verification{Architecture<br>Verification}
    Verification -->|Pass| Complete([Architectural<br>Planning Complete])
    Verification -->|Fail| Revise[Revise<br>Architecture]
    Revise --> Verification
    
    Reqs -.-> ReqDoc((Requirements<br>Document))
    Context -.-> ConDoc((Context<br>Document))
    Vision -.-> VisDoc((Vision<br>Document))
    Principles -.-> PrinDoc((Principles<br>Document))
    Explore -.-> AltDoc((Alternatives<br>Analysis))
    Decision -.-> ADR((Architecture<br>Decision Records))
    Create -.-> ArchDoc((Architecture<br>Documentation))
    
    class Start,Complete milestone
    class Reqs,Context,Vision,Principles,Constraints,Explore,Evaluate,Decision,Create,Validate,Communicate,Revise step
    class Verification verification
    class ReqDoc,ConDoc,VisDoc,PrinDoc,AltDoc,ADR,ArchDoc artifact
```

## 📋 ARCHITECTURAL PLANNING PRINCIPLES

1. **Business Alignment**: Architecture must directly support business objectives and user needs.
2. **Future-Proofing**: Architecture must anticipate future requirements and facilitate change.
3. **Simplicity**: Prefer simple solutions over complex ones when possible.
4. **Separation of Concerns**: Systems should be divided into distinct components with minimal overlap.
5. **Defense in Depth**: Multiple layers of security controls should be employed.
6. **Loose Coupling**: Components should interact through well-defined interfaces with minimal dependencies.
7. **High Cohesion**: Related functionality should be grouped together, unrelated functionality separated.
8. **Resilience**: Architecture should anticipate failures and provide mechanisms for recovery.
9. **Scalability**: Architecture should support growth in users, data, and functionality.
10. **Measurability**: Architecture should enable monitoring and measurement of key metrics.

## 📋 ARCHITECTURAL REQUIREMENTS ANALYSIS

Begin architectural planning with a comprehensive analysis of requirements:

### Functional Requirements Analysis

```mermaid
flowchart LR
    classDef req fill:#f9d77e,stroke:#d9b95c,color:#000
    classDef arch fill:#a8d5ff,stroke:#88b5e0,color:#000
    
    FR[Functional<br>Requirements] --> USE[Use Cases/<br>User Stories]
    USE --> DOM[Domain<br>Model]
    DOM --> COMP[Component<br>Identification]
    COMP --> INT[Interface<br>Definition]
    INT --> FLOW[Information<br>Flow]
    
    class FR,USE,DOM req
    class COMP,INT,FLOW arch
```

**Template for Functional Requirements Analysis:**

```markdown
## Functional Requirements Analysis

### Key Use Cases
- Use Case 1: [Description]
- Use Case 2: [Description]
- Use Case 3: [Description]

### Domain Model
- Entity 1: [Description and attributes]
- Entity 2: [Description and attributes]
- Entity 3: [Description and attributes]
- Relationships:
  - Entity 1 → Entity 2: [Relationship type and description]
  - Entity 2 → Entity 3: [Relationship type and description]

### Component Identification
- Component 1: [Description and responsibilities]
- Component 2: [Description and responsibilities]
- Component 3: [Description and responsibilities]

### Interface Definitions
- Interface 1: [Description, methods, parameters]
- Interface 2: [Description, methods, parameters]
- Interface 3: [Description, methods, parameters]

### Information Flow
- Flow 1: [Description of information exchange]
- Flow 2: [Description of information exchange]
- Flow 3: [Description of information exchange]
```

### Non-Functional Requirements Analysis

```mermaid
flowchart LR
    classDef req fill:#f9d77e,stroke:#d9b95c,color:#000
    classDef arch fill:#a8d5ff,stroke:#88b5e0,color:#000
    
    NFR[Non-Functional<br>Requirements] --> PERF[Performance<br>Requirements]
    NFR --> SEC[Security<br>Requirements]
    NFR --> SCAL[Scalability<br>Requirements]
    NFR --> AVAIL[Availability<br>Requirements]
    NFR --> MAINT[Maintainability<br>Requirements]
    
    PERF & SEC & SCAL & AVAIL & MAINT --> ARCH[Architectural<br>Decisions]
    
    class NFR,PERF,SEC,SCAL,AVAIL,MAINT req
    class ARCH arch
```

**Template for Non-Functional Requirements Analysis:**

```markdown
## Non-Functional Requirements Analysis

### Performance Requirements
- Response Time: [Requirements]
- Throughput: [Requirements]
- Resource Utilization: [Requirements]
- Architectural Implications: [Implications for architecture]

### Security Requirements
- Authentication: [Requirements]
- Authorization: [Requirements]
- Data Protection: [Requirements]
- Audit/Logging: [Requirements]
- Architectural Implications: [Implications for architecture]

### Scalability Requirements
- User Scalability: [Requirements]
- Data Scalability: [Requirements]
- Transaction Scalability: [Requirements]
- Architectural Implications: [Implications for architecture]

### Availability Requirements
- Uptime Requirements: [Requirements]
- Fault Tolerance: [Requirements]
- Disaster Recovery: [Requirements]
- Architectural Implications: [Implications for architecture]

### Maintainability Requirements
- Modularity: [Requirements]
- Extensibility: [Requirements]
- Testability: [Requirements]
- Architectural Implications: [Implications for architecture]
```

## 📋 BUSINESS CONTEXT DOCUMENTATION

Document the business context to ensure architectural alignment:

```markdown
## Business Context Documentation

### Business Objectives
- Objective 1: [Description]
- Objective 2: [Description]
- Objective 3: [Description]

### Key Stakeholders
- Stakeholder Group 1: [Description, needs, and concerns]
- Stakeholder Group 2: [Description, needs, and concerns]
- Stakeholder Group 3: [Description, needs, and concerns]

### Business Processes
- Process 1: [Description and flow]
- Process 2: [Description and flow]
- Process 3: [Description and flow]

### Business Constraints
- Constraint 1: [Description and impact]
- Constraint 2: [Description and impact]
- Constraint 3: [Description and impact]

### Business Metrics
- Metric 1: [Description and target]
- Metric 2: [Description and target]
- Metric 3: [Description and target]

### Business Risks
- Risk 1: [Description, probability, impact, and mitigation]
- Risk 2: [Description, probability, impact, and mitigation]
- Risk 3: [Description, probability, impact, and mitigation]
```

## 📋 ARCHITECTURAL VISION AND GOALS

Document the architectural vision and goals:

```markdown
## Architectural Vision and Goals

### Vision Statement
[Concise statement of the architectural vision]

### Strategic Goals
- Goal 1: [Description and success criteria]
- Goal 2: [Description and success criteria]
- Goal 3: [Description and success criteria]

### Quality Attributes
- Quality Attribute 1: [Description and importance]
- Quality Attribute 2: [Description and importance]
- Quality Attribute 3: [Description and importance]

### Technical Roadmap
- Short-term (0-6 months): [Key architectural milestones]
- Medium-term (6-18 months): [Key architectural milestones]
- Long-term (18+ months): [Key architectural milestones]

### Key Success Indicators
- Indicator 1: [Description and measurement]
- Indicator 2: [Description and measurement]
- Indicator 3: [Description and measurement]
```

## 📋 ARCHITECTURAL PRINCIPLES

Document architectural principles to guide decision-making:

```markdown
## Architectural Principles

### Principle 1: [Name]
- **Statement**: [Concise statement of the principle]
- **Rationale**: [Why this principle is important]
- **Implications**: [What this principle means for the architecture]
- **Examples**: [Examples of applying this principle]

### Principle 2: [Name]
- **Statement**: [Concise statement of the principle]
- **Rationale**: [Why this principle is important]
- **Implications**: [What this principle means for the architecture]
- **Examples**: [Examples of applying this principle]

### Principle 3: [Name]
- **Statement**: [Concise statement of the principle]
- **Rationale**: [Why this principle is important]
- **Implications**: [What this principle means for the architecture]
- **Examples**: [Examples of applying this principle]

...
```

## 📋 CONSTRAINTS IDENTIFICATION

Document constraints that impact architectural decisions:

```markdown
## Architectural Constraints

### Technical Constraints
- Constraint 1: [Description and impact]
- Constraint 2: [Description and impact]
- Constraint 3: [Description and impact]

### Organizational Constraints
- Constraint 1: [Description and impact]
- Constraint 2: [Description and impact]
- Constraint 3: [Description and impact]

### External Constraints
- Constraint 1: [Description and impact]
- Constraint 2: [Description and impact]
- Constraint 3: [Description and impact]

### Regulatory/Compliance Constraints
- Constraint 1: [Description and impact]
- Constraint 2: [Description and impact]
- Constraint 3: [Description and impact]

### Resource Constraints
- Constraint 1: [Description and impact]
- Constraint 2: [Description and impact]
- Constraint 3: [Description and impact]
```

## 📋 ARCHITECTURAL ALTERNATIVES EXPLORATION

Document and evaluate architectural alternatives:

```markdown
## Architectural Alternatives

### Alternative 1: [Name]
- **Description**: [Brief description of the alternative]
- **Key Components**:
  - Component 1: [Description]
  - Component 2: [Description]
  - Component 3: [Description]
- **Advantages**:
  - [Advantage 1]
  - [Advantage 2]
  - [Advantage 3]
- **Disadvantages**:
  - [Disadvantage 1]
  - [Disadvantage 2]
  - [Disadvantage 3]
- **Risks**:
  - [Risk 1]
  - [Risk 2]
  - [Risk 3]
- **Cost Factors**:
  - [Cost Factor 1]
  - [Cost Factor 2]
  - [Cost Factor 3]
- **Alignment with Requirements**:
  - [How well this alternative addresses requirements]

### Alternative 2: [Name]
...

### Alternative 3: [Name]
...

## Evaluation Criteria
- Criterion 1: [Description and weighting]
- Criterion 2: [Description and weighting]
- Criterion 3: [Description and weighting]

## Evaluation Matrix
| Criterion | Alternative 1 | Alternative 2 | Alternative 3 |
|-----------|---------------|---------------|---------------|
| Criterion 1 | Score | Score | Score |
| Criterion 2 | Score | Score | Score |
| Criterion 3 | Score | Score | Score |
| Total | Sum | Sum | Sum |

## Recommended Approach
[Description of the recommended architectural approach with justification]
```

## 📋 ARCHITECTURE DECISION RECORDS (ADRs)

Document key architectural decisions:

```markdown
# Architecture Decision Record: [Decision Title]

## Status
[Proposed/Accepted/Deprecated/Superseded]

## Context
[Description of the context and problem statement]

## Decision
[Description of the decision made]

## Consequences
[Description of the consequences of the decision]

## Alternatives Considered
[Description of alternatives considered]

## Related Decisions
[References to related decisions]

## Notes
[Additional notes and considerations]
```

## 📋 COMPREHENSIVE ARCHITECTURE DOCUMENTATION

Create comprehensive architecture documentation:

### System Context Diagram

```mermaid
flowchart TD
    classDef system fill:#f9d77e,stroke:#d9b95c,color:#000
    classDef external fill:#a8d5ff,stroke:#88b5e0,color:#000
    classDef user fill:#c5e8b7,stroke:#a5c897,color:#000
    
    U1[User 1] --> S[System]
    U2[User 2] --> S
    S --> E1[External<br>System 1]
    S --> E2[External<br>System 2]
    S --> E3[External<br>System 3]
    
    class S system
    class E1,E2,E3 external
    class U1,U2 user
```

### High-Level Architecture Diagram

```mermaid
flowchart TD
    classDef frontend fill:#f9d77e,stroke:#d9b95c,color:#000
    classDef backend fill:#a8d5ff,stroke:#88b5e0,color:#000
    classDef data fill:#c5e8b7,stroke:#a5c897,color:#000
    classDef integration fill:#f4b8c4,stroke:#d498a4,color:#000
    
    U[Users] --> F[Frontend<br>Layer]
    F --> B[Backend<br>Layer]
    B --> D[Data<br>Layer]
    B --> I[Integration<br>Layer]
    I --> E[External<br>Systems]
    
    class F frontend
    class B backend
    class D data
    class I integration
    class U,E external
```

### Component Architecture Diagram

```mermaid
flowchart TD
    classDef ui fill:#f9d77e,stroke:#d9b95c,color:#000
    classDef service fill:#a8d5ff,stroke:#88b5e0,color:#000
    classDef data fill:#c5e8b7,stroke:#a5c897,color:#000
    
    UI[User Interface] --> API[API Gateway]
    API --> S1[Service 1]
    API --> S2[Service 2]
    API --> S3[Service 3]
    S1 --> DB1[Database 1]
    S2 --> DB1
    S2 --> DB2[Database 2]
    S3 --> DB2
    
    class UI ui
    class API,S1,S2,S3 service
    class DB1,DB2 data
```

### Data Architecture Diagram

```mermaid
flowchart TD
    classDef entity fill:#f9d77e,stroke:#d9b95c,color:#000
    classDef relation fill:#a8d5ff,stroke:#88b5e0,color:#000
    
    E1[Entity 1] -- 1:N --> E2[Entity 2]
    E1 -- 1:1 --> E3[Entity 3]
    E2 -- N:M --> E4[Entity 4]
    E3 -- 1:N --> E4
    
    class E1,E2,E3,E4 entity
```

### Security Architecture Diagram

```mermaid
flowchart TD
    classDef security fill:#f9d77e,stroke:#d9b95c,color:#000
    classDef app fill:#a8d5ff,stroke:#88b5e0,color:#000
    
    U[Users] --> WAF[Web Application<br>Firewall]
    WAF --> LB[Load<br>Balancer]
    LB --> API[API Gateway]
    API --> AuthZ[Authorization<br>Service]
    API --> S1[Service 1]
    API --> S2[Service 2]
    AuthZ --> IAM[Identity &<br>Access Management]
    
    class WAF,AuthZ,IAM security
    class API,S1,S2 app
    class U,LB external
```

### Deployment Architecture Diagram

```mermaid
flowchart TD
    classDef env fill:#f9d77e,stroke:#d9b95c,color:#000
    classDef component fill:#a8d5ff,stroke:#88b5e0,color:#000
    
    subgraph Production
    LB[Load Balancer] --> W1[Web Server 1]
    LB --> W2[Web Server 2]
    W1 & W2 --> A1[App Server 1]
    W1 & W2 --> A2[App Server 2]
    A1 & A2 --> DB[Database<br>Cluster]
    end
    
    class Production env
    class LB,W1,W2,A1,A2,DB component
```

### Architecture Documentation Template

```markdown
# System Architecture Document

## 1. Introduction
- **Purpose**: [Purpose of the architecture]
- **Scope**: [Scope of the architecture]
- **Audience**: [Intended audience for the document]
- **References**: [Related documents and references]

## 2. System Context
- **System Purpose**: [Brief description of system purpose]
- **Context Diagram**: [System context diagram]
- **External Systems**: [Description of external systems and interfaces]
- **User Types**: [Description of user types and interactions]

## 3. Architecture Overview
- **Architecture Style**: [Description of the architectural style/pattern]
- **High-Level Architecture**: [High-level architecture diagram]
- **Key Components**: [Overview of key components]
- **Technology Stack**: [Overview of technology stack]

## 4. Component Architecture
- **Component Diagram**: [Component architecture diagram]
- **Component Descriptions**:
  - Component 1: [Description, responsibilities, interfaces]
  - Component 2: [Description, responsibilities, interfaces]
  - Component 3: [Description, responsibilities, interfaces]
- **Component Interactions**: [Description of component interactions]
- **API Specifications**: [Overview of key APIs]

## 5. Data Architecture
- **Data Model**: [Data architecture diagram]
- **Entity Descriptions**:
  - Entity 1: [Description, attributes, relationships]
  - Entity 2: [Description, attributes, relationships]
  - Entity 3: [Description, attributes, relationships]
- **Data Storage**: [Description of data storage approaches]
- **Data Access**: [Description of data access patterns]
- **Data Migration**: [Overview of data migration approach]

## 6. Security Architecture
- **Security Model**: [Security architecture diagram]
- **Authentication**: [Authentication approach]
- **Authorization**: [Authorization approach]
- **Data Protection**: [Data protection mechanisms]
- **Security Controls**: [Key security controls]
- **Audit and Logging**: [Audit and logging approach]

## 7. Deployment Architecture
- **Deployment Model**: [Deployment architecture diagram]
- **Environment Descriptions**:
  - Environment 1: [Description and configuration]
  - Environment 2: [Description and configuration]
  - Environment 3: [Description and configuration]
- **Infrastructure Requirements**: [Infrastructure requirements]
- **Scaling Approach**: [Scaling approach]

## 8. Quality Attributes
- **Performance**: [Performance characteristics and mechanisms]
- **Scalability**: [Scalability approach]
- **Availability**: [Availability approach]
- **Maintainability**: [Maintainability approach]
- **Reliability**: [Reliability approach]
- **Portability**: [Portability considerations]

## 9. Cross-Cutting Concerns
- **Logging**: [Logging approach]
- **Error Handling**: [Error handling approach]
- **Monitoring**: [Monitoring approach]
- **Configuration Management**: [Configuration management approach]
- **Internationalization**: [Internationalization approach]

## 10. Architecture Decisions
- [References to Architecture Decision Records]

## 11. Risks and Mitigations
- Risk 1: [Description and mitigation]
- Risk 2: [Description and mitigation]
- Risk 3: [Description and mitigation]

## 12. Glossary
- Term 1: [Definition]
- Term 2: [Definition]
- Term 3: [Definition]
```

## 📋 ARCHITECTURE VALIDATION

Validate architecture against requirements and principles:

```markdown
## Architecture Validation

### Requirements Coverage
- Requirement 1: [Covered/Partially Covered/Not Covered] - [Explanation]
- Requirement 2: [Covered/Partially Covered/Not Covered] - [Explanation]
- Requirement 3: [Covered/Partially Covered/Not Covered] - [Explanation]

### Principles Alignment
- Principle 1: [Aligned/Partially Aligned/Not Aligned] - [Explanation]
- Principle 2: [Aligned/Partially Aligned/Not Aligned] - [Explanation]
- Principle 3: [Aligned/Partially Aligned/Not Aligned] - [Explanation]

### Quality Attribute Scenarios
- Scenario 1: [Description and validation]
- Scenario 2: [Description and validation]
- Scenario 3: [Description and validation]

### Architecture Review Findings
- Finding 1: [Description and resolution]
- Finding 2: [Description and resolution]
- Finding 3: [Description and resolution]

### Risk Assessment
- Risk 1: [Description, probability, impact, and mitigation]
- Risk 2: [Description, probability, impact, and mitigation]
- Risk 3: [Description, probability, impact, and mitigation]

### Validation Outcome
[Summary of validation outcome and next steps]
```

## 📋 ARCHITECTURE COMMUNICATION

Communicate architecture to stakeholders:

```markdown
## Architecture Communication Plan

### Key Stakeholders
- Stakeholder Group 1: [Communication needs]
- Stakeholder Group 2: [Communication needs]
- Stakeholder Group 3: [Communication needs]

### Communication Materials
- **Executive Summary**: [Purpose and audience]
- **Technical Reference**: [Purpose and audience]
- **Developer Guide**: [Purpose and audience]
- **Operations Guide**: [Purpose and audience]

### Communication Schedule
- Event 1: [Date, audience, purpose]
- Event 2: [Date, audience, purpose]
- Event 3: [Date, audience, purpose]

### Feedback Mechanism
[Description of how feedback will be collected and incorporated]
```

## 📋 MEMORY BANK INTEGRATION

```mermaid
flowchart TD
    classDef memfile fill:#f4b8c4,stroke:#d498a4,color:#000
    classDef process fill:#f9d77e,stroke:#d9b95c,color:#000
    
    Architecture[Architectural<br>Planning] --> PB[projectbrief.md]
    Architecture --> PC[productContext.md]
    Architecture --> SP[systemPatterns.md]
    Architecture --> TC[techContext.md]
    
    PB & PC & SP & TC --> MBI[Memory Bank<br>Integration]
    MBI --> Next[Implementation<br>Phase]
    
    class PB,PC,SP,TC memfile
    class Architecture,MBI,Next process
```

### Memory Bank Updates

Update the following Memory Bank files during architectural planning:

1. **projectbrief.md**
   - Update with architectural vision
   - Document high-level architecture approach
   - Link to architecture documentation

2. **productContext.md**
   - Update with business context documentation
   - Document key stakeholder requirements
   - Capture business drivers for architectural decisions

3. **systemPatterns.md**
   - Document architectural patterns and styles chosen
   - Capture key architecture decisions with rationales
   - Document technical patterns to be used

4. **techContext.md**
   - Update with technology stack decisions
   - Document technical constraints and considerations
   - Capture integration approaches

## 📋 ARCHITECTURAL PLANNING VERIFICATION CHECKLIST

```
✓ ARCHITECTURAL PLANNING VERIFICATION CHECKLIST

Requirements Analysis
- Functional requirements analyzed? [YES/NO]
- Non-functional requirements analyzed? [YES/NO]
- Domain model created? [YES/NO]
- Component identification completed? [YES/NO]

Business Context
- Business objectives documented? [YES/NO]
- Key stakeholders identified? [YES/NO]
- Business processes documented? [YES/NO]
- Business constraints identified? [YES/NO]

Vision and Goals
- Architectural vision stated? [YES/NO]
- Strategic goals defined? [YES/NO]
- Quality attributes identified? [YES/NO]
- Technical roadmap created? [YES/NO]

Architectural Principles
- Core principles defined? [YES/NO]
- Principles have clear rationales? [YES/NO]
- Implications of principles documented? [YES/NO]
- Examples of applying principles provided? [YES/NO]

Constraints Identification
- Technical constraints documented? [YES/NO]
- Organizational constraints documented? [YES/NO]
- External constraints documented? [YES/NO]
- Regulatory constraints documented? [YES/NO]

Alternatives Exploration
- Multiple alternatives identified? [YES/NO]
- Alternatives evaluated against criteria? [YES/NO]
- Advantages and disadvantages documented? [YES/NO]
- Recommended approach justified? [YES/NO]

Architecture Documentation
- System context documented? [YES/NO]
- High-level architecture documented? [YES/NO]
- Component architecture documented? [YES/NO]
- Data architecture documented? [YES/NO]
- Security architecture documented? [YES/NO]
- Deployment architecture documented? [YES/NO]

Architecture Validation
- Requirements coverage validated? [YES/NO]
- Principles alignment checked? [YES/NO]
- Quality attribute scenarios assessed? [YES/NO]
- Architecture review conducted? [YES/NO]

Memory Bank Integration
- projectbrief.md updated? [YES/NO]
- productContext.md updated? [YES/NO]
- systemPatterns.md updated? [YES/NO]
- techContext.md updated? [YES/NO]
```

## 📋 MINIMAL MODE ARCHITECTURE PLANNING FORMAT

For situations requiring a more compact architectural planning approach:

```markdown
## Level 4 Architecture Planning: [System Name]

### System Context
- **Purpose**: [Brief description of system purpose]
- **Users**: [Primary users]
- **External Systems**: [Key external systems]

### Key Architectural Decisions
- **Architecture Style**: [Chosen style with brief rationale]
- **Component Structure**: [Key components with brief descriptions]
- **Data Model**: [Brief description of data approach]
- **Technical Stack**: [Key technologies]

### Quality Attributes
- **Performance**: [Brief description of approach]
- **Security**: [Brief description of approach]
- **Scalability**: [Brief description of approach]
- **Maintainability**: [Brief description of approach]

### Architecture Diagram
[Simple architecture diagram]

### Key Risks and Mitigations
- **Risk 1**: [Brief description] - **Mitigation**: [Brief approach]
- **Risk 2**: [Brief description] - **Mitigation**: [Brief approach]

### Memory Bank Updates
- [Brief description of updates needed]
```

## 🚨 ARCHITECTURAL PLANNING ENFORCEMENT PRINCIPLE

```
┌─────────────────────────────────────────────────────┐
│ ARCHITECTURAL PLANNING IS MANDATORY for Level 4      │
│ tasks. Implementation CANNOT begin until             │
│ architectural planning is complete and approved.     │
└─────────────────────────────────────────────────────┘
```

================
File: .cursor/rules/isolation_rules/Level4/archive-comprehensive.mdc
================
---
description: Comprehensive archiving approach for Level 4 Complex System tasks
globs: "**/level4/**", "**/archive/**"
alwaysApply: false
---

# COMPREHENSIVE ARCHIVING FOR LEVEL 4 TASKS

> **TL;DR:** This document outlines a comprehensive archiving approach for Level 4 (Complex System) tasks, ensuring all system knowledge, decisions, implementation details, and lessons learned are preserved for future reference and reuse.

## 🔍 COMPREHENSIVE ARCHIVING OVERVIEW

Level 4 Complex System tasks require thorough archiving to preserve system knowledge, design decisions, implementation details, and lessons learned. This systematic archiving process ensures that the organization maintains institutional knowledge and enables future teams to understand, maintain, and extend the system.

```mermaid
flowchart TD
    classDef phase fill:#f9d77e,stroke:#d9b95c,color:#000
    classDef artifact fill:#f4b8c4,stroke:#d498a4,color:#000
    classDef verification fill:#c5e8b7,stroke:#a5c897,color:#000
    
    Start([Begin Archiving<br>Process]) --> Template[Load Comprehensive<br>Archive Template]
    Template --> RefDoc[Review Reflection<br>Document]
    RefDoc --> SysDoc[Create System<br>Documentation]
    SysDoc --> ArchDoc[Document Architecture<br>and Design]
    ArchDoc --> ImplDoc[Document Implementation<br>Details]
    ImplDoc --> APIDoc[Create API<br>Documentation]
    APIDoc --> DataDoc[Document Data<br>Models and Schemas]
    DataDoc --> SecDoc[Document Security<br>Measures]
    SecDoc --> TestDoc[Document Testing<br>Procedures and Results]
    TestDoc --> DeployDoc[Document Deployment<br>Procedures]
    DeployDoc --> OpDoc[Create Operational<br>Documentation]
    OpDoc --> KnowledgeDoc[Create Knowledge<br>Transfer Documentation]
    KnowledgeDoc --> CrossRef[Create Cross-Reference<br>Documentation]
    CrossRef --> Archive[Archive All<br>Project Materials]
    Archive --> UpdateMB[Update Memory<br>Bank]
    UpdateMB --> Verification{Archiving<br>Verification}
    Verification -->|Pass| Complete([Archiving<br>Complete])
    Verification -->|Fail| Revise[Revise<br>Archiving]
    Revise --> Verification
    
    Template -.-> AT((Archive<br>Template))
    SysDoc -.-> SD((System<br>Documentation))
    ArchDoc -.-> AD((Architecture<br>Documentation))
    ImplDoc -.-> ID((Implementation<br>Documentation))
    APIDoc & DataDoc -.-> IntDoc((Interface<br>Documentation))
    TestDoc & DeployDoc & OpDoc -.-> OpDocs((Operational<br>Documentation))
    
    class Start,Complete milestone
    class Template,RefDoc,SysDoc,ArchDoc,ImplDoc,APIDoc,DataDoc,SecDoc,TestDoc,DeployDoc,OpDoc,KnowledgeDoc,CrossRef,Archive,UpdateMB step
    class Verification verification
    class AT,SD,AD,ID,IntDoc,OpDocs artifact
```

## 📋 ARCHIVE TEMPLATE STRUCTURE

### 1. System Overview

```markdown
## System Overview

### System Purpose and Scope
[Comprehensive description of the system purpose, scope, and business context]

### System Architecture
[Summary of the architecture, including diagrams, patterns, and key design decisions]

### Key Components
- Component 1: [Description and purpose]
- Component 2: [Description and purpose]
- Component 3: [Description and purpose]

### Integration Points
[Description of all internal and external integration points]

### Technology Stack
[Comprehensive list of all technologies, frameworks, and tools used]

### Deployment Environment
[Description of the deployment environment, infrastructure, and configuration]
```

### 2. Requirements and Design Documentation

```markdown
## Requirements and Design Documentation

### Business Requirements
[Comprehensive list of business requirements with traceability]

### Functional Requirements
[Detailed functional requirements with implementation mapping]

### Non-Functional Requirements
[Non-functional requirements with implementation approaches]

### Architecture Decision Records
[Collection of all architecture decision records (ADRs)]

### Design Patterns Used
[Catalog of all design patterns with usage examples]

### Design Constraints
[Documentation of all design constraints and their impact]

### Design Alternatives Considered
[Summary of alternatives considered and reasons for final selections]
```

### 3. Implementation Documentation

```markdown
## Implementation Documentation

### Component Implementation Details
- **Component 1**:
  - **Purpose**: [Component purpose]
  - **Implementation approach**: [Implementation details]
  - **Key classes/modules**: [List with descriptions]
  - **Dependencies**: [Internal and external dependencies]
  - **Special considerations**: [Important notes]

- **Component 2**:
  - **Purpose**: [Component purpose]
  - **Implementation approach**: [Implementation details]
  - **Key classes/modules**: [List with descriptions]
  - **Dependencies**: [Internal and external dependencies]
  - **Special considerations**: [Important notes]

### Key Files and Components Affected (from tasks.md)
[Summary or direct copy of file/component checklists from the original tasks.md for this project. This provides a quick reference to the scope of changes at a component/file level.]

### Algorithms and Complex Logic
[Documentation of key algorithms and complex business logic]

### Third-Party Integrations
[Details of all third-party integrations including APIs and libraries]

### Configuration Parameters
[Complete listing of all configuration parameters and their purpose]

### Build and Packaging Details
[Documentation of build process, packaging, and artifacts]
```

### 4. API Documentation

```markdown
## API Documentation

### API Overview
[High-level overview of all APIs (internal and external)]

### API Endpoints
- **Endpoint 1**:
  - **URL/Path**: [Endpoint URL or path]
  - **Method**: [HTTP method]
  - **Purpose**: [Purpose of the endpoint]
  - **Request Format**: [Request format with examples]
  - **Response Format**: [Response format with examples]
  - **Error Codes**: [Possible error codes and meanings]
  - **Security**: [Security considerations]
  - **Rate Limits**: [Any rate limits]
  - **Notes**: [Additional notes]

- **Endpoint 2**:
  - **URL/Path**: [Endpoint URL or path]
  - **Method**: [HTTP method]
  - **Purpose**: [Purpose of the endpoint]
  - **Request Format**: [Request format with examples]
  - **Response Format**: [Response format with examples]
  - **Error Codes**: [Possible error codes and meanings]
  - **Security**: [Security considerations]
  - **Rate Limits**: [Any rate limits]
  - **Notes**: [Additional notes]

### API Authentication
[Authentication methods and implementation details]

### API Versioning Strategy
[Versioning approach and migration strategy]

### SDK or Client Libraries
[Available SDKs or client libraries with usage examples]
```

### 5. Data Model and Schema Documentation

```markdown
## Data Model and Schema Documentation

### Data Model Overview
[High-level overview of the data model with entity relationship diagrams]

### Database Schema
[Detailed database schema with tables, columns, and relationships]

### Data Dictionary
[Comprehensive data dictionary with all entities and attributes]

### Data Validation Rules
[Data validation rules and enforcement mechanisms]

### Data Migration Procedures
[Procedures for data migration and version management]

### Data Archiving Strategy
[Strategy for data archiving and retention]
```

### 6. Security Documentation

```markdown
## Security Documentation

### Security Architecture
[Overview of security architecture and design principles]

### Authentication and Authorization
[Detailed implementation of authentication and authorization]

### Data Protection Measures
[Measures implemented to protect sensitive data]

### Security Controls
[Technical and procedural security controls]

### Vulnerability Management
[Approach to vulnerability management and patching]

### Security Testing Results
[Summary of security testing and assessments]

### Compliance Considerations
[Regulatory and compliance considerations addressed]
```

### 7. Testing Documentation

```markdown
## Testing Documentation

### Test Strategy
[Overall testing strategy and approach]

### Test Cases
[Catalog of test cases with expected results]

### Automated Tests
[Documentation of automated tests and frameworks]

### Performance Test Results
[Results of performance testing with benchmarks]

### Security Test Results
[Results of security testing with findings]

### User Acceptance Testing
[UAT approach, scenarios, and results]

### Known Issues and Limitations
[Documentation of known issues and system limitations]
```

### 8. Deployment Documentation

```markdown
## Deployment Documentation

### Deployment Architecture
[Detailed deployment architecture with diagrams]

### Environment Configuration
[Configuration details for all environments]

### Deployment Procedures
[Step-by-step deployment procedures]

### Configuration Management
[Configuration management approach and tools]

### Release Management
[Release management process and procedures]

### Rollback Procedures
[Procedures for rolling back deployments]

### Monitoring and Alerting
[Monitoring setup, metrics, and alerting configuration]
```

### 9. Operational Documentation

```markdown
## Operational Documentation

### Operating Procedures
[Day-to-day operational procedures]

### Maintenance Tasks
[Routine maintenance tasks and schedules]

### Troubleshooting Guide
[Guide for troubleshooting common issues]

### Backup and Recovery
[Backup and recovery procedures]

### Disaster Recovery
[Disaster recovery plan and procedures]

### Performance Tuning
[Performance tuning guidelines and procedures]

### SLAs and Metrics
[Service level agreements and key performance metrics]
```

### 10. Knowledge Transfer Documentation

```markdown
## Knowledge Transfer Documentation

### System Overview for New Team Members
[Concise system overview for onboarding]

### Key Concepts and Terminology
[Glossary of key concepts and terminology]

### Common Tasks and Procedures
[Guide to common tasks and procedures]

### Frequently Asked Questions
[FAQs for system users and maintainers]

### Training Materials
[Training materials for different roles]

### Support Escalation Process
[Process for escalating support issues]

### Further Reading and Resources
[Additional resources and documentation]
```

### 11. Project History and Learnings

```markdown
## Project History and Learnings

### Project Timeline
[Summary of the project timeline and key milestones]

### Key Decisions and Rationale
[Record of key decisions and their rationale]

### Challenges and Solutions
[Documentation of challenges faced and how they were addressed]

### Lessons Learned
[Key lessons learned that might benefit future projects]

### Performance Against Objectives
[Assessment of performance against original objectives]

### Future Enhancements
[Potential future enhancements and extensions]
```

## 📋 ARCHIVING PROCESS

### 1. Preparation

```mermaid
flowchart TD
    classDef step fill:#f9d77e,stroke:#d9b95c,color:#000
    classDef artifact fill:#f4b8c4,stroke:#d498a4,color:#000
    
    Start([Begin Archive<br>Preparation]) --> Template[Load Archive<br>Template]
    Template --> Review[Review Project<br>Documentation]
    Review --> Identify[Identify All<br>Artifacts]
    Identify --> Gather[Gather All<br>Materials]
    Gather --> Organize[Organize<br>Materials]
    Organize --> Plan[Create Archiving<br>Plan]
    Plan --> Resources[Allocate<br>Resources]
    Resources --> Complete([Preparation<br>Complete])
    
    Template -.-> AT((Archive<br>Template))
    Review -.-> ProjDocs((Project<br>Documentation))
    Identify -.-> ArtList((Artifact<br>List))
    Plan -.-> ArchPlan((Archiving<br>Plan))
    
    class Start,Complete milestone
    class Template,Review,Identify,Gather,Organize,Plan,Resources step
    class AT,ProjDocs,ArtList,ArchPlan artifact
```

**Key Preparation Steps:**
1. Load the comprehensive archive template
2. Review all project documentation including reflection document
3. Identify all artifacts to be archived
4. Gather all materials from various sources
5. Organize materials according to the archive structure
6. Create a detailed archiving plan
7. Allocate resources for the archiving process

### 2. Documentation Creation

```mermaid
flowchart TD
    classDef step fill:#f9d77e,stroke:#d9b95c,color:#000
    classDef artifact fill:#f4b8c4,stroke:#d498a4,color:#000
    
    Start([Begin Documentation<br>Creation]) --> System[Create System<br>Documentation]
    System --> Req[Create Requirements<br>and Design Documentation]
    Req --> Impl[Create Implementation<br>Documentation]
    Impl --> API[Create API<br>Documentation]
    API --> Data[Create Data Model<br>Documentation]
    Data --> Security[Create Security<br>Documentation]
    Security --> Test[Create Testing<br>Documentation]
    Test --> Deploy[Create Deployment<br>Documentation]
    Deploy --> Ops[Create Operational<br>Documentation]
    Ops --> Knowledge[Create Knowledge Transfer<br>Documentation]
    Knowledge --> History[Create Project History<br>Documentation]
    History --> Review[Review All<br>Documentation]
    Review --> Complete([Documentation<br>Creation Complete])
    
    System -.-> SysDoc((System<br>Documentation))
    Req -.-> ReqDoc((Requirements<br>Documentation))
    Impl -.-> ImplDoc((Implementation<br>Documentation))
    API -.-> APIDoc((API<br>Documentation))
    Data -.-> DataDoc((Data Model<br>Documentation))
    Security -.-> SecDoc((Security<br>Documentation))
    Test -.-> TestDoc((Testing<br>Documentation))
    Deploy -.-> DeployDoc((Deployment<br>Documentation))
    Ops -.-> OpsDoc((Operational<br>Documentation))
    Knowledge -.-> KnowDoc((Knowledge Transfer<br>Documentation))
    History -.-> HistDoc((Project History<br>Documentation))
    
    class Start,Complete milestone
    class System,Req,Impl,API,Data,Security,Test,Deploy,Ops,Knowledge,History,Review step
    class SysDoc,ReqDoc,ImplDoc,APIDoc,DataDoc,SecDoc,TestDoc,DeployDoc,OpsDoc,KnowDoc,HistDoc artifact
```

**Key Documentation Steps:**
1. Create comprehensive system documentation
2. Document requirements and design decisions
3. Document implementation details for all components
4. Create complete API documentation
5. Document data models and schemas
6. Document security measures and controls
7. Create thorough testing documentation
8. Document deployment procedures
9. Create operational documentation
10. Prepare knowledge transfer documentation
11. Document project history and learnings
12. Review all documentation for completeness and accuracy

### 3. Archiving and Integration

```mermaid
flowchart TD
    classDef step fill:#f9d77e,stroke:#d9b95c,color:#000
    classDef artifact fill:#f4b8c4,stroke:#d498a4,color:#000
    classDef verification fill:#c5e8b7,stroke:#a5c897,color:#000
    
    Start([Begin Archiving<br>and Integration]) --> Consolidate[Consolidate All<br>Documentation]
    Consolidate --> CrossRef[Create Cross-Reference<br>Index]
    CrossRef --> Version[Version All<br>Documentation]
    Version --> Archive[Archive in<br>Repository]
    Archive --> UpdateMB[Update Memory<br>Bank]
    UpdateMB --> AccessControl[Establish Access<br>Controls]
    AccessControl --> Announce[Announce<br>Availability]
    Announce --> Verification{Archiving<br>Verification}
    Verification -->|Pass| Complete([Archiving<br>Complete])
    Verification -->|Fail| Revise[Revise<br>Archiving]
    Revise --> Verification
    
    Consolidate -.-> AllDocs((Consolidated<br>Documentation))
    CrossRef -.-> Index((Cross-Reference<br>Index))
    Archive -.-> Repo((Archive<br>Repository))
    UpdateMB -.-> MB((Updated Memory<br>Bank))
    
    class Start,Complete milestone
    class Consolidate,CrossRef,Version,Archive,UpdateMB,AccessControl,Announce,Revise step
    class Verification verification
    class AllDocs,Index,Repo,MB artifact
```

**Key Archiving Steps:**
1. Consolidate all documentation into a cohesive package
2. Create a cross-reference index linking all documentation
3. Version all documentation appropriately
4. Archive in the designated repository
5. Update Memory Bank with relevant information
6. Establish appropriate access controls
7. Announce availability to relevant stakeholders
8. Verify archiving completeness and accessibility

## 📋 MEMORY BANK INTEGRATION

```mermaid
flowchart TD
    classDef memfile fill:#f4b8c4,stroke:#d498a4,color:#000
    classDef process fill:#f9d77e,stroke:#d9b95c,color:#000
    
    Archiving[Comprehensive<br>Archiving] --> PB[projectbrief.md]
    Archiving --> PC[productContext.md]
    Archiving --> AC[activeContext.md]
    Archiving --> SP[systemPatterns.md]
    Archiving --> TC[techContext.md]
    Archiving --> P[progress.md]
    
    PB & PC & AC & SP & TC & P --> MBI[Memory Bank<br>Integration]
    MBI --> Next[Repository of<br>Knowledge]
    
    class PB,PC,AC,SP,TC,P memfile
    class Archiving,MBI,Next process
```

### Memory Bank Updates

Specific updates to make to Memory Bank files:

1. **projectbrief.md**
   - Update with final system description
   - Document completion status
   - Include links to archived documentation

2. **productContext.md**
   - Update with final business context
   - Document business value delivered
   - Include links to requirements documentation

3. **activeContext.md**
   - Update with system status (completed)
   - Document handover information
   - Include links to operational documentation

4. **systemPatterns.md**
   - Update with final architecture patterns
   - Document successful implementation patterns
   - Include links to architecture documentation

5. **techContext.md**
   - Update with final technology stack
   - Document integration points
   - Include links to technical documentation

6. **progress.md**
   - Update with final project status
   - Document completion metrics
   - Include links to project history documentation

## 📋 ARCHIVING VERIFICATION CHECKLIST

```
✓ ARCHIVING VERIFICATION CHECKLIST

System Documentation
- System overview complete? [YES/NO]
- Architecture documented with diagrams? [YES/NO]
- Key components documented? [YES/NO]
- Integration points documented? [YES/NO]

Requirements and Design
- Business requirements documented? [YES/NO]
- Functional requirements documented? [YES/NO]
- Architecture decisions documented? [YES/NO]
- Design patterns documented? [YES/NO]

Implementation
- Component implementation details documented? [YES/NO]
- Key algorithms documented? [YES/NO]
- Third-party integrations documented? [YES/NO]
- Configuration parameters documented? [YES/NO]

API Documentation
- API endpoints documented? [YES/NO]
- Request/response formats documented? [YES/NO]
- Authentication documented? [YES/NO]
- Error handling documented? [YES/NO]

Data Documentation
- Data model documented? [YES/NO]
- Database schema documented? [YES/NO]
- Data dictionary provided? [YES/NO]
- Data validation rules documented? [YES/NO]

Security Documentation
- Security architecture documented? [YES/NO]
- Authentication/authorization documented? [YES/NO]
- Data protection measures documented? [YES/NO]
- Security testing results documented? [YES/NO]

Testing Documentation
- Test strategy documented? [YES/NO]
- Test cases documented? [YES/NO]
- Test results documented? [YES/NO]
- Known issues documented? [YES/NO]

Deployment Documentation
- Deployment architecture documented? [YES/NO]
- Environment configurations documented? [YES/NO]
- Deployment procedures documented? [YES/NO]
- Rollback procedures documented? [YES/NO]

Operational Documentation
- Operating procedures documented? [YES/NO]
- Troubleshooting guide provided? [YES/NO]
- Backup and recovery documented? [YES/NO]
- Monitoring configuration documented? [YES/NO]

Knowledge Transfer
- Onboarding overview provided? [YES/NO]
- Key concepts documented? [YES/NO]
- Common tasks documented? [YES/NO]
- FAQs provided? [YES/NO]

Project History
- Project timeline documented? [YES/NO]
- Key decisions documented? [YES/NO]
- Lessons learned documented? [YES/NO]
- Future enhancements suggested? [YES/NO]

Memory Bank Integration
- All Memory Bank files updated? [YES/NO]
- Cross-references created? [YES/NO]
- Documentation properly versioned? [YES/NO]
- Archive repository established? [YES/NO]
```

## 📋 MINIMAL MODE ARCHIVING FORMAT

For situations requiring a more compact archiving approach:

```markdown
## Level 4 Task Archive: [System Name]

### System Summary
- **Purpose**: [Brief description of system purpose]
- **Key Components**: [List of key components]
- **Architecture**: [Brief architecture description with diagram]

### Implementation Summary
- **Technology Stack**: [Key technologies used]
- **Key Modules**: [Brief description of important modules]
- **Integration Points**: [List of major integration points]

### Critical Documentation
- **API Documentation**: [Link or brief summary]
- **Data Model**: [Link or brief description]
- **Deployment Configuration**: [Link or brief description]
- **Security Measures**: [Link or brief summary]

### Operational Information
- **Deployment Procedure**: [Link or brief description]
- **Key Configuration Parameters**: [List of important parameters]
- **Monitoring Setup**: [Brief monitoring details]
- **Common Issues**: [List of common issues with solutions]

### Repository Information
- **Code Repository**: [Link to repository]
- **Documentation Repository**: [Link to documentation]
- **Build Artifacts**: [Link to build artifacts]

### Knowledge Transfer Summary
- **Key Contacts**: [List of key people with knowledge]
- **Critical Knowledge Areas**: [Areas requiring special expertise]
- **Training Resources**: [Links to training materials]

### Memory Bank Links
- [Links to updated Memory Bank files]
```

## 🚨 ARCHIVING ENFORCEMENT PRINCIPLE

```
┌─────────────────────────────────────────────────────┐
│ COMPREHENSIVE ARCHIVING IS MANDATORY for Level 4     │
│ tasks. No complex system is considered complete      │
│ until comprehensive archiving is finished and        │
│ verified.                                            │
└─────────────────────────────────────────────────────┘
```

================
File: .cursor/rules/isolation_rules/Level4/phased-implementation.mdc
================
---
description: Phased Implementation for Level 4 Complex System tasks
globs: "**/level4/**", "**/implementation/**"
alwaysApply: false
---

# PHASED IMPLEMENTATION FOR LEVEL 4 TASKS

> **TL;DR:** This document outlines a structured phased implementation approach for Level 4 (Complex System) tasks, ensuring controlled, incremental delivery of complex systems with appropriate verification at each phase.

## 🔍 PHASED IMPLEMENTATION OVERVIEW

Level 4 Complex System tasks require a controlled, incremental approach to implementation to manage complexity, reduce risk, and ensure quality. This document outlines a phased implementation methodology that divides complex system development into discrete, verifiable phases with clear entry and exit criteria.

```mermaid
flowchart TD
    classDef phase fill:#f9d77e,stroke:#d9b95c,color:#000
    classDef artifact fill:#f4b8c4,stroke:#d498a4,color:#000
    classDef verification fill:#c5e8b7,stroke:#a5c897,color:#000
    
    Start([Begin Implementation<br>Process]) --> Framework[Establish Implementation<br>Framework]
    Framework --> Plan[Create Phasing<br>Plan]
    Plan --> Foundation[Implement<br>Foundation Phase]
    Foundation --> VerifyF{Foundation<br>Verification}
    VerifyF -->|Pass| Core[Implement<br>Core Phase]
    VerifyF -->|Fail| ReviseF[Revise<br>Foundation]
    ReviseF --> VerifyF
    
    Core --> VerifyC{Core<br>Verification}
    VerifyC -->|Pass| Extension[Implement<br>Extension Phase]
    VerifyC -->|Fail| ReviseC[Revise<br>Core]
    ReviseC --> VerifyC
    
    Extension --> VerifyE{Extension<br>Verification}
    VerifyE -->|Pass| Integration[Implement<br>Integration Phase]
    VerifyE -->|Fail| ReviseE[Revise<br>Extension]
    ReviseE --> VerifyE
    
    Integration --> VerifyI{Integration<br>Verification}
    VerifyI -->|Pass| Finalization[Implement<br>Finalization Phase]
    VerifyI -->|Fail| ReviseI[Revise<br>Integration]
    ReviseI --> VerifyI
    
    Finalization --> VerifyFin{Finalization<br>Verification}
    VerifyFin -->|Pass| Complete([Implementation<br>Complete])
    VerifyFin -->|Fail| ReviseFin[Revise<br>Finalization]
    ReviseFin --> VerifyFin
    
    Framework -.-> IF((Implementation<br>Framework))
    Plan -.-> PP((Phasing<br>Plan))
    Foundation -.-> FP((Foundation<br>Phase))
    Core -.-> CP((Core<br>Phase))
    Extension -.-> EP((Extension<br>Phase))
    Integration -.-> IP((Integration<br>Phase))
    Finalization -.-> FiP((Finalization<br>Phase))
    
    class Start,Complete milestone
    class Framework,Plan,Foundation,Core,Extension,Integration,Finalization,ReviseF,ReviseC,ReviseE,ReviseI,ReviseFin step
    class VerifyF,VerifyC,VerifyE,VerifyI,VerifyFin verification
    class IF,PP,FP,CP,EP,IP,FiP artifact
```

## 📋 IMPLEMENTATION PHASING PRINCIPLES

1. **Incremental Value Delivery**: Each phase delivers tangible, verifiable value.
2. **Progressive Complexity**: Complexity increases gradually across phases.
3. **Risk Mitigation**: Early phases address high-risk elements to fail fast if needed.
4. **Verification Gates**: Each phase has explicit entry and exit criteria.
5. **Business Alignment**: Phases align with business priorities and user needs.
6. **Technical Integrity**: Each phase maintains architectural and technical integrity.
7. **Continuous Integration**: Work is continuously integrated and tested.
8. **Knowledge Building**: Each phase builds upon knowledge gained in previous phases.
9. **Explicit Dependencies**: Dependencies between phases are clearly documented.
10. **Adaptability**: The phasing plan can adapt to new information while maintaining structure.

## 📋 STANDARD IMPLEMENTATION PHASES

Level 4 Complex System tasks typically follow a five-phase implementation approach:

```mermaid
flowchart LR
    classDef phase fill:#f9d77e,stroke:#d9b95c,color:#000
    
    P1[1. Foundation<br>Phase] --> P2[2. Core<br>Phase]
    P2 --> P3[3. Extension<br>Phase]
    P3 --> P4[4. Integration<br>Phase]
    P4 --> P5[5. Finalization<br>Phase]
    
    class P1,P2,P3,P4,P5 phase
```

### Phase 1: Foundation Phase

The Foundation Phase establishes the basic architecture and infrastructure required for the system.

**Key Activities:**
- Set up development, testing, and deployment environments
- Establish core architectural components and patterns
- Implement database schema and basic data access
- Create skeleton application structure
- Implement authentication and authorization framework
- Establish logging, monitoring, and error handling
- Create basic CI/CD pipeline

**Exit Criteria:**
- Basic architectural framework is functional
- Environment setup is complete and documented
- Core infrastructure components are in place
- Basic CI/CD pipeline is operational
- Architecture review confirms alignment with design

### Phase 2: Core Phase

The Core Phase implements the essential functionality that provides the minimum viable system.

**Key Activities:**
- Implement core business logic
- Develop primary user flows and interfaces
- Create essential system services
- Implement critical API endpoints
- Develop basic reporting capabilities
- Establish primary integration points
- Create automated tests for core functionality

**Exit Criteria:**
- Core business functionality is implemented
- Essential user flows are working
- Primary APIs are functional
- Core automated tests are passing
- Business stakeholders verify core functionality

### Phase 3: Extension Phase

The Extension Phase adds additional features and capabilities to the core system.

**Key Activities:**
- Implement secondary business processes
- Add additional user interfaces and features
- Enhance existing functionality based on feedback
- Implement advanced features
- Extend integration capabilities
- Enhance error handling and edge cases
- Expand test coverage

**Exit Criteria:**
- All planned features are implemented
- Extended functionality is working correctly
- Secondary business processes are functional
- Enhanced features have been validated
- Test coverage meets defined thresholds

### Phase 4: Integration Phase

The Integration Phase ensures all components work together properly and integrates with external systems.

**Key Activities:**
- Perform deep integration testing
- Implement all external system integrations
- Conduct end-to-end testing
- Perform performance and load testing
- Conduct security testing
- Implement any required data migrations
- Verify system behavior under various conditions

**Exit Criteria:**
- All integrations are working correctly
- End-to-end tests are passing
- Performance meets defined requirements
- Security tests show no critical vulnerabilities
- System handles error conditions gracefully

### Phase 5: Finalization Phase

The Finalization Phase prepares the system for production release.

**Key Activities:**
- Optimize performance
- Conduct user acceptance testing
- Finalize documentation
- Conduct final security review
- Create production deployment plan
- Prepare support materials and training
- Conduct final system review

**Exit Criteria:**
- All acceptance criteria are met
- Documentation is complete
- User acceptance testing is successful
- Production deployment plan is approved
- Support and maintenance procedures are established

## 📋 PHASE PLANNING TEMPLATE

For each implementation phase, create a detailed plan using this template:

```markdown
## [Phase Name] Implementation Plan

### Phase Overview
- **Purpose**: [Brief description of phase purpose]
- **Timeline**: [Start and end dates]
- **Dependencies**: [Dependencies on other phases or external factors]
- **Key Stakeholders**: [List of key stakeholders for this phase]

### Entry Criteria
- [ ] [Criterion 1]
- [ ] [Criterion 2]
- [ ] [Criterion 3]

### Implementation Components
- **Component 1**: [Description]
  - [ ] Task 1.1: [Description]
  - [ ] Task 1.2: [Description]
  
- **Component 2**: [Description]
  - [ ] Task 2.1: [Description]
  - [ ] Task 2.2: [Description]

### Technical Considerations
- [Key technical considerations for this phase]

### Risk Assessment
- **Risk 1**: [Description]
  - Impact: [High/Medium/Low]
  - Mitigation: [Strategy]
  
- **Risk 2**: [Description]
  - Impact: [High/Medium/Low]
  - Mitigation: [Strategy]

### Quality Assurance
- [QA approach for this phase]
- [Testing requirements]

### Exit Criteria
- [ ] [Criterion 1]
- [ ] [Criterion 2]
- [ ] [Criterion 3]

### Deliverables
- [List of deliverables for this phase]
```

## 📋 PHASE VERIFICATION

Each phase requires formal verification before proceeding to the next phase.

```mermaid
flowchart TD
    classDef activity fill:#f9d77e,stroke:#d9b95c,color:#000
    classDef artifact fill:#f4b8c4,stroke:#d498a4,color:#000
    classDef decision fill:#c5e8b7,stroke:#a5c897,color:#000
    
    Start([Begin Phase<br>Verification]) --> CodeReview[Conduct Code<br>Review]
    CodeReview --> TestExecution[Execute Automated<br>Tests]
    TestExecution --> QAVerification[Perform QA<br>Verification]
    QAVerification --> ArchReview[Conduct Architecture<br>Review]
    ArchReview --> StakeholderReview[Conduct Stakeholder<br>Review]
    StakeholderReview --> Checklist[Complete Verification<br>Checklist]
    Checklist --> ExitCriteria{All Exit<br>Criteria Met?}
    ExitCriteria -->|Yes| Approval[Obtain Phase<br>Approval]
    ExitCriteria -->|No| Issues[Document<br>Issues]
    Issues --> Remediation[Implement<br>Remediation]
    Remediation --> Retest[Verify<br>Fixes]
    Retest --> ExitCriteria
    Approval --> Complete([Verification<br>Complete])
    
    CodeReview -.-> CodeReport((Code Review<br>Report))
    TestExecution -.-> TestReport((Test<br>Report))
    QAVerification -.-> QAReport((QA<br>Report))
    ArchReview -.-> ArchReport((Architecture<br>Report))
    StakeholderReview -.-> StakeReport((Stakeholder<br>Report))
    Checklist -.-> CheckDoc((Verification<br>Checklist))
    
    class Start,Complete milestone
    class CodeReview,TestExecution,QAVerification,ArchReview,StakeholderReview,Checklist,Approval,Issues,Remediation,Retest activity
    class ExitCriteria decision
    class CodeReport,TestReport,QAReport,ArchReport,StakeReport,CheckDoc artifact
```

### Phase Verification Checklist Template

```markdown
## Phase Verification Checklist

### Implementation Completeness
- [ ] All planned components implemented
- [ ] All tasks marked as complete
- [ ] No outstanding TODOs in code
- [ ] All documentation updated

### Code Quality
- [ ] Code review completed
- [ ] No critical issues found in static analysis
- [ ] Code meets established standards
- [ ] Technical debt documented

### Testing
- [ ] Unit tests completed and passing
- [ ] Integration tests completed and passing
- [ ] End-to-end tests completed and passing
- [ ] Performance testing completed (if applicable)
- [ ] Security testing completed (if applicable)
- [ ] Test coverage meets requirements

### Architecture
- [ ] Implementation follows architectural design
- [ ] No architectural violations introduced
- [ ] Technical patterns correctly implemented
- [ ] Non-functional requirements met

### Stakeholder Verification
- [ ] Business requirements met
- [ ] Stakeholder demo completed
- [ ] Feedback incorporated
- [ ] Acceptance criteria verified

### Risk Assessment
- [ ] All identified risks addressed
- [ ] No new risks introduced
- [ ] Contingency plans in place for known issues

### Exit Criteria
- [ ] All exit criteria met
- [ ] Any exceptions documented and approved
- [ ] Phase signoff obtained from required parties
```

## 📋 HANDLING PHASE DEPENDENCIES

```mermaid
flowchart TD
    classDef solid fill:#f9d77e,stroke:#d9b95c,color:#000
    classDef partial fill:#a8d5ff,stroke:#88b5e0,color:#000
    
    F[Foundation<br>Phase] --> C[Core<br>Phase]
    F --> E[Extension<br>Phase]
    F --> I[Integration<br>Phase]
    F --> FN[Finalization<br>Phase]
    
    C --> E
    C --> I
    C --> FN
    
    E --> I
    E --> FN
    
    I --> FN
    
    class F,C solid
    class E,I,FN partial
```

### Dependency Management Strategies

1. **Vertical Slicing**: Implement complete features across all phases for priority functionality.
2. **Stubbing and Mocking**: Create temporary implementations to allow progress on dependent components.
3. **Interface Contracts**: Define clear interfaces between components to allow parallel development.
4. **Feature Toggles**: Implement features but keep them disabled until dependencies are ready.
5. **Incremental Integration**: Gradually integrate components as they become available.

### Dependency Documentation Format

```markdown
## Implementation Dependencies

### Foundation Phase Dependencies
- **External Dependencies**:
  - Development environment setup
  - Access to source control
  - Access to CI/CD pipeline

### Core Phase Dependencies
- **Foundation Phase Dependencies**:
  - Authentication framework
  - Database schema
  - Logging infrastructure
  - Basic application skeleton
  
- **External Dependencies**:
  - API specifications from external systems
  - Test data

### Extension Phase Dependencies
- **Core Phase Dependencies**:
  - Core business logic
  - Primary user interface
  - Essential services
  
- **External Dependencies**:
  - [List external dependencies]

### Integration Phase Dependencies
- **Core Phase Dependencies**:
  - [List core dependencies]
  
- **Extension Phase Dependencies**:
  - [List extension dependencies]
  
- **External Dependencies**:
  - Access to integration test environments
  - Test credentials for external systems

### Finalization Phase Dependencies
- **All previous phases must be complete**
- **External Dependencies**:
  - User acceptance testing environment
  - Production deployment approval
```

## 📋 PHASE TRANSITION PROCESS

```mermaid
flowchart TD
    classDef step fill:#f9d77e,stroke:#d9b95c,color:#000
    classDef artifact fill:#f4b8c4,stroke:#d498a4,color:#000
    classDef verification fill:#c5e8b7,stroke:#a5c897,color:#000
    
    Start([Begin Phase<br>Transition]) --> Verification[Verify Current<br>Phase Complete]
    Verification --> Checkpoint{Phase<br>Verified?}
    Checkpoint -->|No| Remediation[Remediate<br>Issues]
    Remediation --> Verification
    Checkpoint -->|Yes| Documentation[Update<br>Documentation]
    Documentation --> Reflection[Conduct Phase<br>Reflection]
    Reflection --> NextPlan[Finalize Next<br>Phase Plan]
    NextPlan --> Approvals[Obtain<br>Approvals]
    Approvals --> Kickoff[Conduct Next<br>Phase Kickoff]
    Kickoff --> End([Begin Next<br>Phase])
    
    Verification -.-> VerifDoc((Verification<br>Checklist))
    Documentation -.-> Docs((Updated<br>Documentation))
    Reflection -.-> ReflectDoc((Reflection<br>Document))
    NextPlan -.-> PlanDoc((Phase<br>Plan))
    
    class Start,End milestone
    class Verification,Remediation,Documentation,Reflection,NextPlan,Approvals,Kickoff step
    class Checkpoint verification
    class VerifDoc,Docs,ReflectDoc,PlanDoc artifact
```

### Phase Transition Checklist

```markdown
## Phase Transition Checklist

### Current Phase Closure
- [ ] All exit criteria met and documented
- [ ] All verification steps completed
- [ ] All issues resolved or documented
- [ ] Phase retrospective completed

### Documentation Updates
- [ ] Technical documentation updated
- [ ] User documentation updated
- [ ] Architecture documentation updated
- [ ] Test documentation updated

### Knowledge Transfer
- [ ] Lessons learned documented
- [ ] Knowledge shared with team
- [ ] Training conducted if needed

### Next Phase Preparation
- [ ] Next phase plan reviewed and updated
- [ ] Resources aligned
- [ ] Dependencies verified
- [ ] Entry criteria confirmed

### Approvals
- [ ] Technical lead approval
- [ ] Business stakeholder approval
- [ ] Project management approval
```

## 📋 IMPLEMENTATION TRACKING IN TASKS.MD

Update `tasks.md` to track phased implementation progress:

```markdown
## [SYSTEM-ID]: System Name

### Implementation Phases
#### 1. Foundation Phase
- **Status**: [Not Started/In Progress/Complete]
- **Progress**: [0-100%]
- **Start Date**: [Date]
- **Target Completion**: [Date]
- **Actual Completion**: [Date]

**Key Components**:
- [ ] Component 1: [Status] - [Progress %]
- [ ] Component 2: [Status] - [Progress %]

**Verification Status**:
- [ ] Code Review: [Status]
- [ ] Testing: [Status]
- [ ] Architecture Review: [Status]
- [ ] Stakeholder Approval: [Status]

**Issues/Blockers**:
- [List of issues if any]

#### 2. Core Phase
...

#### 3. Extension Phase
...

#### 4. Integration Phase
...

#### 5. Finalization Phase
...
```

## 📋 MEMORY BANK INTEGRATION

```mermaid
flowchart TD
    classDef memfile fill:#f4b8c4,stroke:#d498a4,color:#000
    classDef process fill:#f9d77e,stroke:#d9b95c,color:#000
    
    Implementation[Phased<br>Implementation] --> PB[projectbrief.md]
    Implementation --> PC[productContext.md]
    Implementation --> AC[activeContext.md]
    Implementation --> SP[systemPatterns.md]
    Implementation --> TC[techContext.md]
    Implementation --> P[progress.md]
    
    PB & PC & AC & SP & TC & P --> MBI[Memory Bank<br>Integration]
    MBI --> Implementation
    
    class PB,PC,AC,SP,TC,P memfile
    class Implementation,MBI process
```

### Memory Bank Updates

Update the following Memory Bank files during phased implementation:

1. **projectbrief.md**
   - Update implementation approach
   - Document phase-specific objectives
   - Link to phase plans

2. **activeContext.md**
   - Update with current implementation phase
   - Document active implementation tasks
   - Highlight current focus areas

3. **systemPatterns.md**
   - Document implementation patterns used
   - Update with architectural decisions made during implementation
   - Record any pattern adaptations

4. **techContext.md**
   - Update with implementation technologies
   - Document technical constraints encountered
   - Record technical decisions made

5. **progress.md**
   - Update implementation progress by phase
   - Document completed components
   - Track overall implementation status

## 📋 IMPLEMENTATION VERIFICATION CHECKLIST

```
✓ IMPLEMENTATION VERIFICATION CHECKLIST

Planning
- Implementation framework established? [YES/NO]
- Phasing plan created? [YES/NO]
- Phase dependencies documented? [YES/NO]
- Entry/exit criteria defined for all phases? [YES/NO]
- Risk assessment performed? [YES/NO]

Foundation Phase
- Environment setup complete? [YES/NO]
- Core architecture implemented? [YES/NO]
- Basic infrastructure in place? [YES/NO]
- CI/CD pipeline operational? [YES/NO]
- Foundation verification completed? [YES/NO]

Core Phase
- Core business logic implemented? [YES/NO]
- Primary user flows working? [YES/NO]
- Essential services operational? [YES/NO]
- Core APIs implemented? [YES/NO]
- Core verification completed? [YES/NO]

Extension Phase
- Secondary features implemented? [YES/NO]
- Enhanced functionality working? [YES/NO]
- Additional user interfaces complete? [YES/NO]
- Extended test coverage in place? [YES/NO]
- Extension verification completed? [YES/NO]

Integration Phase
- All components integrated? [YES/NO]
- External integrations working? [YES/NO]
- End-to-end testing completed? [YES/NO]
- Performance testing executed? [YES/NO]
- Integration verification completed? [YES/NO]

Finalization Phase
- All optimizations complete? [YES/NO]
- User acceptance testing passed? [YES/NO]
- Documentation finalized? [YES/NO]
- Production deployment plan ready? [YES/NO]
- Final system review completed? [YES/NO]

Memory Bank Integration
- All Memory Bank files updated? [YES/NO]
- Implementation status reflected? [YES/NO]
- Technical decisions documented? [YES/NO]
- Progress tracking current? [YES/NO]
```

## 📋 MINIMAL MODE IMPLEMENTATION FORMAT

For situations requiring a more compact implementation approach:

```markdown
## [SYSTEM-ID]: Phased Implementation

### Phase Status Summary
- **Foundation**: [Status] - [Progress %]
- **Core**: [Status] - [Progress %] 
- **Extension**: [Status] - [Progress %]
- **Integration**: [Status] - [Progress %]
- **Finalization**: [Status] - [Progress %]

### Current Phase: [Phase Name]
- **Key Components**: [List of key components being implemented]
- **Blockers**: [List of blockers if any]
- **Next Steps**: [List of immediate next steps]

### Verification Status
- [List of verification steps and their status]

### Memory Bank Updates
- [List of Memory Bank files that need updating]
```

## 🚨 IMPLEMENTATION VERIFICATION PRINCIPLE

```
┌─────────────────────────────────────────────────────┐
│ NO PHASE IS CONSIDERED COMPLETE until all            │
│ verification steps have been passed and documented.  │
│ Phases MUST NOT be rushed to meet deadlines at the   │
│ expense of quality or architectural integrity.       │
└─────────────────────────────────────────────────────┘
```

================
File: .cursor/rules/isolation_rules/Level4/reflection-comprehensive.mdc
================
---
description: Comprehensive reflection format for Level 4 Complex System tasks
globs: "**/level4/**", "**/reflection/**"
alwaysApply: false
---

# COMPREHENSIVE REFLECTION FOR LEVEL 4 TASKS

> **TL;DR:** This document outlines a structured, comprehensive approach to reflection for Level 4 (Complex System) tasks, including system review, success and challenge analysis, strategic insights, and action planning.

## 🔍 COMPREHENSIVE REFLECTION OVERVIEW

Level 4 Complex System tasks require in-depth reflection to capture key insights, document successes and challenges, extract strategic lessons, and guide future improvements. This systematic reflection process ensures organizational learning and continuous improvement.

```mermaid
flowchart TD
    classDef phase fill:#f9d77e,stroke:#d9b95c,color:#000
    classDef artifact fill:#f4b8c4,stroke:#d498a4,color:#000
    classDef verification fill:#c5e8b7,stroke:#a5c897,color:#000
    
    Start([Begin Reflection<br>Process]) --> Template[Load Comprehensive<br>Reflection Template]
    Template --> SysReview[Conduct System<br>Review]
    SysReview --> ArchReview[Review Architecture<br>Decisions]
    ArchReview --> ImplementReview[Review Implementation<br>Approach]
    ImplementReview --> SuccessAnalysis[Document Successes<br>and Achievements]
    SuccessAnalysis --> ChallengeAnalysis[Document Challenges<br>and Solutions]
    ChallengeAnalysis --> Technical[Extract Technical<br>Insights]
    Technical --> Process[Extract Process<br>Insights]
    Process --> Business[Extract Business<br>Insights]
    Business --> Strategic[Define Strategic<br>Actions]
    Strategic --> Timeline[Analyze Timeline<br>Performance]
    Timeline --> Documentation[Complete Reflection<br>Documentation]
    Documentation --> Integration[Integrate with<br>Memory Bank]
    Integration --> Verification{Reflection<br>Verification}
    Verification -->|Pass| Complete([Reflection<br>Complete])
    Verification -->|Fail| Revise[Revise<br>Reflection]
    Revise --> Verification
    
    Template -.-> RT((Reflection<br>Template))
    SysReview -.-> SR((System<br>Review))
    SuccessAnalysis & ChallengeAnalysis -.-> SCD((Success/Challenge<br>Document))
    Technical & Process & Business -.-> Insights((Insight<br>Document))
    Strategic -.-> Actions((Strategic<br>Actions))
    
    class Start,Complete milestone
    class Template,SysReview,ArchReview,ImplementReview,SuccessAnalysis,ChallengeAnalysis,Technical,Process,Business,Strategic,Timeline,Documentation,Integration step
    class Verification verification
    class RT,SR,SCD,Insights,Actions artifact
```

## 📋 REFLECTION TEMPLATE STRUCTURE

### 1. System Overview

```markdown
## System Overview

### System Description
[Comprehensive description of the implemented system, including purpose, scope, and key features]

### System Context
[Description of how the system fits into the broader technical and business ecosystem]

### Key Components
- Component 1: [Description and purpose]
- Component 2: [Description and purpose]
- Component 3: [Description and purpose]

### System Architecture
[Summary of the architectural approach, key patterns, and design decisions]

### System Boundaries
[Description of system boundaries, interfaces, and integration points]

### Implementation Summary
[Overview of the implementation approach, technologies, and methods used]
```

### 2. Project Performance Analysis

```markdown
## Project Performance Analysis

### Timeline Performance
- **Planned Duration**: [X] weeks/months
- **Actual Duration**: [Y] weeks/months
- **Variance**: [+/-Z] weeks/months ([P]%)
- **Explanation**: [Analysis of timeline variances]

### Resource Utilization
- **Planned Resources**: [X] person-months
- **Actual Resources**: [Y] person-months
- **Variance**: [+/-Z] person-months ([P]%)
- **Explanation**: [Analysis of resource variances]

### Quality Metrics
- **Planned Quality Targets**: [List of quality targets]
- **Achieved Quality Results**: [List of achieved quality results]
- **Variance Analysis**: [Analysis of quality variances]

### Risk Management Effectiveness
- **Identified Risks**: [Number of risks identified]
- **Risks Materialized**: [Number and percentage of risks that occurred]
- **Mitigation Effectiveness**: [Effectiveness of risk mitigation strategies]
- **Unforeseen Risks**: [Description of unforeseen risks that emerged]
```

### 3. Achievements and Successes

```markdown
## Achievements and Successes

### Key Achievements
1. **Achievement 1**: [Description]
   - **Evidence**: [Concrete evidence of success]
   - **Impact**: [Business/technical impact]
   - **Contributing Factors**: [What enabled this success]

2. **Achievement 2**: [Description]
   - **Evidence**: [Concrete evidence of success]
   - **Impact**: [Business/technical impact]
   - **Contributing Factors**: [What enabled this success]

### Technical Successes
- **Success 1**: [Description of technical success]
  - **Approach Used**: [Description of approach]
  - **Outcome**: [Results achieved]
  - **Reusability**: [How this can be reused]

- **Success 2**: [Description of technical success]
  - **Approach Used**: [Description of approach]
  - **Outcome**: [Results achieved]
  - **Reusability**: [How this can be reused]

### Process Successes
- **Success 1**: [Description of process success]
  - **Approach Used**: [Description of approach]
  - **Outcome**: [Results achieved]
  - **Reusability**: [How this can be reused]

### Team Successes
- **Success 1**: [Description of team success]
  - **Approach Used**: [Description of approach]
  - **Outcome**: [Results achieved]
  - **Reusability**: [How this can be reused]
```

### 4. Challenges and Solutions

```markdown
## Challenges and Solutions

### Key Challenges
1. **Challenge 1**: [Description]
   - **Impact**: [Business/technical impact]
   - **Resolution Approach**: [How it was addressed]
   - **Outcome**: [Final result]
   - **Preventative Measures**: [How to prevent in future]

2. **Challenge 2**: [Description]
   - **Impact**: [Business/technical impact]
   - **Resolution Approach**: [How it was addressed]
   - **Outcome**: [Final result]
   - **Preventative Measures**: [How to prevent in future]

### Technical Challenges
- **Challenge 1**: [Description of technical challenge]
  - **Root Cause**: [Analysis of root cause]
  - **Solution**: [How it was solved]
  - **Alternative Approaches**: [Other approaches considered]
  - **Lessons Learned**: [Key takeaways]

- **Challenge 2**: [Description of technical challenge]
  - **Root Cause**: [Analysis of root cause]
  - **Solution**: [How it was solved]
  - **Alternative Approaches**: [Other approaches considered]
  - **Lessons Learned**: [Key takeaways]

### Process Challenges
- **Challenge 1**: [Description of process challenge]
  - **Root Cause**: [Analysis of root cause]
  - **Solution**: [How it was solved]
  - **Process Improvements**: [Improvements made or suggested]

### Unresolved Issues
- **Issue 1**: [Description of unresolved issue]
  - **Current Status**: [Status]
  - **Proposed Path Forward**: [Suggested next steps]
  - **Required Resources**: [What's needed to resolve]
```

### 5. Technical Insights

```markdown
## Technical Insights

### Architecture Insights
- **Insight 1**: [Description of architectural insight]
  - **Context**: [When/where this was observed]
  - **Implications**: [What this means for future work]
  - **Recommendations**: [Suggested changes or actions]

- **Insight 2**: [Description of architectural insight]
  - **Context**: [When/where this was observed]
  - **Implications**: [What this means for future work]
  - **Recommendations**: [Suggested changes or actions]

### Implementation Insights
- **Insight 1**: [Description of implementation insight]
  - **Context**: [When/where this was observed]
  - **Implications**: [What this means for future work]
  - **Recommendations**: [Suggested changes or actions]

### Technology Stack Insights
- **Insight 1**: [Description of technology stack insight]
  - **Context**: [When/where this was observed]
  - **Implications**: [What this means for future work]
  - **Recommendations**: [Suggested changes or actions]

### Performance Insights
- **Insight 1**: [Description of performance insight]
  - **Context**: [When/where this was observed]
  - **Metrics**: [Relevant performance metrics]
  - **Implications**: [What this means for future work]
  - **Recommendations**: [Suggested optimizations]

### Security Insights
- **Insight 1**: [Description of security insight]
  - **Context**: [When/where this was observed]
  - **Implications**: [What this means for future work]
  - **Recommendations**: [Suggested security improvements]
```

### 6. Process Insights

```markdown
## Process Insights

### Planning Insights
- **Insight 1**: [Description of planning process insight]
  - **Context**: [When/where this was observed]
  - **Implications**: [What this means for future work]
  - **Recommendations**: [Suggested process improvements]

### Development Process Insights
- **Insight 1**: [Description of development process insight]
  - **Context**: [When/where this was observed]
  - **Implications**: [What this means for future work]
  - **Recommendations**: [Suggested process improvements]

### Testing Insights
- **Insight 1**: [Description of testing process insight]
  - **Context**: [When/where this was observed]
  - **Implications**: [What this means for future work]
  - **Recommendations**: [Suggested process improvements]

### Collaboration Insights
- **Insight 1**: [Description of collaboration insight]
  - **Context**: [When/where this was observed]
  - **Implications**: [What this means for future work]
  - **Recommendations**: [Suggested collaboration improvements]

### Documentation Insights
- **Insight 1**: [Description of documentation insight]
  - **Context**: [When/where this was observed]
  - **Implications**: [What this means for future work]
  - **Recommendations**: [Suggested documentation improvements]
```

### 7. Business Insights

```markdown
## Business Insights

### Value Delivery Insights
- **Insight 1**: [Description of value delivery insight]
  - **Context**: [When/where this was observed]
  - **Business Impact**: [Impact on business outcomes]
  - **Recommendations**: [Suggested improvements]

### Stakeholder Insights
- **Insight 1**: [Description of stakeholder insight]
  - **Context**: [When/where this was observed]
  - **Implications**: [What this means for stakeholder management]
  - **Recommendations**: [Suggested improvements]

### Market/User Insights
- **Insight 1**: [Description of market/user insight]
  - **Context**: [When/where this was observed]
  - **Implications**: [What this means for product direction]
  - **Recommendations**: [Suggested improvements]

### Business Process Insights
- **Insight 1**: [Description of business process insight]
  - **Context**: [When/where this was observed]
  - **Implications**: [What this means for business processes]
  - **Recommendations**: [Suggested improvements]
```

### 8. Strategic Actions

```markdown
## Strategic Actions

### Immediate Actions
- **Action 1**: [Description of immediate action]
  - **Owner**: [Person responsible]
  - **Timeline**: [Expected completion date]
  - **Success Criteria**: [How to measure success]
  - **Resources Required**: [What's needed]
  - **Priority**: [High/Medium/Low]

- **Action 2**: [Description of immediate action]
  - **Owner**: [Person responsible]
  - **Timeline**: [Expected completion date]
  - **Success Criteria**: [How to measure success]
  - **Resources Required**: [What's needed]
  - **Priority**: [High/Medium/Low]

### Short-Term Improvements (1-3 months)
- **Improvement 1**: [Description of short-term improvement]
  - **Owner**: [Person responsible]
  - **Timeline**: [Expected completion date]
  - **Success Criteria**: [How to measure success]
  - **Resources Required**: [What's needed]
  - **Priority**: [High/Medium/Low]

### Medium-Term Initiatives (3-6 months)
- **Initiative 1**: [Description of medium-term initiative]
  - **Owner**: [Person responsible]
  - **Timeline**: [Expected completion date]
  - **Success Criteria**: [How to measure success]
  - **Resources Required**: [What's needed]
  - **Priority**: [High/Medium/Low]

### Long-Term Strategic Directions (6+ months)
- **Direction 1**: [Description of long-term strategic direction]
  - **Business Alignment**: [How this aligns with business strategy]
  - **Expected Impact**: [Anticipated outcomes]
  - **Key Milestones**: [Major checkpoints]
  - **Success Criteria**: [How to measure success]
```

### 9. Knowledge Transfer

```markdown
## Knowledge Transfer

### Key Learnings for Organization
- **Learning 1**: [Description of key organizational learning]
  - **Context**: [When/where this was learned]
  - **Applicability**: [Where this can be applied]
  - **Suggested Communication**: [How to share this]

### Technical Knowledge Transfer
- **Technical Knowledge 1**: [Description of technical knowledge]
  - **Audience**: [Who needs this knowledge]
  - **Transfer Method**: [How to transfer]
  - **Documentation**: [Where documented]

### Process Knowledge Transfer
- **Process Knowledge 1**: [Description of process knowledge]
  - **Audience**: [Who needs this knowledge]
  - **Transfer Method**: [How to transfer]
  - **Documentation**: [Where documented]

### Documentation Updates
- **Document 1**: [Name of document to update]
  - **Required Updates**: [What needs to be updated]
  - **Owner**: [Person responsible]
  - **Timeline**: [When it will be updated]
```

### 10. Reflection Summary

```markdown
## Reflection Summary

### Key Takeaways
- **Takeaway 1**: [Description of key takeaway]
- **Takeaway 2**: [Description of key takeaway]
- **Takeaway 3**: [Description of key takeaway]

### Success Patterns to Replicate
1. [Pattern 1 description]
2. [Pattern 2 description]
3. [Pattern 3 description]

### Issues to Avoid in Future
1. [Issue 1 description]
2. [Issue 2 description]
3. [Issue 3 description]

### Overall Assessment
[Comprehensive assessment of the project's success, challenges, and strategic value]

### Next Steps
[Clear description of immediate next steps following this reflection]
```

## 📋 REFLECTION PROCESS

### 1. Preparation

```mermaid
flowchart TD
    classDef step fill:#f9d77e,stroke:#d9b95c,color:#000
    classDef artifact fill:#f4b8c4,stroke:#d498a4,color:#000
    
    Start([Begin Reflection<br>Preparation]) --> Template[Load Reflection<br>Template]
    Template --> Data[Gather Project<br>Data]
    Data --> Metrics[Collect Performance<br>Metrics]
    Metrics --> Feedback[Gather Stakeholder<br>Feedback]
    Feedback --> Schedule[Schedule Reflection<br>Session]
    Schedule --> Participants[Identify<br>Participants]
    Participants --> Agenda[Create Session<br>Agenda]
    Agenda --> Complete([Preparation<br>Complete])
    
    Template -.-> TDoc((Reflection<br>Template))
    Data -.-> ProjData((Project<br>Data))
    Metrics -.-> MetricsDoc((Performance<br>Metrics))
    Feedback -.-> FeedbackDoc((Stakeholder<br>Feedback))
    
    class Start,Complete milestone
    class Template,Data,Metrics,Feedback,Schedule,Participants,Agenda step
    class TDoc,ProjData,MetricsDoc,FeedbackDoc artifact
```

**Key Preparation Steps:**
1. Load the comprehensive reflection template
2. Gather project data (tasks.md, documentation, artifacts)
3. Collect performance metrics (timeline, resource utilization, quality)
4. Gather stakeholder feedback (internal and external)
5. Schedule reflection session(s) with key participants
6. Prepare session agenda and pre-work materials

### 2. Conducting the Reflection Session

```mermaid
flowchart TD
    classDef step fill:#f9d77e,stroke:#d9b95c,color:#000
    classDef artifact fill:#f4b8c4,stroke:#d498a4,color:#000
    
    Start([Begin Reflection<br>Session]) --> Intro[Introduction and<br>Context Setting]
    Intro --> Project[Project Overview<br>Presentation]
    Project --> Success[Success<br>Identification]
    Success --> Challenge[Challenge<br>Identification]
    Challenge --> Root[Root Cause<br>Analysis]
    Root --> Insights[Insight<br>Generation]
    Insights --> Actions[Action<br>Planning]
    Actions --> Documentation[Document<br>Outcomes]
    Documentation --> Next[Define Next<br>Steps]
    Next --> Complete([Session<br>Complete])
    
    Success -.-> SuccessDoc((Success<br>Document))
    Challenge -.-> ChallengeDoc((Challenge<br>Document))
    Insights -.-> InsightDoc((Insight<br>Document))
    Actions -.-> ActionDoc((Action<br>Plan))
    
    class Start,Complete milestone
    class Intro,Project,Success,Challenge,Root,Insights,Actions,Documentation,Next step
    class SuccessDoc,ChallengeDoc,InsightDoc,ActionDoc artifact
```

**Session Format:**
- **Duration**: 2-4 hours (may be split across multiple sessions)
- **Participants**: Project team, key stakeholders, technical leads
- **Facilitation**: Neutral facilitator to guide the process
- **Documentation**: Dedicated scribe to capture insights and actions

### 3. Documentation and Integration

```mermaid
flowchart TD
    classDef step fill:#f9d77e,stroke:#d9b95c,color:#000
    classDef artifact fill:#f4b8c4,stroke:#d498a4,color:#000
    classDef verification fill:#c5e8b7,stroke:#a5c897,color:#000
    
    Start([Begin Documentation<br>and Integration]) --> Draft[Draft Reflection<br>Document]
    Draft --> Review[Review with<br>Key Stakeholders]
    Review --> Revise[Incorporate<br>Feedback]
    Revise --> Finalize[Finalize<br>Document]
    Finalize --> UpdateMB[Update Memory<br>Bank]
    UpdateMB --> ActionReg[Create Action<br>Register]
    ActionReg --> Archive[Archive Project<br>Documents]
    Archive --> Verification{Documentation<br>Verification}
    Verification -->|Pass| Complete([Documentation<br>Complete])
    Verification -->|Fail| MoreRevision[Address<br>Documentation Gaps]
    MoreRevision --> Verification
    
    Draft -.-> DraftDoc((Draft<br>Document))
    Finalize -.-> FinalDoc((Final<br>Reflection))
    ActionReg -.-> ActReg((Action<br>Register))
    
    class Start,Complete milestone
    class Draft,Review,Revise,Finalize,UpdateMB,ActionReg,Archive,MoreRevision step
    class Verification verification
    class DraftDoc,FinalDoc,ActReg artifact
```

**Key Documentation Steps:**
1. Draft comprehensive reflection document using the template
2. Review draft with key stakeholders and participants
3. Incorporate feedback and finalize document
4. Update Memory Bank with key insights and learnings
5. Create action register for tracking improvement actions
6. Archive project documents with reflection document
7. Verify documentation completeness and quality

## 📋 REFLECTION TECHNIQUES

### Root Cause Analysis

```mermaid
flowchart TD
    classDef step fill:#f9d77e,stroke:#d9b95c,color:#000
    
    Start([Identify<br>Challenge]) --> What[What<br>Happened?]
    What --> When[When Did<br>It Happen?]
    When --> Where[Where Did<br>It Happen?]
    Where --> Who[Who Was<br>Involved?]
    Who --> How[How Did<br>It Happen?]
    How --> Why1[Why Did<br>It Happen?]
    Why1 --> Why2[Why?<br>Deeper]
    Why2 --> Why3[Why?<br>Deeper]
    Why3 --> Why4[Why?<br>Deeper]
    Why4 --> Why5[Why?<br>Root Cause]
    Why5 --> Solution[Identify<br>Solution]
    Solution --> Prevent[Prevention<br>Strategy]
    
    class Start milestone
    class What,When,Where,Who,How,Why1,Why2,Why3,Why4,Why5,Solution,Prevent step
```

### Success Analysis

```mermaid
flowchart TD
    classDef step fill:#f9d77e,stroke:#d9b95c,color:#000
    
    Start([Identify<br>Success]) --> Define[Define the<br>Success]
    Define --> Impact[Measure the<br>Impact]
    Impact --> Factors[Identify Contributing<br>Factors]
    Factors --> Context[Consider<br>Context]
    Context --> Patterns[Identify<br>Patterns]
    Patterns --> Generalize[Generalize<br>Approach]
    Generalize --> Apply[Define Where<br>to Apply]
    
    class Start milestone
    class Define,Impact,Factors,Context,Patterns,Generalize,Apply step
```

### Insight Generation

```mermaid
flowchart TD
    classDef step fill:#f9d77e,stroke:#d9b95c,color:#000
    
    Start([Begin Insight<br>Generation]) --> Observe[Observe<br>Patterns]
    Observe --> Question[Question<br>Assumptions]
    Question --> Connect[Connect<br>Dots]
    Connect --> Contrast[Contrast with<br>Prior Knowledge]
    Contrast --> Hypothesize[Form<br>Hypothesis]
    Hypothesize --> Test[Test<br>Hypothesis]
    Test --> Refine[Refine<br>Insight]
    Refine --> Apply[Apply to<br>Future Work]
    
    class Start milestone
    class Observe,Question,Connect,Contrast,Hypothesize,Test,Refine,Apply step
```

## 📋 MEMORY BANK INTEGRATION

```mermaid
flowchart TD
    classDef memfile fill:#f4b8c4,stroke:#d498a4,color:#000
    classDef process fill:#f9d77e,stroke:#d9b95c,color:#000
    
    Reflection[Comprehensive<br>Reflection] --> PB[projectbrief.md]
    Reflection --> PC[productContext.md]
    Reflection --> AC[activeContext.md]
    Reflection --> SP[systemPatterns.md]
    Reflection --> TC[techContext.md]
    Reflection --> P[progress.md]
    
    PB & PC & AC & SP & TC & P --> MBI[Memory Bank<br>Integration]
    MBI --> Next[Enhanced Future<br>Projects]
    
    class PB,PC,AC,SP,TC,P memfile
    class Reflection,MBI,Next process
```

### Memory Bank Updates

Specific updates to make to Memory Bank files:

1. **projectbrief.md**
   - Update with strategic insights
   - Document key achievements
   - Incorporate lessons learned

2. **productContext.md**
   - Update with business insights
   - Document market/user insights
   - Include value delivery insights

3. **activeContext.md**
   - Update with current status
   - Document action items
   - Include next steps

4. **systemPatterns.md**
   - Update with architectural insights
   - Document successful patterns
   - Include technical knowledge

5. **techContext.md**
   - Update with implementation insights
   - Document technology stack insights
   - Include performance and security insights

6. **progress.md**
   - Update with final status
   - Document achievements
   - Include project metrics

## 📋 REFLECTION VERIFICATION CHECKLIST

```
✓ REFLECTION VERIFICATION CHECKLIST

System Review
- System overview complete and accurate? [YES/NO]
- Project performance metrics collected and analyzed? [YES/NO]
- System boundaries and interfaces described? [YES/NO]

Success and Challenge Analysis
- Key achievements documented with evidence? [YES/NO]
- Technical successes documented with approach? [YES/NO]
- Key challenges documented with resolutions? [YES/NO]
- Technical challenges documented with solutions? [YES/NO]
- Unresolved issues documented with path forward? [YES/NO]

Insight Generation
- Technical insights extracted and documented? [YES/NO]
- Process insights extracted and documented? [YES/NO]
- Business insights extracted and documented? [YES/NO]

Strategic Planning
- Immediate actions defined with owners? [YES/NO]
- Short-term improvements identified? [YES/NO]
- Medium-term initiatives planned? [YES/NO]
- Long-term strategic directions outlined? [YES/NO]

Knowledge Transfer
- Key learnings for organization documented? [YES/NO]
- Technical knowledge transfer planned? [YES/NO]
- Process knowledge transfer planned? [YES/NO]
- Documentation updates identified? [YES/NO]

Memory Bank Integration
- projectbrief.md updated with insights? [YES/NO]
- productContext.md updated with insights? [YES/NO]
- activeContext.md updated with insights? [YES/NO]
- systemPatterns.md updated with insights? [YES/NO]
- techContext.md updated with insights? [YES/NO]
- progress.md updated with final status? [YES/NO]
```

## 📋 MINIMAL MODE REFLECTION FORMAT

For situations requiring a more compact reflection:

```markdown
## Level 4 Task Reflection: [System Name]

### System Summary
- **Purpose**: [Brief description of system purpose]
- **Key Components**: [List of key components]
- **Architecture**: [Brief architecture description]

### Performance Summary
- **Timeline**: [Planned] vs [Actual] ([Variance])
- **Resources**: [Planned] vs [Actual] ([Variance])
- **Quality**: [Summary of quality achievements]

### Key Successes
1. [Success 1 with evidence and impact]
2. [Success 2 with evidence and impact]
3. [Success 3 with evidence and impact]

### Key Challenges
1. [Challenge 1 with resolution and lessons]
2. [Challenge 2 with resolution and lessons]
3. [Challenge 3 with resolution and lessons]

### Critical Insights
- **Technical**: [Key technical insight with recommendation]
- **Process**: [Key process insight with recommendation]
- **Business**: [Key business insight with recommendation]

### Priority Actions
1. [Immediate action with owner and timeline]
2. [Short-term improvement with owner and timeline]
3. [Medium-term initiative with owner and timeline]

### Memory Bank Updates
- [List of specific Memory Bank updates needed]
```

## 🚨 REFLECTION ENFORCEMENT PRINCIPLE

```
┌─────────────────────────────────────────────────────┐
│ COMPREHENSIVE REFLECTION IS MANDATORY for Level 4    │
│ tasks. Archiving CANNOT proceed until reflection     │
│ is completed and verified.                           │
└─────────────────────────────────────────────────────┘
```

================
File: .cursor/rules/isolation_rules/Level4/task-tracking-advanced.mdc
================
---
description: Advanced task tracking for Level 4 Complex System tasks
globs: "**/level4/**", "**/task-tracking/**"
alwaysApply: false
---

# ADVANCED TASK TRACKING FOR LEVEL 4 TASKS

> **TL;DR:** This document outlines a comprehensive task tracking approach for Level 4 (Complex System) tasks, ensuring detailed tracking of complex, multi-phase work with clear dependencies, progress tracking, and architectural alignment.

## 🔍 ADVANCED TASK TRACKING OVERVIEW

Level 4 Complex System tasks require sophisticated task tracking to manage the complexity of system development, coordinate multiple team members, track dependencies, and ensure alignment with architectural principles. This document outlines a comprehensive task tracking approach for such complex endeavors.

```mermaid
flowchart TD
    classDef phase fill:#f9d77e,stroke:#d9b95c,color:#000
    classDef artifact fill:#f4b8c4,stroke:#d498a4,color:#000
    classDef verification fill:#c5e8b7,stroke:#a5c897,color:#000
    
    Start([Begin Task<br>Tracking]) --> Framework[Establish Task<br>Framework]
    Framework --> Hierarchy[Define Task<br>Hierarchy]
    Hierarchy --> Breakdown[Create Work<br>Breakdown Structure]
    Breakdown --> Dependencies[Document<br>Dependencies]
    Dependencies --> Milestones[Define Key<br>Milestones]
    Milestones --> Schedule[Create<br>Schedule]
    Schedule --> Resources[Define Resource<br>Allocation]
    Resources --> Risks[Document<br>Risks]
    Risks --> Quality[Define Quality<br>Metrics]
    Quality --> Progress[Track<br>Progress]
    Progress --> Adaptations[Document<br>Adaptations]
    Adaptations --> Verification{Task Tracking<br>Verification}
    Verification -->|Pass| Complete([Task Tracking<br>Complete])
    Verification -->|Fail| Revise[Revise Task<br>Tracking]
    Revise --> Verification
    
    Framework -.-> TF((Task<br>Framework))
    Hierarchy -.-> TH((Task<br>Hierarchy))
    Breakdown -.-> WBS((Work Breakdown<br>Structure))
    Dependencies -.-> DP((Dependency<br>Matrix))
    Milestones -.-> MS((Milestone<br>Document))
    Schedule -.-> SC((Schedule<br>Document))
    Resources -.-> RA((Resource<br>Allocation))
    Risks -.-> RM((Risk<br>Management))
    Quality -.-> QM((Quality<br>Metrics))
    Progress -.-> PT((Progress<br>Tracking))
    Adaptations -.-> AD((Adaptation<br>Document))
    
    class Start,Complete milestone
    class Framework,Hierarchy,Breakdown,Dependencies,Milestones,Schedule,Resources,Risks,Quality,Progress,Adaptations,Revise step
    class Verification verification
    class TF,TH,WBS,DP,MS,SC,RA,RM,QM,PT,AD artifact
```

## 📋 TASK TRACKING PRINCIPLES

1. **Architectural Alignment**: All tasks must align with the established architectural principles and patterns.
2. **Hierarchical Organization**: Tasks are organized in a hierarchical structure with clear parent-child relationships.
3. **Dependency Management**: All task dependencies are explicitly documented and tracked.
4. **Progression Transparency**: Task status and progress are clearly documented and visible to all stakeholders.
5. **Quality Integration**: Quality metrics and verification are integrated into task definitions.
6. **Resource Allocation**: Tasks include clear allocation of resources required for completion.
7. **Risk Awareness**: Each significant task includes risk assessment and mitigation strategies.
8. **Adaptive Planning**: Task tracking accommodates changes and adaptations while maintaining system integrity.
9. **Milestone Tracking**: Clear milestones are defined and used to track overall progress.
10. **Comprehensive Documentation**: All aspects of the task lifecycle are documented thoroughly.

## 📋 TASK HIERARCHY STRUCTURE

Level 4 tasks follow a hierarchical structure:

```mermaid
flowchart TD
    classDef system fill:#f9d77e,stroke:#d9b95c,color:#000
    classDef component fill:#a8d5ff,stroke:#88b5e0,color:#000
    classDef feature fill:#c5e8b7,stroke:#a5c897,color:#000
    classDef task fill:#f4b8c4,stroke:#d498a4,color:#000
    classDef subtask fill:#d8c1f7,stroke:#b8a1d7,color:#000
    
    System[System-Level Work] --> Component1[Component 1]
    System --> Component2[Component 2]
    System --> Component3[Component 3]
    
    Component1 --> Feature1[Feature 1.1]
    Component1 --> Feature2[Feature 1.2]
    
    Feature1 --> Task1[Task 1.1.1]
    Feature1 --> Task2[Task 1.1.2]
    
    Task1 --> Subtask1[Subtask 1.1.1.1]
    Task1 --> Subtask2[Subtask 1.1.1.2]
    Task1 --> Subtask3[Subtask 1.1.1.3]
    
    class System system
    class Component1,Component2,Component3 component
    class Feature1,Feature2 feature
    class Task1,Task2 task
    class Subtask1,Subtask2,Subtask3 subtask
```

### Levels of Hierarchy:

1. **System Level**: The overall system being built or modified.
2. **Component Level**: Major components or subsystems of the system.
3. **Feature Level**: Specific features within each component.
4. **Task Level**: Concrete tasks required to implement a feature.
5. **Subtask Level**: Detailed subtasks for complex tasks.

## 📋 COMPREHENSIVE TASK STRUCTURE

Each Level 4 task in `tasks.md` follows this comprehensive structure:

```markdown
## [SYSTEM-ID]: System Name

### System Overview
- **Purpose**: [Brief description of system purpose]
- **Architectural Alignment**: [How the system aligns with architectural principles]
- **Status**: [Planning/In Progress/Review/Complete]
- **Milestones**: 
  - Milestone 1: [Date] - [Status]
  - Milestone 2: [Date] - [Status]
  - Milestone 3: [Date] - [Status]

### Components
#### [COMP-ID]: Component Name
- **Purpose**: [Brief description of component purpose]
- **Status**: [Planning/In Progress/Review/Complete]
- **Dependencies**: [List of dependencies]
- **Responsible**: [Team or individual responsible]

##### [FEAT-ID]: Feature Name
- **Description**: [Feature description]
- **Status**: [Planning/In Progress/Review/Complete]
- **Priority**: [Critical/High/Medium/Low]
- **Related Requirements**: [List of requirements IDs this feature addresses]
- **Quality Criteria**: [Measurable criteria for completion]
- **Progress**: [0-100%]

###### [TASK-ID]: Task Name
- **Description**: [Task description]
- **Status**: [TODO/In Progress/Review/Done]
- **Assigned To**: [Assignee]
- **Estimated Effort**: [Effort estimate]
- **Actual Effort**: [Actual effort]
- **Dependencies**: [Tasks this depends on]
- **Blocks**: [Tasks blocked by this]
- **Risk Assessment**: [Risk level and description]
- **Quality Gates**: [Quality gates this must pass]
- **Implementation Notes**: [Key implementation notes]

**Subtasks**:
- [ ] [SUB-ID]: [Subtask description] - [Status]
- [ ] [SUB-ID]: [Subtask description] - [Status]
- [ ] [SUB-ID]: [Subtask description] - [Status]

### System-Wide Tasks
- [ ] [SYS-TASK-ID]: [System-wide task description] - [Status]
- [ ] [SYS-TASK-ID]: [System-wide task description] - [Status]

### Risks and Mitigations
- **Risk 1**: [Description] - **Mitigation**: [Mitigation strategy]
- **Risk 2**: [Description] - **Mitigation**: [Mitigation strategy]

### Progress Summary
- **Overall Progress**: [0-100%]
- **Component 1**: [0-100%]
- **Component 2**: [0-100%]
- **Component 3**: [0-100%]

### Latest Updates
- [Date]: [Update description]
- [Date]: [Update description]
```

## 📋 TASK TRACKING ORGANIZATION IN TASKS.MD

For Level 4 Complex System tasks, organize `tasks.md` as follows:

```markdown
# TASK TRACKING

## ACTIVE SYSTEMS
- [SYSTEM-ID]: [System Name] - [Status]
- [SYSTEM-ID]: [System Name] - [Status]

## SYSTEM DETAILS

[Detailed task structure for each system as per the template above]

## COMPLETED SYSTEMS
- [SYSTEM-ID]: [System Name] - Completed [Date]
- [SYSTEM-ID]: [System Name] - Completed [Date]

## SYSTEM DEPENDENCIES
```mermaid
graph TD
    System1 --> System2
    System1 --> System3
    System2 --> System4
```

## RISK REGISTER
| Risk ID | Description | Probability | Impact | Mitigation |
|---------|-------------|-------------|--------|------------|
| RISK-01 | [Description] | High/Med/Low | High/Med/Low | [Strategy] |
| RISK-02 | [Description] | High/Med/Low | High/Med/Low | [Strategy] |

## RESOURCE ALLOCATION
| Resource | System | Allocation % | Time Period |
|----------|--------|--------------|------------|
| [Name/Team] | [System-ID] | [%] | [Start-End] |
| [Name/Team] | [System-ID] | [%] | [Start-End] |
```

## 📋 DEPENDENCY MANAGEMENT

```mermaid
flowchart TD
    classDef critical fill:#f8707e,stroke:#d85060,color:#000
    classDef high fill:#f9d77e,stroke:#d9b95c,color:#000
    classDef medium fill:#a8d5ff,stroke:#88b5e0,color:#000
    classDef low fill:#c5e8b7,stroke:#a5c897,color:#000
    
    Task1[Task 1] --> Task2[Task 2]
    Task1 --> Task3[Task 3]
    Task2 --> Task4[Task 4]
    Task3 --> Task4
    Task4 --> Task5[Task 5]
    Task4 --> Task6[Task 6]
    Task5 --> Task7[Task 7]
    Task6 --> Task7
    
    class Task1,Task4,Task7 critical
    class Task2,Task5 high
    class Task3 medium
    class Task6 low
```

For complex systems, document dependencies in a dedicated section:

```markdown
## Dependency Matrix

| Task ID | Depends On | Blocks | Type | Status |
|---------|------------|--------|------|--------|
| TASK-01 | - | TASK-02, TASK-03 | Technical | Completed |
| TASK-02 | TASK-01 | TASK-04 | Technical | In Progress |
| TASK-03 | TASK-01 | TASK-04 | Resource | Not Started |
| TASK-04 | TASK-02, TASK-03 | TASK-05, TASK-06 | Technical | Not Started |
```

### Dependency Types:
- **Technical**: One task technically requires another to be completed first
- **Resource**: Tasks compete for the same resources
- **Information**: One task requires information produced by another
- **Architectural**: Tasks have architectural dependencies
- **Temporal**: Tasks must be completed in a specific time sequence

## 📋 MILESTONE TRACKING

For Level 4 tasks, track milestones explicitly:

```markdown
## System Milestones

| Milestone ID | Description | Target Date | Actual Date | Status | Deliverables |
|--------------|-------------|-------------|-------------|--------|--------------|
| MILE-01 | Architecture Approved | [Date] | [Date] | Completed | Architecture Document |
| MILE-02 | Component Design Completed | [Date] | - | In Progress | Design Documents |
| MILE-03 | Component 1 Implementation | [Date] | - | Not Started | Code, Tests |
| MILE-04 | Integration Complete | [Date] | - | Not Started | Integrated System |
| MILE-05 | System Testing Complete | [Date] | - | Not Started | Test Reports |
| MILE-06 | Deployment Ready | [Date] | - | Not Started | Deployment Package |
```

## 📋 PROGRESS VISUALIZATION

Include visual representations of progress in `tasks.md`:

```markdown
## Progress Visualization

### Overall System Progress
```mermaid
pie title System Progress
    "Completed" : 30
    "In Progress" : 25
    "Not Started" : 45
```

### Component Progress
```mermaid
graph TD
    subgraph Progress
    C1[Component 1: 75%]
    C2[Component 2: 50%]
    C3[Component 3: 20%]
    C4[Component 4: 5%]
    end
```

### Timeline
```mermaid
gantt
    title System Timeline
    dateFormat  YYYY-MM-DD
    
    section Architecture
    Architecture Design    :done, arch, 2023-01-01, 30d
    Architecture Review    :done, arch-rev, after arch, 10d
    
    section Component 1
    Design                 :active, c1-des, after arch-rev, 20d
    Implementation         :c1-imp, after c1-des, 40d
    Testing                :c1-test, after c1-imp, 15d
    
    section Component 2
    Design                 :active, c2-des, after arch-rev, 25d
    Implementation         :c2-imp, after c2-des, 50d
    Testing                :c2-test, after c2-imp, 20d
```
```

## 📋 UPDATING TASK STATUS

For Level 4 tasks, status updates include:

1. **Progress Updates**: Update task status and progress percentage
2. **Effort Tracking**: Record actual effort against estimates
3. **Risk Updates**: Update risk assessments and mitigations
4. **Dependency Status**: Update status of dependencies
5. **Milestone Tracking**: Update milestone status
6. **Issue Documentation**: Document issues encountered
7. **Adaptation Documentation**: Document any adaptations to the original plan
8. **Quality Gate Status**: Update status of quality gates

Status update cycle:
- **Daily**: Update task and subtask status
- **Weekly**: Update component status and progress visualization
- **Bi-weekly**: Update system-level progress and milestone status
- **Monthly**: Complete system review including risks and adaptations

## 📋 TASK TRACKING VERIFICATION CHECKLIST

```
✓ TASK TRACKING VERIFICATION CHECKLIST

Task Structure
- System level work properly defined? [YES/NO]
- Component level tasks identified? [YES/NO]
- Feature level tasks specified? [YES/NO]
- Task level details provided? [YES/NO]
- Subtasks created for complex tasks? [YES/NO]

Task Information
- All tasks have clear descriptions? [YES/NO]
- Status accurately reflected? [YES/NO]
- Proper assignments made? [YES/NO]
- Effort estimates provided? [YES/NO]
- Dependencies documented? [YES/NO]

Progress Tracking
- Overall progress calculated? [YES/NO]
- Component progress updated? [YES/NO]
- Milestone status updated? [YES/NO]
- Progress visualizations current? [YES/NO]
- Latest updates documented? [YES/NO]

Risk Management
- Risks identified and assessed? [YES/NO]
- Mitigation strategies documented? [YES/NO]
- Risk register updated? [YES/NO]
- Impact on schedule assessed? [YES/NO]
- Contingency plans documented? [YES/NO]

Resource Allocation
- Resources allocated to tasks? [YES/NO]
- Resource conflicts identified? [YES/NO]
- Resource allocation optimized? [YES/NO]
- Future resource needs projected? [YES/NO]
- Resource allocation documented? [YES/NO]

Quality Integration
- Quality criteria defined for tasks? [YES/NO]
- Quality gates specified? [YES/NO]
- Verification procedures documented? [YES/NO]
- Quality metrics being tracked? [YES/NO]
- Quality issues documented? [YES/NO]

Architectural Alignment
- Tasks align with architecture? [YES/NO]
- Architectural dependencies tracked? [YES/NO]
- Architectural constraints documented? [YES/NO]
- Architecture evolution tracked? [YES/NO]
- Architectural decisions documented? [YES/NO]
```

## 📋 INTEGRATION WITH MEMORY BANK

Level 4 task tracking is tightly integrated with the Memory Bank:

1. **projectbrief.md**: System-level tasks are derived from and linked to the project brief
2. **productContext.md**: Tasks are aligned with business context and objectives
3. **systemPatterns.md**: Tasks respect and implement defined architectural patterns
4. **techContext.md**: Tasks are aligned with the technology stack and constraints
5. **activeContext.md**: Current focus and status from `tasks.md` informs the active context
6. **progress.md**: System progress from `tasks.md` is reflected in overall progress

```mermaid
flowchart TD
    classDef memfile fill:#f4b8c4,stroke:#d498a4,color:#000
    classDef process fill:#f9d77e,stroke:#d9b95c,color:#000
    
    TaskTracking[Advanced Task<br>Tracking] --> PB[projectbrief.md]
    TaskTracking --> PC[productContext.md]
    TaskTracking --> AC[activeContext.md]
    TaskTracking --> SP[systemPatterns.md]
    TaskTracking --> TC[techContext.md]
    TaskTracking --> P[progress.md]
    
    P --> TU[Task<br>Updates]
    TU --> TaskTracking
    
    class PB,PC,AC,SP,TC,P memfile
    class TaskTracking,TU process
```

## 📋 MINIMAL MODE TASK TRACKING

For situations requiring a more compact tracking approach:

```markdown
## [SYSTEM-ID]: System Name - [Status]

### Key Components:
- [COMP-ID]: [Component Name] - [Status] - [Progress %]
- [COMP-ID]: [Component Name] - [Status] - [Progress %]

### Active Tasks:
- [ ] [TASK-ID]: [Task Description] - [Assignee] - [Status]
  - Dependencies: [List of task IDs]
  - Risks: [Brief risk description]
- [ ] [TASK-ID]: [Task Description] - [Assignee] - [Status]

### Milestones:
- [MILE-ID]: [Milestone description] - [Target Date] - [Status]
- [MILE-ID]: [Milestone description] - [Target Date] - [Status]

### Critical Paths:
- [TASK-ID] → [TASK-ID] → [TASK-ID] → [TASK-ID]
- [TASK-ID] → [TASK-ID] → [TASK-ID]

### Updates:
- [Date]: [Brief update]
```

## 🚨 TASK TRACKING PRIMACY PRINCIPLE

```
┌─────────────────────────────────────────────────────┐
│ tasks.md is the SINGLE SOURCE OF TRUTH for all task  │
│ tracking. All task-related decisions and status      │
│ updates MUST be reflected in tasks.md.               │
└─────────────────────────────────────────────────────┘
```

================
File: .cursor/rules/isolation_rules/Level4/workflow-level4.mdc
================
---
description: Comprehensive workflow for Level 4 Complex System tasks
globs: "**/level4/**", "**/workflow/**"
alwaysApply: false
---
# COMPREHENSIVE WORKFLOW FOR LEVEL 4 TASKS

> **TL;DR:** This document outlines a comprehensive workflow for Level 4 (Complex System) tasks, including 7 key phases with rigorous planning, mandatory creative phases, architectural design, phased implementation, and extensive documentation.

## 🔍 LEVEL 4 WORKFLOW OVERVIEW

```mermaid
graph LR
    Init["1. INITIALIZATION"] --> Doc["2. DOCUMENTATION<br>SETUP"]
    Doc --> Plan["3. ARCHITECTURAL<br>PLANNING"]
    Plan --> Create["4. CREATIVE<br>PHASES"]
    Create --> Impl["5. PHASED<br>IMPLEMENTATION"]
    Impl --> Reflect["6. REFLECTION"]
    Reflect --> Archive["7. ARCHIVING"]
    
    %% Document connections for each phase
    Init -.-> InitDocs["INITIALIZATION"]
    Doc -.-> DocDocs["DOCUMENTATION"]
    Plan -.-> PlanDocs["ARCHITECTURAL PLANNING"]
    Create -.-> CreateDocs["CREATIVE PHASES"]
    Impl -.-> ImplDocs["PHASED IMPLEMENTATION"]
    Reflect -.-> ReflectDocs["REFLECTION"]
    Archive -.-> ArchiveDocs["ARCHIVING"]
```

## 🔄 LEVEL TRANSITION HANDLING

```mermaid
graph TD
    L4["Level 4 Task"] --> Assess["Continuous<br>Assessment"]
    
    Assess --> Down["Downgrade to<br>Level 2/3"]
    Assess --> Split["Split into<br>Multiple Tasks"]
    
    Down --> L23Trigger["Triggers:<br>- Less complex<br>- Limited scope<br>- Few components"]
    
    Split --> MultiTrigger["Triggers:<br>- Too large<br>- Independent parts<br>- Parallel possible"]
    
    L23Trigger --> L23Switch["Switch to<br>Level 2/3 Workflow"]
    MultiTrigger --> CreateTasks["Create Multiple<br>Lower Level Tasks"]
```

Level 4 tasks involve complex systems that require comprehensive planning, rigorous design, systematic implementation, and thorough documentation. This workflow ensures all aspects are addressed with the appropriate level of detail, structure, and verification.

## 📋 WORKFLOW PHASES

### Phase 1: INITIALIZATION

```mermaid
graph TD
    Start["Start Level 4 Task"] --> Platform{"Detect<br>Platform"}
    Platform --> FileCheck["Critical File<br>Verification"]
    FileCheck --> LoadStructure["Comprehensive Memory<br>Bank Structure Loading"]
    LoadStructure --> TaskCreation["Create Detailed<br>Task Framework"]
    TaskCreation --> Context["Establish Enterprise<br>Context"]
    Context --> Resources["Identify and Allocate<br>All Resources"]
    Resources --> SetupComplete["Initialization<br>Complete"]
```

**Steps:**
1. Platform detection with comprehensive environment configuration
2. Critical file verification with in-depth integrity checks
3. Comprehensive Memory Bank structure loading with full reference mapping
4. Create detailed task framework in tasks.md with full structure
5. Establish complete enterprise context and stakeholder requirements
6. Identify and allocate all necessary resources (technical, human, time)
7. Perform system readiness assessment

**Milestone Checkpoint:**
```
✓ INITIALIZATION CHECKPOINT
- Platform detected and fully configured? [YES/NO]
- Critical files verified with integrity checks? [YES/NO]
- Memory Bank comprehensively loaded and mapped? [YES/NO]
- Detailed task framework created? [YES/NO]
- Enterprise context established? [YES/NO]
- Stakeholder requirements documented? [YES/NO]
- All resources identified and allocated? [YES/NO]
- System readiness assessed? [YES/NO]

→ If all YES: Proceed to Documentation Setup
→ If any NO: Complete initialization steps
```

### Phase 2: DOCUMENTATION SETUP

```mermaid
graph TD
    Start["Begin Documentation<br>Setup"] --> LoadTemplate["Load Comprehensive<br>Documentation Templates"]
    LoadTemplate --> Framework["Establish Documentation<br>Framework"]
    Framework --> UpdateProject["Update<br>projectbrief.md"]
    UpdateProject --> UpdateContext["Update<br>activeContext.md"]
    UpdateContext --> SystemPatterns["Update<br>systemPatterns.md"]
    SystemPatterns --> TechContext["Update<br>techContext.md"]
    TechContext --> Standards["Document System<br>Standards"]
    Standards --> Architecture["Document Existing<br>Architecture"]
    Architecture --> SetupComplete["Documentation<br>Setup Complete"]
```

**Steps:**
1. Load comprehensive documentation templates for all aspects
2. Establish complete documentation framework with structure
3. Update projectbrief.md with detailed system description and requirements
4. Update activeContext.md with current focus, dependencies, and stakeholders
5. Update systemPatterns.md with comprehensive patterns and principles
6. Update techContext.md with complete technical landscape
7. Document system standards, constraints, and conventions
8. Document existing architecture and integration points

**Milestone Checkpoint:**
```
✓ DOCUMENTATION CHECKPOINT
- Documentation templates loaded? [YES/NO]
- Documentation framework established? [YES/NO]
- projectbrief.md comprehensively updated? [YES/NO]
- activeContext.md fully updated? [YES/NO]
- systemPatterns.md comprehensively updated? [YES/NO]
- techContext.md fully updated? [YES/NO]
- System standards documented? [YES/NO]
- Existing architecture documented? [YES/NO]

→ If all YES: Proceed to Architectural Planning
→ If any NO: Complete documentation setup
```

### Phase 3: ARCHITECTURAL PLANNING

```mermaid
graph TD
    Start["Begin Architectural<br>Planning"] --> Requirements["Analyze Comprehensive<br>Requirements"]
    Requirements --> BusinessContext["Document Business<br>Context"]
    BusinessContext --> VisionDefine["Define Vision<br>and Goals"]
    VisionDefine --> ArchitecturalPrinciples["Establish Architectural<br>Principles"]
    ArchitecturalPrinciples --> Alternatives["Explore Architectural<br>Alternatives"]
    Alternatives --> Evaluation["Perform Detailed<br>Evaluation"]
    Evaluation --> Selection["Make Architecture<br>Selection"]
    Selection --> Documentation["Create Architecture<br>Documentation"]
    Documentation --> Review["Conduct Architecture<br>Review"]
    Review --> PlanComplete["Architectural Planning<br>Complete"]
```

**Steps:**
1. Analyze comprehensive requirements with traceability
2. Document complete business context and constraints
3. Define clear vision and goals with measurable objectives
4. Establish architectural principles and non-functional requirements
5. Explore multiple architectural alternatives with thorough analysis
6. Perform detailed evaluation using weighted criteria
7. Make architecture selection with comprehensive justification
8. Create complete architecture documentation with diagrams
9. Conduct formal architecture review with stakeholders

**Milestone Checkpoint:**
```
✓ ARCHITECTURAL PLANNING CHECKPOINT
- Requirements comprehensively analyzed? [YES/NO]
- Business context fully documented? [YES/NO]
- Vision and goals clearly defined? [YES/NO]
- Architectural principles established? [YES/NO]
- Alternatives thoroughly explored? [YES/NO]
- Detailed evaluation performed? [YES/NO]
- Architecture selection justified? [YES/NO]
- Architecture documentation complete? [YES/NO]
- Architecture review conducted? [YES/NO]

→ If all YES: Proceed to Creative Phases
→ If any NO: Complete architectural planning
```

### Phase 4: CREATIVE PHASES

```mermaid
graph TD
    Start["Begin Creative<br>Phases"] --> IdentifyNeeds["Identify Creative<br>Phase Needs"]
    IdentifyNeeds --> Architecture["Architecture<br>Design Phase"]
    Architecture --> Algorithm["Algorithm<br>Design Phase"]
    Algorithm --> UIUX["UI/UX<br>Design Phase"]
    UIUX --> Integration["Integration<br>Design Phase"]
    Integration --> Security["Security<br>Design Phase"]
    Security --> Performance["Performance<br>Design Phase"]
    Performance --> Resilience["Resilience<br>Design Phase"]
    Resilience --> Documentation["Comprehensive<br>Design Documentation"]
    Documentation --> Review["Design<br>Review"]
    Review --> CreativeComplete["Creative Phases<br>Complete"]
```

**Steps:**
1. Identify all required creative phases based on system needs
2. Execute comprehensive Architecture Design with patterns and principles
3. Conduct thorough Algorithm Design for all complex processes
4. Perform detailed UI/UX Design with user research and testing
5. Create Integration Design for all system interfaces
6. Develop Security Design with threat modeling
7. Design for Performance with capacity planning
8. Plan for Resilience with failure modes and recovery
9. Create comprehensive design documentation for all aspects
10. Conduct formal design review with stakeholders

**Milestone Checkpoint:**
```
✓ CREATIVE PHASES CHECKPOINT
- All required creative phases identified? [YES/NO]
- Architecture design completed with patterns? [YES/NO]
- Algorithm design conducted for complex processes? [YES/NO]
- UI/UX design performed with user research? [YES/NO]
- Integration design created for interfaces? [YES/NO]
- Security design developed with threat modeling? [YES/NO]
- Performance design completed with capacity planning? [YES/NO]
- Resilience design planned with failure modes? [YES/NO]
- Comprehensive design documentation created? [YES/NO]
- Formal design review conducted? [YES/NO]

→ If all YES: Proceed to Phased Implementation
→ If any NO: Complete creative phases
```

### Phase 5: PHASED IMPLEMENTATION

```mermaid
graph TD
    Start["Begin Phased<br>Implementation"] --> PrepEnv["Prepare Comprehensive<br>Implementation Environment"]
    PrepEnv --> Framework["Establish Implementation<br>Framework"]
    Framework --> RoadmapDefine["Define Implementation<br>Roadmap"]
    RoadmapDefine --> PhaseImplementation["Implement<br>Sequential Phases"]
    PhaseImplementation --> PhaseVerification["Verify Each<br>Phase"]
    PhaseVerification --> Integration["Perform Integration<br>Testing"]
    Integration --> SystemTest["Conduct System<br>Testing"]
    SystemTest --> UAT["User Acceptance<br>Testing"]
    UAT --> Stabilization["System<br>Stabilization"]
    Stabilization --> ImplComplete["Implementation<br>Complete"]
```

**Steps:**
1. Prepare comprehensive implementation environment with all tools
2. Establish implementation framework with standards and processes
3. Define detailed implementation roadmap with phases and dependencies
4. Implement sequential phases with milestone verification
5. Verify each phase against requirements and design
6. Perform comprehensive integration testing across phases
7. Conduct thorough system testing of the complete solution
8. Execute formal user acceptance testing with stakeholders
9. Perform system stabilization and performance tuning
10. Document all implementation details and deployment procedures

**Milestone Checkpoint:**
```
✓ PHASED IMPLEMENTATION CHECKPOINT
- Implementation environment fully prepared? [YES/NO]
- Implementation framework established? [YES/NO]
- Detailed roadmap defined with phases? [YES/NO]
- All phases sequentially implemented? [YES/NO]
- Each phase verified against requirements? [YES/NO]
- Comprehensive integration testing performed? [YES/NO]
- Thorough system testing conducted? [YES/NO]
- User acceptance testing executed? [YES/NO]
- System stabilization completed? [YES/NO]
- Implementation details documented? [YES/NO]

→ If all YES: Proceed to Reflection
→ If any NO: Complete implementation steps
```

### Phase 6: REFLECTION

```mermaid
graph TD
    Start["Begin<br>Reflection"] --> Template["Load Comprehensive<br>Reflection Template"]
    Template --> SystemReview["Complete System<br>Review"]
    SystemReview --> Process["Analyze Process<br>Effectiveness"]
    Process --> Success["Document Successes<br>with Evidence"]
    Success --> Challenges["Document Challenges<br>with Solutions"]
    Challenges --> TechnicalInsights["Extract Strategic<br>Technical Insights"]
    TechnicalInsights --> ProcessInsights["Extract Process<br>Improvement Insights"]
    ProcessInsights --> BusinessInsights["Document Business<br>Impact"]
    BusinessInsights --> StrategicActions["Define Strategic<br>Action Items"]
    StrategicActions --> ReflectComplete["Reflection<br>Complete"]
```

**Steps:**
1. Load comprehensive reflection template with all sections
2. Conduct complete system review against original goals
3. Analyze process effectiveness with metrics
4. Document successes with concrete evidence and impact
5. Document challenges with implemented solutions and lessons
6. Extract strategic technical insights for enterprise knowledge
7. Extract process improvement insights for future projects
8. Document business impact and value delivered
9. Define strategic action items with prioritization
10. Create comprehensive reflection documentation

**Milestone Checkpoint:**
```
✓ REFLECTION CHECKPOINT
- Comprehensive reflection template loaded? [YES/NO]
- Complete system review conducted? [YES/NO]
- Process effectiveness analyzed? [YES/NO]
- Successes documented with evidence? [YES/NO]
- Challenges documented with solutions? [YES/NO]
- Strategic technical insights extracted? [YES/NO]
- Process improvement insights extracted? [YES/NO]
- Business impact documented? [YES/NO]
- Strategic action items defined? [YES/NO]
- Comprehensive reflection documentation created? [YES/NO]

→ If all YES: Proceed to Archiving
→ If any NO: Complete reflection steps
```

### Phase 7: ARCHIVING

```mermaid
graph TD
    Start["Begin<br>Archiving"] --> Template["Load Comprehensive<br>Archive Template"]
    Template --> SystemDoc["Create System<br>Documentation"]
    SystemDoc --> Architecture["Document Final<br>Architecture"]
    Architecture --> Design["Compile Design<br>Decisions"]
    Design --> Implementation["Document Implementation<br>Details"]
    Implementation --> Testing["Compile Testing<br>Documentation"]
    Testing --> Deployment["Create Deployment<br>Documentation"]
    Deployment --> Maintenance["Prepare Maintenance<br>Guide"]
    Maintenance --> Knowledge["Transfer Knowledge<br>to Stakeholders"]
    Knowledge --> Archive["Create Comprehensive<br>Archive Package"]
    Archive --> ArchiveComplete["Archiving<br>Complete"]
```

**Steps:**
1. Load comprehensive archive template with all sections
2. Create complete system documentation with all aspects
3. Document final architecture with diagrams and rationales
4. Compile all design decisions with justifications
5. Document all implementation details with technical specifics
6. Compile comprehensive testing documentation with results
7. Create detailed deployment documentation with procedures
8. Prepare maintenance guide with operational procedures
9. Transfer knowledge to all stakeholders with training
10. Create comprehensive archive package with all artifacts

**Milestone Checkpoint:**
```
✓ ARCHIVING CHECKPOINT
- Comprehensive archive template loaded? [YES/NO]
- Complete system documentation created? [YES/NO]
- Final architecture documented? [YES/NO]
- Design decisions compiled? [YES/NO]
- Implementation details documented? [YES/NO]
- Testing documentation compiled? [YES/NO]
- Deployment documentation created? [YES/NO]
- Maintenance guide prepared? [YES/NO]
- Knowledge transferred to stakeholders? [YES/NO]
- Comprehensive archive package created? [YES/NO]

→ If all YES: Task Complete
→ If any NO: Complete archiving steps
```

## 📋 WORKFLOW VERIFICATION CHECKLIST

```
✓ FINAL WORKFLOW VERIFICATION
- All 7 phases completed? [YES/NO]
- All milestone checkpoints passed? [YES/NO]
- Architectural planning properly executed? [YES/NO]
- All required creative phases completed? [YES/NO]
- Implementation performed in proper phases? [YES/NO]
- Comprehensive reflection conducted? [YES/NO]
- Complete system documentation archived? [YES/NO]
- Memory Bank fully updated? [YES/NO]
- Knowledge successfully transferred? [YES/NO]

→ If all YES: Level 4 Task Successfully Completed
→ If any NO: Address outstanding items
```

## 📋 MINIMAL MODE WORKFLOW

For minimal mode, use this streamlined workflow while retaining key elements:

```
1. INIT: Verify environment, create structured task framework, establish context
2. DOCS: Update all Memory Bank documents, document standards and architecture
3. PLAN: Define architecture with principles, alternatives, evaluation, selection
4. CREATE: Execute all required creative phases with documentation
5. IMPL: Implement in phases with verification, integration, testing
6. REFLECT: Document successes, challenges, insights, and strategic actions
7. ARCHIVE: Create comprehensive documentation and knowledge transfer
```

## 🔄 INTEGRATION WITH MEMORY BANK

This workflow integrates comprehensively with Memory Bank:

```mermaid
graph TD
    Workflow["Level 4<br>Workflow"] --> PB["Comprehensive Update<br>projectbrief.md"]
    Workflow --> AC["Detailed Update<br>activeContext.md"]
    Workflow --> SP["Strategic Update<br>systemPatterns.md"]
    Workflow --> TC["Complete Update<br>techContext.md"]
    Workflow --> TM["Structured Maintenance<br>tasks.md"]
    Workflow --> PM["Enterprise Update<br>progress.md"]
    
    PB & AC & SP & TC & TM & PM --> MB["Memory Bank<br>Integration"]
    MB --> KT["Knowledge<br>Transfer"]
    KT --> NextSystem["Enterprise<br>System Evolution"]
```

## 🚨 LEVEL 4 GOVERNANCE PRINCIPLE

Remember:

```
┌─────────────────────────────────────────────────────┐
│ Level 4 tasks represent ENTERPRISE-CRITICAL work.   │
│ RIGOROUS governance, comprehensive documentation,   │
│ and thorough verification are MANDATORY at each     │
│ phase. NO EXCEPTIONS.                               │
└─────────────────────────────────────────────────────┘
```

This ensures that complex systems are designed, implemented, and documented to the highest standards, with enterprise-grade quality and governance.




================================================================
End of Codebase
================================================================

================
File: cursor-memory-bank/mdc rules/rules-phases-main.txt
================
This file is a merged representation of a subset of the codebase, containing specifically included files, combined into a single document by Repomix.

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: .cursor/rules/isolation_rules/Phases/CreativePhase, .cursor/rules/isolation_rules/main-optimized.mdc, .cursor/rules/isolation_rules/main.mdc
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)


================================================================
Directory Structure
================================================================
.cursor/rules/isolation_rules/main-optimized.mdc
.cursor/rules/isolation_rules/main.mdc
.cursor/rules/isolation_rules/Phases/CreativePhase/creative-phase-architecture.mdc
.cursor/rules/isolation_rules/Phases/CreativePhase/creative-phase-uiux.mdc
.cursor/rules/isolation_rules/Phases/CreativePhase/optimized-creative-template.mdc

================================================================
Files
================================================================

================
File: .cursor/rules/isolation_rules/main-optimized.mdc
================
---
description: Optimized main rule for improved token efficiency
globs: main-optimized.mdc
alwaysApply: false
---
# 🔍 OPTIMIZED MEMORY BANK SYSTEM

🚨 CRITICAL RULE: MEMORY BANK CREATION IS MANDATORY 🚨
Memory Bank MUST be created BEFORE any other operation in ANY mode
NO process can continue without verifying Memory Bank existence

> **TL;DR:** This system uses optimized context management and adaptive rule loading to maximize token efficiency while preserving the structured development approach.

## 🧭 OPTIMIZED MODE ARCHITECTURE

```mermaid
graph TD
    subgraph "Memory Bank Core"
        Context["Context Manager"]
        Rules["Rule Loader"]
        FileIO["File Manager"]
        Transition["Mode Transition"]
    end
    
    subgraph "Custom Modes"
        VAN["VAN<br>Initialization"]
        PLAN["PLAN<br>Planning"]
        CREATIVE["CREATIVE<br>Design"]
        IMPLEMENT["IMPLEMENT<br>Building"]
        REFLECT["REFLECT<br>Review"]
        ARCHIVE["ARCHIVE<br>Documentation"]
    end
    
    Context --> VAN & PLAN & CREATIVE & IMPLEMENT & REFLECT & ARCHIVE
    Rules --> VAN & PLAN & CREATIVE & IMPLEMENT & REFLECT & ARCHIVE
    FileIO --> VAN & PLAN & CREATIVE & IMPLEMENT & REFLECT & ARCHIVE
    Transition --> VAN & PLAN & CREATIVE & IMPLEMENT & REFLECT & ARCHIVE
    
    VAN --> PLAN
    PLAN --> CREATIVE
    CREATIVE --> IMPLEMENT
    IMPLEMENT --> REFLECT
    REFLECT --> ARCHIVE
    
    style Context fill:#4da6ff,stroke:#0066cc,color:white
    style Rules fill:#ffa64d,stroke:#cc7a30,color:white
    style FileIO fill:#4dbb5f,stroke:#36873f,color:white
    style Transition fill:#d94dbb,stroke:#a3378a,color:white
```

## 📈 ADAPTIVE COMPLEXITY MODEL

```mermaid
graph TD
    Task["Task Creation"] --> Complexity{"Complexity<br>Level?"}
    
    Complexity -->|"Level 1<br>Quick Fix"| L1["3-Phase<br>Streamlined Process"]
    Complexity -->|"Level 2<br>Enhancement"| L2["4-Phase<br>Balanced Process"]
    Complexity -->|"Level 3<br>Feature"| L3["5-Phase<br>Comprehensive Process"]
    Complexity -->|"Level 4<br>Enterprise"| L4["6-Phase<br>Governance Process"]
    
    L1 --> L1_Process["VAN → IMPLEMENT → REFLECT"]
    L2 --> L2_Process["VAN → PLAN → IMPLEMENT → REFLECT"]
    L3 --> L3_Process["VAN → PLAN → CREATIVE → IMPLEMENT → REFLECT"]
    L4 --> L4_Process["VAN → PLAN → CREATIVE → IMPLEMENT → REFLECT → ARCHIVE"]
    
    style Complexity fill:#d94dbb,stroke:#a3378a,color:white
    style L1 fill:#4dbb5f,stroke:#36873f,color:white
    style L2 fill:#ffa64d,stroke:#cc7a30,color:white
    style L3 fill:#4da6ff,stroke:#0066cc,color:white
    style L4 fill:#ff5555,stroke:#cc0000,color:white
```

## 🧠 HIERARCHICAL RULE LOADING

Rules are loaded hierarchically to optimize context usage:

```mermaid
graph TD
    Root["Memory Bank<br>Common Rules"] --> Core["Core Rules<br>Shared Across Modes"]
    
    Core --> L1["Level 1<br>Rules"]
    Core --> L2["Level 2<br>Rules"]
    Core --> L3["Level 3<br>Rules"]
    Core --> L4["Level 4<br>Rules"]
    
    Core --> VM["Mode<br>Visual Maps"]
    
    Core --> Phase["Phase-Specific<br>Rules"]
    
    Phase --> VAN_Rules["VAN Mode<br>Rules"]
    Phase --> PLAN_Rules["PLAN Mode<br>Rules"]
    Phase --> CREATIVE_Rules["CREATIVE Mode<br>Rules"]
    Phase --> IMPLEMENT_Rules["IMPLEMENT Mode<br>Rules"]
    Phase --> REFLECT_Rules["REFLECT Mode<br>Rules"]
    Phase --> ARCHIVE_Rules["ARCHIVE Mode<br>Rules"]
    
    style Root fill:#4da6ff,stroke:#0066cc,color:white
    style Core fill:#ffa64d,stroke:#cc7a30,color:white
    style Phase fill:#4dbb5f,stroke:#36873f,color:white
```

## 🔄 TOKEN-OPTIMIZED CREATIVE PHASE

Creative phase documentation is progressively generated:

```mermaid
graph TD
    Start["Creative Phase<br>Initiation"] --> P1["1️⃣ PROBLEM<br>Define scope"]
    P1 --> P2["2️⃣ OPTIONS<br>List alternatives"]
    P2 --> P3["3️⃣ ANALYSIS<br>Compare options"]
    P3 --> P4["4️⃣ DECISION<br>Select approach"]
    P4 --> P5["5️⃣ GUIDELINES<br>Document implementation"]
    
    P3 -.->|"On Demand"| Details["Detailed Option<br>Analysis"]
    
    style Start fill:#d971ff,stroke:#a33bc2,color:white
    style P1 fill:#4da6ff,stroke:#0066cc,color:white
    style P2 fill:#ffa64d,stroke:#cc7a30,color:white
    style P3 fill:#4dbb5f,stroke:#36873f,color:white
    style P4 fill:#d94dbb,stroke:#a3378a,color:white
    style P5 fill:#4dbbbb,stroke:#368787,color:white
    style Details fill:#e699d9,stroke:#d94dbb,color:white,stroke-dasharray: 5 5
```

## 🔀 OPTIMIZED MODE TRANSITIONS

Mode transitions use a unified context transfer protocol:

```mermaid
sequenceDiagram
    participant Current as Current Mode
    participant Context as Context Manager
    participant Next as Next Mode
    
    Current->>Context: Create transition document
    Current->>Context: Store critical context
    Context->>Context: Prepare rule cache
    Current->>Next: Initiate transition
    Next->>Context: Verify context availability
    Context->>Next: Load relevant context
    Context->>Next: Load cached rules
    Next->>Next: Continue with preserved context
```

## 📊 MEMORY BANK EFFICIENT UPDATES

```mermaid
graph TD
    subgraph "Memory Bank Files"
        tasks["tasks.md<br>Source of Truth"]
        active["activeContext.md<br>Current Focus"]
        creative["creative-*.md<br>Design Decisions"]
        progress["progress.md<br>Implementation Status"]
        transition["transition.md<br>Mode Transitions"]
    end
    
    Update["Update Request"] --> Diff{"Changed?"}
    Diff -->|"No"| Skip["Skip Update"]
    Diff -->|"Yes"| Section{"Section<br>Change?"}
    Section -->|"Yes"| Partial["Update Changed<br>Sections Only"]
    Section -->|"No"| Full["Full File<br>Update"]
    
    Partial --> tasks
    Full --> tasks
    
    style Update fill:#4da6ff,stroke:#0066cc,color:white
    style Diff fill:#ffa64d,stroke:#cc7a30,color:white
    style Section fill:#4dbb5f,stroke:#36873f,color:white
    style Partial fill:#d94dbb,stroke:#a3378a,color:white
    style Full fill:#4dbbbb,stroke:#368787,color:white
```

## 💻 COMPLEXITY-BASED DOCUMENTATION

Documentation requirements scale based on complexity level:

| Documentation | Level 1 | Level 2 | Level 3 | Level 4 |
|---------------|---------|---------|---------|---------|
| Problem Definition | Brief | Standard | Detailed | Comprehensive |
| Options Analysis | Optional | Basic | Multiple Options | Extensive |
| Implementation Plan | Simple | Standard | Detailed | Phased |
| Testing Requirements | Basic | Standard | Comprehensive | Rigorous |
| Documentation | Minimal | Standard | Detailed | Extensive |

## 📑 OPTIMIZED TEMPLATES BY LEVEL

### Level 1: Quick Fix Template
```markdown
## QUICK FIX: [Issue Name]
- Problem: [Brief description]
- Solution: [Implemented approach]
- Verification: [How fix was tested]
```

### Level 2: Enhancement Template
```markdown
## ENHANCEMENT: [Feature Name]
- Requirement: [What needs to be done]
- Approach: [How it was implemented]
- Testing: [Verification approach]
- Documentation: [Where documented]
```

### Level 3-4: Comprehensive Template
Uses the optimized creative phase template with appropriate documentation depth

## 🔄 REFERENCE MAPS

Each mode's visual process map is optimized for token efficiency:

- @VAN Mode Map (Optimized)
- @PLAN Mode Map (Optimized)
- @CREATIVE Mode Map (Optimized)
- @IMPLEMENT Mode Map (Optimized)
- @REFLECT Mode Map (Optimized)
- @ARCHIVE Mode Map (Optimized)

## ⚡ TOKEN EFFICIENCY IMPROVEMENTS

Optimizations in this version:

1. Hierarchical rule loading (65% token reduction)
2. Progressive creative phase documentation (60% token reduction)
3. Context preservation during mode transitions (40% token reduction)
4. Differential Memory Bank updates (30% token reduction)
5. Complexity-based template scaling (varies by level)

## 💡 USAGE GUIDANCE

To use the optimized system:

1. Start with the VAN command to initialize and determine complexity
2. Follow the complexity-appropriate workflow
3. Use progressive documentation appropriate to task complexity
4. Let the system manage rule loading and context preservation
5. Enjoy the improved token efficiency while maintaining structured development

================
File: .cursor/rules/isolation_rules/main.mdc
================
---
description: main rule
globs: main.mdc
alwaysApply: false
---
# 🔍 ISOLATION-FOCUSED MEMORY BANK SYSTEM

🚨 CRITICAL RULE: MEMORY BANK CREATION IS MANDATORY 🚨
Memory Bank MUST be created BEFORE any other operation in ANY mode
NO process can continue without verifying Memory Bank existence

> **TL;DR:** This system is designed to work with Cursor custom modes, where each mode loads only the rules it needs. The system uses visual Mermaid diagrams and selective document loading to optimize context usage.

## 🧭 MODE-SPECIFIC VISUAL MAPS

```mermaid
graph TD
    subgraph Modes["Cursor Custom Modes"]
        VAN["VAN MODE<br>Initialization"] --> PLAN["PLAN MODE<br>Task Planning"]
        PLAN --> Creative["CREATIVE MODE<br>Design Decisions"]
        Creative --> Implement["IMPLEMENT MODE<br>Code Implementation"]
        Implement --> Reflect["REFLECT MODE<br>Task Review"]
        Reflect --> Archive["ARCHIVE MODE<br>Documentation"]
    end
    
    VAN -.->|"Loads"| VANRules["• main.md<br>• platform-awareness.md<br>• file-verification.md<br>• workflow-init.md"]
    PLAN -.->|"Loads"| PLANRules["• main.md<br>• task-tracking.md<br>• planning-process.md"]
    Creative -.->|"Loads"| CreativeRules["• main.md<br>• creative-phase.md<br>• design-patterns.md"]
    Implement -.->|"Loads"| ImplementRules["• main.md<br>• command-execution.md<br>• implementation-guide.md"]
    Reflect -.->|"Loads"| ReflectRules["• main.md<br>• reflection-format.md"]
    Archive -.->|"Loads"| ArchiveRules["• main.md<br>• archiving-guide.md"]
```

## 📋 MEMORY BANK VERIFICATION - MANDATORY IN ALL MODES

```mermaid
graph TD
    Start["Mode Activation"] --> CheckMemBank{"Memory Bank<br>Exists?"}
    
    CheckMemBank -->|"No"| CreateMemBank["CREATE MEMORY BANK<br>[CRITICAL STEP]"]
    CheckMemBank -->|"Yes"| VerifyMemBank["Verify Memory Bank<br>Structure"]
    
    CreateMemBank --> VerifyCreation{"Creation<br>Successful?"}
    VerifyCreation -->|"No"| AbortAll["⛔ ABORT ALL OPERATIONS<br>Fix Memory Bank First"]
    VerifyCreation -->|"Yes"| VerifyMemBank
    
    VerifyMemBank --> StructureCheck{"Structure<br>Valid?"}
    StructureCheck -->|"No"| FixStructure["Fix Memory Bank<br>Structure"]
    StructureCheck -->|"Yes"| ContinueMode["Continue with<br>Mode Operations"]
    
    FixStructure --> VerifyFix{"Fix<br>Successful?"}
    VerifyFix -->|"No"| AbortAll
    VerifyFix -->|"Yes"| ContinueMode
    
    style CheckMemBank fill:#ff0000,stroke:#990000,color:white,stroke-width:3px
    style CreateMemBank fill:#ff0000,stroke:#990000,color:white,stroke-width:3px
    style VerifyCreation fill:#ff0000,stroke:#990000,color:white,stroke-width:3px
    style AbortAll fill:#ff0000,stroke:#990000,color:white,stroke-width:3px
    style StructureCheck fill:#ff0000,stroke:#990000,color:white,stroke-width:3px
    style FixStructure fill:#ff5555,stroke:#dd3333,color:white
    style VerifyFix fill:#ff5555,stroke:#dd3333,color:white
```

## 📚 VISUAL PROCESS MAPS

Each mode has its own visual process map:

- @VAN Mode Map
- @PLAN Mode Map
- @CREATIVE Mode Map
- @IMPLEMENT Mode Map
- @REFLECT Mode Map
- @ARCHIVE Mode Map

## 🔄 FILE STATE VERIFICATION

In this isolation-focused approach, Memory Bank files maintain continuity between modes:

```mermaid
graph TD
    subgraph "Memory Bank Files"
        tasks["tasks.md<br>Source of Truth"]
        active["activeContext.md<br>Current Focus"]
        creative["creative-*.md<br>Design Decisions"]
        progress["progress.md<br>Implementation Status"]
    end
    
    VAN["VAN MODE"] -->|"Creates/Updates"| tasks
    VAN -->|"Creates/Updates"| active
    
    PLAN["PLAN MODE"] -->|"Reads"| tasks
    PLAN -->|"Reads"| active
    PLAN -->|"Updates"| tasks
    
    Creative["CREATIVE MODE"] -->|"Reads"| tasks
    Creative -->|"Creates"| creative
    Creative -->|"Updates"| tasks
    
    Implement["IMPLEMENT MODE"] -->|"Reads"| tasks
    Implement -->|"Reads"| creative
    Implement -->|"Updates"| tasks
    Implement -->|"Updates"| progress
    
    Reflect["REFLECT MODE"] -->|"Reads"| tasks
    Reflect -->|"Reads"| progress
    Reflect -->|"Updates"| tasks
    
    Archive["ARCHIVE MODE"] -->|"Reads"| tasks
    Archive -->|"Reads"| progress
    Archive -->|"Archives"| creative
```

## 📋 MODE TRANSITION PROTOCOL

```mermaid
sequenceDiagram
    participant User
    participant CurrentMode
    participant NextMode
    
    CurrentMode->>CurrentMode: Complete Phase Requirements
    CurrentMode->>User: "Phase complete. NEXT MODE: [mode name]"
    User->>CurrentMode: End Current Mode
    User->>NextMode: Start Next Mode
    NextMode->>NextMode: Verify Required File State
    
    alt File State Valid
        NextMode->>User: "Continuing from previous mode..."
    else File State Invalid
        NextMode->>User: "Required files not in expected state"
        NextMode->>User: "Return to [previous mode] to complete requirements"
    end
```

## 💻 PLATFORM-SPECIFIC COMMANDS

| Action | Windows | Mac/Linux |
|--------|---------|-----------|
| Create file | `echo. > file.ext` | `touch file.ext` |
| Create directory | `mkdir directory` | `mkdir -p directory` |
| Change directory | `cd directory` | `cd directory` |
| List files | `dir` | `ls` |
| Show file content | `type file.ext` | `cat file.ext` |

## ⚠️ COMMAND EFFICIENCY GUIDANCE

For optimal performance, use efficient command chaining when appropriate:

```
# Efficient command chaining examples:
mkdir -p project/{src,tests,docs} && cd project
grep "TODO" $(find . -name "*.js")
npm install && npm start
```

Refer to [command-execution.mdc](mdc:.cursor/rules/isolation_rules/Core/command-execution.mdc) for detailed guidance.

================
File: .cursor/rules/isolation_rules/Phases/CreativePhase/creative-phase-architecture.mdc
================
---
description: creative phase architecture
globs: creative-phase-architecture.md
alwaysApply: false
---

# CREATIVE PHASE: ARCHITECTURE DESIGN

> **TL;DR:** This document provides structured guidance for architectural design decisions during creative phases, ensuring comprehensive evaluation of options and clear documentation of architectural choices.

## 🏗️ ARCHITECTURE DESIGN WORKFLOW

```mermaid
graph TD
    Start["Architecture<br>Design Start"] --> Req["1. Requirements<br>Analysis"]
    Req --> Comp["2. Component<br>Identification"]
    Comp --> Options["3. Architecture<br>Options"]
    Options --> Eval["4. Option<br>Evaluation"]
    Eval --> Decision["5. Decision &<br>Documentation"]
    Decision --> Valid["6. Validation &<br>Verification"]
    
    style Start fill:#4da6ff,stroke:#0066cc,color:white
    style Req fill:#ffa64d,stroke:#cc7a30,color:white
    style Comp fill:#4dbb5f,stroke:#36873f,color:white
    style Options fill:#d94dbb,stroke:#a3378a,color:white
    style Eval fill:#4dbbbb,stroke:#368787,color:white
    style Decision fill:#d971ff,stroke:#a33bc2,color:white
    style Valid fill:#ff71c2,stroke:#c23b8a,color:white
```

## 📋 ARCHITECTURE DECISION TEMPLATE

```markdown
# Architecture Decision Record

## Context
- System Requirements:
  - [Requirement 1]
  - [Requirement 2]
- Technical Constraints:
  - [Constraint 1]
  - [Constraint 2]

## Component Analysis
- Core Components:
  - [Component 1]: [Purpose/Role]
  - [Component 2]: [Purpose/Role]
- Interactions:
  - [Interaction 1]
  - [Interaction 2]

## Architecture Options
### Option 1: [Name]
- Description: [Brief description]
- Pros:
  - [Pro 1]
  - [Pro 2]
- Cons:
  - [Con 1]
  - [Con 2]
- Technical Fit: [High/Medium/Low]
- Complexity: [High/Medium/Low]
- Scalability: [High/Medium/Low]

### Option 2: [Name]
[Same structure as Option 1]

## Decision
- Chosen Option: [Option name]
- Rationale: [Explanation]
- Implementation Considerations:
  - [Consideration 1]
  - [Consideration 2]

## Validation
- Requirements Met:
  - [✓] Requirement 1
  - [✓] Requirement 2
- Technical Feasibility: [Assessment]
- Risk Assessment: [Evaluation]
```

## 🎯 ARCHITECTURE EVALUATION CRITERIA

```mermaid
graph TD
    subgraph "EVALUATION CRITERIA"
    C1["Scalability"]
    C2["Maintainability"]
    C3["Performance"]
    C4["Security"]
    C5["Cost"]
    C6["Time to Market"]
    end
    
    style C1 fill:#4dbb5f,stroke:#36873f,color:white
    style C2 fill:#ffa64d,stroke:#cc7a30,color:white
    style C3 fill:#d94dbb,stroke:#a3378a,color:white
    style C4 fill:#4dbbbb,stroke:#368787,color:white
    style C5 fill:#d971ff,stroke:#a33bc2,color:white
    style C6 fill:#ff71c2,stroke:#c23b8a,color:white
```

## 📊 ARCHITECTURE VISUALIZATION TEMPLATES

### Component Diagram Template
```mermaid
graph TD
    subgraph "SYSTEM ARCHITECTURE"
    C1["Component 1"]
    C2["Component 2"]
    C3["Component 3"]
    
    C1 -->|"Interface 1"| C2
    C2 -->|"Interface 2"| C3
    end
    
    style C1 fill:#4dbb5f,stroke:#36873f,color:white
    style C2 fill:#ffa64d,stroke:#cc7a30,color:white
    style C3 fill:#d94dbb,stroke:#a3378a,color:white
```

### Data Flow Template
```mermaid
sequenceDiagram
    participant C1 as Component 1
    participant C2 as Component 2
    participant C3 as Component 3
    
    C1->>C2: Request
    C2->>C3: Process
    C3-->>C2: Response
    C2-->>C1: Result
```

## ✅ VERIFICATION CHECKLIST

```markdown
## Architecture Design Verification
- [ ] All system requirements addressed
- [ ] Component responsibilities defined
- [ ] Interfaces specified
- [ ] Data flows documented
- [ ] Security considerations addressed
- [ ] Scalability requirements met
- [ ] Performance requirements met
- [ ] Maintenance approach defined

## Implementation Readiness
- [ ] All components identified
- [ ] Dependencies mapped
- [ ] Technical constraints documented
- [ ] Risk assessment completed
- [ ] Resource requirements defined
- [ ] Timeline estimates provided
```

## 🔄 ARCHITECTURE REVIEW PROCESS

```mermaid
graph TD
    subgraph "REVIEW PROCESS"
    R1["Technical<br>Review"]
    R2["Security<br>Review"]
    R3["Performance<br>Review"]
    R4["Final<br>Approval"]
    end
    
    R1 --> R2 --> R3 --> R4
    
    style R1 fill:#4dbb5f,stroke:#36873f,color:white
    style R2 fill:#ffa64d,stroke:#cc7a30,color:white
    style R3 fill:#d94dbb,stroke:#a3378a,color:white
    style R4 fill:#4dbbbb,stroke:#368787,color:white
```

## 🔄 DOCUMENT MANAGEMENT

```mermaid
graph TD
    Current["Current Document"] --> Active["Active:<br>- creative-phase-architecture.md"]
    Current --> Related["Related:<br>- creative-phase-enforcement.md<br>- planning-comprehensive.md"]
    
    style Current fill:#4da6ff,stroke:#0066cc,color:white
    style Active fill:#4dbb5f,stroke:#36873f,color:white
    style Related fill:#ffa64d,stroke:#cc7a30,color:white
```

================
File: .cursor/rules/isolation_rules/Phases/CreativePhase/creative-phase-uiux.mdc
================
---
description: UI/UX Design Guidelines and Process for the Creative Phase
globs: creative-phase-uiux.mdc
alwaysApply: false
---
Okay, I've updated the style guide location to `memory-bank/style-guide.md` and will provide the entire content for the new `creative-phase-uiux.md` file within a single markdown code block for easy copying. I've also reviewed the Mermaid diagrams to ensure they are correctly formatted.

# Creative Phase: UI/UX Design Guidelines

**Document Purpose:** This document outlines the structured approach for UI/UX design decisions during the Creative Phase. It ensures user-centric designs, exploration of multiple options, adherence to a style guide (if available or created), and clear documentation of UI/UX choices, aligning with React/Tailwind best practices.

## 🎨 UI/UX Design Philosophy

* **User-Centricity**: Designs must prioritize the user's needs, goals, and context.
* **Clarity & Simplicity**: Interfaces should be intuitive and easy to understand.
* **Consistency**: Maintain consistency with established design patterns, project-specific styles, and platform conventions.
* **Accessibility (A11y)**: Adhere to WCAG guidelines to ensure usability for people with disabilities.
* **Efficiency**: Enable users to accomplish tasks with minimal effort.
* **Feedback**: Provide clear and timely feedback for user actions.
* **Visual Cohesion**: Ensure new UI elements align with the existing or defined project style guide.

## 🌊 UI/UX Design Workflow

This workflow guides the UI/UX design process within the Creative Phase, incorporating a crucial style guide check.

```mermaid
graph TD
    Start["UI/UX Design Start"] --> StyleGuideCheck["0. Style Guide Check<br>Attempt to locate 'memory-bank/style-guide.md' or user-provided path."]
    StyleGuideCheck --> HasStyleGuide{"Style Guide<br>Available/Loaded?"}

    HasStyleGuide -- "Yes" --> Understand["Understand User & Task<br>(Personas, User Stories, Requirements)"]
    HasStyleGuide -- "No" --> PromptCreateStyleGuide["Prompt User: Create/Link Style Guide?"]

    PromptCreateStyleGuide --> UserResponse{"User Opts to Create/Link?"}
    UserResponse -- "Yes, Create" --> DefineStyleGuideSubProcess["SUB-PROCESS:Define Basic Style Guide"]
    UserResponse -- "Yes, Link" --> LinkStyleGuide["User provides path/URL.<br>Load Style Guide."]
    UserResponse -- "No" --> Understand_NoGuide["Understand User & Task<br>(Proceeding without Style Guide - WARN user of inconsistencies)"]

    DefineStyleGuideSubProcess --> StyleGuideCreated["Basic 'memory-bank/style-guide.md' Created/Defined"]
    StyleGuideCreated --> Understand
    LinkStyleGuide --> Understand
    Understand_NoGuide --> InfoArch_NoGuide["Information Architecture"]

    Understand --> InfoArch["Information Architecture<br>(Structure, Navigation, Content Hierarchy)"]
    InfoArch --> Interaction["Interaction Design<br>(User Flows, Wireframes, Prototypes - Conceptual)"]
    Interaction --> VisualDesign["Visual Design<br>(APPLY STYLE GUIDE, Leverage React/Tailwind, Mockups - Conceptual)"]
    VisualDesign --> Options["Explore UI/UX Options<br>(Generate 2-3 distinct solutions)"]
    Options --> Evaluate["Evaluate Options<br>(Usability, Feasibility, A11y, Aesthetics, <b>Style Guide Alignment</b>)"]
    Evaluate --> Decision["Make & Document UI/UX Decision<br>(Use Optimized Creative Template)"]
    Decision --> Validate["Validate Against Requirements, Principles & <b>Style Guide</b>"]
    Validate --> UIUX_Complete["UI/UX Design Complete for Component"]

    InfoArch_NoGuide --> Interaction_NoGuide["Interaction Design"]
    Interaction_NoGuide --> VisualDesign_NoGuide["Visual Design<br>(Leverage React/Tailwind, Aim for Internal Consistency)"]
    VisualDesign_NoGuide --> Options_NoGuide["Explore UI/UX Options"]
    Options_NoGuide --> Evaluate_NoGuide["Evaluate Options<br>(Usability, Feasibility, A11y, Aesthetics)"]
    Evaluate_NoGuide --> Decision_NoGuide["Make & Document UI/UX Decision"]
    Decision_NoGuide --> Validate_NoGuide["Validate Against Requirements & Principles"]
    Validate_NoGuide --> UIUX_Complete

    style Start fill:#4da6ff,stroke:#0066cc,color:white
    style StyleGuideCheck fill:#ab87ff,stroke:#7d5bbe,color:white
    style HasStyleGuide fill:#ab87ff,stroke:#7d5bbe,color:white
    style PromptCreateStyleGuide fill:#ffcb6b,stroke:#f9a825,color:black
    style UserResponse fill:#ffcb6b,stroke:#f9a825,color:black
    style DefineStyleGuideSubProcess fill:#c3e88d,stroke:#82a75c,color:black
    style LinkStyleGuide fill:#c3e88d,stroke:#82a75c,color:black
    style StyleGuideCreated fill:#c3e88d,stroke:#82a75c,color:black
    style VisualDesign fill:#4dbbbb,stroke:#368787,color:white
    style Evaluate fill:#d971ff,stroke:#a33bc2,color:white
    style Validate fill:#71c2ff,stroke:#3b8aa3,color:white
    style Understand_NoGuide fill:#ff8a80,stroke:#c85a54,color:black
    style UIUX_Complete fill:#5fd94d,stroke:#3da336,color:white
```

## 📖 Style Guide Integration

A consistent visual style is paramount for good UI/UX. This section details how to reference an existing style guide or prompt for its creation. **The primary location for the style guide in this system will be `memory-bank/style-guide.md`.**

### Step 0: Style Guide Check & Handling

**A. Checking for an Existing Style Guide:**
1.  **Primary Location Check**: The system **MUST** first look for the style guide at this specific path:
    * `memory-bank/style-guide.md`
2.  **Secondary Check (User Prompt)**: If `memory-bank/style-guide.md` is not found, the system **MUST** prompt the user:
    ```
    "I could not find 'memory-bank/style-guide.md'.
    Is there an existing style guide at a different location, or a URL I should reference?
    If yes, please provide the full path or URL.
    Otherwise, we can create a basic 'memory-bank/style-guide.md' now, or you can opt to proceed without one (though this is not recommended for new UI development)."
    ```

**B. Using an Existing Style Guide:**
* If `memory-bank/style-guide.md` is found or an alternative path/URL is provided by the user:
    * Load its content into context.
    * **CRITICAL**: All subsequent UI/UX design proposals (colors, typography, spacing, component appearance) **MUST** adhere strictly to this guide.
    * When evaluating options (Step 6 of the workflow), "Adherence to Style Guide" **MUST** be a key evaluation criterion.

**C. If No Style Guide Exists or is Provided (User Interaction):**
* If no style guide is found or linked by the user, the system **MUST** strongly recommend creating one:
    ```
    "No style guide has been referenced. For optimal UI consistency and development efficiency, creating 'memory-bank/style-guide.md' is highly recommended."

    "Would you like to:"
    "1. Create a basic 'memory-bank/style-guide.md' now? (I can help you define core elements like colors, typography, and spacing based on observations or your input.)"
    "2. Proceed with UI/UX design without a style guide? (WARNING: This may lead to visual inconsistencies and is strongly discouraged for new features or significant UI changes.)"
    "Please choose 1 or 2."
    ```
    (If the user previously chose to link one but it failed, this prompt should adapt).

**D. Assisting in Style Guide Creation (If user opts-in for option 1):**
This initiates a sub-process to define and document a basic style guide, which will be saved as `memory-bank/style-guide.md`.

```mermaid
graph TD
    StartCreate["User Opts to Create Style Guide"] --> GatherInspiration["Gather Inspiration<br>(e.g., Analyze user-provided image, existing UI, or direct user input)"]
    GatherInspiration --> DefineColors["Define Core Color Palette<br>(Primary, Secondary, Accent, Neutrals, Status Colors - with hex codes)"]
    DefineColors --> DefineTypography["Define Typography<br>(Font Families, Sizes, Weights for Headings, Body, Links)"]
    DefineTypography --> DefineSpacing["Define Spacing System<br>(Base unit, margins, paddings, Tailwind scale usage)"]
    DefineSpacing --> DefineComponents["Define Key Component Styles (Conceptual)<br>(Buttons, Inputs, Cards - using Tailwind utility classes if applicable)"]
    DefineComponents --> DefineTone["Define Tone of Voice & Imagery Style (Optional)"]
    DefineTone --> GenerateDoc["Generate content for 'memory-bank/style-guide.md'<br>(Populate with defined elements)"]
    GenerateDoc --> SaveFile["Save the generated content to 'memory-bank/style-guide.md'"]
    SaveFile --> Confirm["Confirm 'memory-bank/style-guide.md' creation & Proceed with UI/UX Design"]

    style StartCreate fill:#c3e88d,stroke:#82a75c,color:black
    style GatherInspiration fill:#e0f2f1,stroke:#a7c4c0,color:black
    style SaveFile fill:#89cff0,stroke:#50a6c2,color:black
```
* **Process**:
    1.  **Inspiration**: Analyze user-provided examples (like the dashboard image `original-a5959a2926d1e7ede16dbe1d27593a59.webp`) or ask for user preferences.
        * `AI: "To create a style guide, do you have an existing design, screenshot, or website I can analyze for styles? Or would you like to define them from scratch?"`
    2.  **Define Elements**: Guide the user through defining colors, typography, spacing, and key component styles (as detailed in the previous response regarding the sample based on the image).
    3.  **Documentation**: Generate the content for `memory-bank/style-guide.md`. The structure should be similar to the sample style guide created from the dashboard image.
    4.  **Save File**: The system should then create and save this content to the file `memory-bank/style-guide.md`.
* Once `memory-bank/style-guide.md` is created/loaded, it becomes the **single source of truth for visual design**.

## 🖼️ Key UI/UX Design Considerations (To be applied using `memory-bank/style-guide.md`)

### 1. User Needs Analysis
* **Personas**: Define target user personas.
* **User Stories/Jobs-to-be-Done**: Clarify what users need to achieve.
* **Use Cases**: Detail specific interaction scenarios.

### 2. Information Architecture (IA)
* **Content Inventory & Audit**: Understand existing content.
* **Hierarchy & Structure**: Organize content logically.
* **Navigation Design**: Design intuitive navigation (menus, breadcrumbs) adhering to `memory-bank/style-guide.md` for appearance.
* **Labeling**: Use clear and consistent labels.

### 3. Interaction Design (IxD)
* **User Flows**: Map out the user's path.
* **Wireframes**: Create low-fidelity layouts.
* **Prototypes (Conceptual)**: Describe interactive elements and transitions.
* **Error Handling & Prevention**: Design clear error messages (styled per `memory-bank/style-guide.md`).
* **Feedback Mechanisms**: Implement visual/textual feedback (styled per `memory-bank/style-guide.md`).

### 4. Visual Design (Strictly follow `memory-bank/style-guide.md`)
* **Style Guide Adherence**: **CRITICAL** - All visual choices **MUST** conform to `memory-bank/style-guide.md`.
* **Visual Hierarchy**: Use the Style Guide's typography and spacing to guide the user.
* **Layout & Composition**: Arrange elements effectively using Tailwind CSS and Style Guide spacing.
* **Typography**: Apply defined font families, sizes, and weights from the Style Guide.
* **Color Palette**: Exclusively use colors defined in the Style Guide.
* **Imagery & Iconography**: Use icons and images that match the Style Guide's defined style.
* **Branding**: Align with project branding guidelines as documented in the Style Guide.

### 5. Accessibility (A11y)
* **WCAG Compliance Level**: Target AA or AAA.
* **Semantic HTML**.
* **Keyboard Navigation**.
* **ARIA Attributes**.
* **Color Contrast**: Verify against Style Guide colors.
* **Alternative Text**.

### 6. Platform & Responsiveness
* **Responsive Design**: Ensure UI adapts to screen sizes using Style Guide's responsive principles (if defined).
* **Platform Conventions**: Adhere to UI patterns for the target platform(s).

## 🛠️ UI/UX Option Evaluation & Decision Making

Reference the project's `optimized-creative-template.mdc`. Key evaluation criteria **must** include:

* Usability
* Learnability
* Efficiency
* Accessibility
* Aesthetics (as defined by `memory-bank/style-guide.md`)
* Feasibility (React/Tailwind)
* Alignment with Requirements
* **Adherence to `memory-bank/style-guide.md` (CRITICAL if guide exists)**

```mermaid
graph TD
    subgraph "UI/UX EVALUATION CRITERIA"
        C1["Usability"]
        C2["Learnability"]
        C3["Efficiency"]
        C4["Accessibility (A11y)"]
        C5["Aesthetics (Per Style Guide)"]
        C6["Feasibility (React/Tailwind)"]
        C7["Alignment with Requirements"]
        C8["<b>Style Guide Adherence</b>"]
    end

    style C8 fill:#ff5555,stroke:#c30052,color:white
```

## 📝 Documentation Standards

* Use the project's `optimized-creative-template.mdc` for documenting UI/UX decisions.
* Clearly describe chosen UI patterns and rationale, referencing `memory-bank/style-guide.md`.
* Document considerations for responsive states and accessibility, as guided by `memory-bank/style-guide.md`.

## ✅ UI/UX Design Verification Checklist

* [ ] **Style Guide (`memory-bank/style-guide.md`) referenced or created?**
* [ ] User needs clearly understood and addressed?
* [ ] Information architecture logical and intuitive?
* [ ] Interaction design clear and efficient?
* [ ] **Visual design strictly adheres to `memory-bank/style-guide.md`?**
* [ ] Accessibility standards met?
* [ ] Responsive design addressed?
* [ ] Design decisions documented with rationale and Style Guide references?
* [ ] Alignment with React/Tailwind best practices and Style Guide considered?

## 🔄 Integration with Other Creative Phases

* **Architecture Design**: Ensure UI/UX is compatible with system architecture.
* **Data Model Design**: UI should effectively present/capture data from the data model.
* **Style Guide**: All UI/UX work **must** be a direct application or extension of the established `memory-bank/style-guide.md`.

```

================
File: .cursor/rules/isolation_rules/Phases/CreativePhase/optimized-creative-template.mdc
================
---
description: Optimized creative phase template with progressive documentation
globs: "**/creative*/**", "**/design*/**", "**/decision*/**"
alwaysApply: false
---

# OPTIMIZED CREATIVE PHASE TEMPLATE

> **TL;DR:** This template implements a progressive documentation approach for creative phases, optimizing token usage while maintaining thorough design exploration.

## 📝 PROGRESSIVE DOCUMENTATION MODEL

```mermaid
graph TD
    Start["Creative Phase Start"] --> P1["1️⃣ PROBLEM<br>Define scope"]
    P1 --> P2["2️⃣ OPTIONS<br>Explore alternatives"]
    P2 --> P3["3️⃣ ANALYSIS<br>Evaluate selected options"]
    P3 --> P4["4️⃣ DECISION<br>Finalize approach"]
    P4 --> P5["5️⃣ IMPLEMENTATION<br>Document guidelines"]
    
    style Start fill:#d971ff,stroke:#a33bc2,color:white
    style P1 fill:#4da6ff,stroke:#0066cc,color:white
    style P2 fill:#ffa64d,stroke:#cc7a30,color:white
    style P3 fill:#4dbb5f,stroke:#36873f,color:white
    style P4 fill:#d94dbb,stroke:#a3378a,color:white
    style P5 fill:#4dbbbb,stroke:#368787,color:white
```

## 📋 TEMPLATE STRUCTURE

```markdown
📌 CREATIVE PHASE START: [Component Name]
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

1️⃣ PROBLEM
   Description: [Brief problem description]
   Requirements: [Key requirements as bullet points]
   Constraints: [Technical or business constraints]

2️⃣ OPTIONS
   Option A: [Name] - [One-line description]
   Option B: [Name] - [One-line description]
   Option C: [Name] - [One-line description]

3️⃣ ANALYSIS
   | Criterion | Option A | Option B | Option C |
   |-----------|----------|----------|----------|
   | Performance | ⭐⭐⭐ | ⭐⭐ | ⭐⭐⭐⭐ |
   | Complexity | ⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐⭐ |
   | Maintainability | ⭐⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐ |
   
   Key Insights:
   - [Insight 1]
   - [Insight 2]

4️⃣ DECISION
   Selected: [Option X]
   Rationale: [Brief justification]
   
5️⃣ IMPLEMENTATION NOTES
   - [Implementation note 1]
   - [Implementation note 2]
   - [Implementation note 3]

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
📌 CREATIVE PHASE END
```

## 🧩 DETAILED OPTION ANALYSIS (ON DEMAND)

Detailed analysis can be provided on demand for selected options:

```markdown
<details>
  <summary>Detailed Analysis: Option A</summary>
  
  ### Option A: [Full Name]
  
  **Complete Description**:
  [Detailed description of how the option works]
  
  **Pros**:
  - [Pro 1 with explanation]
  - [Pro 2 with explanation]
  - [Pro 3 with explanation]
  
  **Cons**:
  - [Con 1 with explanation]
  - [Con 2 with explanation]
  
  **Implementation Complexity**: [Low/Medium/High]
  [Explanation of complexity factors]
  
  **Resource Requirements**:
  [Details on resource needs]
  
  **Risk Assessment**:
  [Analysis of risks]
</details>
```

## 📊 COMPLEXITY-BASED SCALING

The template automatically scales documentation requirements based on task complexity level:

### Level 1-2 (Quick Fix/Enhancement)
- Simplified problem/solution
- Focus on implementation
- Minimal option exploration

### Level 3 (Feature Development)
- Multiple options required
- Analysis table with key criteria
- Implementation guidelines

### Level 4 (Enterprise Development)
- Comprehensive analysis
- Multiple viewpoints considered
- Detailed implementation plan
- Expanded verification criteria

## ✅ VERIFICATION PROTOCOL

Quality verification is condensed into a simple checklist:

```markdown
VERIFICATION:
[x] Problem clearly defined
[x] Multiple options considered
[x] Decision made with rationale
[x] Implementation guidance provided
```

## 🔄 USAGE EXAMPLES

### Architecture Decision (Level 3)

```markdown
📌 CREATIVE PHASE START: Authentication System
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

1️⃣ PROBLEM
   Description: Design an authentication system for the application
   Requirements: Secure, scalable, supports SSO, easy to maintain
   Constraints: Must work with existing user database, <100ms response time

2️⃣ OPTIONS
   Option A: JWT-based stateless auth - Simple token-based approach
   Option B: Session-based auth with Redis - Server-side session storage
   Option C: OAuth2 implementation - Delegated authorization framework

3️⃣ ANALYSIS
   | Criterion | JWT | Sessions | OAuth2 |
   |-----------|-----|----------|--------|
   | Security | ⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ |
   | Scalability | ⭐⭐⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐⭐ |
   | Complexity | ⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐⭐ |
   | Performance | ⭐⭐⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐ |
   
   Key Insights:
   - JWT offers best performance but limited revocation options
   - Sessions provide better security control but require more infrastructure
   - OAuth2 most complex but offers best integration possibilities

4️⃣ DECISION
   Selected: Option A: JWT-based auth with refresh tokens
   Rationale: Best balance of performance and scalability while meeting security needs
   
5️⃣ IMPLEMENTATION NOTES
   - Use HS256 algorithm for token signing
   - Implement short-lived access tokens (15min) with longer refresh tokens (7 days)
   - Store token blacklist in Redis for revocation capability
   - Add rate limiting on token endpoints

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
📌 CREATIVE PHASE END
```

### Algorithm Decision (Level 2)

```markdown
📌 CREATIVE PHASE START: Search Algorithm
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

1️⃣ PROBLEM
   Description: Implement efficient text search for product catalog
   Requirements: Fast results, support for partial matches, case insensitive
   Constraints: Dataset < 10,000 items, must work in browser environment

2️⃣ OPTIONS
   Option A: Simple regex search - Basic pattern matching
   Option B: Trie-based search - Prefix tree structure
   Option C: Fuzzy search with Levenshtein - Edit distance algorithm

3️⃣ DECISION
   Selected: Option B: Trie-based search
   Rationale: Best performance for prefix searches with manageable memory usage
   
4️⃣ IMPLEMENTATION NOTES
   - Use existing trie library
   - Preprocess text to lowercase during indexing
   - Implement letter-by-letter search for instant results
   - Add debounce (300ms) to prevent excessive rebuilding

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
📌 CREATIVE PHASE END
```

## 🏆 TOKEN EFFICIENCY BENEFITS

This template significantly reduces token usage by:

1. Focusing on essential information without unnecessary verbosity
2. Using compact tabular formats for comparisons
3. Implementing progressive disclosure for detailed information
4. Scaling documentation requirements by task complexity
5. Using visual indicators (emojis) for quick scanning

The template maintains the rigor of the creative process while improving token efficiency by approximately 60% over the previous format.




================================================================
End of Codebase
================================================================

================
File: cursor-memory-bank/mdc rules/rules-visual-maps.txt
================
This file is a merged representation of a subset of the codebase, containing specifically included files, combined into a single document by Repomix.

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: .cursor/rules/isolation_rules/visual-maps
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)


================================================================
Directory Structure
================================================================
.cursor/rules/isolation_rules/visual-maps/archive-mode-map.mdc
.cursor/rules/isolation_rules/visual-maps/creative-mode-map.mdc
.cursor/rules/isolation_rules/visual-maps/implement-mode-map.mdc
.cursor/rules/isolation_rules/visual-maps/plan-mode-map.mdc
.cursor/rules/isolation_rules/visual-maps/qa-mode-map.mdc
.cursor/rules/isolation_rules/visual-maps/reflect-mode-map.mdc
.cursor/rules/isolation_rules/visual-maps/van_mode_split/van-complexity-determination.mdc
.cursor/rules/isolation_rules/visual-maps/van_mode_split/van-file-verification.mdc
.cursor/rules/isolation_rules/visual-maps/van_mode_split/van-mode-map.mdc
.cursor/rules/isolation_rules/visual-maps/van_mode_split/van-platform-detection.mdc
.cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-checks/build-test.mdc
.cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-checks/config-check.mdc
.cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-checks/dependency-check.mdc
.cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-checks/environment-check.mdc
.cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-checks/file-verification.mdc
.cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-main.mdc
.cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-utils/common-fixes.mdc
.cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-utils/mode-transitions.mdc
.cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-utils/reports.mdc
.cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-utils/rule-calling-guide.mdc
.cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-utils/rule-calling-help.mdc
.cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-validation.md.old
.cursor/rules/isolation_rules/visual-maps/van-mode-map.mdc

================================================================
Files
================================================================

================
File: .cursor/rules/isolation_rules/visual-maps/archive-mode-map.mdc
================
---
description: Visual process map for ARCHIVE mode (Task Documentation)
globs: "**/archive*/**", "**/document*/**", "**/complete*/**"
alwaysApply: false
---

# ARCHIVE MODE: TASK DOCUMENTATION PROCESS MAP

> **TL;DR:** This visual map guides the ARCHIVE mode process, focusing on creating comprehensive documentation of the completed task, archiving relevant files, and updating the Memory Bank for future reference.

## 🧭 ARCHIVE MODE PROCESS FLOW

```mermaid
graph TD
    Start["START ARCHIVE MODE"] --> ReadTasks["Read tasks.md<br>reflection.md and<br>progress.md"]
    
    %% Initial Assessment
    ReadTasks --> VerifyReflect{"Reflection<br>Complete?"}
    VerifyReflect -->|"No"| ReturnReflect["Return to<br>REFLECT Mode"]
    VerifyReflect -->|"Yes"| AssessLevel{"Determine<br>Complexity Level"}
    
    %% Level-Based Archiving
    AssessLevel -->|"Level 1"| L1Archive["LEVEL 1 ARCHIVING<br>Level1/archive-minimal.md"]
    AssessLevel -->|"Level 2"| L2Archive["LEVEL 2 ARCHIVING<br>Level2/archive-basic.md"]
    AssessLevel -->|"Level 3"| L3Archive["LEVEL 3 ARCHIVING<br>Level3/archive-standard.md"]
    AssessLevel -->|"Level 4"| L4Archive["LEVEL 4 ARCHIVING<br>Level4/archive-comprehensive.md"]
    
    %% Level 1 Archiving (Minimal)
    L1Archive --> L1Summary["Create Quick<br>Summary"]
    L1Summary --> L1Task["Update<br>tasks.md"]
    L1Task --> L1Complete["Mark Task<br>Complete"]
    
    %% Level 2 Archiving (Basic)
    L2Archive --> L2Summary["Create Basic<br>Archive Document"]
    L2Summary --> L2Doc["Document<br>Changes"]
    L2Doc --> L2Task["Update<br>tasks.md"]
    L2Task --> L2Progress["Update<br>progress.md"]
    L2Progress --> L2Complete["Mark Task<br>Complete"]
    
    %% Level 3-4 Archiving (Comprehensive)
    L3Archive & L4Archive --> L34Summary["Create Comprehensive<br>Archive Document"]
    L34Summary --> L34Doc["Document<br>Implementation"]
    L34Doc --> L34Creative["Archive Creative<br>Phase Documents"]
    L34Creative --> L34Code["Document Code<br>Changes"]
    L34Code --> L34Test["Document<br>Testing"]
    L34Test --> L34Lessons["Summarize<br>Lessons Learned"]
    L34Lessons --> L34Task["Update<br>tasks.md"]
    L34Task --> L34Progress["Update<br>progress.md"]
    L34Progress --> L34System["Update System<br>Documentation"]
    L34System --> L34Complete["Mark Task<br>Complete"]
    
    %% Completion
    L1Complete & L2Complete & L34Complete --> CreateArchive["Create Archive<br>Document in<br>docs/archive/"]
    CreateArchive --> UpdateActive["Update<br>activeContext.md"]
    UpdateActive --> Reset["Reset for<br>Next Task"]
```

## 📋 ARCHIVE DOCUMENT STRUCTURE

The archive document should follow this structured format:

```mermaid
graph TD
    subgraph "Archive Document Structure"
        Header["# TASK ARCHIVE: [Task Name]"]
        Meta["## METADATA<br>Task info, dates, complexity"]
        Summary["## SUMMARY<br>Brief overview of the task"]
        Requirements["## REQUIREMENTS<br>What the task needed to accomplish"]
        Implementation["## IMPLEMENTATION<br>How the task was implemented"]
        Testing["## TESTING<br>How the solution was verified"]
        Lessons["## LESSONS LEARNED<br>Key takeaways from the task"]
        Refs["## REFERENCES<br>Links to related documents"]
    end
    
    Header --> Meta --> Summary --> Requirements --> Implementation --> Testing --> Lessons --> Refs
```

## 📊 REQUIRED FILE STATE VERIFICATION

Before archiving can begin, verify file state:

```mermaid
graph TD
    Start["File State<br>Verification"] --> CheckTasks{"tasks.md has<br>reflection<br>complete?"}
    
    CheckTasks -->|"No"| ErrorReflect["ERROR:<br>Return to REFLECT Mode"]
    CheckTasks -->|"Yes"| CheckReflection{"reflection.md<br>exists?"}
    
    CheckReflection -->|"No"| ErrorCreate["ERROR:<br>Create reflection.md first"]
    CheckReflection -->|"Yes"| CheckProgress{"progress.md<br>updated?"}
    
    CheckProgress -->|"No"| ErrorProgress["ERROR:<br>Update progress.md first"]
    CheckProgress -->|"Yes"| ReadyArchive["Ready for<br>Archiving"]
```

## 🔍 ARCHIVE TYPES BY COMPLEXITY

```mermaid
graph TD
    subgraph "Level 1: Minimal Archive"
        L1A["Basic Bug<br>Description"]
        L1B["Solution<br>Summary"]
        L1C["Affected<br>Files"]
    end
    
    subgraph "Level 2: Basic Archive"
        L2A["Enhancement<br>Description"]
        L2B["Implementation<br>Summary"]
        L2C["Testing<br>Results"]
        L2D["Lessons<br>Learned"]
    end
    
    subgraph "Level 3-4: Comprehensive Archive"
        L3A["Detailed<br>Requirements"]
        L3B["Architecture/<br>Design Decisions"]
        L3C["Implementation<br>Details"]
        L3D["Testing<br>Strategy"]
        L3E["Performance<br>Considerations"]
        L3F["Future<br>Enhancements"]
        L3G["Cross-References<br>to Other Systems"]
    end
    
    L1A --> L1B --> L1C
    
    L2A --> L2B --> L2C --> L2D
    
    L3A --> L3B --> L3C --> L3D --> L3E --> L3F --> L3G
```

## 📝 ARCHIVE DOCUMENT TEMPLATES

### Level 1 (Minimal) Archive
```
# Bug Fix Archive: [Bug Name]

## Date
[Date of fix]

## Summary
[Brief description of the bug and solution]

## Implementation
[Description of the fix implemented]

## Files Changed
- [File 1]
- [File 2]
```

### Levels 2-4 (Comprehensive) Archive
```
# Task Archive: [Task Name]

## Metadata
- **Complexity**: Level [2/3/4]
- **Type**: [Enhancement/Feature/System]
- **Date Completed**: [Date]
- **Related Tasks**: [Related task references]

## Summary
[Comprehensive summary of the task]

## Requirements
- [Requirement 1]
- [Requirement 2]
- [Requirement 3]

## Implementation
### Approach
[Description of implementation approach]

### Key Components
- [Component 1]: [Description]
- [Component 2]: [Description]

### Files Changed
- [File 1]: [Description of changes]
- [File 2]: [Description of changes]

## Testing
- [Test 1]: [Result]
- [Test 2]: [Result]

## Lessons Learned
- [Lesson 1]
- [Lesson 2]
- [Lesson 3]

## Future Considerations
- [Future enhancement 1]
- [Future enhancement 2]

## References
- [Link to reflection document]
- [Link to creative phase documents]
- [Other relevant references]
```

## 📋 ARCHIVE LOCATION AND NAMING

Archive documents should be organized following this pattern:

```mermaid
graph TD
    subgraph "Archive Structure"
        Root["docs/archive/"]
        Tasks["tasks/"]
        Features["features/"]
        Systems["systems/"]
        
        Root --> Tasks
        Root --> Features
        Root --> Systems
        
        Tasks --> Bug["bug-fix-name-YYYYMMDD.md"]
        Tasks --> Enhancement["enhancement-name-YYYYMMDD.md"]
        Features --> Feature["feature-name-YYYYMMDD.md"]
        Systems --> System["system-name-YYYYMMDD.md"]
    end
```

## 📊 TASKS.MD FINAL UPDATE

When archiving is complete, update tasks.md with:

```
## Status
- [x] Initialization complete
- [x] Planning complete
[For Level 3-4:]
- [x] Creative phases complete
- [x] Implementation complete
- [x] Reflection complete
- [x] Archiving complete

## Archive
- **Date**: [Completion date]
- **Archive Document**: [Link to archive document]
- **Status**: COMPLETED
```

## 📋 ARCHIVE VERIFICATION CHECKLIST

```
✓ ARCHIVE VERIFICATION
- Reflection document reviewed? [YES/NO]
- Archive document created with all sections? [YES/NO]
- Archive document placed in correct location? [YES/NO]
- tasks.md marked as completed? [YES/NO]
- progress.md updated with archive reference? [YES/NO]
- activeContext.md updated for next task? [YES/NO]
- Creative phase documents archived (Level 3-4)? [YES/NO/NA]

→ If all YES: Archiving complete - Memory Bank reset for next task
→ If any NO: Complete missing archive elements
```

## 🔄 TASK COMPLETION NOTIFICATION

When archiving is complete, notify user with:

```
## TASK ARCHIVED

✅ Archive document created in docs/archive/
✅ All task documentation preserved
✅ Memory Bank updated with references
✅ Task marked as COMPLETED

→ Memory Bank is ready for the next task
→ To start a new task, use VAN MODE
```

================
File: .cursor/rules/isolation_rules/visual-maps/creative-mode-map.mdc
================
---
description: Visual process map for CREATIVE mode (Design Decisions)
globs: "**/creative*/**", "**/design*/**", "**/decision*/**"
alwaysApply: false
---

# CREATIVE MODE: DESIGN PROCESS MAP

> **TL;DR:** This visual map guides the CREATIVE mode process, focusing on structured design decision-making for components that require deeper exploration before implementation.

## 🧭 CREATIVE MODE PROCESS FLOW

```mermaid
graph TD
    Start["START CREATIVE MODE"] --> ReadTasks["Read tasks.md<br>For Creative Requirements"]
    
    %% Initial Assessment
    ReadTasks --> VerifyPlan{"Plan Complete<br>& Creative Phases<br>Identified?"}
    VerifyPlan -->|"No"| ReturnPlan["Return to<br>PLAN Mode"]
    VerifyPlan -->|"Yes"| IdentifyPhases["Identify Creative<br>Phases Required"]
    
    %% Creative Phase Selection
    IdentifyPhases --> SelectPhase["Select Next<br>Creative Phase"]
    SelectPhase --> PhaseType{"Creative<br>Phase Type?"}
    
    %% Creative Phase Types
    PhaseType -->|"UI/UX<br>Design"| UIPhase["UI/UX CREATIVE PHASE<br>Core/creative-phase-uiux.md"]
    PhaseType -->|"Architecture<br>Design"| ArchPhase["ARCHITECTURE CREATIVE PHASE<br>Core/creative-phase-architecture.md"]
    PhaseType -->|"Data Model<br>Design"| DataPhase["DATA MODEL CREATIVE PHASE<br>Core/creative-phase-data.md"]
    PhaseType -->|"Algorithm<br>Design"| AlgoPhase["ALGORITHM CREATIVE PHASE<br>Core/creative-phase-algorithm.md"]
    
    %% UI/UX Creative Phase
    UIPhase --> UI_Problem["Define UI/UX<br>Problem"]
    UI_Problem --> UI_Research["Research UI<br>Patterns"]
    UI_Research --> UI_Options["Explore UI<br>Options"]
    UI_Options --> UI_Evaluate["Evaluate User<br>Experience"]
    UI_Evaluate --> UI_Decision["Make Design<br>Decision"]
    UI_Decision --> UI_Document["Document UI<br>Design"]
    
    %% Architecture Creative Phase
    ArchPhase --> Arch_Problem["Define Architecture<br>Challenge"]
    Arch_Problem --> Arch_Options["Explore Architecture<br>Options"]
    Arch_Options --> Arch_Analyze["Analyze Tradeoffs"]
    Arch_Analyze --> Arch_Decision["Make Architecture<br>Decision"]
    Arch_Decision --> Arch_Document["Document<br>Architecture"]
    Arch_Document --> Arch_Diagram["Create Architecture<br>Diagram"]
    
    %% Data Model Creative Phase
    DataPhase --> Data_Requirements["Define Data<br>Requirements"]
    Data_Requirements --> Data_Structure["Design Data<br>Structure"]
    Data_Structure --> Data_Relations["Define<br>Relationships"]
    Data_Relations --> Data_Validation["Design<br>Validation"]
    Data_Validation --> Data_Document["Document<br>Data Model"]
    
    %% Algorithm Creative Phase
    AlgoPhase --> Algo_Problem["Define Algorithm<br>Problem"]
    Algo_Problem --> Algo_Options["Explore Algorithm<br>Approaches"]
    Algo_Options --> Algo_Evaluate["Evaluate Time/Space<br>Complexity"]
    Algo_Evaluate --> Algo_Decision["Make Algorithm<br>Decision"]
    Algo_Decision --> Algo_Document["Document<br>Algorithm"]
    
    %% Documentation & Completion
    UI_Document & Arch_Diagram & Data_Document & Algo_Document --> CreateDoc["Create Creative<br>Phase Document"]
    CreateDoc --> UpdateTasks["Update tasks.md<br>with Decision"]
    UpdateTasks --> MorePhases{"More Creative<br>Phases?"}
    MorePhases -->|"Yes"| SelectPhase
    MorePhases -->|"No"| VerifyComplete["Verify All<br>Phases Complete"]
    VerifyComplete --> NotifyComplete["Signal Creative<br>Phases Complete"]
```

## 📋 CREATIVE PHASE DOCUMENT FORMAT

Each creative phase should produce a document with this structure:

```mermaid
graph TD
    subgraph "Creative Phase Document"
        Header["🎨 CREATIVE PHASE: [TYPE]"]
        Problem["PROBLEM STATEMENT<br>Clear definition of the problem"]
        Options["OPTIONS ANALYSIS<br>Multiple approaches considered"]
        Pros["PROS & CONS<br>Tradeoffs for each option"]
        Decision["DECISION<br>Selected approach + rationale"]
        Impl["IMPLEMENTATION PLAN<br>Steps to implement the decision"]
        Diagram["VISUALIZATION<br>Diagrams of the solution"]
    end
    
    Header --> Problem --> Options --> Pros --> Decision --> Impl --> Diagram
```

## 🔍 CREATIVE TYPES AND APPROACHES

```mermaid
graph TD
    subgraph "UI/UX Design"
        UI1["User Flow<br>Analysis"]
        UI2["Component<br>Hierarchy"]
        UI3["Interaction<br>Patterns"]
        UI4["Visual Design<br>Principles"]
    end
    
    subgraph "Architecture Design"
        A1["Component<br>Structure"]
        A2["Data Flow<br>Patterns"]
        A3["Interface<br>Design"]
        A4["System<br>Integration"]
    end
    
    subgraph "Data Model Design"
        D1["Entity<br>Relationships"]
        D2["Schema<br>Design"]
        D3["Validation<br>Rules"]
        D4["Query<br>Optimization"]
    end
    
    subgraph "Algorithm Design"
        AL1["Complexity<br>Analysis"]
        AL2["Efficiency<br>Optimization"]
        AL3["Edge Case<br>Handling"]
        AL4["Scaling<br>Considerations"]
    end
```

## 📊 REQUIRED FILE STATE VERIFICATION

Before creative phase work can begin, verify file state:

```mermaid
graph TD
    Start["File State<br>Verification"] --> CheckTasks{"tasks.md has<br>planning complete?"}
    
    CheckTasks -->|"No"| ErrorPlan["ERROR:<br>Return to PLAN Mode"]
    CheckTasks -->|"Yes"| CheckCreative{"Creative phases<br>identified?"}
    
    CheckCreative -->|"No"| ErrorCreative["ERROR:<br>Return to PLAN Mode"]
    CheckCreative -->|"Yes"| ReadyCreative["Ready for<br>Creative Phase"]
```

## 📋 OPTIONS ANALYSIS TEMPLATE

For each creative phase, analyze multiple options:

```
## OPTIONS ANALYSIS

### Option 1: [Name]
**Description**: [Brief description]
**Pros**:
- [Pro 1]
- [Pro 2]
**Cons**:
- [Con 1]
- [Con 2]
**Complexity**: [Low/Medium/High]
**Implementation Time**: [Estimate]

### Option 2: [Name]
**Description**: [Brief description]
**Pros**:
- [Pro 1]
- [Pro 2]
**Cons**:
- [Con 1]
- [Con 2]
**Complexity**: [Low/Medium/High]
**Implementation Time**: [Estimate]

### Option 3: [Name]
**Description**: [Brief description]
**Pros**:
- [Pro 1]
- [Pro 2]
**Cons**:
- [Con 1]
- [Con 2]
**Complexity**: [Low/Medium/High]
**Implementation Time**: [Estimate]
```

## 🎨 CREATIVE PHASE MARKERS

Use these visual markers for creative phases:

```
🎨🎨🎨 ENTERING CREATIVE PHASE: [TYPE] 🎨🎨🎨

[Creative phase content]

🎨 CREATIVE CHECKPOINT: [Milestone]

[Additional content]

🎨🎨🎨 EXITING CREATIVE PHASE - DECISION MADE 🎨🎨🎨
```

## 📊 CREATIVE PHASE VERIFICATION CHECKLIST

```
✓ CREATIVE PHASE VERIFICATION
- Problem clearly defined? [YES/NO]
- Multiple options considered (3+)? [YES/NO]
- Pros/cons documented for each option? [YES/NO]
- Decision made with clear rationale? [YES/NO]
- Implementation plan included? [YES/NO]
- Visualization/diagrams created? [YES/NO]
- tasks.md updated with decision? [YES/NO]

→ If all YES: Creative phase complete
→ If any NO: Complete missing elements
```

## 🔄 MODE TRANSITION NOTIFICATION

When all creative phases are complete, notify user with:

```
## CREATIVE PHASES COMPLETE

✅ All required design decisions made
✅ Creative phase documents created
✅ tasks.md updated with decisions
✅ Implementation plan updated

→ NEXT RECOMMENDED MODE: IMPLEMENT MODE
```

================
File: .cursor/rules/isolation_rules/visual-maps/implement-mode-map.mdc
================
---
description: Visual process map for BUILD mode (Code Implementation)
globs: implementation-mode-map.mdc
alwaysApply: false
---

# BUILD MODE: CODE EXECUTION PROCESS MAP

> **TL;DR:** This visual map guides the BUILD mode process, focusing on efficient code implementation based on the planning and creative phases, with proper command execution and progress tracking.

## 🧭 BUILD MODE PROCESS FLOW

```mermaid
graph TD
    Start["START BUILD MODE"] --> ReadDocs["Read Reference Documents<br>Core/command-execution.md"]
    
    %% Initialization
    ReadDocs --> CheckLevel{"Determine<br>Complexity Level<br>from tasks.md"}
    
    %% Level 1 Implementation
    CheckLevel -->|"Level 1<br>Quick Bug Fix"| L1Process["LEVEL 1 PROCESS<br>Level1/quick-bug-workflow.md"]
    L1Process --> L1Review["Review Bug<br>Report"]
    L1Review --> L1Examine["Examine<br>Relevant Code"]
    L1Examine --> L1Fix["Implement<br>Targeted Fix"]
    L1Fix --> L1Test["Test<br>Fix"]
    L1Test --> L1Update["Update<br>tasks.md"]
    
    %% Level 2 Implementation
    CheckLevel -->|"Level 2<br>Simple Enhancement"| L2Process["LEVEL 2 PROCESS<br>Level2/enhancement-workflow.md"]
    L2Process --> L2Review["Review Build<br>Plan"]
    L2Review --> L2Examine["Examine Relevant<br>Code Areas"]
    L2Examine --> L2Implement["Implement Changes<br>Sequentially"]
    L2Implement --> L2Test["Test<br>Changes"]
    L2Test --> L2Update["Update<br>tasks.md"]
    
    %% Level 3-4 Implementation
    CheckLevel -->|"Level 3-4<br>Feature/System"| L34Process["LEVEL 3-4 PROCESS<br>Level3/feature-workflow.md<br>Level4/system-workflow.md"]
    L34Process --> L34Review["Review Plan &<br>Creative Decisions"]
    L34Review --> L34Phase{"Creative Phase<br>Documents<br>Complete?"}
    
    L34Phase -->|"No"| L34Error["ERROR:<br>Return to CREATIVE Mode"]
    L34Phase -->|"Yes"| L34DirSetup["Create Directory<br>Structure"]
    L34DirSetup --> L34VerifyDirs["VERIFY Directories<br>Created Successfully"]
    L34VerifyDirs --> L34Implementation["Build<br>Phase"]
    
    %% Implementation Phases
    L34Implementation --> L34Phase1["Phase 1<br>Build"]
    L34Phase1 --> L34VerifyFiles["VERIFY Files<br>Created Successfully"]
    L34VerifyFiles --> L34Test1["Test<br>Phase 1"]
    L34Test1 --> L34Document1["Document<br>Phase 1"]
    L34Document1 --> L34Next1{"Next<br>Phase?"}
    L34Next1 -->|"Yes"| L34Implementation
    
    L34Next1 -->|"No"| L34Integration["Integration<br>Testing"]
    L34Integration --> L34Document["Document<br>Integration Points"]
    L34Document --> L34Update["Update<br>tasks.md"]
    
    %% Command Execution
    L1Fix & L2Implement & L34Phase1 --> CommandExec["COMMAND EXECUTION<br>Core/command-execution.md"]
    CommandExec --> DocCommands["Document Commands<br>& Results"]
    
    %% Completion & Transition
    L1Update & L2Update & L34Update --> VerifyComplete["Verify Build<br>Complete"]
    VerifyComplete --> UpdateProgress["Update progress.md<br>with Status"]
    UpdateProgress --> Transition["NEXT MODE:<br>REFLECT MODE"]
```

## 📋 REQUIRED FILE STATE VERIFICATION

Before implementation can begin, verify file state:

```mermaid
graph TD
    Start["File State<br>Verification"] --> CheckTasks{"tasks.md has<br>planning complete?"}
    
    CheckTasks -->|"No"| ErrorPlan["ERROR:<br>Return to PLAN Mode"]
    CheckTasks -->|"Yes"| CheckLevel{"Task<br>Complexity?"}
    
    CheckLevel -->|"Level 1"| L1Ready["Ready for<br>Implementation"]
    
    CheckLevel -->|"Level 2"| L2Ready["Ready for<br>Implementation"]
    
    CheckLevel -->|"Level 3-4"| CheckCreative{"Creative phases<br>required?"}
    
    CheckCreative -->|"No"| L34Ready["Ready for<br>Implementation"]
    CheckCreative -->|"Yes"| VerifyCreative{"Creative phases<br>completed?"}
    
    VerifyCreative -->|"No"| ErrorCreative["ERROR:<br>Return to CREATIVE Mode"]
    VerifyCreative -->|"Yes"| L34Ready
```

## 🔄 FILE SYSTEM VERIFICATION PROCESS

```mermaid
graph TD
    Start["Start File<br>Verification"] --> CheckDir["Check Directory<br>Structure"]
    CheckDir --> DirResult{"Directories<br>Exist?"}
    
    DirResult -->|"No"| ErrorDir["❌ ERROR:<br>Missing Directories"]
    DirResult -->|"Yes"| CheckFiles["Check Each<br>Created File"]
    
    ErrorDir --> FixDir["Fix Directory<br>Structure"]
    FixDir --> CheckDir
    
    CheckFiles --> FileResult{"All Files<br>Exist?"}
    FileResult -->|"No"| ErrorFile["❌ ERROR:<br>Missing/Wrong Path Files"]
    FileResult -->|"Yes"| Complete["✅ Verification<br>Complete"]
    
    ErrorFile --> FixFile["Fix File Paths<br>or Recreate Files"]
    FixFile --> CheckFiles
```

## 📋 DIRECTORY VERIFICATION STEPS

Before beginning any file creation:

```
✓ DIRECTORY VERIFICATION PROCEDURE
1. Create all directories first before any files
2. Use ABSOLUTE paths: /full/path/to/directory
3. Verify each directory after creation:
   ls -la /full/path/to/directory     # Linux/Mac
   dir "C:\full\path\to\directory"    # Windows
4. Document directory structure in progress.md
5. Only proceed to file creation AFTER verifying ALL directories exist
```

## 📋 FILE CREATION VERIFICATION

After creating files:

```
✓ FILE VERIFICATION PROCEDURE
1. Use ABSOLUTE paths for all file operations: /full/path/to/file.ext
2. Verify each file creation was successful:
   ls -la /full/path/to/file.ext     # Linux/Mac
   dir "C:\full\path\to\file.ext"    # Windows 
3. If verification fails:
   a. Check for path resolution issues
   b. Verify directory exists
   c. Try creating with corrected path
   d. Recheck file exists after correction
4. Document all file paths in progress.md
```

## 🔄 COMMAND EXECUTION WORKFLOW

```mermaid
graph TD
    Start["Command<br>Execution"] --> Analyze["Analyze Command<br>Requirements"]
    Analyze --> Complexity{"Command<br>Complexity?"}
    
    Complexity -->|"Simple"| Simple["Execute<br>Single Command"]
    Complexity -->|"Moderate"| Chain["Use Efficient<br>Command Chaining"]
    Complexity -->|"Complex"| Break["Break Into<br>Logical Steps"]
    
    Simple & Chain & Break --> Verify["Verify<br>Results"]
    Verify --> Document["Document<br>Command & Result"]
    Document --> Next["Next<br>Command"]
```

## 📋 LEVEL-SPECIFIC BUILD APPROACHES

```mermaid
graph TD
    subgraph "Level 1: Quick Bug Fix"
        L1A["Targeted Code<br>Examination"]
        L1B["Minimal<br>Change Scope"]
        L1C["Direct<br>Fix"]
        L1D["Verify<br>Fix"]
    end
    
    subgraph "Level 2: Enhancement"
        L2A["Sequential<br>Build"]
        L2B["Contained<br>Changes"]
        L2C["Standard<br>Testing"]
        L2D["Component<br>Documentation"]
    end
    
    subgraph "Level 3-4: Feature/System"
        L3A["Directory<br>Structure First"]
        L3B["Verify Dirs<br>Before Files"]
        L3C["Phased<br>Build"]
        L3D["Verify Files<br>After Creation"]
        L3E["Integration<br>Testing"]
        L3F["Detailed<br>Documentation"]
    end
    
    L1A --> L1B --> L1C --> L1D
    L2A --> L2B --> L2C --> L2D
    L3A --> L3B --> L3C --> L3D --> L3E --> L3F
```

## 📝 BUILD DOCUMENTATION FORMAT

Document builds with:

```
## Build: [Component/Feature]

### Approach
[Brief description of build approach]

### Directory Structure
- [/absolute/path/to/dir1/]: [Purpose]
- [/absolute/path/to/dir2/]: [Purpose]

### Code Changes
- [/absolute/path/to/file1.ext]: [Description of changes]
- [/absolute/path/to/file2.ext]: [Description of changes]

### Verification Steps
- [✓] Directory structure created and verified
- [✓] All files created in correct locations
- [✓] File content verified

### Commands Executed
```
[Command 1]
[Result]
```

```
[Command 2]
[Result]
```

### Testing
- [Test 1]: [Result]
- [Test 2]: [Result]

### Status
- [x] Build complete
- [x] Testing performed
- [x] File verification completed
- [ ] Documentation updated
```

## 📊 TASKS.MD UPDATE FORMAT

During the build process, update tasks.md with progress:

```
## Status
- [x] Initialization complete
- [x] Planning complete
[For Level 3-4:]
- [x] Creative phases complete
- [x] Directory structure created and verified
- [x] [Built component 1]
- [x] [Built component 2]
- [ ] [Remaining component]

## Build Progress
- [Component 1]: Complete
  - Files: [/absolute/path/to/files]
  - [Details about implementation]
- [Component 2]: Complete
  - Files: [/absolute/path/to/files]
  - [Details about implementation]
- [Component 3]: In Progress
  - [Current status]
```

## 📋 PROGRESS.MD UPDATE FORMAT

Update progress.md with:

```
# Build Progress

## Directory Structure
- [/absolute/path/to/dir1/]: Created and verified
- [/absolute/path/to/dir2/]: Created and verified

## [Date]: [Component/Feature] Built
- **Files Created**: 
  - [/absolute/path/to/file1.ext]: Verified
  - [/absolute/path/to/file2.ext]: Verified
- **Key Changes**: 
  - [Change 1]
  - [Change 2]
- **Testing**: [Test results]
- **Next Steps**: [What comes next]
```

## 📊 BUILD VERIFICATION CHECKLIST

```
✓ BUILD VERIFICATION
- Directory structure created correctly? [YES/NO]
- All files created in correct locations? [YES/NO]
- All file paths verified with absolute paths? [YES/NO]
- All planned changes implemented? [YES/NO]
- Testing performed for all changes? [YES/NO]
- Code follows project standards? [YES/NO]
- Edge cases handled appropriately? [YES/NO]
- Build documented with absolute paths? [YES/NO]
- tasks.md updated with progress? [YES/NO]
- progress.md updated with details? [YES/NO]

→ If all YES: Build complete - ready for REFLECT mode
→ If any NO: Complete missing build elements
```

## 🔄 MODE TRANSITION NOTIFICATION

When the build is complete, notify user with:

```
## BUILD COMPLETE

✅ Directory structure verified
✅ All files created in correct locations
✅ All planned changes implemented
✅ Testing performed successfully
✅ tasks.md updated with status
✅ progress.md updated with details

→ NEXT RECOMMENDED MODE: REFLECT MODE
```

================
File: .cursor/rules/isolation_rules/visual-maps/plan-mode-map.mdc
================
---
description: Visual process map for PLAN mode (Code Implementation)
globs: plan-mode-map.mdc
alwaysApply: false
---

# PLAN MODE: TASK PLANNING PROCESS MAP

> **TL;DR:** This visual map guides the PLAN mode process, focusing on creating detailed implementation plans based on the complexity level determined during initialization, with mandatory technology validation before implementation.

## 🧭 PLAN MODE PROCESS FLOW

```mermaid
graph TD
    Start["START PLANNING"] --> ReadTasks["Read tasks.md<br>Core/task-tracking.md"]
    
    %% Complexity Level Determination
    ReadTasks --> CheckLevel{"Determine<br>Complexity Level"}
    CheckLevel -->|"Level 2"| Level2["LEVEL 2 PLANNING<br>Level2/enhancement-planning.md"]
    CheckLevel -->|"Level 3"| Level3["LEVEL 3 PLANNING<br>Level3/feature-planning.md"]
    CheckLevel -->|"Level 4"| Level4["LEVEL 4 PLANNING<br>Level4/system-planning.md"]
    
    %% Level 2 Planning
    Level2 --> L2Review["Review Code<br>Structure"]
    L2Review --> L2Document["Document<br>Planned Changes"]
    L2Document --> L2Challenges["Identify<br>Challenges"]
    L2Challenges --> L2Checklist["Create Task<br>Checklist"]
    L2Checklist --> L2Update["Update tasks.md<br>with Plan"]
    L2Update --> L2Tech["TECHNOLOGY<br>VALIDATION"]
    L2Tech --> L2Verify["Verify Plan<br>Completeness"]
    
    %% Level 3 Planning
    Level3 --> L3Review["Review Codebase<br>Structure"]
    L3Review --> L3Requirements["Document Detailed<br>Requirements"]
    L3Requirements --> L3Components["Identify Affected<br>Components"]
    L3Components --> L3Plan["Create Comprehensive<br>Implementation Plan"]
    L3Plan --> L3Challenges["Document Challenges<br>& Solutions"]
    L3Challenges --> L3Update["Update tasks.md<br>with Plan"]
    L3Update --> L3Tech["TECHNOLOGY<br>VALIDATION"]
    L3Tech --> L3Flag["Flag Components<br>Requiring Creative"]
    L3Flag --> L3Verify["Verify Plan<br>Completeness"]
    
    %% Level 4 Planning
    Level4 --> L4Analysis["Codebase Structure<br>Analysis"]
    L4Analysis --> L4Requirements["Document Comprehensive<br>Requirements"]
    L4Requirements --> L4Diagrams["Create Architectural<br>Diagrams"]
    L4Diagrams --> L4Subsystems["Identify Affected<br>Subsystems"]
    L4Subsystems --> L4Dependencies["Document Dependencies<br>& Integration Points"]
    L4Dependencies --> L4Plan["Create Phased<br>Implementation Plan"]
    L4Plan --> L4Update["Update tasks.md<br>with Plan"]
    L4Update --> L4Tech["TECHNOLOGY<br>VALIDATION"]
    L4Tech --> L4Flag["Flag Components<br>Requiring Creative"]
    L4Flag --> L4Verify["Verify Plan<br>Completeness"]
    
    %% Technology Validation Gate - NEW
    L2Tech & L3Tech & L4Tech --> TechGate["⛔ TECHNOLOGY<br>VALIDATION GATE"]
    TechGate --> TechSelection["Document Technology<br>Stack Selection"]
    TechSelection --> TechHelloWorld["Create Hello World<br>Proof of Concept"]
    TechHelloWorld --> TechDependencies["Verify Required<br>Dependencies"]
    TechDependencies --> TechConfig["Validate Build<br>Configuration"]
    TechConfig --> TechBuild["Complete Test<br>Build"]
    TechBuild --> TechVerify["⛔ TECHNOLOGY<br>CHECKPOINT"]
    
    %% Verification & Completion
    L2Verify & L3Verify & L4Verify & TechVerify --> CheckCreative{"Creative<br>Phases<br>Required?"}
    
    %% Mode Transition
    CheckCreative -->|"Yes"| RecCreative["NEXT MODE:<br>CREATIVE MODE"]
    CheckCreative -->|"No"| RecImplement["NEXT MODE:<br>IMPLEMENT MODE"]
    
    %% Style for Technology Gate
    style TechGate fill:#ff5555,stroke:#dd3333,color:white,stroke-width:3px
    style TechVerify fill:#ff5555,stroke:#dd3333,color:white,stroke-width:3px
    style TechSelection fill:#4da6ff,stroke:#0066cc,color:white
    style TechHelloWorld fill:#4da6ff,stroke:#0066cc,color:white
    style TechDependencies fill:#4da6ff,stroke:#0066cc,color:white
    style TechConfig fill:#4da6ff,stroke:#0066cc,color:white
    style TechBuild fill:#4da6ff,stroke:#0066cc,color:white
```

## 📋 LEVEL-SPECIFIC PLANNING APPROACHES

```mermaid
graph TD
    subgraph "Level 2: Enhancement"
        L2A["Basic Requirements<br>Analysis"]
        L2B["Simple Component<br>Identification"]
        L2C["Linear Implementation<br>Plan"]
        L2D["Basic Checklist<br>Creation"]
    end
    
    subgraph "Level 3: Feature"
        L3A["Detailed Requirements<br>Analysis"]
        L3B["Component Mapping<br>with Dependencies"]
        L3C["Multi-Phase<br>Implementation Plan"]
        L3D["Comprehensive<br>Checklist"]
        L3E["Creative Phase<br>Identification"]
    end
    
    subgraph "Level 4: System"
        L4A["Architectural<br>Requirements Analysis"]
        L4B["System Component<br>Mapping"]
        L4C["Subsystem<br>Integration Plan"]
        L4D["Phased Implementation<br>Strategy"]
        L4E["Risk Assessment<br>& Mitigation"]
        L4F["Multiple Creative<br>Phase Requirements"]
    end
    
    L2A --> L2B --> L2C --> L2D
    L3A --> L3B --> L3C --> L3D --> L3E
    L4A --> L4B --> L4C --> L4D --> L4E --> L4F
```

## 🔧 TECHNOLOGY VALIDATION WORKFLOW

```mermaid
graph TD
    Start["Technology<br>Validation Start"] --> Select["Technology<br>Stack Selection"]
    Select --> Document["Document Chosen<br>Technologies"]
    Document --> POC["Create Minimal<br>Proof of Concept"]
    POC --> Build["Verify Build<br>Process Works"]
    Build --> Dependencies["Validate All<br>Dependencies"]
    Dependencies --> Config["Confirm Configuration<br>Files Are Correct"]
    Config --> Test["Complete Test<br>Build/Run"]
    Test --> Success{"All Checks<br>Pass?"}
    
    Success -->|"Yes"| Ready["Ready for<br>Implementation"]
    Success -->|"No"| Fix["Fix Technology<br>Issues"]
    Fix --> Document
    
    style Start fill:#4da6ff,stroke:#0066cc,color:white
    style POC fill:#4da6ff,stroke:#0066cc,color:white
    style Success fill:#ff5555,stroke:#dd3333,color:white
    style Fix fill:#ff5555,stroke:#dd3333,color:white
    style Ready fill:#10b981,stroke:#059669,color:white
```

## 📊 REQUIRED FILE STATE VERIFICATION

Before planning can begin, verify the file state:

```mermaid
graph TD
    Start["File State<br>Verification"] --> CheckTasks{"tasks.md<br>initialized?"}
    
    CheckTasks -->|"No"| ErrorTasks["ERROR:<br>Return to VAN Mode"]
    CheckTasks -->|"Yes"| CheckActive{"activeContext.md<br>exists?"}
    
    CheckActive -->|"No"| ErrorActive["ERROR:<br>Return to VAN Mode"]
    CheckActive -->|"Yes"| ReadyPlan["Ready for<br>Planning"]
```

## 📝 TASKS.MD UPDATE FORMAT

During planning, update tasks.md with this structure:

```
# Task: [Task name]

## Description
[Detailed description]

## Complexity
Level: [2/3/4]
Type: [Enhancement/Feature/Complex System]

## Technology Stack
- Framework: [Selected framework]
- Build Tool: [Selected build tool]
- Language: [Selected language]
- Storage: [Selected storage mechanism]

## Technology Validation Checkpoints
- [ ] Project initialization command verified
- [ ] Required dependencies identified and installed
- [ ] Build configuration validated
- [ ] Hello world verification completed
- [ ] Test build passes successfully

## Status
- [x] Initialization complete
- [x] Planning complete
- [ ] Technology validation complete
- [ ] [Implementation steps]

## Implementation Plan
1. [Step 1]
   - [Subtask 1.1]
   - [Subtask 1.2]
2. [Step 2]
   - [Subtask 2.1]
   - [Subtask 2.2]

## Creative Phases Required
- [ ] [Component 1] Design
- [ ] [Component 2] Architecture
- [ ] [Component 3] Data Model

## Dependencies
- [Dependency 1]
- [Dependency 2]

## Challenges & Mitigations
- [Challenge 1]: [Mitigation strategy]
- [Challenge 2]: [Mitigation strategy]
```

## 📋 CREATIVE PHASE IDENTIFICATION

For Level 3-4 tasks, identify components requiring creative phases:

```mermaid
graph TD
    Start["Creative Phase<br>Identification"] --> CheckComp{"Component<br>Analysis"}
    
    CheckComp --> UI["UI/UX<br>Components"]
    CheckComp --> Data["Data Model<br>Components"]
    CheckComp --> Arch["Architecture<br>Components"]
    CheckComp --> Algo["Algorithm<br>Components"]
    
    UI & Data & Arch & Algo --> Decision{"Design Decisions<br>Required?"}
    
    Decision -->|"Yes"| Flag["Flag for<br>Creative Phase"]
    Decision -->|"No"| Skip["Standard<br>Implementation"]
    
    Flag --> Document["Document in<br>tasks.md"]
```

## 📊 TECHNOLOGY VALIDATION CHECKLIST

```
✓ TECHNOLOGY VALIDATION CHECKLIST
- Technology stack clearly defined? [YES/NO]
- Project initialization command documented? [YES/NO]
- Required dependencies identified? [YES/NO]
- Minimal proof of concept created? [YES/NO]
- Hello world build/run successful? [YES/NO]
- Configuration files validated? [YES/NO]
- Test build completes successfully? [YES/NO]

→ If all YES: Technology validation complete - ready for next phase
→ If any NO: Resolve technology issues before proceeding
```

## 📊 PLAN VERIFICATION CHECKLIST

```
✓ PLAN VERIFICATION CHECKLIST
- Requirements clearly documented? [YES/NO]
- Technology stack validated? [YES/NO]
- Affected components identified? [YES/NO]
- Implementation steps detailed? [YES/NO]
- Dependencies documented? [YES/NO]
- Challenges & mitigations addressed? [YES/NO]
- Creative phases identified (Level 3-4)? [YES/NO/NA]
- tasks.md updated with plan? [YES/NO]

→ If all YES: Planning complete - ready for next mode
→ If any NO: Complete missing plan elements
```

## 🔄 MODE TRANSITION NOTIFICATION

When planning is complete, notify user with:

```
## PLANNING COMPLETE

✅ Implementation plan created
✅ Technology stack validated
✅ tasks.md updated with plan
✅ Challenges and mitigations documented
[✅ Creative phases identified (for Level 3-4)]

→ NEXT RECOMMENDED MODE: [CREATIVE/IMPLEMENT] MODE

================
File: .cursor/rules/isolation_rules/visual-maps/qa-mode-map.mdc
================
---
description: QA Mode
globs: qa-mode-map.mdc
alwaysApply: false
---


> **TL;DR:** This enhanced QA mode provides comprehensive validation at any stage of development. It automatically detects the current phase, validates Memory Bank consistency, verifies task tracking, and performs phase-specific technical validation to ensure project quality throughout the development lifecycle.

## 🔍 ENHANCED QA MODE PROCESS FLOW

```mermaid
graph TD
    Start["🚀 START QA MODE"] --> DetectPhase["🧭 PHASE DETECTION<br>Determine current project phase"]
    
    %% Phase detection decision path
    DetectPhase --> PhaseDetermination{"Current Phase?"}
    PhaseDetermination -->|"VAN"| VANChecks["VAN Phase Validation"]
    PhaseDetermination -->|"PLAN"| PLANChecks["PLAN Phase Validation"]
    PhaseDetermination -->|"CREATIVE"| CREATIVEChecks["CREATIVE Phase Validation"] 
    PhaseDetermination -->|"IMPLEMENT"| IMPLEMENTChecks["IMPLEMENT Phase Validation"]
    
    %% Universal checks that apply to all phases
    DetectPhase --> UniversalChecks["🔍 UNIVERSAL VALIDATION"]
    UniversalChecks --> MemoryBankCheck["1️⃣ MEMORY BANK VERIFICATION<br>Check consistency & updates"]
    MemoryBankCheck --> TaskTrackingCheck["2️⃣ TASK TRACKING VERIFICATION<br>Validate tasks.md as source of truth"]
    TaskTrackingCheck --> ReferenceCheck["3️⃣ REFERENCE VALIDATION<br>Verify cross-references between docs"]
    
    %% Phase-specific validations feed into comprehensive report
    VANChecks & PLANChecks & CREATIVEChecks & IMPLEMENTChecks --> PhaseSpecificResults["Phase-Specific Results"]
    ReferenceCheck & PhaseSpecificResults --> ValidationResults{"✅ All Checks<br>Passed?"}
    
    %% Results Processing
    ValidationResults -->|"Yes"| SuccessReport["📝 GENERATE SUCCESS REPORT<br>All validations passed"]
    ValidationResults -->|"No"| FailureReport["⚠️ GENERATE FAILURE REPORT<br>With specific fix instructions"]
    
    %% Success Path
    SuccessReport --> UpdateMB["📚 Update Memory Bank<br>Record successful validation"]
    UpdateMB --> ContinueProcess["🚦 CONTINUE: Phase processes<br>can proceed"]
    
    %% Failure Path
    FailureReport --> IdentifyFixes["🔧 IDENTIFY REQUIRED FIXES"]
    IdentifyFixes --> ApplyFixes["🛠️ APPLY FIXES"]
    ApplyFixes --> Revalidate["🔄 Re-run validation"]
    Revalidate --> ValidationResults
    
    %% Style nodes for clarity
    style Start fill:#4da6ff,stroke:#0066cc,color:white
    style DetectPhase fill:#f6ad55,stroke:#c27022,color:white
    style UniversalChecks fill:#f6546a,stroke:#c30052,color:white
    style MemoryBankCheck fill:#10b981,stroke:#059669,color:white
    style TaskTrackingCheck fill:#10b981,stroke:#059669,color:white
    style ReferenceCheck fill:#10b981,stroke:#059669,color:white
    style ValidationResults fill:#f6546a,stroke:#c30052,color:white
    style SuccessReport fill:#10b981,stroke:#059669,color:white
    style FailureReport fill:#f6ad55,stroke:#c27022,color:white
    style ContinueProcess fill:#10b981,stroke:#059669,color:white,stroke-width:2px
    style IdentifyFixes fill:#f6ad55,stroke:#c27022,color:white
```

## 🧭 PHASE DETECTION PROCESS

The enhanced QA mode first determines which phase the project is currently in:

```mermaid
graph TD
    PD["Phase Detection"] --> CheckMB["Analyze Memory Bank Files"]
    CheckMB --> CheckActive["Check activeContext.md<br>for current phase"]
    CheckActive --> CheckProgress["Check progress.md<br>for recent activities"]
    CheckProgress --> CheckTasks["Check tasks.md<br>for task status"]
    
    CheckTasks --> PhaseResult{"Determine<br>Current Phase"}
    PhaseResult -->|"VAN"| VAN["VAN Phase<br>Initialization"]
    PhaseResult -->|"PLAN"| PLAN["PLAN Phase<br>Task Planning"]
    PhaseResult -->|"CREATIVE"| CREATIVE["CREATIVE Phase<br>Design Decisions"]
    PhaseResult -->|"IMPLEMENT"| IMPLEMENT["IMPLEMENT Phase<br>Implementation"]
    
    VAN & PLAN & CREATIVE & IMPLEMENT --> LoadChecks["Load Phase-Specific<br>Validation Checks"]
    
    style PD fill:#4da6ff,stroke:#0066cc,color:white
    style PhaseResult fill:#f6546a,stroke:#c30052,color:white
    style LoadChecks fill:#10b981,stroke:#059669,color:white
```

## 📝 UNIVERSAL MEMORY BANK VERIFICATION

This process ensures Memory Bank files are consistent and up-to-date regardless of phase:

```mermaid
graph TD
    MBVS["Memory Bank<br>Verification"] --> CoreCheck["Check Core Files Exist"]
    CoreCheck --> CoreFiles["Verify Required Files:<br>projectbrief.md<br>activeContext.md<br>tasks.md<br>progress.md"]
    
    CoreFiles --> ContentCheck["Verify Content<br>Consistency"]
    ContentCheck --> LastModified["Check Last Modified<br>Timestamps"]
    LastModified --> CrossRef["Validate Cross-<br>References"]
    
    CrossRef --> ConsistencyCheck{"All Files<br>Consistent?"}
    ConsistencyCheck -->|"Yes"| PassMB["✅ Memory Bank<br>Verification Passed"]
    ConsistencyCheck -->|"No"| FailMB["❌ Memory Bank<br>Inconsistencies Found"]
    
    FailMB --> FixSuggestions["Generate Fix<br>Suggestions"]
    
    style MBVS fill:#4da6ff,stroke:#0066cc,color:white
    style ConsistencyCheck fill:#f6546a,stroke:#c30052,color:white
    style PassMB fill:#10b981,stroke:#059669,color:white
    style FailMB fill:#ff5555,stroke:#dd3333,color:white
```

## 📋 TASK TRACKING VERIFICATION

This process validates tasks.md as the single source of truth:

```mermaid
graph TD
    TTV["Task Tracking<br>Verification"] --> CheckTasksFile["Check tasks.md<br>Existence & Format"]
    CheckTasksFile --> VerifyReferences["Verify Task References<br>in Other Documents"]
    VerifyReferences --> ProgressCheck["Check Consistency with<br>progress.md"]
    ProgressCheck --> StatusCheck["Verify Task Status<br>Accuracy"]
    
    StatusCheck --> TaskConsistency{"Tasks Properly<br>Tracked?"}
    TaskConsistency -->|"Yes"| PassTasks["✅ Task Tracking<br>Verification Passed"]
    TaskConsistency -->|"No"| FailTasks["❌ Task Tracking<br>Issues Found"]
    
    FailTasks --> TaskFixSuggestions["Generate Task Tracking<br>Fix Suggestions"]
    
    style TTV fill:#4da6ff,stroke:#0066cc,color:white
    style TaskConsistency fill:#f6546a,stroke:#c30052,color:white
    style PassTasks fill:#10b981,stroke:#059669,color:white
    style FailTasks fill:#ff5555,stroke:#dd3333,color:white
```

## 🔄 REFERENCE VALIDATION PROCESS

This process ensures proper cross-referencing between documents:

```mermaid
graph TD
    RV["Reference<br>Validation"] --> FindRefs["Find Cross-References<br>in Documents"]
    FindRefs --> VerifyRefs["Verify Reference<br>Accuracy"]
    VerifyRefs --> CheckBackRefs["Check Bidirectional<br>References"]
    
    CheckBackRefs --> RefConsistency{"References<br>Consistent?"}
    RefConsistency -->|"Yes"| PassRefs["✅ Reference Validation<br>Passed"]
    RefConsistency -->|"No"| FailRefs["❌ Reference<br>Issues Found"]
    
    FailRefs --> RefFixSuggestions["Generate Reference<br>Fix Suggestions"]
    
    style RV fill:#4da6ff,stroke:#0066cc,color:white
    style RefConsistency fill:#f6546a,stroke:#c30052,color:white
    style PassRefs fill:#10b981,stroke:#059669,color:white
    style FailRefs fill:#ff5555,stroke:#dd3333,color:white
```

## 🚨 PHASE-SPECIFIC VALIDATION PROCESSES

### VAN Phase Validation

```mermaid
graph TD
    VAN["VAN Phase<br>Validation"] --> InitCheck["Check Initialization<br>Completeness"]
    InitCheck --> PlatformCheck["Verify Platform<br>Detection"]
    PlatformCheck --> ComplexityCheck["Validate Complexity<br>Determination"]
    
    ComplexityCheck --> VANConsistency{"VAN Phase<br>Complete?"}
    VANConsistency -->|"Yes"| PassVAN["✅ VAN Phase<br>Validation Passed"]
    VANConsistency -->|"No"| FailVAN["❌ VAN Phase<br>Issues Found"]
    
    style VAN fill:#4da6ff,stroke:#0066cc,color:white
    style VANConsistency fill:#f6546a,stroke:#c30052,color:white
    style PassVAN fill:#10b981,stroke:#059669,color:white
    style FailVAN fill:#ff5555,stroke:#dd3333,color:white
```

### PLAN Phase Validation

```mermaid
graph TD
    PLAN["PLAN Phase<br>Validation"] --> PlanCheck["Check Planning<br>Documentation"]
    PlanCheck --> TaskBreakdown["Verify Task<br>Breakdown"]
    TaskBreakdown --> ScopeCheck["Validate Scope<br>Definition"]
    
    ScopeCheck --> PLANConsistency{"PLAN Phase<br>Complete?"}
    PLANConsistency -->|"Yes"| PassPLAN["✅ PLAN Phase<br>Validation Passed"]
    PLANConsistency -->|"No"| FailPLAN["❌ PLAN Phase<br>Issues Found"]
    
    style PLAN fill:#4da6ff,stroke:#0066cc,color:white
    style PLANConsistency fill:#f6546a,stroke:#c30052,color:white
    style PassPLAN fill:#10b981,stroke:#059669,color:white
    style FailPLAN fill:#ff5555,stroke:#dd3333,color:white
```

### CREATIVE Phase Validation

```mermaid
graph TD
    CREATIVE["CREATIVE Phase<br>Validation"] --> DesignCheck["Check Design<br>Documents"]
    DesignCheck --> ArchCheck["Verify Architectural<br>Decisions"]
    ArchCheck --> PatternCheck["Validate Design<br>Patterns"]
    
    PatternCheck --> CREATIVEConsistency{"CREATIVE Phase<br>Complete?"}
    CREATIVEConsistency -->|"Yes"| PassCREATIVE["✅ CREATIVE Phase<br>Validation Passed"]
    CREATIVEConsistency -->|"No"| FailCREATIVE["❌ CREATIVE Phase<br>Issues Found"]
    
    style CREATIVE fill:#4da6ff,stroke:#0066cc,color:white
    style CREATIVEConsistency fill:#f6546a,stroke:#c30052,color:white
    style PassCREATIVE fill:#10b981,stroke:#059669,color:white
    style FailCREATIVE fill:#ff5555,stroke:#dd3333,color:white
```

### IMPLEMENT Phase Technical Validation

This retains the original QA validation from the previous version:

```mermaid
graph TD
    IMPLEMENT["IMPLEMENT Phase<br>Validation"] --> ReadDesign["Read Design Decisions"]
    ReadDesign --> FourChecks["Four-Point Technical<br>Validation"]
    
    FourChecks --> DepCheck["1️⃣ Dependency<br>Verification"]
    DepCheck --> ConfigCheck["2️⃣ Configuration<br>Validation"]
    ConfigCheck --> EnvCheck["3️⃣ Environment<br>Validation"]
    EnvCheck --> MinBuildCheck["4️⃣ Minimal Build<br>Test"]
    
    MinBuildCheck --> IMPLEMENTConsistency{"Technical<br>Prerequisites Met?"}
    IMPLEMENTConsistency -->|"Yes"| PassIMPLEMENT["✅ IMPLEMENT Phase<br>Validation Passed"]
    IMPLEMENTConsistency -->|"No"| FailIMPLEMENT["❌ IMPLEMENT Phase<br>Issues Found"]
    
    style IMPLEMENT fill:#4da6ff,stroke:#0066cc,color:white
    style FourChecks fill:#f6546a,stroke:#c30052,color:white
    style IMPLEMENTConsistency fill:#f6546a,stroke:#c30052,color:white
    style PassIMPLEMENT fill:#10b981,stroke:#059669,color:white
    style FailIMPLEMENT fill:#ff5555,stroke:#dd3333,color:white
```

## 📋 UNIVERSAL VALIDATION COMMAND EXECUTION

### Memory Bank Verification Commands:

```bash
# Check Memory Bank file existence and recency
ls -la memory-bank/
find memory-bank/ -type f -mtime -7 | sort

# Check for consistency between files
grep -r "task" memory-bank/
grep -r "requirement" memory-bank/
```

### Task Tracking Verification Commands:

```bash
# Verify tasks.md as source of truth
test -f tasks.md && echo "✅ tasks.md exists" || echo "❌ tasks.md missing"

# Check references to tasks in other files
grep -r "Task" --include="*.md" .
grep -r "task" --include="*.md" . | grep -v "tasks.md" | wc -l

# Verify task status consistency
grep -i "completed\|done\|finished" tasks.md
grep -i "in progress\|started" tasks.md
```

### Reference Validation Commands:

```bash
# Find cross-references between files
grep -r "see\|refer\|reference" --include="*.md" .

# Check for broken references
for file in $(grep -l "see\|refer\|reference" --include="*.md" .); do
  for ref in $(grep -o '[a-zA-Z0-9_-]*\.md' $file); do
    test -f $ref || echo "❌ Broken reference: $ref in $file"
  done
done
```

## 📋 1️⃣ DEPENDENCY VERIFICATION PROCESS (Original)

This validation point ensures all required packages are correctly installed.

### Command Execution:

```bash
# Check if packages are installed
npm list react react-dom tailwindcss postcss autoprefixer

# Verify package versions match requirements
npm list | grep -E "react|tailwind|postcss"

# Check for peer dependency warnings
npm ls --depth=0
```

### Validation Criteria:
- All required packages must be installed
- Versions must be compatible with requirements
- No critical peer dependency warnings
- Required dev dependencies must be present

### Common Fixes:
- `npm install [missing-package]` - Install missing packages
- `npm install [package]@[version]` - Fix version mismatches
- `npm install --save-dev [dev-dependency]` - Add development dependencies

## 📝 2️⃣ CONFIGURATION VALIDATION PROCESS (Original)

This validation point ensures configuration files are in the correct format for the project.

### Command Execution:

```bash
# Check package.json for module type
grep "\"type\":" package.json

# Verify configuration file extensions match module type
find . -name "*.config.*" | grep -E "\.(js|cjs|mjs)$"

# Test configuration syntax
node -c *.config.js || node -c *.config.cjs || node -c *.config.mjs
```

### Validation Criteria:
- Configuration file extensions must match module type in package.json
- File syntax must be valid
- Configuration must reference installed packages

### Common Fixes:
- Rename `.js` to `.cjs` for CommonJS in ES module projects
- Fix syntax errors in configuration files
- Adjust configuration to reference installed packages

## 🌐 3️⃣ ENVIRONMENT VALIDATION PROCESS (Original)

This validation point ensures the development environment is correctly set up.

### Command Execution:

```bash
# Check build tools 
npm run --help

# Verify node version compatibility
node -v

# Check for environment variables
printenv | grep -E "NODE_|PATH|HOME"

# Verify access permissions
ls -la .
```

### Validation Criteria:
- Node.js version must be compatible with requirements
- Build commands must be defined in package.json
- Environment must have necessary access permissions
- Required environment variables must be set

### Common Fixes:
- Update Node.js version
- Add missing scripts to package.json
- Fix file permissions with chmod/icacls
- Set required environment variables

## 🔥 4️⃣ MINIMAL BUILD TEST PROCESS (Original)

This validation point tests a minimal build to ensure basic functionality works.

### Command Execution:

```bash
# Run a minimal build
npm run build -- --dry-run || npm run dev -- --dry-run

# Test entry point file existence
find src -name "main.*" -o -name "index.*"

# Validate HTML entry point
grep -i "script.*src=" index.html
```

### Validation Criteria:
- Build process must complete without errors
- Entry point files must exist and be correctly referenced
- HTML must reference the correct JavaScript entry point
- Basic rendering must work in a test environment

### Common Fixes:
- Fix entry point references in HTML
- Correct import paths in JavaScript
- Fix build configuration errors
- Update incorrect paths or references

## 📊 ENHANCED COMPREHENSIVE QA REPORT FORMAT

```
╔═════════════════════════ 🔍 ENHANCED QA VALIDATION REPORT ═════════════════════╗
│                                                                               │
│ Project: [Project Name]               Date: [Current Date]                    │
│ Platform: [OS Platform]               Detected Phase: [Current Phase]         │
│                                                                               │
│ ━━━━━━━━━━━━━━━━━━━━━━━━ UNIVERSAL VALIDATION RESULTS ━━━━━━━━━━━━━━━━━━━━━━━ │
│                                                                               │
│ 1️⃣ MEMORY BANK VERIFICATION                                                   │
│    ✓ Core Files: [Status]                                                     │
│    ✓ Content Consistency: [Status]                                            │
│    ✓ Last Modified: [Status]                                                  │
│                                                                               │
│ 2️⃣ TASK TRACKING VERIFICATION                                                 │
│    ✓ tasks.md Status: [Status]                                                │
│    ✓ Task References: [Status]                                                │
│    ✓ Status Consistency: [Status]                                             │
│                                                                               │
│ 3️⃣ REFERENCE VALIDATION                                                       │
│    ✓ Cross-References: [Status]                                               │
│    ✓ Reference Accuracy: [Status]                                             │
│                                                                               │
│ ━━━━━━━━━━━━━━━━━━━━━━━ PHASE-SPECIFIC VALIDATION ━━━━━━━━━━━━━━━━━━━━━━━━━━━ │
│                                                                               │
│ [VAN/PLAN/CREATIVE/IMPLEMENT] PHASE VALIDATION                                │
│    ✓ [Phase-specific check 1]: [Status]                                       │
│    ✓ [Phase-specific check 2]: [Status]                                       │
│    ✓ [Phase-specific check 3]: [Status]                                       │
│                                                                               │
│ [Technical validation section shown only for IMPLEMENT phase]                  │
│                                                                               │
│ ━━━━━━━━━━━━━━━━━━━━━━━━━━━ OVERALL STATUS ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ │
│                                                                               │
│ ✅ VALIDATION PASSED - Project quality verified for current phase              │
│                                                                               │
╚═══════════════════════════════════════════════════════════════════════════════╝
```

## 🚫 ENHANCED FAILURE REPORT FORMAT

If validation fails, a detailed failure report is generated:

```
╔═════════════════════════ ⚠️ QA VALIDATION FAILURES ═════════════════════════════╗
│                                                                                 │
│ Project: [Project Name]               Date: [Current Date]                      │
│ Platform: [OS Platform]               Detected Phase: [Current Phase]           │
│                                                                                 │
│ ━━━━━━━━━━━━━━━━━━━━━━━━━━ FAILED CHECKS ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ │
│                                                                                 │
│ ❌ MEMORY BANK ISSUES                                                           │
│    • [Specific issue details]                                                   │
│    • [Specific issue details]                                                   │
│                                                                                 │
│ ❌ TASK TRACKING ISSUES                                                         │
│    • [Specific issue details]                                                   │
│    • [Specific issue details]                                                   │
│                                                                                 │
│ ❌ REFERENCE ISSUES                                                             │
│    • [Specific issue details]                                                   │
│    • [Specific issue details]                                                   │
│                                                                                 │
│ ❌ [PHASE]-SPECIFIC ISSUES                                                      │
│    • [Specific issue details]                                                   │
│    • [Specific issue details]                                                   │
│                                                                                 │
│ ━━━━━━━━━━━━━━━━━━━━━━━━━━━ REQUIRED FIXES ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ │
│                                                                                 │
│ 1. [Specific fix instruction with command]                                      │
│ 2. [Specific fix instruction with command]                                      │
│ 3. [Specific fix instruction with command]                                      │
│                                                                                 │
│ ⚠️ VALIDATION FAILED - Please resolve issues before proceeding                  │
│                                                                                 │
╚═════════════════════════════════════════════════════════════════════════════════╝
```

## 🔄 QA-ANYTIME ACTIVATION PROTOCOL

The enhanced QA mode can be activated at any time in the development process:

```mermaid
graph TD
    Start["User Types: QA"] --> DetectContext["Detect Current Context"]
    DetectContext --> RunQA["Run QA with Context-Aware Checks"]
    RunQA --> GenerateReport["Generate Appropriate QA Report"]
    GenerateReport --> UserResponse["Present Report to User"]
    
    UserResponse --> FixNeeded{"Fixes<br>Needed?"}
    FixNeeded -->|"Yes"| SuggestFixes["Display Fix Instructions"]
    FixNeeded -->|"No"| ContinueWork["Continue Current Phase Work"]
    
    style Start fill:#4da6ff,stroke:#0066cc,color:white
    style FixNeeded fill:#f6546a,stroke:#c30052,color:white
    style SuggestFixes fill:#ff5555,stroke:#dd3333,color:white
    style ContinueWork fill:#10b981,stroke:#059669,color:white
```

This enhanced QA mode serves as a "quality guardian" throughout the development process, ensuring documentation is consistently maintained and all phase requirements are met before proceeding to the next phase.

================
File: .cursor/rules/isolation_rules/visual-maps/reflect-mode-map.mdc
================
---
description: Visual process map for REFLECT mode (Task Reflection)
globs: "**/reflect*/**", "**/review*/**", "**/retrospect*/**"
alwaysApply: false
---

# REFLECT MODE: TASK REVIEW PROCESS MAP

> **TL;DR:** This visual map guides the REFLECT mode process, focusing on structured review of the implementation, documenting lessons learned, and preparing insights for future reference.

## 🧭 REFLECT MODE PROCESS FLOW

```mermaid
graph TD
    Start["START REFLECT MODE"] --> ReadTasks["Read tasks.md<br>and progress.md"]
    
    %% Initial Assessment
    ReadTasks --> VerifyImplement{"Implementation<br>Complete?"}
    VerifyImplement -->|"No"| ReturnImplement["Return to<br>IMPLEMENT Mode"]
    VerifyImplement -->|"Yes"| AssessLevel{"Determine<br>Complexity Level"}
    
    %% Level-Based Reflection
    AssessLevel -->|"Level 1"| L1Reflect["LEVEL 1 REFLECTION<br>Level1/reflection-basic.md"]
    AssessLevel -->|"Level 2"| L2Reflect["LEVEL 2 REFLECTION<br>Level2/reflection-standard.md"]
    AssessLevel -->|"Level 3"| L3Reflect["LEVEL 3 REFLECTION<br>Level3/reflection-comprehensive.md"]
    AssessLevel -->|"Level 4"| L4Reflect["LEVEL 4 REFLECTION<br>Level4/reflection-advanced.md"]
    
    %% Level 1 Reflection (Quick)
    L1Reflect --> L1Review["Review<br>Bug Fix"]
    L1Review --> L1Document["Document<br>Solution"]
    L1Document --> L1Update["Update<br>tasks.md"]
    
    %% Level 2 Reflection (Standard)
    L2Reflect --> L2Review["Review<br>Enhancement"]
    L2Review --> L2WWW["Document<br>What Went Well"]
    L2WWW --> L2Challenges["Document<br>Challenges"]
    L2Challenges --> L2Lessons["Document<br>Lessons Learned"]
    L2Lessons --> L2Update["Update<br>tasks.md"]
    
    %% Level 3-4 Reflection (Comprehensive)
    L3Reflect & L4Reflect --> L34Review["Review Implementation<br>& Creative Phases"]
    L34Review --> L34Plan["Compare Against<br>Original Plan"]
    L34Plan --> L34WWW["Document<br>What Went Well"]
    L34WWW --> L34Challenges["Document<br>Challenges"]
    L34Challenges --> L34Lessons["Document<br>Lessons Learned"]
    L34Lessons --> L34ImproveProcess["Document Process<br>Improvements"]
    L34ImproveProcess --> L34Update["Update<br>tasks.md"]
    
    %% Completion & Transition
    L1Update & L2Update & L34Update --> CreateReflection["Create<br>reflection.md"]
    CreateReflection --> UpdateSystem["Update System<br>Documentation"]
    UpdateSystem --> Transition["NEXT MODE:<br>ARCHIVE MODE"]
```

## 📋 REFLECTION STRUCTURE

The reflection should follow this structured format:

```mermaid
graph TD
    subgraph "Reflection Document Structure"
        Header["# TASK REFLECTION: [Task Name]"]
        Summary["## SUMMARY<br>Brief summary of completed task"]
        WWW["## WHAT WENT WELL<br>Successful aspects of implementation"]
        Challenges["## CHALLENGES<br>Difficulties encountered during implementation"]
        Lessons["## LESSONS LEARNED<br>Key insights gained from the experience"]
        ProcessImp["## PROCESS IMPROVEMENTS<br>How to improve for future tasks"]
        TechImp["## TECHNICAL IMPROVEMENTS<br>Better approaches for similar tasks"]
        NextSteps["## NEXT STEPS<br>Follow-up actions or future work"]
    end
    
    Header --> Summary --> WWW --> Challenges --> Lessons --> ProcessImp --> TechImp --> NextSteps
```

## 📊 REQUIRED FILE STATE VERIFICATION

Before reflection can begin, verify file state:

```mermaid
graph TD
    Start["File State<br>Verification"] --> CheckTasks{"tasks.md has<br>implementation<br>complete?"}
    
    CheckTasks -->|"No"| ErrorImplement["ERROR:<br>Return to IMPLEMENT Mode"]
    CheckTasks -->|"Yes"| CheckProgress{"progress.md<br>has implementation<br>details?"}
    
    CheckProgress -->|"No"| ErrorProgress["ERROR:<br>Update progress.md first"]
    CheckProgress -->|"Yes"| ReadyReflect["Ready for<br>Reflection"]
```

## 🔍 IMPLEMENTATION REVIEW APPROACH

```mermaid
graph TD
    subgraph "Implementation Review"
        Original["Review Original<br>Requirements"]
        Plan["Compare Against<br>Implementation Plan"]
        Actual["Assess Actual<br>Implementation"]
        Creative["Review Creative<br>Phase Decisions"]
        Changes["Identify Deviations<br>from Plan"]
        Results["Evaluate<br>Results"]
    end
    
    Original --> Plan --> Actual
    Plan --> Creative --> Changes
    Actual --> Results
    Changes --> Results
```

## 📝 REFLECTION DOCUMENT TEMPLATES

### Level 1 (Basic) Reflection
```
# Bug Fix Reflection: [Bug Name]

## Summary
[Brief description of the bug and solution]

## Implementation
[Description of the fix implemented]

## Testing
[Description of testing performed]

## Additional Notes
[Any other relevant information]
```

### Levels 2-4 (Comprehensive) Reflection
```
# Task Reflection: [Task Name]

## Summary
[Brief summary of the task and what was achieved]

## What Went Well
- [Success point 1]
- [Success point 2]
- [Success point 3]

## Challenges
- [Challenge 1]: [How it was addressed]
- [Challenge 2]: [How it was addressed]
- [Challenge 3]: [How it was addressed]

## Lessons Learned
- [Lesson 1]
- [Lesson 2]
- [Lesson 3]

## Process Improvements
- [Process improvement 1]
- [Process improvement 2]

## Technical Improvements
- [Technical improvement 1]
- [Technical improvement 2]

## Next Steps
- [Follow-up task 1]
- [Follow-up task 2]
```

## 📊 REFLECTION QUALITY METRICS

```mermaid
graph TD
    subgraph "Reflection Quality Metrics"
        Specific["Specific<br>Not general or vague"]
        Actionable["Actionable<br>Provides clear direction"]
        Honest["Honest<br>Acknowledges successes and failures"]
        Forward["Forward-Looking<br>Focuses on future improvement"]
        Evidence["Evidence-Based<br>Based on concrete examples"]
    end
```

## 📋 TASKS.MD UPDATE FORMAT

During reflection, update tasks.md with:

```
## Status
- [x] Initialization complete
- [x] Planning complete
[For Level 3-4:]
- [x] Creative phases complete
- [x] Implementation complete
- [x] Reflection complete
- [ ] Archiving

## Reflection Highlights
- **What Went Well**: [Key successes]
- **Challenges**: [Key challenges]
- **Lessons Learned**: [Key lessons]
- **Next Steps**: [Follow-up actions]
```

## 📊 REFLECTION VERIFICATION CHECKLIST

```
✓ REFLECTION VERIFICATION
- Implementation thoroughly reviewed? [YES/NO]
- What Went Well section completed? [YES/NO]
- Challenges section completed? [YES/NO]
- Lessons Learned section completed? [YES/NO]
- Process Improvements identified? [YES/NO]
- Technical Improvements identified? [YES/NO]
- Next Steps documented? [YES/NO]
- reflection.md created? [YES/NO]
- tasks.md updated with reflection status? [YES/NO]

→ If all YES: Reflection complete - ready for ARCHIVE mode
→ If any NO: Complete missing reflection elements
```

## 🔄 MODE TRANSITION NOTIFICATION

When reflection is complete, notify user with:

```
## REFLECTION COMPLETE

✅ Implementation thoroughly reviewed
✅ Reflection document created
✅ Lessons learned documented
✅ Process improvements identified
✅ tasks.md updated with reflection status

→ NEXT RECOMMENDED MODE: ARCHIVE MODE
```

================
File: .cursor/rules/isolation_rules/visual-maps/van_mode_split/van-complexity-determination.mdc
================
---
description: Visual process map for VAN mode complexity determination
globs: van-complexity-determination.mdc
alwaysApply: false
---
# VAN MODE: COMPLEXITY DETERMINATION

> **TL;DR:** This component determines the appropriate complexity level (1-4) for the current task and directs the workflow accordingly.

## 🔍 COMPLEXITY DECISION TREE

```mermaid
graph TD
    Start["New Task"] --> Q1{"Bug fix or<br>error correction?"}
    Q1 -->|Yes| Q1a{"Affects single<br>component?"}
    Q1a -->|Yes| L1["Level 1:<br>Quick Bug Fix"]
    Q1a -->|No| Q1b{"Affects multiple<br>components?"}
    Q1b -->|Yes| L2["Level 2:<br>Simple Enhancement"]
    Q1b -->|No| Q1c{"Affects system<br>architecture?"}
    Q1c -->|Yes| L3["Level 3:<br>Intermediate Feature"]
    Q1c -->|No| L2
    
    Q1 -->|No| Q2{"Adding small<br>feature or<br>enhancement?"}
    Q2 -->|Yes| Q2a{"Self-contained<br>change?"}
    Q2a -->|Yes| L2
    Q2a -->|No| Q2b{"Affects multiple<br>components?"}
    Q2b -->|Yes| L3
    Q2b -->|No| L2
    
    Q2 -->|No| Q3{"Complete feature<br>requiring multiple<br>components?"}
    Q3 -->|Yes| Q3a{"Architectural<br>implications?"}
    Q3a -->|Yes| L4["Level 4:<br>Complex System"]
    Q3a -->|No| L3
    
    Q3 -->|No| Q4{"System-wide or<br>architectural<br>change?"}
    Q4 -->|Yes| L4
    Q4 -->|No| L3

    style Start fill:#4da6ff,stroke:#0066cc,color:white
    style L1 fill:#10b981,stroke:#059669,color:white
    style L2 fill:#f6546a,stroke:#c30052,color:white
    style L3 fill:#f6546a,stroke:#c30052,color:white
    style L4 fill:#f6546a,stroke:#c30052,color:white
```

## 📋 LEVEL INDICATORS

### Level 1: Quick Bug Fix
- **Keywords**: fix, bug, error, crash, issue
- **Scope**: Single component
- **Time**: Minutes to hours
- **Risk**: Low, isolated
- **Example**: Button not working, styling issue

### Level 2: Simple Enhancement
- **Keywords**: add, improve, update, enhance
- **Scope**: Single component/subsystem
- **Time**: Hours to 1-2 days
- **Risk**: Moderate, contained
- **Example**: Add form field, improve validation

### Level 3: Intermediate Feature
- **Keywords**: implement, create, develop
- **Scope**: Multiple components
- **Time**: Days to 1-2 weeks
- **Risk**: Significant
- **Example**: User authentication, dashboard

### Level 4: Complex System
- **Keywords**: system, architecture, redesign
- **Scope**: Multiple subsystems
- **Time**: Weeks to months
- **Risk**: High, architectural
- **Example**: Payment system, microservices

## 📋 COMPLEXITY CHECKLIST

```
✓ COMPLEXITY DETERMINATION
- Task type identified? [YES/NO]
- Scope assessed? [YES/NO]
- Time estimated? [YES/NO]
- Risk evaluated? [YES/NO]
- Dependencies mapped? [YES/NO]

→ If all YES: Proceed with level-specific workflow
→ If any NO: Complete assessment
```

## 🔄 LEVEL TRANSITION TRIGGERS

```mermaid
graph TD
    Current["Current Level"] --> Higher["Level Up Triggers"]
    Current --> Lower["Level Down Triggers"]
    
    Higher --> H1["Multiple Components"]
    Higher --> H2["Design Decisions"]
    Higher --> H3["System Impact"]
    
    Lower --> L1["Isolated Change"]
    Lower --> L2["Simple Fix"]
    Lower --> L3["No Design Needed"]

    style Current fill:#4da6ff,stroke:#0066cc,color:white
    style Higher fill:#f6546a,stroke:#c30052,color:white
    style Lower fill:#10b981,stroke:#059669,color:white
```

## 📋 WORKFLOW LOADING

Based on determined level:
- Level 1: Continue in VAN mode
- Level 2-4: Transition to PLAN mode

**Next Step:** Load appropriate level-specific workflow

## 🚨 MODE TRANSITION TRIGGER (VAN to PLAN)

If complexity is determined to be Level 2, 3, or 4:

```
🚫 LEVEL [2-4] TASK DETECTED
Implementation in VAN mode is BLOCKED
This task REQUIRES PLAN mode
You MUST switch to PLAN mode for proper documentation and planning
Type 'PLAN' to switch to planning mode
```

## 📋 CHECKPOINT VERIFICATION TEMPLATE (Example)

```
✓ SECTION CHECKPOINT: COMPLEXITY DETERMINATION
- Task Analyzed? [YES/NO]
- Complexity Level Determined? [YES/NO]

→ If Level 1: Proceed to VAN Mode Completion.
→ If Level 2-4: Trigger PLAN Mode transition.
```

**Next Step (Level 1):** Complete VAN Initialization (e.g., initialize Memory Bank if needed).
**Next Step (Level 2-4):** Exit VAN mode and initiate PLAN mode.

================
File: .cursor/rules/isolation_rules/visual-maps/van_mode_split/van-file-verification.mdc
================
---
description: Visual process map for VAN mode file verification
globs: van-file-verification.mdc
alwaysApply: false
---
# OPTIMIZED FILE VERIFICATION SYSTEM

🚨 CRITICAL: MEMORY BANK VERIFICATION REQUIRED 🚨
Memory Bank structure MUST exist before any file operations
This check MUST be executed first in all verification processes

> **TL;DR:** This system provides a structured approach to verify file structure integrity before task implementation, with emphasis on efficient checks and clear status reporting.

## 🔍 FILE VERIFICATION WORKFLOW

```mermaid
graph TD
    %% Critical Memory Bank verification - MUST be first
    Start["Start File Verification"] --> MemBankCheck{"Memory Bank<br>Exists?"}
    MemBankCheck -->|"No"| CreateMemBank["CREATE MEMORY BANK<br>[CRITICAL]"]
    MemBankCheck -->|"Yes"| VerifyMemBankComplete["Verify Memory Bank<br>Structure Complete"]
    CreateMemBank --> VerifyMemBankComplete
    
    VerifyMemBankComplete --> PassCheck{"All Critical<br>Checks Pass?"}
    PassCheck -->|"No"| AbortAll["⛔ ABORT ALL OPERATIONS<br>Fix Memory Bank First"]
    PassCheck -->|"Yes"| MainVerification

    %% Regular verification flow continues here
    MainVerification["Start Full<br>File Verification"] --> BatchVerify["Batch Verification<br>Using Patterns"]
    BatchVerify --> BrokenLinks["Check for<br>Broken References"]
    BrokenLinks --> DirectoryStructure["Verify Directory<br>Structure"]
    DirectoryStructure --> Status{"All Verifications<br>Successful?"}
    
    Status -->|"Yes"| Complete["Verification<br>Complete ✓"]
    Status -->|"No"| Diagnose["Diagnose<br>Issues"]
    Diagnose --> Attempt{"Attempt Auto<br>Resolution?"}
    
    Attempt -->|"Yes"| AutoFix["Auto-Fix<br>Issues"]
    Attempt -->|"No"| ReportIssue["Report Issues to<br>User"]
    
    AutoFix --> Recheck{"Issues<br>Resolved?"}
    Recheck -->|"Yes"| ReportSuccess["Report Success<br>to User"]
    Recheck -->|"No"| ReportIssue
    
    ReportSuccess --> Complete
    ReportIssue --> UserAction["Wait for<br>User Action"]
    UserAction --> ReVerify["Re-Verify<br>After User Action"]
    ReVerify --> Status
    
    style MemBankCheck fill:#ff0000,stroke:#990000,color:white,stroke-width:3px
    style CreateMemBank fill:#ff0000,stroke:#990000,color:white,stroke-width:3px
    style VerifyMemBankComplete fill:#ff0000,stroke:#990000,color:white,stroke-width:3px
    style PassCheck fill:#ff0000,stroke:#990000,color:white,stroke-width:3px
    style AbortAll fill:#ff0000,stroke:#990000,color:white,stroke-width:3px
    style Status fill:#f6546a,stroke:#c30052,color:white
    style Complete fill:#10b981,stroke:#059669,color:white
```

## 🧩 MEMORY BANK VERIFICATION - CRITICAL COMPONENT

Memory Bank verification MUST be executed first in any file verification process:

```javascript
function verifyMemoryBank() {
  // Check if Memory Bank exists
  const memoryBankExists = checkDirectoryExists("memory-bank");
  if (!memoryBankExists) {
    console.error("⛔ CRITICAL ERROR: Memory Bank does not exist");
    createMemoryBankStructure();
    return verifyMemoryBankCreation();
  }
  
  // Check required subdirectories
  const requiredDirs = [
    "memory-bank/active-context",
    "memory-bank/system-patterns",
    "memory-bank/creative-phase",
    "memory-bank/implementation"
  ];
  
  const missingDirs = requiredDirs.filter(dir => !checkDirectoryExists(dir));
  if (missingDirs.length > 0) {
    console.error(`⛔ CRITICAL ERROR: Missing Memory Bank directories: ${missingDirs.join(", ")}`);
    createMissingDirectories(missingDirs);
    return verifyMemoryBankCreation();
  }
  
  // Check critical files
  const criticalFiles = [
    "memory-bank/active-context/activeContext.md",
    "memory-bank/system-patterns/systemPatterns.md"
  ];
  
  const missingFiles = criticalFiles.filter(file => !checkFileExists(file));
  if (missingFiles.length > 0) {
    console.error(`⛔ CRITICAL ERROR: Missing critical files: ${missingFiles.join(", ")}`);
    createMissingFiles(missingFiles);
    return verifyMemoryBankCreation();
  }
  
  return true; // Memory Bank verification successful
}

// MANDATORY: This must be called before any other verification
const memoryBankVerified = verifyMemoryBank();
if (!memoryBankVerified) {
  throw new Error("⛔ MEMORY BANK VERIFICATION FAILED - CANNOT PROCEED");
}
```

## 📋 MEMORY BANK VERIFICATION CHECKLIST

```
✓ MEMORY BANK VERIFICATION CHECKLIST
- Memory Bank directory exists? [YES/NO]
- Required subdirectories exist? [YES/NO]
- Critical files exist? [YES/NO]
- File content is valid? [YES/NO]

→ If ALL YES: Memory Bank verification passed - Continue file verification
→ If ANY NO: STOP ALL PROCESSING and FIX MEMORY BANK
```

## 🔍 BATCH VERIFICATION WORKFLOW

## 📋 OPTIMIZED DIRECTORY CREATION

```mermaid
graph TD
    Start["Directory<br>Creation"] --> DetectOS["Detect Operating<br>System"]
    DetectOS -->|"Windows"| WinCmd["Batch Create<br>Windows Command"]
    DetectOS -->|"Mac/Linux"| UnixCmd["Batch Create<br>Unix Command"]
    WinCmd & UnixCmd --> Verify["Verify<br>Creation Success"]
    Verify --> Complete["Directory Setup<br>Complete"]
```

### Platform-Specific Commands

#### Windows (PowerShell)
```powershell
# Create all directories in one command
mkdir memory-bank, docs, docs\archive -ErrorAction SilentlyContinue

# Create all required files
$files = @(".cursorrules", "tasks.md", 
           "memory-bank\projectbrief.md", 
           "memory-bank\productContext.md",
           "memory-bank\systemPatterns.md",
           "memory-bank\techContext.md",
           "memory-bank\activeContext.md",
           "memory-bank\progress.md")

foreach ($file in $files) {
    if (-not (Test-Path $file)) {
        New-Item -Path $file -ItemType File -Force
    }
}
```

#### Mac/Linux (Bash)
```bash
# Create all directories in one command
mkdir -p memory-bank docs/archive

# Create all required files
touch .cursorrules tasks.md \
      memory-bank/projectbrief.md \
      memory-bank/productContext.md \
      memory-bank/systemPatterns.md \
      memory-bank/techContext.md \
      memory-bank/activeContext.md \
      memory-bank/progress.md
```

## 📝 STREAMLINED VERIFICATION PROCESS

Instead of checking each component separately, perform batch verification:

```powershell
# Windows - PowerShell
$requiredDirs = @("memory-bank", "docs", "docs\archive")
$requiredFiles = @(".cursorrules", "tasks.md")
$mbFiles = @("projectbrief.md", "productContext.md", "systemPatterns.md", 
             "techContext.md", "activeContext.md", "progress.md")

$missingDirs = $requiredDirs | Where-Object { -not (Test-Path $_) -or -not (Test-Path $_ -PathType Container) }
$missingFiles = $requiredFiles | Where-Object { -not (Test-Path $_) -or (Test-Path $_ -PathType Container) }
$missingMBFiles = $mbFiles | ForEach-Object { "memory-bank\$_" } | 
                  Where-Object { -not (Test-Path $_) -or (Test-Path $_ -PathType Container) }

if ($missingDirs.Count -eq 0 -and $missingFiles.Count -eq 0 -and $missingMBFiles.Count -eq 0) {
    Write-Output "✓ All required components verified"
} else {
    # Create all missing items at once
    if ($missingDirs.Count -gt 0) {
        $missingDirs | ForEach-Object { mkdir $_ -Force }
    }
    if ($missingFiles.Count -gt 0 -or $missingMBFiles.Count -gt 0) {
        $allMissingFiles = $missingFiles + $missingMBFiles
        $allMissingFiles | ForEach-Object { New-Item -Path $_ -ItemType File -Force }
    }
}
```

## 📝 TEMPLATE INITIALIZATION

Optimize template creation with a single script:

```powershell
# Windows - PowerShell
$templates = @{
    "tasks.md" = @"
# Memory Bank: Tasks

## Current Task
[Task not yet defined]

## Status
- [ ] Task definition
- [ ] Implementation plan
- [ ] Execution
- [ ] Documentation

## Requirements
[No requirements defined yet]
"@

    "memory-bank\activeContext.md" = @"
# Memory Bank: Active Context

## Current Focus
[No active focus defined]

## Status
[No status defined]

## Latest Changes
[No changes recorded]
"@

    # Add other templates here
}

foreach ($file in $templates.Keys) {
    if (Test-Path $file) {
        Set-Content -Path $file -Value $templates[$file]
    }
}
```

## 🔍 PERFORMANCE OPTIMIZATION BEST PRACTICES

1. **Batch Operations**: Always use batch operations instead of individual commands
   ```
   # GOOD: Create all directories at once
   mkdir memory-bank docs docs\archive
   
   # BAD: Create directories one at a time
   mkdir memory-bank
   mkdir docs
   mkdir docs\archive
   ```

2. **Pre-Check Optimization**: Check all requirements first, then create only what's missing
   ```
   # First check what's missing
   $missingItems = ...
   
   # Then create only what's missing
   if ($missingItems) { ... }
   ```

3. **Error Handling**: Include error handling in all commands
   ```
   mkdir memory-bank, docs, docs\archive -ErrorAction SilentlyContinue
   ```

4. **Platform Adaptation**: Auto-detect platform and use appropriate commands
   ```
   if ($IsWindows) {
       # Windows commands
   } else {
       # Unix commands
   }
   ```

5. **One-Pass Verification**: Verify directory structure in a single pass
   ```
   $requiredPaths = @("memory-bank", "docs", "docs\archive", ".cursorrules", "tasks.md")
   $missingPaths = $requiredPaths | Where-Object { -not (Test-Path $_) }
   ```

## 📝 VERIFICATION REPORT FORMAT

```
✅ VERIFICATION COMPLETE
- Created directories: [list]
- Created files: [list]
- All components verified

Memory Bank system ready for use.
```

================
File: .cursor/rules/isolation_rules/visual-maps/van_mode_split/van-mode-map.mdc
================
---
description: Visual process map for VAN mode (Index/Entry Point)
globs: van-mode-map.mdc
alwaysApply: false
---
# VAN MODE: INITIALIZATION PROCESS MAP

🚨 MANDATORY FIRST STEP: MEMORY BANK CREATION 🚨
NO OPERATION CAN PROCEED WITHOUT MEMORY BANK STRUCTURE

> **TL;DR:** This visual map defines the VAN mode process for project initialization, task analysis, and technical validation. It guides users through platform detection, file verification, complexity determination, and technical validation to ensure proper setup before implementation.

## 🧭 VAN MODE PROCESS FLOW

```mermaid
graph TD
    Start["START VAN MODE"] --> PlatformDetect["PLATFORM DETECTION"]
    PlatformDetect --> DetectOS["Detect Operating System"]
    DetectOS --> CheckPath["Check Path Separator Format"]
    CheckPath --> AdaptCmds["Adapt Commands if Needed"]
    AdaptCmds --> PlatformCP["⛔ PLATFORM CHECKPOINT"]
    
    %% Add Critical Memory Bank Checkpoint
    PlatformCP --> MemoryBankCheck{"Memory Bank<br>Exists?"}
    MemoryBankCheck -->|"No"| CreateMemoryBank["CREATE MEMORY BANK<br>[CRITICAL STEP]"]
    MemoryBankCheck -->|"Yes"| BasicFileVerify["BASIC FILE VERIFICATION"]
    CreateMemoryBank --> MemoryBankCP["⛔ MEMORY BANK VERIFICATION [REQUIRED]"]
    MemoryBankCP --> BasicFileVerify
    
    %% Basic File Verification with checkpoint
    BasicFileVerify --> BatchCheck["Batch Check Essential Components"]
    BatchCheck --> BatchCreate["Batch Create Essential Structure"]
    BatchCreate --> BasicFileCP["⛔ BASIC FILE CHECKPOINT"]
    
    %% Early Complexity Determination
    BasicFileCP --> EarlyComplexity["EARLY COMPLEXITY DETERMINATION"]
    EarlyComplexity --> AnalyzeTask["Analyze Task Requirements"]
    AnalyzeTask --> EarlyLevelCheck{"Complexity Level?"}
    
    %% Level handling paths
    EarlyLevelCheck -->|"Level 1"| ComplexityCP["⛔ COMPLEXITY CHECKPOINT"]
    EarlyLevelCheck -->|"Level 2-4"| CRITICALGATE["🚫 CRITICAL GATE: FORCE MODE SWITCH"]
    CRITICALGATE --> ForceExit["Exit to PLAN mode"]
    
    %% Level 1 continues normally
    ComplexityCP --> InitSystem["INITIALIZE MEMORY BANK"]
    InitSystem --> Complete1["LEVEL 1 INITIALIZATION COMPLETE"]
    
    %% For Level 2+ tasks after PLAN and CREATIVE modes
    ForceExit -.-> OtherModes["PLAN → CREATIVE modes"]
    OtherModes -.-> VANQA["VAN QA MODE"]
    VANQA --> QAProcess["Technical Validation Process"]
    QAProcess --> QACheck{"All Checks Pass?"}
    QACheck -->|"Yes"| BUILD["To BUILD MODE"]
    QACheck -->|"No"| FixIssues["Fix Technical Issues"]
    FixIssues --> QAProcess
    
    %% Style nodes
    style PlatformCP fill:#f55,stroke:#d44,color:white
    style MemoryBankCP fill:#ff0000,stroke:#990000,color:white,stroke-width:3px
    style MemoryBankCheck fill:#ff0000,stroke:#990000,color:white,stroke-width:3px
    style CreateMemoryBank fill:#ff0000,stroke:#990000,color:white,stroke-width:3px
    style BasicFileCP fill:#f55,stroke:#d44,color:white
    style ComplexityCP fill:#f55,stroke:#d44,color:white
    style CRITICALGATE fill:#ff0000,stroke:#990000,color:white,stroke-width:3px
    style ForceExit fill:#ff0000,stroke:#990000,color:white,stroke-width:2px
    style VANQA fill:#4da6ff,stroke:#0066cc,color:white,stroke-width:3px
    style QAProcess fill:#4da6ff,stroke:#0066cc,color:white
    style QACheck fill:#4da6ff,stroke:#0066cc,color:white
    style FixIssues fill:#ff5555,stroke:#dd3333,color:white
```

## 🌐 PLATFORM DETECTION PROCESS

```mermaid
graph TD
    PD["Platform Detection"] --> CheckOS["Detect Operating System"]
    CheckOS --> Win["Windows"]
    CheckOS --> Mac["macOS"]
    CheckOS --> Lin["Linux"]
    
    Win & Mac & Lin --> Adapt["Adapt Commands<br>for Platform"]
    
    Win --> WinPath["Path: Backslash (\\)"]
    Mac --> MacPath["Path: Forward Slash (/)"]
    Lin --> LinPath["Path: Forward Slash (/)"]
    
    Win --> WinCmd["Command Adaptations:<br>dir, icacls, etc."]
    Mac --> MacCmd["Command Adaptations:<br>ls, chmod, etc."]
    Lin --> LinCmd["Command Adaptations:<br>ls, chmod, etc."]
    
    WinPath & MacPath & LinPath --> PathCP["Path Separator<br>Checkpoint"]
    WinCmd & MacCmd & LinCmd --> CmdCP["Command<br>Checkpoint"]
    
    PathCP & CmdCP --> PlatformComplete["Platform Detection<br>Complete"]
    
    style PD fill:#4da6ff,stroke:#0066cc,color:white
    style PlatformComplete fill:#10b981,stroke:#059669,color:white
```

## 📁 FILE VERIFICATION PROCESS

```mermaid
graph TD
    FV["File Verification"] --> CheckFiles["Check Essential Files"]
    CheckFiles --> CheckMB["Check Memory Bank<br>Structure"]
    CheckMB --> MBExists{"Memory Bank<br>Exists?"}
    
    MBExists -->|"Yes"| VerifyMB["Verify Memory Bank<br>Contents"]
    MBExists -->|"No"| CreateMB["Create Memory Bank<br>Structure"]
    
    CheckFiles --> CheckDocs["Check Documentation<br>Files"]
    CheckDocs --> DocsExist{"Docs<br>Exist?"}
    
    DocsExist -->|"Yes"| VerifyDocs["Verify Documentation<br>Structure"]
    DocsExist -->|"No"| CreateDocs["Create Documentation<br>Structure"]
    
    VerifyMB & CreateMB --> MBCP["Memory Bank<br>Checkpoint"]
    VerifyDocs & CreateDocs --> DocsCP["Documentation<br>Checkpoint"]
    
    MBCP & DocsCP --> FileComplete["File Verification<br>Complete"]
    
    style FV fill:#4da6ff,stroke:#0066cc,color:white
    style FileComplete fill:#10b981,stroke:#059669,color:white
    style MBCP fill:#f6546a,stroke:#c30052,color:white
    style DocsCP fill:#f6546a,stroke:#c30052,color:white
```

## 🧩 COMPLEXITY DETERMINATION PROCESS

```mermaid
graph TD
    CD["Complexity<br>Determination"] --> AnalyzeTask["Analyze Task<br>Requirements"]
    
    AnalyzeTask --> CheckKeywords["Check Task<br>Keywords"]
    CheckKeywords --> ScopeCheck["Assess<br>Scope Impact"]
    ScopeCheck --> RiskCheck["Evaluate<br>Risk Level"]
    RiskCheck --> EffortCheck["Estimate<br>Implementation Effort"]
    
    EffortCheck --> DetermineLevel{"Determine<br>Complexity Level"}
    DetermineLevel -->|"Level 1"| L1["Level 1:<br>Quick Bug Fix"]
    DetermineLevel -->|"Level 2"| L2["Level 2:<br>Simple Enhancement"]
    DetermineLevel -->|"Level 3"| L3["Level 3:<br>Intermediate Feature"]
    DetermineLevel -->|"Level 4"| L4["Level 4:<br>Complex System"]
    
    L1 --> CDComplete["Complexity Determination<br>Complete"]
    L2 & L3 & L4 --> ModeSwitch["Force Mode Switch<br>to PLAN"]
    
    style CD fill:#4da6ff,stroke:#0066cc,color:white
    style CDComplete fill:#10b981,stroke:#059669,color:white
    style ModeSwitch fill:#ff0000,stroke:#990000,color:white
    style DetermineLevel fill:#f6546a,stroke:#c30052,color:white
```

## 🔄 COMPLETE WORKFLOW WITH QA VALIDATION

The full workflow includes technical validation before implementation:

```mermaid
flowchart LR
    VAN1["VAN MODE 
    (Initial Analysis)"] --> PLAN["PLAN MODE
    (Task Planning)"]
    PLAN --> CREATIVE["CREATIVE MODE
    (Design Decisions)"]
    CREATIVE --> VANQA["VAN QA MODE
    (Technical Validation)"] 
    VANQA --> BUILD["BUILD MODE
    (Implementation)"]
```

## 🔍 TECHNICAL VALIDATION OVERVIEW

The VAN QA technical validation process consists of four key validation points:

```mermaid
graph TD
    VANQA["VAN QA MODE"] --> FourChecks["FOUR-POINT VALIDATION"]
    
    FourChecks --> DepCheck["1️⃣ DEPENDENCY VERIFICATION<br>Check all required packages"]
    DepCheck --> ConfigCheck["2️⃣ CONFIGURATION VALIDATION<br>Verify format & compatibility"]
    ConfigCheck --> EnvCheck["3️⃣ ENVIRONMENT VALIDATION<br>Check build environment"]
    EnvCheck --> MinBuildCheck["4️⃣ MINIMAL BUILD TEST<br>Test core functionality"]
    
    MinBuildCheck --> ValidationResults{"All Checks<br>Passed?"}
    ValidationResults -->|"Yes"| SuccessReport["GENERATE SUCCESS REPORT"]
    ValidationResults -->|"No"| FailureReport["GENERATE FAILURE REPORT"]
    
    SuccessReport --> BUILD["Proceed to BUILD MODE"]
    FailureReport --> FixIssues["Fix Technical Issues"]
    FixIssues --> ReValidate["Re-validate"]
    ReValidate --> ValidationResults
    
    style VANQA fill:#4da6ff,stroke:#0066cc,color:white
    style FourChecks fill:#f6546a,stroke:#c30052,color:white
    style ValidationResults fill:#f6546a,stroke:#c30052,color:white
    style BUILD fill:#10b981,stroke:#059669,color:white
    style FixIssues fill:#ff5555,stroke:#dd3333,color:white
```

## 📝 VALIDATION STATUS FORMAT

The QA Validation step includes clear status indicators:

```
╔═════════════════ 🔍 QA VALIDATION STATUS ═════════════════╗
│ ✓ Design Decisions   │ Verified as implementable          │
│ ✓ Dependencies       │ All required packages installed    │
│ ✓ Configurations     │ Format verified for platform       │
│ ✓ Environment        │ Suitable for implementation        │
╚════════════════════════════════════════════════════════════╝
✅ VERIFIED - Clear to proceed to BUILD mode
```

## 🚨 MODE TRANSITION TRIGGERS

### VAN to PLAN Transition
For complexity levels 2-4:
```
🚫 LEVEL [2-4] TASK DETECTED
Implementation in VAN mode is BLOCKED
This task REQUIRES PLAN mode
You MUST switch to PLAN mode for proper documentation and planning
Type 'PLAN' to switch to planning mode
```

### CREATIVE to VAN QA Transition
After completing the CREATIVE mode:
```
⏭️ NEXT MODE: VAN QA
To validate technical requirements before implementation, please type 'VAN QA'
```

### VAN QA to BUILD Transition
After successful validation:
```
✅ TECHNICAL VALIDATION COMPLETE
All prerequisites verified successfully
You may now proceed to BUILD mode
Type 'BUILD' to begin implementation
```

## 🔒 BUILD MODE PREVENTION MECHANISM

The system prevents moving to BUILD mode without passing QA validation:

```mermaid
graph TD
    Start["User Types: BUILD"] --> CheckQA{"QA Validation<br>Completed?"}
    CheckQA -->|"Yes and Passed"| AllowBuild["Allow BUILD Mode"]
    CheckQA -->|"No or Failed"| BlockBuild["BLOCK BUILD MODE"]
    BlockBuild --> Message["Display:<br>⚠️ QA VALIDATION REQUIRED"]
    Message --> ReturnToVANQA["Prompt: Type VAN QA"]
    
    style CheckQA fill:#f6546a,stroke:#c30052,color:white
    style BlockBuild fill:#ff0000,stroke:#990000,color:white,stroke-width:3px
    style Message fill:#ff5555,stroke:#dd3333,color:white
    style ReturnToVANQA fill:#4da6ff,stroke:#0066cc,color:white
```

## 🔄 QA COMMAND PRECEDENCE

QA validation can be called at any point in the process flow, and takes immediate precedence over any other current steps, including forced mode switches:

```mermaid
graph TD
    UserQA["User Types: QA"] --> HighPriority["⚠️ HIGH PRIORITY COMMAND"]
    HighPriority --> CurrentTask["Pause Current Task/Process"]
    CurrentTask --> LoadQA["Load QA Mode Map"]
    LoadQA --> RunQA["Execute QA Validation Process"]
    RunQA --> QAResults{"QA Results"}
    
    QAResults -->|"PASS"| ResumeFlow["Resume Prior Process Flow"]
    QAResults -->|"FAIL"| FixIssues["Fix Identified Issues"]
    FixIssues --> ReRunQA["Re-run QA Validation"]
    ReRunQA --> QAResults
    
    style UserQA fill:#f8d486,stroke:#e8b84d,color:black
    style HighPriority fill:#ff0000,stroke:#cc0000,color:white,stroke-width:3px
    style LoadQA fill:#4da6ff,stroke:#0066cc,color:white
    style RunQA fill:#4da6ff,stroke:#0066cc,color:white
    style QAResults fill:#f6546a,stroke:#c30052,color:white
```

### QA Interruption Rules

When a user types **QA** at any point:

1. **The QA command MUST take immediate precedence** over any current operation, including the "FORCE MODE SWITCH" triggered by complexity assessment.
2. The system MUST:
   - Immediately load the QA mode map
   - Execute the full QA validation process
   - Address any failures before continuing
3. **Required remediation steps take priority** over any pending mode switches or complexity rules
4. After QA validation is complete and passes:
   - Resume the previously determined process flow
   - Continue with any required mode switches

```
⚠️ QA OVERRIDE ACTIVATED
All other processes paused
QA validation checks now running...
Any issues found MUST be remediated before continuing with normal process flow
```

## 📋 CHECKPOINT VERIFICATION TEMPLATE

Each major checkpoint in VAN mode uses this format:

```
✓ SECTION CHECKPOINT: [SECTION NAME]
- Requirement 1? [YES/NO]
- Requirement 2? [YES/NO]
- Requirement 3? [YES/NO]

→ If all YES: Ready for next section
→ If any NO: Fix missing items before proceeding
```

## 🚀 VAN MODE ACTIVATION

When the user types "VAN", respond with a confirmation and start the process:

```
User: VAN

Response: OK VAN - Beginning Initialization Process
```

After completing CREATIVE mode, when the user types "VAN QA", respond:

```
User: VAN QA

Response: OK VAN QA - Beginning Technical Validation
```

This ensures clear communication about which phase of VAN mode is active. 

## 🔍 DETAILED QA VALIDATION PROCESS

### 1️⃣ DEPENDENCY VERIFICATION

This step verifies that all required packages are installed and compatible:

```mermaid
graph TD
    Start["Dependency Verification"] --> ReadDeps["Read Required Dependencies<br>from Creative Phase"]
    ReadDeps --> CheckInstalled["Check if Dependencies<br>are Installed"]
    CheckInstalled --> DepStatus{"All Dependencies<br>Installed?"}
    
    DepStatus -->|"Yes"| VerifyVersions["Verify Versions<br>and Compatibility"]
    DepStatus -->|"No"| InstallMissing["Install Missing<br>Dependencies"]
    InstallMissing --> VerifyVersions
    
    VerifyVersions --> VersionStatus{"Versions<br>Compatible?"}
    VersionStatus -->|"Yes"| DepSuccess["Dependencies Verified<br>✅ PASS"]
    VersionStatus -->|"No"| UpgradeVersions["Upgrade/Downgrade<br>as Needed"]
    UpgradeVersions --> RetryVerify["Retry Verification"]
    RetryVerify --> VersionStatus
    
    style Start fill:#4da6ff,stroke:#0066cc,color:white
    style DepSuccess fill:#10b981,stroke:#059669,color:white
    style DepStatus fill:#f6546a,stroke:#c30052,color:white
    style VersionStatus fill:#f6546a,stroke:#c30052,color:white
```

#### Windows (PowerShell) Implementation:
```powershell
# Example: Verify Node.js dependencies for a React project
function Verify-Dependencies {
    $requiredDeps = @{
        "node" = ">=14.0.0"
        "npm" = ">=6.0.0"
    }
    
    $missingDeps = @()
    $incompatibleDeps = @()
    
    # Check Node.js version
    $nodeVersion = $null
    try {
        $nodeVersion = node -v
        if ($nodeVersion -match "v(\d+)\.(\d+)\.(\d+)") {
            $major = [int]$Matches[1]
            if ($major -lt 14) {
                $incompatibleDeps += "node (found $nodeVersion, required >=14.0.0)"
            }
        }
    } catch {
        $missingDeps += "node"
    }
    
    # Check npm version
    $npmVersion = $null
    try {
        $npmVersion = npm -v
        if ($npmVersion -match "(\d+)\.(\d+)\.(\d+)") {
            $major = [int]$Matches[1]
            if ($major -lt 6) {
                $incompatibleDeps += "npm (found $npmVersion, required >=6.0.0)"
            }
        }
    } catch {
        $missingDeps += "npm"
    }
    
    # Display results
    if ($missingDeps.Count -eq 0 -and $incompatibleDeps.Count -eq 0) {
        Write-Output "✅ All dependencies verified and compatible"
        return $true
    } else {
        if ($missingDeps.Count -gt 0) {
            Write-Output "❌ Missing dependencies: $($missingDeps -join ', ')"
        }
        if ($incompatibleDeps.Count -gt 0) {
            Write-Output "❌ Incompatible versions: $($incompatibleDeps -join ', ')"
        }
        return $false
    }
}
```

#### Mac/Linux (Bash) Implementation:
```bash
#!/bin/bash

# Example: Verify Node.js dependencies for a React project
verify_dependencies() {
    local missing_deps=()
    local incompatible_deps=()
    
    # Check Node.js version
    if command -v node &> /dev/null; then
        local node_version=$(node -v)
        if [[ $node_version =~ v([0-9]+)\.([0-9]+)\.([0-9]+) ]]; then
            local major=${BASH_REMATCH[1]}
            if (( major < 14 )); then
                incompatible_deps+=("node (found $node_version, required >=14.0.0)")
            fi
        fi
    else
        missing_deps+=("node")
    fi
    
    # Check npm version
    if command -v npm &> /dev/null; then
        local npm_version=$(npm -v)
        if [[ $npm_version =~ ([0-9]+)\.([0-9]+)\.([0-9]+) ]]; then
            local major=${BASH_REMATCH[1]}
            if (( major < 6 )); then
                incompatible_deps+=("npm (found $npm_version, required >=6.0.0)")
            fi
        fi
    else
        missing_deps+=("npm")
    fi
    
    # Display results
    if [ ${#missing_deps[@]} -eq 0 ] && [ ${#incompatible_deps[@]} -eq 0 ]; then
        echo "✅ All dependencies verified and compatible"
        return 0
    else
        if [ ${#missing_deps[@]} -gt 0 ]; then
            echo "❌ Missing dependencies: ${missing_deps[*]}"
        fi
        if [ ${#incompatible_deps[@]} -gt 0 ]; then
            echo "❌ Incompatible versions: ${incompatible_deps[*]}"
        fi
        return 1
    fi
}
```

### 2️⃣ CONFIGURATION VALIDATION

This step validates configuration files format and compatibility:

```mermaid
graph TD
    Start["Configuration Validation"] --> IdentifyConfigs["Identify Configuration<br>Files"]
    IdentifyConfigs --> ReadConfigs["Read Configuration<br>Files"]
    ReadConfigs --> ValidateSyntax["Validate Syntax<br>and Format"]
    ValidateSyntax --> SyntaxStatus{"Syntax<br>Valid?"}
    
    SyntaxStatus -->|"Yes"| CheckCompatibility["Check Compatibility<br>with Platform"]
    SyntaxStatus -->|"No"| FixSyntax["Fix Syntax<br>Errors"]
    FixSyntax --> RetryValidate["Retry Validation"]
    RetryValidate --> SyntaxStatus
    
    CheckCompatibility --> CompatStatus{"Compatible with<br>Platform?"}
    CompatStatus -->|"Yes"| ConfigSuccess["Configurations Validated<br>✅ PASS"]
    CompatStatus -->|"No"| AdaptConfigs["Adapt Configurations<br>for Platform"]
    AdaptConfigs --> RetryCompat["Retry Compatibility<br>Check"]
    RetryCompat --> CompatStatus
    
    style Start fill:#4da6ff,stroke:#0066cc,color:white
    style ConfigSuccess fill:#10b981,stroke:#059669,color:white
    style SyntaxStatus fill:#f6546a,stroke:#c30052,color:white
    style CompatStatus fill:#f6546a,stroke:#c30052,color:white
``` 

#### Configuration Validation Implementation:
```powershell
# Example: Validate configuration files for a web project
function Validate-Configurations {
    $configFiles = @(
        "package.json",
        "tsconfig.json",
        "vite.config.js"
    )
    
    $invalidConfigs = @()
    $incompatibleConfigs = @()
    
    foreach ($configFile in $configFiles) {
        if (Test-Path $configFile) {
            # Check JSON syntax for JSON files
            if ($configFile -match "\.json$") {
                try {
                    Get-Content $configFile -Raw | ConvertFrom-Json | Out-Null
                } catch {
                    $invalidConfigs += "$configFile (JSON syntax error: $($_.Exception.Message))"
                    continue
                }
            }
            
            # Specific configuration compatibility checks
            if ($configFile -eq "vite.config.js") {
                $content = Get-Content $configFile -Raw
                # Check for React plugin in Vite config
                if ($content -notmatch "react\(\)") {
                    $incompatibleConfigs += "$configFile (Missing React plugin for React project)"
                }
            }
        } else {
            $invalidConfigs += "$configFile (file not found)"
        }
    }
    
    # Display results
    if ($invalidConfigs.Count -eq 0 -and $incompatibleConfigs.Count -eq 0) {
        Write-Output "✅ All configurations validated and compatible"
        return $true
    } else {
        if ($invalidConfigs.Count -gt 0) {
            Write-Output "❌ Invalid configurations: $($invalidConfigs -join ', ')"
        }
        if ($incompatibleConfigs.Count -gt 0) {
            Write-Output "❌ Incompatible configurations: $($incompatibleConfigs -join ', ')"
        }
        return $false
    }
}
```

### 3️⃣ ENVIRONMENT VALIDATION

This step checks if the environment is properly set up for the implementation:

```mermaid
graph TD
    Start["Environment Validation"] --> CheckEnv["Check Build Environment"]
    CheckEnv --> VerifyBuildTools["Verify Build Tools"]
    VerifyBuildTools --> ToolsStatus{"Build Tools<br>Available?"}
    
    ToolsStatus -->|"Yes"| CheckPerms["Check Permissions<br>and Access"]
    ToolsStatus -->|"No"| InstallTools["Install Required<br>Build Tools"]
    InstallTools --> RetryTools["Retry Verification"]
    RetryTools --> ToolsStatus
    
    CheckPerms --> PermsStatus{"Permissions<br>Sufficient?"}
    PermsStatus -->|"Yes"| EnvSuccess["Environment Validated<br>✅ PASS"]
    PermsStatus -->|"No"| FixPerms["Fix Permission<br>Issues"]
    FixPerms --> RetryPerms["Retry Permission<br>Check"]
    RetryPerms --> PermsStatus
    
    style Start fill:#4da6ff,stroke:#0066cc,color:white
    style EnvSuccess fill:#10b981,stroke:#059669,color:white
    style ToolsStatus fill:#f6546a,stroke:#c30052,color:white
    style PermsStatus fill:#f6546a,stroke:#c30052,color:white
```

#### Environment Validation Implementation:
```powershell
# Example: Validate environment for a web project
function Validate-Environment {
    $requiredTools = @(
        @{Name = "git"; Command = "git --version"},
        @{Name = "node"; Command = "node --version"},
        @{Name = "npm"; Command = "npm --version"}
    )
    
    $missingTools = @()
    $permissionIssues = @()
    
    # Check build tools
    foreach ($tool in $requiredTools) {
        try {
            Invoke-Expression $tool.Command | Out-Null
        } catch {
            $missingTools += $tool.Name
        }
    }
    
    # Check write permissions in project directory
    try {
        $testFile = ".__permission_test"
        New-Item -Path $testFile -ItemType File -Force | Out-Null
        Remove-Item -Path $testFile -Force
    } catch {
        $permissionIssues += "Current directory (write permission denied)"
    }
    
    # Check if port 3000 is available (commonly used for dev servers)
    try {
        $listener = New-Object System.Net.Sockets.TcpListener([System.Net.IPAddress]::Loopback, 3000)
        $listener.Start()
        $listener.Stop()
    } catch {
        $permissionIssues += "Port 3000 (already in use or access denied)"
    }
    
    # Display results
    if ($missingTools.Count -eq 0 -and $permissionIssues.Count -eq 0) {
        Write-Output "✅ Environment validated successfully"
        return $true
    } else {
        if ($missingTools.Count -gt 0) {
            Write-Output "❌ Missing tools: $($missingTools -join ', ')"
        }
        if ($permissionIssues.Count -gt 0) {
            Write-Output "❌ Permission issues: $($permissionIssues -join ', ')"
        }
        return $false
    }
}
```

### 4️⃣ MINIMAL BUILD TEST

This step performs a minimal build test to ensure core functionality:

```mermaid
graph TD
    Start["Minimal Build Test"] --> CreateTest["Create Minimal<br>Test Project"]
    CreateTest --> BuildTest["Attempt<br>Build"]
    BuildTest --> BuildStatus{"Build<br>Successful?"}
    
    BuildStatus -->|"Yes"| RunTest["Run Basic<br>Functionality Test"]
    BuildStatus -->|"No"| FixBuild["Fix Build<br>Issues"]
    FixBuild --> RetryBuild["Retry Build"]
    RetryBuild --> BuildStatus
    
    RunTest --> TestStatus{"Test<br>Passed?"}
    TestStatus -->|"Yes"| TestSuccess["Minimal Build Test<br>✅ PASS"]
    TestStatus -->|"No"| FixTest["Fix Test<br>Issues"]
    FixTest --> RetryTest["Retry Test"]
    RetryTest --> TestStatus
    
    style Start fill:#4da6ff,stroke:#0066cc,color:white
    style TestSuccess fill:#10b981,stroke:#059669,color:white
    style BuildStatus fill:#f6546a,stroke:#c30052,color:white
    style TestStatus fill:#f6546a,stroke:#c30052,color:white
```

#### Minimal Build Test Implementation:
```powershell
# Example: Perform minimal build test for a React project
function Perform-MinimalBuildTest {
    $buildSuccess = $false
    $testSuccess = $false
    
    # Create minimal test project
    $testDir = ".__build_test"
    if (Test-Path $testDir) {
        Remove-Item -Path $testDir -Recurse -Force
    }
    
    try {
        # Create minimal test directory
        New-Item -Path $testDir -ItemType Directory | Out-Null
        Push-Location $testDir
        
        # Initialize minimal package.json
        @"
{
  "name": "build-test",
  "version": "1.0.0",
  "description": "Minimal build test",
  "main": "index.js",
  "scripts": {
    "build": "echo Build test successful"
  }
}
"@ | Set-Content -Path "package.json"
        
        # Attempt build
        npm run build | Out-Null
        $buildSuccess = $true
        
        # Create minimal test file
        @"
console.log('Test successful');
"@ | Set-Content -Path "index.js"
        
        # Run basic test
        node index.js | Out-Null
        $testSuccess = $true
        
    } catch {
        Write-Output "❌ Build test failed: $($_.Exception.Message)"
    } finally {
        Pop-Location
        if (Test-Path $testDir) {
            Remove-Item -Path $testDir -Recurse -Force
        }
    }
    
    # Display results
    if ($buildSuccess -and $testSuccess) {
        Write-Output "✅ Minimal build test passed successfully"
        return $true
    } else {
        if (-not $buildSuccess) {
            Write-Output "❌ Build process failed"
        }
        if (-not $testSuccess) {
            Write-Output "❌ Basic functionality test failed"
        }
        return $false
    }
}
```

## 📋 COMPREHENSIVE QA REPORT FORMAT

After running all validation steps, a comprehensive report is generated:

```
╔═════════════════════ 🔍 QA VALIDATION REPORT ══════════════════════╗
│                                                                     │
│  PROJECT: [Project Name]                                            │
│  TIMESTAMP: [Current Date/Time]                                     │
│                                                                     │
│  1️⃣ DEPENDENCY VERIFICATION                                         │
│  ✓ Required: [List of required dependencies]                        │
│  ✓ Installed: [List of installed dependencies]                      │
│  ✓ Compatible: [Yes/No]                                            │
│                                                                     │
│  2️⃣ CONFIGURATION VALIDATION                                        │
│  ✓ Config Files: [List of configuration files]                      │
│  ✓ Syntax Valid: [Yes/No]                                          │
│  ✓ Platform Compatible: [Yes/No]                                   │
│                                                                     │
│  3️⃣ ENVIRONMENT VALIDATION                                          │
│  ✓ Build Tools: [Available/Missing]                                │
│  ✓ Permissions: [Sufficient/Insufficient]                          │
│  ✓ Environment Ready: [Yes/No]                                     │
│                                                                     │
│  4️⃣ MINIMAL BUILD TEST                                              │
│  ✓ Build Process: [Successful/Failed]                              │
│  ✓ Functionality Test: [Passed/Failed]                             │
│  ✓ Build Ready: [Yes/No]                                           │
│                                                                     │
│  🚨 FINAL VERDICT: [PASS/FAIL]                                      │
│  ➡️ [Success message or error details]                              │
╚═════════════════════════════════════════════════════════════════════╝
```

## ❌ FAILURE REPORT FORMAT

If any validation step fails, a detailed failure report is generated:

```
⚠️⚠️⚠️ QA VALIDATION FAILED ⚠️⚠️⚠️

The following issues must be resolved before proceeding to BUILD mode:

1️⃣ DEPENDENCY ISSUES:
- [Detailed description of dependency issues]
- [Recommended fix]

2️⃣ CONFIGURATION ISSUES:
- [Detailed description of configuration issues]
- [Recommended fix]

3️⃣ ENVIRONMENT ISSUES:
- [Detailed description of environment issues]
- [Recommended fix]

4️⃣ BUILD TEST ISSUES:
- [Detailed description of build test issues]
- [Recommended fix]

⚠️ BUILD MODE IS BLOCKED until these issues are resolved.
Type 'VAN QA' after fixing the issues to re-validate.
```

## 🔄 INTEGRATION WITH DESIGN DECISIONS

The VAN QA mode reads and validates design decisions from the CREATIVE phase:

```mermaid
graph TD
    Start["Read Design Decisions"] --> ReadCreative["Parse Creative Phase<br>Documentation"]
    ReadCreative --> ExtractTech["Extract Technology<br>Choices"]
    ExtractTech --> ExtractDeps["Extract Required<br>Dependencies"]
    ExtractDeps --> BuildValidationPlan["Build Validation<br>Plan"]
    BuildValidationPlan --> StartValidation["Start Four-Point<br>Validation Process"]
    
    style Start fill:#4da6ff,stroke:#0066cc,color:white
    style ExtractTech fill:#f6546a,stroke:#c30052,color:white
    style BuildValidationPlan fill:#10b981,stroke:#059669,color:white
    style StartValidation fill:#f6546a,stroke:#c30052,color:white
```

### Technology Extraction Process:
```powershell
# Example: Extract technology choices from creative phase documentation
function Extract-TechnologyChoices {
    $techChoices = @{}
    
    # Read from systemPatterns.md
    if (Test-Path "memory-bank\systemPatterns.md") {
        $content = Get-Content "memory-bank\systemPatterns.md" -Raw
        
        # Extract framework choice
        if ($content -match "Framework:\s*(\w+)") {
            $techChoices["framework"] = $Matches[1]
        }
        
        # Extract UI library choice
        if ($content -match "UI Library:\s*(\w+)") {
            $techChoices["ui_library"] = $Matches[1]
        }
        
        # Extract state management choice
        if ($content -match "State Management:\s*([^\\n]+)") {
            $techChoices["state_management"] = $Matches[1].Trim()
        }
    }
    
    return $techChoices
}
```

## 🚨 IMPLEMENTATION PREVENTION MECHANISM

If QA validation fails, the system prevents moving to BUILD mode:

```powershell
# Example: Enforce QA validation before allowing BUILD mode
function Check-QAValidationStatus {
    $qaStatusFile = "memory-bank\.qa_validation_status"
    
    if (Test-Path $qaStatusFile) {
        $status = Get-Content $qaStatusFile -Raw
        if ($status -match "PASS") {
            return $true
        }
    }
    
    # Display block message
    Write-Output "`n`n"
    Write-Output "🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫"
    Write-Output "⛔️ BUILD MODE BLOCKED: QA VALIDATION REQUIRED"
    Write-Output "⛔️ You must complete QA validation before proceeding to BUILD mode"
    Write-Output "`n"
    Write-Output "Type 'VAN QA' to perform technical validation"
    Write-Output "`n"
    Write-Output "🚫 NO IMPLEMENTATION CAN PROCEED WITHOUT VALIDATION 🚫"
    Write-Output "🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫"
    
    return $false
}
```

## 🧪 COMMON QA VALIDATION FIXES

Here are common fixes for issues encountered during QA validation:

### Dependency Issues:
- **Missing Node.js**: Install Node.js from https://nodejs.org/
- **Outdated npm**: Run `npm install -g npm@latest` to update
- **Missing packages**: Run `npm install` or `npm install [package-name]`

### Configuration Issues:
- **Invalid JSON**: Use a JSON validator to check syntax
- **Missing React plugin**: Add `import react from '@vitejs/plugin-react'` and `plugins: [react()]` to vite.config.js
- **Incompatible TypeScript config**: Update `tsconfig.json` with correct React settings

### Environment Issues:
- **Permission denied**: Run terminal as administrator (Windows) or use sudo (Mac/Linux)
- **Port already in use**: Kill process using the port or change the port in configuration
- **Missing build tools**: Install required command-line tools

### Build Test Issues:
- **Build fails**: Check console for specific error messages
- **Test fails**: Verify minimal configuration is correct
- **Path issues**: Ensure paths use correct separators for the platform

## 🔒 FINAL QA VALIDATION CHECKPOINT

```
✓ SECTION CHECKPOINT: QA VALIDATION
- Dependency Verification Passed? [YES/NO]
- Configuration Validation Passed? [YES/NO]
- Environment Validation Passed? [YES/NO]
- Minimal Build Test Passed? [YES/NO]

→ If all YES: Ready for BUILD mode
→ If any NO: Fix identified issues before proceeding
```

================
File: .cursor/rules/isolation_rules/visual-maps/van_mode_split/van-platform-detection.mdc
================
---
description: Visual process map for VAN mode platform detection
globs: van-platform-detection.mdc
alwaysApply: false
---
# VAN MODE: PLATFORM DETECTION

> **TL;DR:** Detects the OS, determines path separators, and notes command adaptations required.

## 🌐 PLATFORM DETECTION PROCESS

```mermaid
graph TD
    PD["Platform Detection"] --> CheckOS["Detect Operating System"]
    CheckOS --> Win["Windows"]
    CheckOS --> Mac["macOS"]
    CheckOS --> Lin["Linux"]
    
    Win & Mac & Lin --> Adapt["Adapt Commands<br>for Platform"]
    
    Win --> WinPath["Path: Backslash (\\)"]
    Mac --> MacPath["Path: Forward Slash (/)"]
    Lin --> LinPath["Path: Forward Slash (/)"]
    
    Win --> WinCmd["Command Adaptations:<br>dir, icacls, etc."]
    Mac --> MacCmd["Command Adaptations:<br>ls, chmod, etc."]
    Lin --> LinCmd["Command Adaptations:<br>ls, chmod, etc."]
    
    WinPath & MacPath & LinPath --> PathCP["Path Separator<br>Checkpoint"]
    WinCmd & MacCmd & LinCmd --> CmdCP["Command<br>Checkpoint"]
    
    PathCP & CmdCP --> PlatformComplete["Platform Detection<br>Complete"]
    
    style PD fill:#4da6ff,stroke:#0066cc,color:white
    style PlatformComplete fill:#10b981,stroke:#059669,color:white
```

## 📋 CHECKPOINT VERIFICATION TEMPLATE (Example)

```
✓ SECTION CHECKPOINT: PLATFORM DETECTION
- Operating System Detected? [YES/NO]
- Path Separator Confirmed? [YES/NO]
- Command Adaptations Noted? [YES/NO]

→ If all YES: Platform Detection Complete.
→ If any NO: Resolve before proceeding.
```

**Next Step:** Load and process `van-file-verification.mdc`.

================
File: .cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-checks/build-test.mdc
================
---
description: Process map for VAN QA minimal build test
globs: van-qa-checks/build-test.mdc
alwaysApply: false
---
# VAN QA: MINIMAL BUILD TEST

> **TL;DR:** This component performs a minimal build test to ensure core build functionality works properly.

## 4️⃣ MINIMAL BUILD TEST PROCESS

```mermaid
graph TD
    Start["Minimal Build Test"] --> CreateTest["Create Minimal<br>Test Project"]
    CreateTest --> BuildTest["Attempt<br>Build"]
    BuildTest --> BuildStatus{"Build<br>Successful?"}
    
    BuildStatus -->|"Yes"| RunTest["Run Basic<br>Functionality Test"]
    BuildStatus -->|"No"| FixBuild["Fix Build<br>Issues"]
    FixBuild --> RetryBuild["Retry Build"]
    RetryBuild --> BuildStatus
    
    RunTest --> TestStatus{"Test<br>Passed?"}
    TestStatus -->|"Yes"| TestSuccess["Minimal Build Test<br>✅ PASS"]
    TestStatus -->|"No"| FixTest["Fix Test<br>Issues"]
    FixTest --> RetryTest["Retry Test"]
    RetryTest --> TestStatus
    
    style Start fill:#4da6ff,stroke:#0066cc,color:white
    style TestSuccess fill:#10b981,stroke:#059669,color:white
    style BuildStatus fill:#f6546a,stroke:#c30052,color:white
    style TestStatus fill:#f6546a,stroke:#c30052,color:white
```

### Minimal Build Test Implementation:
```powershell
# Example: Perform minimal build test for a React project
function Perform-MinimalBuildTest {
    $buildSuccess = $false
    $testSuccess = $false
    
    # Create minimal test project
    $testDir = ".__build_test"
    if (Test-Path $testDir) {
        Remove-Item -Path $testDir -Recurse -Force
    }
    
    try {
        # Create minimal test directory
        New-Item -Path $testDir -ItemType Directory | Out-Null
        Push-Location $testDir
        
        # Initialize minimal package.json
        @"
{
  "name": "build-test",
  "version": "1.0.0",
  "description": "Minimal build test",
  "main": "index.js",
  "scripts": {
    "build": "echo Build test successful"
  }
}
"@ | Set-Content -Path "package.json"
        
        # Attempt build
        npm run build | Out-Null
        $buildSuccess = $true
        
        # Create minimal test file
        @"
console.log('Test successful');
"@ | Set-Content -Path "index.js"
        
        # Run basic test
        node index.js | Out-Null
        $testSuccess = $true
        
    } catch {
        Write-Output "❌ Build test failed: $($_.Exception.Message)"
    } finally {
        Pop-Location
        if (Test-Path $testDir) {
            Remove-Item -Path $testDir -Recurse -Force
        }
    }
    
    # Display results
    if ($buildSuccess -and $testSuccess) {
        Write-Output "✅ Minimal build test passed successfully"
        return $true
    } else {
        if (-not $buildSuccess) {
            Write-Output "❌ Build process failed"
        }
        if (-not $testSuccess) {
            Write-Output "❌ Basic functionality test failed"
        }
        return $false
    }
}
```

## 📋 MINIMAL BUILD TEST CHECKPOINT

```
✓ CHECKPOINT: MINIMAL BUILD TEST
- Test project creation successful? [YES/NO]
- Build process completed successfully? [YES/NO]
- Basic functionality test passed? [YES/NO]

→ If all YES: QA Validation complete, proceed to generate success report.
→ If any NO: Fix build issues before continuing.
```

**Next Step (on PASS):** Load `van-qa-utils/reports.mdc` to generate success report.
**Next Step (on FAIL):** Check `van-qa-utils/common-fixes.mdc` for build test fixes.

================
File: .cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-checks/config-check.mdc
================
---
description: Process map for VAN QA configuration validation
globs: van-qa-checks/config-check.mdc
alwaysApply: false
---
# VAN QA: CONFIGURATION VALIDATION

> **TL;DR:** This component validates configuration files for proper syntax and compatibility with the project and platform.

## 2️⃣ CONFIGURATION VALIDATION PROCESS

```mermaid
graph TD
    Start["Configuration Validation"] --> IdentifyConfigs["Identify Configuration<br>Files"]
    IdentifyConfigs --> ReadConfigs["Read Configuration<br>Files"]
    ReadConfigs --> ValidateSyntax["Validate Syntax<br>and Format"]
    ValidateSyntax --> SyntaxStatus{"Syntax<br>Valid?"}
    
    SyntaxStatus -->|"Yes"| CheckCompatibility["Check Compatibility<br>with Platform"]
    SyntaxStatus -->|"No"| FixSyntax["Fix Syntax<br>Errors"]
    FixSyntax --> RetryValidate["Retry Validation"]
    RetryValidate --> SyntaxStatus
    
    CheckCompatibility --> CompatStatus{"Compatible with<br>Platform?"}
    CompatStatus -->|"Yes"| ConfigSuccess["Configurations Validated<br>✅ PASS"]
    CompatStatus -->|"No"| AdaptConfigs["Adapt Configurations<br>for Platform"]
    AdaptConfigs --> RetryCompat["Retry Compatibility<br>Check"]
    RetryCompat --> CompatStatus
    
    style Start fill:#4da6ff,stroke:#0066cc,color:white
    style ConfigSuccess fill:#10b981,stroke:#059669,color:white
    style SyntaxStatus fill:#f6546a,stroke:#c30052,color:white
    style CompatStatus fill:#f6546a,stroke:#c30052,color:white
```

### Configuration Validation Implementation:
```powershell
# Example: Validate configuration files for a web project
function Validate-Configurations {
    $configFiles = @(
        "package.json",
        "tsconfig.json",
        "vite.config.js"
    )
    
    $invalidConfigs = @()
    $incompatibleConfigs = @()
    
    foreach ($configFile in $configFiles) {
        if (Test-Path $configFile) {
            # Check JSON syntax for JSON files
            if ($configFile -match "\.json$") {
                try {
                    Get-Content $configFile -Raw | ConvertFrom-Json | Out-Null
                } catch {
                    $invalidConfigs += "$configFile (JSON syntax error: $($_.Exception.Message))"
                    continue
                }
            }
            
            # Specific configuration compatibility checks
            if ($configFile -eq "vite.config.js") {
                $content = Get-Content $configFile -Raw
                # Check for React plugin in Vite config
                if ($content -notmatch "react\(\)") {
                    $incompatibleConfigs += "$configFile (Missing React plugin for React project)"
                }
            }
        } else {
            $invalidConfigs += "$configFile (file not found)"
        }
    }
    
    # Display results
    if ($invalidConfigs.Count -eq 0 -and $incompatibleConfigs.Count -eq 0) {
        Write-Output "✅ All configurations validated and compatible"
        return $true
    } else {
        if ($invalidConfigs.Count -gt 0) {
            Write-Output "❌ Invalid configurations: $($invalidConfigs -join ', ')"
        }
        if ($incompatibleConfigs.Count -gt 0) {
            Write-Output "❌ Incompatible configurations: $($incompatibleConfigs -join ', ')"
        }
        return $false
    }
}
```

## 📋 CONFIGURATION VALIDATION CHECKPOINT

```
✓ CHECKPOINT: CONFIGURATION VALIDATION
- All configuration files found? [YES/NO]
- All configuration syntax valid? [YES/NO]
- All configurations compatible with platform? [YES/NO]

→ If all YES: Continue to Environment Validation.
→ If any NO: Fix configuration issues before continuing.
```

**Next Step (on PASS):** Load `van-qa-checks/environment-check.mdc`.
**Next Step (on FAIL):** Check `van-qa-utils/common-fixes.mdc` for configuration fixes.

================
File: .cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-checks/dependency-check.mdc
================
---
description: Process map for VAN QA dependency verification
globs: van-qa-checks/dependency-check.mdc
alwaysApply: false
---
# VAN QA: DEPENDENCY VERIFICATION

> **TL;DR:** This component verifies that all required dependencies are installed and compatible with the project requirements.

## 1️⃣ DEPENDENCY VERIFICATION PROCESS

```mermaid
graph TD
    Start["Dependency Verification"] --> ReadDeps["Read Required Dependencies<br>from Creative Phase"]
    ReadDeps --> CheckInstalled["Check if Dependencies<br>are Installed"]
    CheckInstalled --> DepStatus{"All Dependencies<br>Installed?"}
    
    DepStatus -->|"Yes"| VerifyVersions["Verify Versions<br>and Compatibility"]
    DepStatus -->|"No"| InstallMissing["Install Missing<br>Dependencies"]
    InstallMissing --> VerifyVersions
    
    VerifyVersions --> VersionStatus{"Versions<br>Compatible?"}
    VersionStatus -->|"Yes"| DepSuccess["Dependencies Verified<br>✅ PASS"]
    VersionStatus -->|"No"| UpgradeVersions["Upgrade/Downgrade<br>as Needed"]
    UpgradeVersions --> RetryVerify["Retry Verification"]
    RetryVerify --> VersionStatus
    
    style Start fill:#4da6ff,stroke:#0066cc,color:white
    style DepSuccess fill:#10b981,stroke:#059669,color:white
    style DepStatus fill:#f6546a,stroke:#c30052,color:white
    style VersionStatus fill:#f6546a,stroke:#c30052,color:white
```

### Windows (PowerShell) Implementation:
```powershell
# Example: Verify Node.js dependencies for a React project
function Verify-Dependencies {
    $requiredDeps = @{ "node" = ">=14.0.0"; "npm" = ">=6.0.0" }
    $missingDeps = @(); $incompatibleDeps = @()
    
    # Check Node.js version
    try { 
        $nodeVersion = node -v
        if ($nodeVersion -match "v(\d+)\.(\d+)\.(\d+)") {
            $major = [int]$Matches[1]
            if ($major -lt 14) {
                $incompatibleDeps += "node (found $nodeVersion, required >=14.0.0)"
            }
        }
    } catch {
        $missingDeps += "node"
    }
    
    # Check npm version
    try { 
        $npmVersion = npm -v
        if ($npmVersion -match "(\d+)\.(\d+)\.(\d+)") {
            $major = [int]$Matches[1]
            if ($major -lt 6) {
                $incompatibleDeps += "npm (found $npmVersion, required >=6.0.0)"
            }
        }
    } catch {
        $missingDeps += "npm"
    }
    
    # Display results
    if ($missingDeps.Count -eq 0 -and $incompatibleDeps.Count -eq 0) {
        Write-Output "✅ All dependencies verified and compatible"
        return $true
    } else {
        if ($missingDeps.Count -gt 0) {
            Write-Output "❌ Missing dependencies: $($missingDeps -join ', ')"
        }
        if ($incompatibleDeps.Count -gt 0) {
            Write-Output "❌ Incompatible versions: $($incompatibleDeps -join ', ')"
        }
        return $false
    }
}
```

### Mac/Linux (Bash) Implementation:
```bash
#!/bin/bash

# Example: Verify Node.js dependencies for a React project
verify_dependencies() {
    local missing_deps=()
    local incompatible_deps=()
    
    # Check Node.js version
    if command -v node &> /dev/null; then
        local node_version=$(node -v)
        if [[ $node_version =~ v([0-9]+)\.([0-9]+)\.([0-9]+) ]]; then
            local major=${BASH_REMATCH[1]}
            if (( major < 14 )); then
                incompatible_deps+=("node (found $node_version, required >=14.0.0)")
            fi
        fi
    else
        missing_deps+=("node")
    fi
    
    # Check npm version
    if command -v npm &> /dev/null; then
        local npm_version=$(npm -v)
        if [[ $npm_version =~ ([0-9]+)\.([0-9]+)\.([0-9]+) ]]; then
            local major=${BASH_REMATCH[1]}
            if (( major < 6 )); then
                incompatible_deps+=("npm (found $npm_version, required >=6.0.0)")
            fi
        fi
    else
        missing_deps+=("npm")
    fi
    
    # Display results
    if [ ${#missing_deps[@]} -eq 0 ] && [ ${#incompatible_deps[@]} -eq 0 ]; then
        echo "✅ All dependencies verified and compatible"
        return 0
    else
        if [ ${#missing_deps[@]} -gt 0 ]; then
            echo "❌ Missing dependencies: ${missing_deps[*]}"
        fi
        if [ ${#incompatible_deps[@]} -gt 0 ]; then
            echo "❌ Incompatible versions: ${incompatible_deps[*]}"
        fi
        return 1
    fi
}
```

## 📋 DEPENDENCY VERIFICATION CHECKPOINT

```
✓ CHECKPOINT: DEPENDENCY VERIFICATION
- Required dependencies identified? [YES/NO]
- All dependencies installed? [YES/NO]
- All versions compatible? [YES/NO]

→ If all YES: Continue to Configuration Validation.
→ If any NO: Fix dependency issues before continuing.
```

**Next Step (on PASS):** Load `van-qa-checks/config-check.mdc`.
**Next Step (on FAIL):** Check `van-qa-utils/common-fixes.mdc` for dependency fixes.

================
File: .cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-checks/environment-check.mdc
================
---
description: Process map for VAN QA environment validation
globs: van-qa-checks/environment-check.mdc
alwaysApply: false
---
# VAN QA: ENVIRONMENT VALIDATION

> **TL;DR:** This component verifies that the build environment is properly set up with required tools and permissions.

## 3️⃣ ENVIRONMENT VALIDATION PROCESS

```mermaid
graph TD
    Start["Environment Validation"] --> CheckEnv["Check Build Environment"]
    CheckEnv --> VerifyBuildTools["Verify Build Tools"]
    VerifyBuildTools --> ToolsStatus{"Build Tools<br>Available?"}
    
    ToolsStatus -->|"Yes"| CheckPerms["Check Permissions<br>and Access"]
    ToolsStatus -->|"No"| InstallTools["Install Required<br>Build Tools"]
    InstallTools --> RetryTools["Retry Verification"]
    RetryTools --> ToolsStatus
    
    CheckPerms --> PermsStatus{"Permissions<br>Sufficient?"}
    PermsStatus -->|"Yes"| EnvSuccess["Environment Validated<br>✅ PASS"]
    PermsStatus -->|"No"| FixPerms["Fix Permission<br>Issues"]
    FixPerms --> RetryPerms["Retry Permission<br>Check"]
    RetryPerms --> PermsStatus
    
    style Start fill:#4da6ff,stroke:#0066cc,color:white
    style EnvSuccess fill:#10b981,stroke:#059669,color:white
    style ToolsStatus fill:#f6546a,stroke:#c30052,color:white
    style PermsStatus fill:#f6546a,stroke:#c30052,color:white
```

### Environment Validation Implementation:
```powershell
# Example: Validate environment for a web project
function Validate-Environment {
    $requiredTools = @(
        @{Name = "git"; Command = "git --version"},
        @{Name = "node"; Command = "node --version"},
        @{Name = "npm"; Command = "npm --version"}
    )
    
    $missingTools = @()
    $permissionIssues = @()
    
    # Check build tools
    foreach ($tool in $requiredTools) {
        try {
            Invoke-Expression $tool.Command | Out-Null
        } catch {
            $missingTools += $tool.Name
        }
    }
    
    # Check write permissions in project directory
    try {
        $testFile = ".__permission_test"
        New-Item -Path $testFile -ItemType File -Force | Out-Null
        Remove-Item -Path $testFile -Force
    } catch {
        $permissionIssues += "Current directory (write permission denied)"
    }
    
    # Check if port 3000 is available (commonly used for dev servers)
    try {
        $listener = New-Object System.Net.Sockets.TcpListener([System.Net.IPAddress]::Loopback, 3000)
        $listener.Start()
        $listener.Stop()
    } catch {
        $permissionIssues += "Port 3000 (already in use or access denied)"
    }
    
    # Display results
    if ($missingTools.Count -eq 0 -and $permissionIssues.Count -eq 0) {
        Write-Output "✅ Environment validated successfully"
        return $true
    } else {
        if ($missingTools.Count -gt 0) {
            Write-Output "❌ Missing tools: $($missingTools -join ', ')"
        }
        if ($permissionIssues.Count -gt 0) {
            Write-Output "❌ Permission issues: $($permissionIssues -join ', ')"
        }
        return $false
    }
}
```

## 📋 ENVIRONMENT VALIDATION CHECKPOINT

```
✓ CHECKPOINT: ENVIRONMENT VALIDATION
- All required build tools installed? [YES/NO]
- Project directory permissions sufficient? [YES/NO]
- Required ports available? [YES/NO]

→ If all YES: Continue to Minimal Build Test.
→ If any NO: Fix environment issues before continuing.
```

**Next Step (on PASS):** Load `van-qa-checks/build-test.mdc`.
**Next Step (on FAIL):** Check `van-qa-utils/common-fixes.mdc` for environment fixes.

================
File: .cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-checks/file-verification.mdc
================


================
File: .cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-main.mdc
================
---
description: Visual process map for VAN QA mode (Technical Validation Entry Point)
globs: van-qa-main.mdc
alwaysApply: false
---
# VAN MODE: QA TECHNICAL VALIDATION (Main Entry)

> **TL;DR:** This is the entry point for the QA validation process that executes *after* CREATIVE mode and *before* BUILD mode. It ensures technical requirements are met before implementation begins.

## 📣 HOW TO USE THESE QA RULES

To access any QA validation rule or component, use the `fetch_rules` tool with exact rule names:

```
// CRITICAL: Always use fetch_rules to load validation components
// For detailed examples and guidance, load:
// isolation_rules/visual-maps/van-qa-utils/rule-calling-guide
```

## 🚀 VAN QA MODE ACTIVATION

After completing CREATIVE mode, when the user types "VAN QA", respond:

```mermaid
graph TD
    UserQA["User Types: QA"] --> HighPriority["⚠️ HIGH PRIORITY COMMAND"]
    HighPriority --> CurrentTask["Pause Current Task/Process"]
    CurrentTask --> LoadQA["Load QA Main Map (This File)"]
    LoadQA --> RunQA["Execute QA Validation Process"]
    RunQA --> QAResults{"QA Results"}
    
    QAResults -->|"PASS"| ResumeFlow["Resume Prior Process Flow"]
    QAResults -->|"FAIL"| FixIssues["Fix Identified Issues"]
    FixIssues --> ReRunQA["Re-run QA Validation"]
    ReRunQA --> QAResults
    
    style UserQA fill:#f8d486,stroke:#e8b84d,color:black
    style HighPriority fill:#ff0000,stroke:#cc0000,color:white,stroke-width:3px
    style LoadQA fill:#4da6ff,stroke:#0066cc,color:white
    style RunQA fill:#4da6ff,stroke:#0066cc,color:white
    style QAResults fill:#f6546a,stroke:#c30052,color:white
```

### QA Interruption Rules

1. **Immediate Precedence:** `QA` command interrupts everything.
2. **Load & Execute:** Load this map (`van-qa-main.mdc`) and its components (see below).
3. **Remediation Priority:** Fixes take priority over pending mode switches.
4. **Resume:** On PASS, resume the previous flow.

```
⚠️ QA OVERRIDE ACTIVATED
All other processes paused
QA validation checks now running...
Any issues found MUST be remediated before continuing with normal process flow
```

## 🔍 TECHNICAL VALIDATION OVERVIEW

Four-point validation process with selective loading:

```mermaid
graph TD
    VANQA["VAN QA MODE"] --> FourChecks["FOUR-POINT VALIDATION"]
    
    FourChecks --> DepCheck["1️⃣ DEPENDENCY VERIFICATION
    Load: van-qa-checks/dependency-check.mdc"]
    DepCheck --> ConfigCheck["2️⃣ CONFIGURATION VALIDATION
    Load: van-qa-checks/config-check.mdc"]
    ConfigCheck --> EnvCheck["3️⃣ ENVIRONMENT VALIDATION
    Load: van-qa-checks/environment-check.mdc"]
    EnvCheck --> MinBuildCheck["4️⃣ MINIMAL BUILD TEST
    Load: van-qa-checks/build-test.mdc"]
    
    MinBuildCheck --> ValidationResults{"All Checks<br>Passed?"}
    ValidationResults -->|"Yes"| SuccessReport["GENERATE SUCCESS REPORT
    Load: van-qa-utils/reports.mdc"]
    ValidationResults -->|"No"| FailureReport["GENERATE FAILURE REPORT
    Load: van-qa-utils/reports.mdc"]
    
    SuccessReport --> BUILD_Transition["Trigger BUILD Mode
    Load: van-qa-utils/mode-transitions.mdc"]
    FailureReport --> FixIssues["Fix Technical Issues
    Load: van-qa-utils/common-fixes.mdc"]
    FixIssues --> ReValidate["Re-validate (Re-run VAN QA)"]
    ReValidate --> FourChecks
    
    style VANQA fill:#4da6ff,stroke:#0066cc,color:white
    style FourChecks fill:#f6546a,stroke:#c30052,color:white
    style ValidationResults fill:#f6546a,stroke:#c30052,color:white
    style BUILD_Transition fill:#10b981,stroke:#059669,color:white
    style FixIssues fill:#ff5555,stroke:#dd3333,color:white
```

## 🔄 INTEGRATION WITH DESIGN DECISIONS

Reads Creative Phase outputs to inform validation:

```mermaid
graph TD
    Start["Read Design Decisions"] --> ReadCreative["Parse Creative Phase<br>Documentation"]
    ReadCreative --> ExtractTech["Extract Technology<br>Choices"]
    ExtractTech --> ExtractDeps["Extract Required<br>Dependencies"]
    ExtractDeps --> BuildValidationPlan["Build Validation<br>Plan"]
    BuildValidationPlan --> StartValidation["Start Four-Point<br>Validation Process"]
    
    style Start fill:#4da6ff,stroke:#0066cc,color:white
    style ExtractTech fill:#f6546a,stroke:#c30052,color:white
    style BuildValidationPlan fill:#10b981,stroke:#059669,color:white
    style StartValidation fill:#f6546a,stroke:#c30052,color:white
```

## 📋 COMPONENT LOADING SEQUENCE

The QA validation process follows this selective loading sequence:

1. **Main Entry (This File)**: `van-qa-main.mdc`
2. **Validation Checks**:
   - `van-qa-checks/dependency-check.mdc`
   - `van-qa-checks/config-check.mdc`
   - `van-qa-checks/environment-check.mdc`
   - `van-qa-checks/build-test.mdc`
3. **Utilities (As Needed)**:
   - `van-qa-utils/reports.mdc`
   - `van-qa-utils/common-fixes.mdc`
   - `van-qa-utils/mode-transitions.mdc`

## 📋 FINAL QA VALIDATION CHECKPOINT

```
✓ SECTION CHECKPOINT: QA VALIDATION
- Dependency Verification Passed? [YES/NO]
- Configuration Validation Passed? [YES/NO]
- Environment Validation Passed? [YES/NO]
- Minimal Build Test Passed? [YES/NO]

→ If all YES: Ready for BUILD mode transition.
→ If any NO: Fix identified issues and re-run VAN QA.
```

**Next Step (on PASS):** Trigger BUILD mode (load `van-qa-utils/mode-transitions.mdc`).
**Next Step (on FAIL):** Address issues (load `van-qa-utils/common-fixes.mdc`) and re-run `VAN QA`.

================
File: .cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-utils/common-fixes.mdc
================
---
description: Utility for VAN QA common validation fixes
globs: van-qa-utils/common-fixes.mdc
alwaysApply: false
---
# VAN QA: COMMON VALIDATION FIXES

> **TL;DR:** This component provides common fixes for issues that may arise during the QA validation process.

## 🧪 COMMON QA VALIDATION FIXES BY CATEGORY

### Dependency Issues

| Issue | Fix |
|-------|-----|
| **Missing Node.js** | Download and install Node.js from https://nodejs.org/ |
| **Outdated npm** | Run `npm install -g npm@latest` to update |
| **Missing packages** | Run `npm install` or `npm install [package-name]` |
| **Package version conflicts** | Adjust versions in package.json and run `npm install` |
| **Dependency resolution issues** | Run `npm cache clean -f` and try installing again |

### Configuration Issues

| Issue | Fix |
|-------|-----|
| **Invalid JSON** | Use a JSON validator (e.g., jsonlint) to check syntax |
| **Missing React plugin** | Add `import react from '@vitejs/plugin-react'` and `plugins: [react()]` to vite.config.js |
| **Incompatible TypeScript config** | Update `tsconfig.json` with correct React settings |
| **Mismatched version references** | Ensure consistent versions across configuration files |
| **Missing entries in config files** | Add required fields to configuration files |

### Environment Issues

| Issue | Fix |
|-------|-----|
| **Permission denied** | Run terminal as administrator (Windows) or use sudo (Mac/Linux) |
| **Port already in use** | Kill process using the port: `netstat -ano \| findstr :PORT` then `taskkill /F /PID PID` (Windows) or `lsof -i :PORT` then `kill -9 PID` (Mac/Linux) |
| **Missing build tools** | Install required command-line tools (git, node, etc.) |
| **Environment variable issues** | Set required environment variables: `$env:VAR_NAME = "value"` (PowerShell) or `export VAR_NAME="value"` (Bash) |
| **Disk space issues** | Free up disk space, clean npm/package cache files |

### Build Test Issues

| Issue | Fix |
|-------|-----|
| **Build fails** | Check console for specific error messages |
| **Test fails** | Verify minimal configuration is correct |
| **Path issues** | Ensure paths use correct separators for the platform (`\` for Windows, `/` for Mac/Linux) |
| **Missing dependencies** | Make sure all required dependencies are installed |
| **Script permissions** | Ensure script files have execution permissions (chmod +x on Unix) |

## 📝 ISSUE DIAGNOSIS PROCEDURES

### 1. Dependency Diagnosis
```powershell
# Find conflicting dependencies
npm ls [package-name]

# Check for outdated packages
npm outdated

# Check for vulnerabilities
npm audit
```

### 2. Configuration Diagnosis
```powershell
# List all configuration files
Get-ChildItem -Recurse -Include "*.json","*.config.js" | Select-Object FullName

# Find missing references in tsconfig.json
if (Test-Path "tsconfig.json") { 
    $tsconfig = Get-Content "tsconfig.json" -Raw | ConvertFrom-Json
    if (-not $tsconfig.compilerOptions.jsx) {
        Write-Output "Missing jsx setting in tsconfig.json"
    }
}
```

### 3. Environment Diagnosis
```powershell
# Check process using a port (Windows)
netstat -ano | findstr ":3000"

# List environment variables
Get-ChildItem Env:

# Check disk space
Get-PSDrive C | Select-Object Used,Free
```

**Next Step:** Return to the validation process or follow the specific fix recommendations provided above.

================
File: .cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-utils/mode-transitions.mdc
================
---
description: Utility for VAN QA mode transitions
globs: van-qa-utils/mode-transitions.mdc
alwaysApply: false
---
# VAN QA: MODE TRANSITIONS

> **TL;DR:** This component handles transitions between modes, particularly the QA validation to BUILD mode transition, and prevents BUILD mode access without successful QA validation.

## 🔒 BUILD MODE PREVENTION MECHANISM

The system prevents moving to BUILD mode without passing QA validation:

```mermaid
graph TD
    Start["User Types: BUILD"] --> CheckQA{"QA Validation<br>Completed?"}
    CheckQA -->|"Yes and Passed"| AllowBuild["Allow BUILD Mode"]
    CheckQA -->|"No or Failed"| BlockBuild["BLOCK BUILD MODE"]
    BlockBuild --> Message["Display:<br>⚠️ QA VALIDATION REQUIRED"]
    Message --> ReturnToVANQA["Prompt: Type VAN QA"]
    
    style CheckQA fill:#f6546a,stroke:#c30052,color:white
    style BlockBuild fill:#ff0000,stroke:#990000,color:white,stroke-width:3px
    style Message fill:#ff5555,stroke:#dd3333,color:white
    style ReturnToVANQA fill:#4da6ff,stroke:#0066cc,color:white
```

### Implementation Example (PowerShell):
```powershell
# Check QA status before allowing BUILD mode
function Check-QAValidationStatus {
    $qaStatusFile = "memory-bank\.qa_validation_status" # Assumes status is written by reports.mdc
    
    if (Test-Path $qaStatusFile) {
        $status = Get-Content $qaStatusFile -Raw
        if ($status -match "PASS") {
            return $true
        }
    }
    
    # Display block message
    Write-Output "`n`n"
    Write-Output "🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫"
    Write-Output "⛔️ BUILD MODE BLOCKED: QA VALIDATION REQUIRED"
    Write-Output "⛔️ You must complete QA validation before proceeding to BUILD mode"
    Write-Output "`n"
    Write-Output "Type 'VAN QA' to perform technical validation"
    Write-Output "`n"
    Write-Output "🚫 NO IMPLEMENTATION CAN PROCEED WITHOUT VALIDATION 🚫"
    Write-Output "🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫"
    
    return $false
}
```

## 🚨 MODE TRANSITION TRIGGERS

### CREATIVE to VAN QA Transition:
After completing the CREATIVE phase, trigger this message to prompt QA validation:

```
⏭️ NEXT MODE: VAN QA
To validate technical requirements before implementation, please type 'VAN QA'
```

### VAN QA to BUILD Transition (On Success):
After successful QA validation, trigger this message to allow BUILD mode:

```
✅ TECHNICAL VALIDATION COMPLETE
All prerequisites verified successfully
You may now proceed to BUILD mode
Type 'BUILD' to begin implementation
```

### Manual BUILD Mode Access (When QA Already Passed):
When the user manually types 'BUILD', check the QA status before allowing access:

```powershell
# Handle BUILD mode request
function Handle-BuildModeRequest {
    if (Check-QAValidationStatus) {
        # Allow transition to BUILD mode
        Write-Output "`n"
        Write-Output "✅ QA VALIDATION CHECK: PASSED"
        Write-Output "Loading BUILD mode..."
        Write-Output "`n"
        
        # Here you would load the BUILD mode map
        # [Code to load BUILD mode map]
        
        return $true
    }
    
    # QA validation failed or not completed, BUILD mode blocked
    return $false
}
```

**Next Step (on QA SUCCESS):** Continue to BUILD mode.
**Next Step (on QA FAILURE):** Return to QA validation process.

================
File: .cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-utils/reports.mdc
================
---
description: Utility for VAN QA validation reports
globs: van-qa-utils/reports.mdc
alwaysApply: false
---
# VAN QA: VALIDATION REPORTS

> **TL;DR:** This component contains the formats for comprehensive success and failure reports generated upon completion of the QA validation process.

## 📋 COMPREHENSIVE SUCCESS REPORT FORMAT

After all four validation points pass, generate this success report:

```
╔═════════════════════ 🔍 QA VALIDATION REPORT ══════════════════════╗
│ PROJECT: [Project Name] | TIMESTAMP: [Current Date/Time]            │
├─────────────────────────────────────────────────────────────────────┤
│ 1️⃣ DEPENDENCIES: ✓ Compatible                                       │
│ 2️⃣ CONFIGURATION: ✓ Valid & Compatible                             │
│ 3️⃣ ENVIRONMENT: ✓ Ready                                             │
│ 4️⃣ MINIMAL BUILD: ✓ Successful & Passed                            │
├─────────────────────────────────────────────────────────────────────┤
│ 🚨 FINAL VERDICT: PASS                                              │
│ ➡️ Clear to proceed to BUILD mode                                   │
╚═════════════════════════════════════════════════════════════════════╝
```

### Success Report Generation Example:
```powershell
function Generate-SuccessReport {
    param (
        [string]$ProjectName = "Current Project"
    )
    
    $timestamp = Get-Date -Format "yyyy-MM-dd HH:mm:ss"
    
    $report = @"
╔═════════════════════ 🔍 QA VALIDATION REPORT ══════════════════════╗
│ PROJECT: $ProjectName | TIMESTAMP: $timestamp            │
├─────────────────────────────────────────────────────────────────────┤
│ 1️⃣ DEPENDENCIES: ✓ Compatible                                       │
│ 2️⃣ CONFIGURATION: ✓ Valid & Compatible                             │
│ 3️⃣ ENVIRONMENT: ✓ Ready                                             │
│ 4️⃣ MINIMAL BUILD: ✓ Successful & Passed                            │
├─────────────────────────────────────────────────────────────────────┤
│ 🚨 FINAL VERDICT: PASS                                              │
│ ➡️ Clear to proceed to BUILD mode                                   │
╚═════════════════════════════════════════════════════════════════════╝
"@
    
    # Save validation status (used by BUILD mode prevention mechanism)
    "PASS" | Set-Content -Path "memory-bank\.qa_validation_status"
    
    return $report
}
```

## ❌ FAILURE REPORT FORMAT

If any validation step fails, generate this detailed failure report:

```
⚠️⚠️⚠️ QA VALIDATION FAILED ⚠️⚠️⚠️

The following issues must be resolved before proceeding to BUILD mode:

1️⃣ DEPENDENCY ISSUES:
- [Detailed description of dependency issues]
- [Recommended fix]

2️⃣ CONFIGURATION ISSUES:
- [Detailed description of configuration issues]
- [Recommended fix]

3️⃣ ENVIRONMENT ISSUES:
- [Detailed description of environment issues]
- [Recommended fix]

4️⃣ BUILD TEST ISSUES:
- [Detailed description of build test issues]
- [Recommended fix]

⚠️ BUILD MODE IS BLOCKED until these issues are resolved.
Type 'VAN QA' after fixing the issues to re-validate.
```

### Failure Report Generation Example:
```powershell
function Generate-FailureReport {
    param (
        [string[]]$DependencyIssues = @(),
        [string[]]$ConfigIssues = @(),
        [string[]]$EnvironmentIssues = @(),
        [string[]]$BuildIssues = @()
    )
    
    $report = @"
⚠️⚠️⚠️ QA VALIDATION FAILED ⚠️⚠️⚠️

The following issues must be resolved before proceeding to BUILD mode:

"@
    
    if ($DependencyIssues.Count -gt 0) {
        $report += @"
1️⃣ DEPENDENCY ISSUES:
$(($DependencyIssues | ForEach-Object { "- $_" }) -join "`n")

"@
    }
    
    if ($ConfigIssues.Count -gt 0) {
        $report += @"
2️⃣ CONFIGURATION ISSUES:
$(($ConfigIssues | ForEach-Object { "- $_" }) -join "`n")

"@
    }
    
    if ($EnvironmentIssues.Count -gt 0) {
        $report += @"
3️⃣ ENVIRONMENT ISSUES:
$(($EnvironmentIssues | ForEach-Object { "- $_" }) -join "`n")

"@
    }
    
    if ($BuildIssues.Count -gt 0) {
        $report += @"
4️⃣ BUILD TEST ISSUES:
$(($BuildIssues | ForEach-Object { "- $_" }) -join "`n")

"@
    }
    
    $report += @"
⚠️ BUILD MODE IS BLOCKED until these issues are resolved.
Type 'VAN QA' after fixing the issues to re-validate.
"@
    
    # Save validation status (used by BUILD mode prevention mechanism)
    "FAIL" | Set-Content -Path "memory-bank\.qa_validation_status"
    
    return $report
}
```

**Next Step (on SUCCESS):** Load `van-qa-utils/mode-transitions.mdc` to handle BUILD mode transition.
**Next Step (on FAILURE):** Load `van-qa-utils/common-fixes.mdc` for issue remediation guidance.

================
File: .cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-utils/rule-calling-guide.mdc
================
---
description: Comprehensive guide for calling VAN QA rules
globs: van-qa-utils/rule-calling-guide.mdc
alwaysApply: false
---
# VAN QA: COMPREHENSIVE RULE CALLING GUIDE

> **TL;DR:** This reference guide shows how to properly call all VAN QA rules at the right time during the validation process.

## 🔍 RULE CALLING BASICS

Remember these key principles:
1. Always use the `fetch_rules` tool to load rules
2. Use exact rule paths
3. Load components only when needed

## 📋 MAIN QA ENTRY POINT

When user types "VAN QA", load the main entry point:

```
fetch_rules with "isolation_rules/visual-maps/van-qa-main"
```

## 📋 VALIDATION CHECKS

Load these components sequentially during validation:

```
1. fetch_rules with "isolation_rules/visual-maps/van-qa-checks/dependency-check"
2. fetch_rules with "isolation_rules/visual-maps/van-qa-checks/config-check"
3. fetch_rules with "isolation_rules/visual-maps/van-qa-checks/environment-check"
4. fetch_rules with "isolation_rules/visual-maps/van-qa-checks/build-test"
```

## 📋 UTILITY COMPONENTS

Load these when needed based on validation results:

```
- For reports: fetch_rules with "isolation_rules/visual-maps/van-qa-utils/reports"
- For fixes: fetch_rules with "isolation_rules/visual-maps/van-qa-utils/common-fixes"
- For transitions: fetch_rules with "isolation_rules/visual-maps/van-qa-utils/mode-transitions"
```

## ⚠️ CRITICAL REMINDERS

Remember to call these rules at these specific points:
- ALWAYS load the main QA entry point when "VAN QA" is typed
- ALWAYS load dependency-check before starting validation
- ALWAYS load reports after completing validation
- ALWAYS load mode-transitions after successful validation
- ALWAYS load common-fixes after failed validation

## 🔄 FULL VALIDATION SEQUENCE

Complete sequence for a QA validation process:

1. Load main entry: `isolation_rules/visual-maps/van-qa-main`
2. Load first check: `isolation_rules/visual-maps/van-qa-checks/dependency-check`
3. Load second check: `isolation_rules/visual-maps/van-qa-checks/config-check`
4. Load third check: `isolation_rules/visual-maps/van-qa-checks/environment-check`
5. Load fourth check: `isolation_rules/visual-maps/van-qa-checks/build-test`
6. If pass, load: `isolation_rules/visual-maps/van-qa-utils/reports`
7. If pass, load: `isolation_rules/visual-maps/van-qa-utils/mode-transitions` 
8. If fail, load: `isolation_rules/visual-maps/van-qa-utils/common-fixes`

================
File: .cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-utils/rule-calling-help.mdc
================
---
description: Utility for remembering how to call VAN QA rules
globs: van-qa-utils/rule-calling-help.mdc
alwaysApply: false
---
# VAN QA: HOW TO CALL RULES

> **TL;DR:** This file provides examples and reminders on how to properly call VAN QA rules using the fetch_rules tool.

## 🚨 RULE CALLING SYNTAX

Always use the `fetch_rules` tool with the correct syntax:

```
<function_calls>
<invoke name="fetch_rules">
<parameter name="rule_names">["isolation_rules/visual-maps/rule-name"]
</invoke>
</function_calls>

================
File: .cursor/rules/isolation_rules/visual-maps/van_mode_split/van-qa-validation.md.old
================
# VAN MODE: QA TECHNICAL VALIDATION (Pre-BUILD)

> **TL;DR:** This map details the technical validation process executed *after* CREATIVE mode and *before* BUILD mode, triggered by the `VAN QA` command. It ensures dependencies, configuration, environment, and basic build functionality are sound.

## 🚀 VAN QA MODE ACTIVATION

After completing CREATIVE mode, when the user types "VAN QA", respond:

```
User: VAN QA

Response: OK VAN QA - Beginning Technical Validation
Loading QA Validation map...
```

## 🔄 QA COMMAND PRECEDENCE (QA Override)

QA validation can be called at any point (`QA` command) and takes immediate precedence:

```mermaid
graph TD
    UserQA["User Types: QA"] --> HighPriority["⚠️ HIGH PRIORITY COMMAND"]
    HighPriority --> CurrentTask["Pause Current Task/Process"]
    CurrentTask --> LoadQA["Load QA Validation Map (This File)"]
    LoadQA --> RunQA["Execute QA Validation Process"]
    RunQA --> QAResults{"QA Results"}
    
    QAResults -->|"PASS"| ResumeFlow["Resume Prior Process Flow"]
    QAResults -->|"FAIL"| FixIssues["Fix Identified Issues"]
    FixIssues --> ReRunQA["Re-run QA Validation"]
    ReRunQA --> QAResults
    
    style UserQA fill:#f8d486,stroke:#e8b84d,color:black
    style HighPriority fill:#ff0000,stroke:#cc0000,color:white,stroke-width:3px
    style LoadQA fill:#4da6ff,stroke:#0066cc,color:white
    style RunQA fill:#4da6ff,stroke:#0066cc,color:white
    style QAResults fill:#f6546a,stroke:#c30052,color:white
```

### QA Interruption Rules

1. **Immediate Precedence:** `QA` command interrupts everything.
2. **Load & Execute:** Load this map (`van-qa-validation.mdc`) and run the full process.
3. **Remediation Priority:** Fixes take priority over pending mode switches.
4. **Resume:** On PASS, resume the previous flow.

```
⚠️ QA OVERRIDE ACTIVATED
All other processes paused
QA validation checks now running...
Any issues found MUST be remediated before continuing with normal process flow
```

## 🔍 TECHNICAL VALIDATION OVERVIEW

Four-point validation process:

```mermaid
graph TD
    VANQA["VAN QA MODE"] --> FourChecks["FOUR-POINT VALIDATION"]
    
    FourChecks --> DepCheck["1️⃣ DEPENDENCY VERIFICATION"]
    DepCheck --> ConfigCheck["2️⃣ CONFIGURATION VALIDATION"]
    ConfigCheck --> EnvCheck["3️⃣ ENVIRONMENT VALIDATION"]
    EnvCheck --> MinBuildCheck["4️⃣ MINIMAL BUILD TEST"]
    
    MinBuildCheck --> ValidationResults{"All Checks<br>Passed?"}
    ValidationResults -->|"Yes"| SuccessReport["GENERATE SUCCESS REPORT"]
    ValidationResults -->|"No"| FailureReport["GENERATE FAILURE REPORT"]
    
    SuccessReport --> BUILD_Transition["Trigger BUILD Mode"]
    FailureReport --> FixIssues["Fix Technical Issues"]
    FixIssues --> ReValidate["Re-validate (Re-run VAN QA)"]
    ReValidate --> FourChecks
    
    style VANQA fill:#4da6ff,stroke:#0066cc,color:white
    style FourChecks fill:#f6546a,stroke:#c30052,color:white
    style ValidationResults fill:#f6546a,stroke:#c30052,color:white
    style BUILD_Transition fill:#10b981,stroke:#059669,color:white
    style FixIssues fill:#ff5555,stroke:#dd3333,color:white
```

## 🔄 INTEGRATION WITH DESIGN DECISIONS

Reads Creative Phase outputs (e.g., `memory-bank/systemPatterns.md`) to inform validation:

```mermaid
graph TD
    Start["Read Design Decisions"] --> ReadCreative["Parse Creative Phase<br>Documentation"]
    ReadCreative --> ExtractTech["Extract Technology<br>Choices"]
    ExtractTech --> ExtractDeps["Extract Required<br>Dependencies"]
    ExtractDeps --> BuildValidationPlan["Build Validation<br>Plan"]
    BuildValidationPlan --> StartValidation["Start Four-Point<br>Validation Process"]
    
    style Start fill:#4da6ff,stroke:#0066cc,color:white
    style ExtractTech fill:#f6546a,stroke:#c30052,color:white
    style BuildValidationPlan fill:#10b981,stroke:#059669,color:white
    style StartValidation fill:#f6546a,stroke:#c30052,color:white
```

### Example Technology Extraction (PowerShell):
```powershell
# Example: Extract technology choices from creative phase documentation
function Extract-TechnologyChoices {
    $techChoices = @{}
    # Read from systemPatterns.md
    if (Test-Path "memory-bank\systemPatterns.md") {
        $content = Get-Content "memory-bank\systemPatterns.md" -Raw
        if ($content -match "Framework:\s*(\w+)") { $techChoices["framework"] = $Matches[1] }
        if ($content -match "UI Library:\s*(\w+)") { $techChoices["ui_library"] = $Matches[1] }
        if ($content -match "State Management:\s*([^\n]+)") { $techChoices["state_management"] = $Matches[1].Trim() }
    }
    return $techChoices
}
```

## 🔍 DETAILED QA VALIDATION STEPS & SCRIPTS

### 1️⃣ DEPENDENCY VERIFICATION

```mermaid
# Mermaid graph for Dependency Verification (as in original file)
graph TD
    Start["Dependency Verification"] --> ReadDeps["Read Required Dependencies<br>from Creative Phase"]
    ReadDeps --> CheckInstalled["Check if Dependencies<br>are Installed"]
    CheckInstalled --> DepStatus{"All Dependencies<br>Installed?"}
    DepStatus -->|"Yes"| VerifyVersions["Verify Versions<br>and Compatibility"]
    DepStatus -->|"No"| InstallMissing["Install Missing<br>Dependencies"]
    InstallMissing --> VerifyVersions
    VerifyVersions --> VersionStatus{"Versions<br>Compatible?"}
    VersionStatus -->|"Yes"| DepSuccess["Dependencies Verified<br>✅ PASS"]
    VersionStatus -->|"No"| UpgradeVersions["Upgrade/Downgrade<br>as Needed"]
    UpgradeVersions --> RetryVerify["Retry Verification"]
    RetryVerify --> VersionStatus
    style Start fill:#4da6ff; style DepSuccess fill:#10b981; style DepStatus fill:#f6546a; style VersionStatus fill:#f6546a;
```

#### Example Implementation (PowerShell):
```powershell
# Verify-Dependencies function (as in original file)
function Verify-Dependencies {
    $requiredDeps = @{ "node" = ">=14.0.0"; "npm" = ">=6.0.0" }
    $missingDeps = @(); $incompatibleDeps = @()
    try { $nodeVersion = node -v; if ($nodeVersion -match "v(\d+).*") { if ([int]$Matches[1] -lt 14) { $incompatibleDeps += "node" } } } catch { $missingDeps += "node" }
    try { $npmVersion = npm -v; if ($npmVersion -match "(\d+).*") { if ([int]$Matches[1] -lt 6) { $incompatibleDeps += "npm" } } } catch { $missingDeps += "npm" }
    if ($missingDeps.Count -eq 0 -and $incompatibleDeps.Count -eq 0) { Write-Output "✅ Deps OK"; return $true } else { Write-Output "❌ Deps FAIL"; return $false }
}
```

#### Example Implementation (Bash):
```bash
# verify_dependencies function (as in original file)
verify_dependencies() {
    local missing_deps=(); local incompatible_deps=()
    if command -v node &> /dev/null; then node_version=$(node -v); if [[ $node_version =~ v([0-9]+) ]]; then if (( ${BASH_REMATCH[1]} < 14 )); then incompatible_deps+=("node"); fi; fi; else missing_deps+=("node"); fi
    if command -v npm &> /dev/null; then npm_version=$(npm -v); if [[ $npm_version =~ ([0-9]+) ]]; then if (( ${BASH_REMATCH[1]} < 6 )); then incompatible_deps+=("npm"); fi; fi; else missing_deps+=("npm"); fi
    if [ ${#missing_deps[@]} -eq 0 ] && [ ${#incompatible_deps[@]} -eq 0 ]; then echo "✅ Deps OK"; return 0; else echo "❌ Deps FAIL"; return 1; fi
}
```

### 2️⃣ CONFIGURATION VALIDATION

```mermaid
# Mermaid graph for Configuration Validation (as in original file)
graph TD
    Start["Configuration Validation"] --> IdentifyConfigs["Identify Files"]
    IdentifyConfigs --> ReadConfigs["Read Files"]
    ReadConfigs --> ValidateSyntax["Validate Syntax"]
    ValidateSyntax --> SyntaxStatus{"Valid?"}
    SyntaxStatus -->|"Yes"| CheckCompatibility["Check Compatibility"]
    SyntaxStatus -->|"No"| FixSyntax["Fix Syntax"]
    FixSyntax --> RetryValidate["Retry"]
    RetryValidate --> SyntaxStatus
    CheckCompatibility --> CompatStatus{"Compatible?"}
    CompatStatus -->|"Yes"| ConfigSuccess["Configs Validated ✅ PASS"]
    CompatStatus -->|"No"| AdaptConfigs["Adapt Configs"]
    AdaptConfigs --> RetryCompat["Retry Check"]
    RetryCompat --> CompatStatus
    style Start fill:#4da6ff; style ConfigSuccess fill:#10b981; style SyntaxStatus fill:#f6546a; style CompatStatus fill:#f6546a;
```

#### Example Implementation (PowerShell):
```powershell
# Validate-Configurations function (as in original file)
function Validate-Configurations {
    $configFiles = @("package.json", "tsconfig.json", "vite.config.js")
    $invalidConfigs = @(); $incompatibleConfigs = @()
    foreach ($configFile in $configFiles) {
        if (Test-Path $configFile) {
            if ($configFile -match "\.json$") { try { Get-Content $configFile -Raw | ConvertFrom-Json | Out-Null } catch { $invalidConfigs += "$configFile (JSON)"; continue } }
            if ($configFile -eq "vite.config.js") { $content = Get-Content $configFile -Raw; if ($content -notmatch "react\(\)") { $incompatibleConfigs += "$configFile (React)" } }
        } else { $invalidConfigs += "$configFile (missing)" }
    }
    if ($invalidConfigs.Count -eq 0 -and $incompatibleConfigs.Count -eq 0) { Write-Output "✅ Configs OK"; return $true } else { Write-Output "❌ Configs FAIL"; return $false }
}
```

### 3️⃣ ENVIRONMENT VALIDATION

```mermaid
# Mermaid graph for Environment Validation (as in original file)
graph TD
    Start["Environment Validation"] --> CheckEnv["Check Env"]
    CheckEnv --> VerifyBuildTools["Verify Tools"]
    VerifyBuildTools --> ToolsStatus{"Available?"}
    ToolsStatus -->|"Yes"| CheckPerms["Check Permissions"]
    ToolsStatus -->|"No"| InstallTools["Install Tools"]
    InstallTools --> RetryTools["Retry"]
    RetryTools --> ToolsStatus
    CheckPerms --> PermsStatus{"Sufficient?"}
    PermsStatus -->|"Yes"| EnvSuccess["Environment Validated ✅ PASS"]
    PermsStatus -->|"No"| FixPerms["Fix Permissions"]
    FixPerms --> RetryPerms["Retry Check"]
    RetryPerms --> PermsStatus
    style Start fill:#4da6ff; style EnvSuccess fill:#10b981; style ToolsStatus fill:#f6546a; style PermsStatus fill:#f6546a;
```

#### Example Implementation (PowerShell):
```powershell
# Validate-Environment function (as in original file)
function Validate-Environment {
    $requiredTools = @(@{Name='git';Cmd='git --version'},@{Name='node';Cmd='node --version'},@{Name='npm';Cmd='npm --version'})
    $missingTools = @(); $permissionIssues = @()
    foreach ($tool in $requiredTools) { try { Invoke-Expression $tool.Cmd | Out-Null } catch { $missingTools += $tool.Name } }
    try { $testFile = ".__perm_test"; New-Item $testFile -ItemType File -Force | Out-Null; Remove-Item $testFile -Force } catch { $permissionIssues += "CWD Write" }
    try { $L = New-Object Net.Sockets.TcpListener([Net.IPAddress]::Loopback, 3000); $L.Start(); $L.Stop() } catch { $permissionIssues += "Port 3000" }
    if ($missingTools.Count -eq 0 -and $permissionIssues.Count -eq 0) { Write-Output "✅ Env OK"; return $true } else { Write-Output "❌ Env FAIL"; return $false }
}
```

### 4️⃣ MINIMAL BUILD TEST

```mermaid
# Mermaid graph for Minimal Build Test (as in original file)
graph TD
    Start["Minimal Build Test"] --> CreateTest["Create Test Proj"]
    CreateTest --> BuildTest["Attempt Build"]
    BuildTest --> BuildStatus{"Success?"}
    BuildStatus -->|"Yes"| RunTest["Run Basic Test"]
    BuildStatus -->|"No"| FixBuild["Fix Build Issues"]
    FixBuild --> RetryBuild["Retry Build"]
    RetryBuild --> BuildStatus
    RunTest --> TestStatus{"Passed?"}
    TestStatus -->|"Yes"| TestSuccess["Build Test ✅ PASS"]
    TestStatus -->|"No"| FixTest["Fix Test Issues"]
    FixTest --> RetryTest["Retry Test"]
    RetryTest --> TestStatus
    style Start fill:#4da6ff; style TestSuccess fill:#10b981; style BuildStatus fill:#f6546a; style TestStatus fill:#f6546a;
```

#### Example Implementation (PowerShell):
```powershell
# Perform-MinimalBuildTest function (as in original file)
function Perform-MinimalBuildTest {
    $buildSuccess = $false; $testSuccess = $false; $testDir = ".__build_test"
    if (Test-Path $testDir) { Remove-Item $testDir -Recurse -Force }
    try {
        New-Item $testDir -ItemType Directory | Out-Null; Push-Location $testDir
        '{"name": "build-test","scripts": {"build": "echo Build test successful"}}' | Set-Content package.json
        npm run build | Out-Null; $buildSuccess = $true
        'console.log("Test successful");' | Set-Content index.js
        node index.js | Out-Null; $testSuccess = $true
    } catch { Write-Output "❌ Build test exception" } finally { Pop-Location; if (Test-Path $testDir) { Remove-Item $testDir -Recurse -Force } }
    if ($buildSuccess -and $testSuccess) { Write-Output "✅ Build Test OK"; return $true } else { Write-Output "❌ Build Test FAIL"; return $false }
}
```

## 📝 VALIDATION REPORT FORMATS

### Comprehensive Success Report:
```
╔═════════════════════ 🔍 QA VALIDATION REPORT ══════════════════════╗
│ PROJECT: [Project Name] | TIMESTAMP: [Current Date/Time]            │
├─────────────────────────────────────────────────────────────────────┤
│ 1️⃣ DEPENDENCIES: ✓ Compatible                                       │
│ 2️⃣ CONFIGURATION: ✓ Valid & Compatible                             │
│ 3️⃣ ENVIRONMENT: ✓ Ready                                             │
│ 4️⃣ MINIMAL BUILD: ✓ Successful & Passed                            │
├─────────────────────────────────────────────────────────────────────┤
│ 🚨 FINAL VERDICT: PASS                                              │
│ ➡️ Clear to proceed to BUILD mode                                   │
╚═════════════════════════════════════════════════════════════════════╝
```

### Detailed Failure Report:
```
⚠️⚠️⚠️ QA VALIDATION FAILED ⚠️⚠️⚠️
Issues must be resolved before BUILD mode:

1️⃣ DEPENDENCY ISSUES: [Details/Fix]
2️⃣ CONFIGURATION ISSUES: [Details/Fix]
3️⃣ ENVIRONMENT ISSUES: [Details/Fix]
4️⃣ BUILD TEST ISSUES: [Details/Fix]

⚠️ BUILD MODE BLOCKED. Type 'VAN QA' after fixing to re-validate.
```

## 🧪 COMMON QA VALIDATION FIXES

- **Dependencies:** Install Node/npm, run `npm install`, check versions.
- **Configuration:** Validate JSON, check required plugins (e.g., React for Vite), ensure TSConfig compatibility.
- **Environment:** Check permissions (Admin/sudo), ensure ports are free, install missing CLI tools (git, etc.).
- **Build Test:** Check logs for errors, verify minimal config, check path separators.

## 🔒 BUILD MODE PREVENTION MECHANISM

Logic to check QA status before allowing BUILD mode transition.

```mermaid
graph TD
    Start["User Types: BUILD"] --> CheckQA{"QA Validation<br>Passed?"}
    CheckQA -->|"Yes"| AllowBuild["Allow BUILD Mode"]
    CheckQA -->|"No"| BlockBuild["BLOCK BUILD MODE"]
    BlockBuild --> Message["Display:<br>⚠️ QA VALIDATION REQUIRED"]
    Message --> ReturnToVANQA["Prompt: Type VAN QA"]
    
    style CheckQA fill:#f6546a; style BlockBuild fill:#ff0000,stroke:#990000; style Message fill:#ff5555; style ReturnToVANQA fill:#4da6ff;
```

### Example Implementation (PowerShell):
```powershell
# Example: Check QA status before allowing BUILD
function Check-QAValidationStatus {
    $qaStatusFile = "memory-bank\.qa_validation_status" # Assumes status is written here
    if (Test-Path $qaStatusFile) {
        if ((Get-Content $qaStatusFile -Raw) -match "PASS") { return $true }
    }
    Write-Output "🚫 BUILD MODE BLOCKED: QA VALIDATION REQUIRED. Type 'VAN QA'. 🚫"
    return $false
}
```

## 🚨 MODE TRANSITION TRIGGERS (Relevant to QA)

### CREATIVE to VAN QA Transition:
```
⏭️ NEXT MODE: VAN QA
To validate technical requirements before implementation, please type 'VAN QA'
```

### VAN QA to BUILD Transition (On Success):
```
✅ TECHNICAL VALIDATION COMPLETE
All prerequisites verified successfully
You may now proceed to BUILD mode
Type 'BUILD' to begin implementation
```

## 📋 FINAL QA VALIDATION CHECKPOINT

```
✓ SECTION CHECKPOINT: QA VALIDATION
- Dependency Verification Passed? [YES/NO]
- Configuration Validation Passed? [YES/NO]
- Environment Validation Passed? [YES/NO]
- Minimal Build Test Passed? [YES/NO]

→ If all YES: Ready for BUILD mode transition.
→ If any NO: Fix identified issues and re-run VAN QA.
```

**Next Step (on PASS):** Trigger BUILD mode.
**Next Step (on FAIL):** Address issues and re-run `VAN QA`.

================
File: .cursor/rules/isolation_rules/visual-maps/van-mode-map.mdc
================
---
description: Visual process map for VAN mode (Initialization)
globs: van-mode-map.mdc
alwaysApply: false
---
# VAN MODE: INITIALIZATION PROCESS MAP

> **TL;DR:** This visual map defines the VAN mode process for project initialization, task analysis, and technical validation. It guides users through platform detection, file verification, complexity determination, and technical validation to ensure proper setup before implementation.

## 🧭 VAN MODE PROCESS FLOW

```mermaid
graph TD
    Start["START VAN MODE"] --> PlatformDetect["PLATFORM DETECTION"]
    PlatformDetect --> DetectOS["Detect Operating System"]
    DetectOS --> CheckPath["Check Path Separator Format"]
    CheckPath --> AdaptCmds["Adapt Commands if Needed"]
    AdaptCmds --> PlatformCP["⛔ PLATFORM CHECKPOINT"]
    
    %% Basic File Verification with checkpoint
    PlatformCP --> BasicFileVerify["BASIC FILE VERIFICATION"]
    BasicFileVerify --> BatchCheck["Batch Check Essential Components"]
    BatchCheck --> BatchCreate["Batch Create Essential Structure"]
    BatchCreate --> BasicFileCP["⛔ BASIC FILE CHECKPOINT"]
    
    %% Early Complexity Determination
    BasicFileCP --> EarlyComplexity["EARLY COMPLEXITY DETERMINATION"]
    EarlyComplexity --> AnalyzeTask["Analyze Task Requirements"]
    AnalyzeTask --> EarlyLevelCheck{"Complexity Level?"}
    
    %% Level handling paths
    EarlyLevelCheck -->|"Level 1"| ComplexityCP["⛔ COMPLEXITY CHECKPOINT"]
    EarlyLevelCheck -->|"Level 2-4"| CRITICALGATE["🚫 CRITICAL GATE: FORCE MODE SWITCH"]
    CRITICALGATE --> ForceExit["Exit to PLAN mode"]
    
    %% Level 1 continues normally
    ComplexityCP --> InitSystem["INITIALIZE MEMORY BANK"]
    InitSystem --> Complete1["LEVEL 1 INITIALIZATION COMPLETE"]
    
    %% For Level 2+ tasks after PLAN and CREATIVE modes
    ForceExit -.-> OtherModes["PLAN → CREATIVE modes"]
    OtherModes -.-> VANQA["VAN QA MODE"]
    VANQA --> QAProcess["Technical Validation Process"]
    QAProcess --> QACheck{"All Checks Pass?"}
    QACheck -->|"Yes"| BUILD["To BUILD MODE"]
    QACheck -->|"No"| FixIssues["Fix Technical Issues"]
    FixIssues --> QAProcess
    
    %% Style nodes
    style PlatformCP fill:#f55,stroke:#d44,color:white
    style BasicFileCP fill:#f55,stroke:#d44,color:white
    style ComplexityCP fill:#f55,stroke:#d44,color:white
    style CRITICALGATE fill:#ff0000,stroke:#990000,color:white,stroke-width:3px
    style ForceExit fill:#ff0000,stroke:#990000,color:white,stroke-width:2px
    style VANQA fill:#4da6ff,stroke:#0066cc,color:white,stroke-width:3px
    style QAProcess fill:#4da6ff,stroke:#0066cc,color:white
    style QACheck fill:#4da6ff,stroke:#0066cc,color:white
    style FixIssues fill:#ff5555,stroke:#dd3333,color:white
```

## 🌐 PLATFORM DETECTION PROCESS

```mermaid
graph TD
    PD["Platform Detection"] --> CheckOS["Detect Operating System"]
    CheckOS --> Win["Windows"]
    CheckOS --> Mac["macOS"]
    CheckOS --> Lin["Linux"]
    
    Win & Mac & Lin --> Adapt["Adapt Commands<br>for Platform"]
    
    Win --> WinPath["Path: Backslash (\\)"]
    Mac --> MacPath["Path: Forward Slash (/)"]
    Lin --> LinPath["Path: Forward Slash (/)"]
    
    Win --> WinCmd["Command Adaptations:<br>dir, icacls, etc."]
    Mac --> MacCmd["Command Adaptations:<br>ls, chmod, etc."]
    Lin --> LinCmd["Command Adaptations:<br>ls, chmod, etc."]
    
    WinPath & MacPath & LinPath --> PathCP["Path Separator<br>Checkpoint"]
    WinCmd & MacCmd & LinCmd --> CmdCP["Command<br>Checkpoint"]
    
    PathCP & CmdCP --> PlatformComplete["Platform Detection<br>Complete"]
    
    style PD fill:#4da6ff,stroke:#0066cc,color:white
    style PlatformComplete fill:#10b981,stroke:#059669,color:white
```

## 📁 FILE VERIFICATION PROCESS

```mermaid
graph TD
    FV["File Verification"] --> CheckFiles["Check Essential Files"]
    CheckFiles --> CheckMB["Check Memory Bank<br>Structure"]
    CheckMB --> MBExists{"Memory Bank<br>Exists?"}
    
    MBExists -->|"Yes"| VerifyMB["Verify Memory Bank<br>Contents"]
    MBExists -->|"No"| CreateMB["Create Memory Bank<br>Structure"]
    
    CheckFiles --> CheckDocs["Check Documentation<br>Files"]
    CheckDocs --> DocsExist{"Docs<br>Exist?"}
    
    DocsExist -->|"Yes"| VerifyDocs["Verify Documentation<br>Structure"]
    DocsExist -->|"No"| CreateDocs["Create Documentation<br>Structure"]
    
    VerifyMB & CreateMB --> MBCP["Memory Bank<br>Checkpoint"]
    VerifyDocs & CreateDocs --> DocsCP["Documentation<br>Checkpoint"]
    
    MBCP & DocsCP --> FileComplete["File Verification<br>Complete"]
    
    style FV fill:#4da6ff,stroke:#0066cc,color:white
    style FileComplete fill:#10b981,stroke:#059669,color:white
    style MBCP fill:#f6546a,stroke:#c30052,color:white
    style DocsCP fill:#f6546a,stroke:#c30052,color:white
```

## 🧩 COMPLEXITY DETERMINATION PROCESS

```mermaid
graph TD
    CD["Complexity<br>Determination"] --> AnalyzeTask["Analyze Task<br>Requirements"]
    
    AnalyzeTask --> CheckKeywords["Check Task<br>Keywords"]
    CheckKeywords --> ScopeCheck["Assess<br>Scope Impact"]
    ScopeCheck --> RiskCheck["Evaluate<br>Risk Level"]
    RiskCheck --> EffortCheck["Estimate<br>Implementation Effort"]
    
    EffortCheck --> DetermineLevel{"Determine<br>Complexity Level"}
    DetermineLevel -->|"Level 1"| L1["Level 1:<br>Quick Bug Fix"]
    DetermineLevel -->|"Level 2"| L2["Level 2:<br>Simple Enhancement"]
    DetermineLevel -->|"Level 3"| L3["Level 3:<br>Intermediate Feature"]
    DetermineLevel -->|"Level 4"| L4["Level 4:<br>Complex System"]
    
    L1 --> CDComplete["Complexity Determination<br>Complete"]
    L2 & L3 & L4 --> ModeSwitch["Force Mode Switch<br>to PLAN"]
    
    style CD fill:#4da6ff,stroke:#0066cc,color:white
    style CDComplete fill:#10b981,stroke:#059669,color:white
    style ModeSwitch fill:#ff0000,stroke:#990000,color:white
    style DetermineLevel fill:#f6546a,stroke:#c30052,color:white
```

## 🔄 COMPLETE WORKFLOW WITH QA VALIDATION

The full workflow includes technical validation before implementation:

```mermaid
flowchart LR
    VAN1["VAN MODE 
    (Initial Analysis)"] --> PLAN["PLAN MODE
    (Task Planning)"]
    PLAN --> CREATIVE["CREATIVE MODE
    (Design Decisions)"]
    CREATIVE --> VANQA["VAN QA MODE
    (Technical Validation)"] 
    VANQA --> BUILD["BUILD MODE
    (Implementation)"]
```

## 🔍 TECHNICAL VALIDATION OVERVIEW

The VAN QA technical validation process consists of four key validation points:

```mermaid
graph TD
    VANQA["VAN QA MODE"] --> FourChecks["FOUR-POINT VALIDATION"]
    
    FourChecks --> DepCheck["1️⃣ DEPENDENCY VERIFICATION<br>Check all required packages"]
    DepCheck --> ConfigCheck["2️⃣ CONFIGURATION VALIDATION<br>Verify format & compatibility"]
    ConfigCheck --> EnvCheck["3️⃣ ENVIRONMENT VALIDATION<br>Check build environment"]
    EnvCheck --> MinBuildCheck["4️⃣ MINIMAL BUILD TEST<br>Test core functionality"]
    
    MinBuildCheck --> ValidationResults{"All Checks<br>Passed?"}
    ValidationResults -->|"Yes"| SuccessReport["GENERATE SUCCESS REPORT"]
    ValidationResults -->|"No"| FailureReport["GENERATE FAILURE REPORT"]
    
    SuccessReport --> BUILD["Proceed to BUILD MODE"]
    FailureReport --> FixIssues["Fix Technical Issues"]
    FixIssues --> ReValidate["Re-validate"]
    ReValidate --> ValidationResults
    
    style VANQA fill:#4da6ff,stroke:#0066cc,color:white
    style FourChecks fill:#f6546a,stroke:#c30052,color:white
    style ValidationResults fill:#f6546a,stroke:#c30052,color:white
    style BUILD fill:#10b981,stroke:#059669,color:white
    style FixIssues fill:#ff5555,stroke:#dd3333,color:white
```

## 📝 VALIDATION STATUS FORMAT

The QA Validation step includes clear status indicators:

```
╔═════════════════ 🔍 QA VALIDATION STATUS ═════════════════╗
│ ✓ Design Decisions   │ Verified as implementable          │
│ ✓ Dependencies       │ All required packages installed    │
│ ✓ Configurations     │ Format verified for platform       │
│ ✓ Environment        │ Suitable for implementation        │
╚════════════════════════════════════════════════════════════╝
✅ VERIFIED - Clear to proceed to BUILD mode
```

## 🚨 MODE TRANSITION TRIGGERS

### VAN to PLAN Transition
For complexity levels 2-4:
```
🚫 LEVEL [2-4] TASK DETECTED
Implementation in VAN mode is BLOCKED
This task REQUIRES PLAN mode
You MUST switch to PLAN mode for proper documentation and planning
Type 'PLAN' to switch to planning mode
```

### CREATIVE to VAN QA Transition
After completing the CREATIVE mode:
```
⏭️ NEXT MODE: VAN QA
To validate technical requirements before implementation, please type 'VAN QA'
```

### VAN QA to BUILD Transition
After successful validation:
```
✅ TECHNICAL VALIDATION COMPLETE
All prerequisites verified successfully
You may now proceed to BUILD mode
Type 'BUILD' to begin implementation
```

## 🔒 BUILD MODE PREVENTION MECHANISM

The system prevents moving to BUILD mode without passing QA validation:

```mermaid
graph TD
    Start["User Types: BUILD"] --> CheckQA{"QA Validation<br>Completed?"}
    CheckQA -->|"Yes and Passed"| AllowBuild["Allow BUILD Mode"]
    CheckQA -->|"No or Failed"| BlockBuild["BLOCK BUILD MODE"]
    BlockBuild --> Message["Display:<br>⚠️ QA VALIDATION REQUIRED"]
    Message --> ReturnToVANQA["Prompt: Type VAN QA"]
    
    style CheckQA fill:#f6546a,stroke:#c30052,color:white
    style BlockBuild fill:#ff0000,stroke:#990000,color:white,stroke-width:3px
    style Message fill:#ff5555,stroke:#dd3333,color:white
    style ReturnToVANQA fill:#4da6ff,stroke:#0066cc,color:white
```

## 🔄 QA COMMAND PRECEDENCE

QA validation can be called at any point in the process flow, and takes immediate precedence over any other current steps, including forced mode switches:

```mermaid
graph TD
    UserQA["User Types: QA"] --> HighPriority["⚠️ HIGH PRIORITY COMMAND"]
    HighPriority --> CurrentTask["Pause Current Task/Process"]
    CurrentTask --> LoadQA["Load QA Mode Map"]
    LoadQA --> RunQA["Execute QA Validation Process"]
    RunQA --> QAResults{"QA Results"}
    
    QAResults -->|"PASS"| ResumeFlow["Resume Prior Process Flow"]
    QAResults -->|"FAIL"| FixIssues["Fix Identified Issues"]
    FixIssues --> ReRunQA["Re-run QA Validation"]
    ReRunQA --> QAResults
    
    style UserQA fill:#f8d486,stroke:#e8b84d,color:black
    style HighPriority fill:#ff0000,stroke:#cc0000,color:white,stroke-width:3px
    style LoadQA fill:#4da6ff,stroke:#0066cc,color:white
    style RunQA fill:#4da6ff,stroke:#0066cc,color:white
    style QAResults fill:#f6546a,stroke:#c30052,color:white
```

### QA Interruption Rules

When a user types **QA** at any point:

1. **The QA command MUST take immediate precedence** over any current operation, including the "FORCE MODE SWITCH" triggered by complexity assessment.
2. The system MUST:
   - Immediately load the QA mode map
   - Execute the full QA validation process
   - Address any failures before continuing
3. **Required remediation steps take priority** over any pending mode switches or complexity rules
4. After QA validation is complete and passes:
   - Resume the previously determined process flow
   - Continue with any required mode switches

```
⚠️ QA OVERRIDE ACTIVATED
All other processes paused
QA validation checks now running...
Any issues found MUST be remediated before continuing with normal process flow
```

## 📋 CHECKPOINT VERIFICATION TEMPLATE

Each major checkpoint in VAN mode uses this format:

```
✓ SECTION CHECKPOINT: [SECTION NAME]
- Requirement 1? [YES/NO]
- Requirement 2? [YES/NO]
- Requirement 3? [YES/NO]

→ If all YES: Ready for next section
→ If any NO: Fix missing items before proceeding
```

## 🚀 VAN MODE ACTIVATION

When the user types "VAN", respond with a confirmation and start the process:

```
User: VAN

Response: OK VAN - Beginning Initialization Process
```

After completing CREATIVE mode, when the user types "VAN QA", respond:

```
User: VAN QA

Response: OK VAN QA - Beginning Technical Validation
```

This ensures clear communication about which phase of VAN mode is active. 

## 🔍 DETAILED QA VALIDATION PROCESS

### 1️⃣ DEPENDENCY VERIFICATION

This step verifies that all required packages are installed and compatible:

```mermaid
graph TD
    Start["Dependency Verification"] --> ReadDeps["Read Required Dependencies<br>from Creative Phase"]
    ReadDeps --> CheckInstalled["Check if Dependencies<br>are Installed"]
    CheckInstalled --> DepStatus{"All Dependencies<br>Installed?"}
    
    DepStatus -->|"Yes"| VerifyVersions["Verify Versions<br>and Compatibility"]
    DepStatus -->|"No"| InstallMissing["Install Missing<br>Dependencies"]
    InstallMissing --> VerifyVersions
    
    VerifyVersions --> VersionStatus{"Versions<br>Compatible?"}
    VersionStatus -->|"Yes"| DepSuccess["Dependencies Verified<br>✅ PASS"]
    VersionStatus -->|"No"| UpgradeVersions["Upgrade/Downgrade<br>as Needed"]
    UpgradeVersions --> RetryVerify["Retry Verification"]
    RetryVerify --> VersionStatus
    
    style Start fill:#4da6ff,stroke:#0066cc,color:white
    style DepSuccess fill:#10b981,stroke:#059669,color:white
    style DepStatus fill:#f6546a,stroke:#c30052,color:white
    style VersionStatus fill:#f6546a,stroke:#c30052,color:white
```

#### Windows (PowerShell) Implementation:
```powershell
# Example: Verify Node.js dependencies for a React project
function Verify-Dependencies {
    $requiredDeps = @{
        "node" = ">=14.0.0"
        "npm" = ">=6.0.0"
    }
    
    $missingDeps = @()
    $incompatibleDeps = @()
    
    # Check Node.js version
    $nodeVersion = $null
    try {
        $nodeVersion = node -v
        if ($nodeVersion -match "v(\d+)\.(\d+)\.(\d+)") {
            $major = [int]$Matches[1]
            if ($major -lt 14) {
                $incompatibleDeps += "node (found $nodeVersion, required >=14.0.0)"
            }
        }
    } catch {
        $missingDeps += "node"
    }
    
    # Check npm version
    $npmVersion = $null
    try {
        $npmVersion = npm -v
        if ($npmVersion -match "(\d+)\.(\d+)\.(\d+)") {
            $major = [int]$Matches[1]
            if ($major -lt 6) {
                $incompatibleDeps += "npm (found $npmVersion, required >=6.0.0)"
            }
        }
    } catch {
        $missingDeps += "npm"
    }
    
    # Display results
    if ($missingDeps.Count -eq 0 -and $incompatibleDeps.Count -eq 0) {
        Write-Output "✅ All dependencies verified and compatible"
        return $true
    } else {
        if ($missingDeps.Count -gt 0) {
            Write-Output "❌ Missing dependencies: $($missingDeps -join ', ')"
        }
        if ($incompatibleDeps.Count -gt 0) {
            Write-Output "❌ Incompatible versions: $($incompatibleDeps -join ', ')"
        }
        return $false
    }
}
```

#### Mac/Linux (Bash) Implementation:
```bash
#!/bin/bash

# Example: Verify Node.js dependencies for a React project
verify_dependencies() {
    local missing_deps=()
    local incompatible_deps=()
    
    # Check Node.js version
    if command -v node &> /dev/null; then
        local node_version=$(node -v)
        if [[ $node_version =~ v([0-9]+)\.([0-9]+)\.([0-9]+) ]]; then
            local major=${BASH_REMATCH[1]}
            if (( major < 14 )); then
                incompatible_deps+=("node (found $node_version, required >=14.0.0)")
            fi
        fi
    else
        missing_deps+=("node")
    fi
    
    # Check npm version
    if command -v npm &> /dev/null; then
        local npm_version=$(npm -v)
        if [[ $npm_version =~ ([0-9]+)\.([0-9]+)\.([0-9]+) ]]; then
            local major=${BASH_REMATCH[1]}
            if (( major < 6 )); then
                incompatible_deps+=("npm (found $npm_version, required >=6.0.0)")
            fi
        fi
    else
        missing_deps+=("npm")
    fi
    
    # Display results
    if [ ${#missing_deps[@]} -eq 0 ] && [ ${#incompatible_deps[@]} -eq 0 ]; then
        echo "✅ All dependencies verified and compatible"
        return 0
    else
        if [ ${#missing_deps[@]} -gt 0 ]; then
            echo "❌ Missing dependencies: ${missing_deps[*]}"
        fi
        if [ ${#incompatible_deps[@]} -gt 0 ]; then
            echo "❌ Incompatible versions: ${incompatible_deps[*]}"
        fi
        return 1
    fi
}
```

### 2️⃣ CONFIGURATION VALIDATION

This step validates configuration files format and compatibility:

```mermaid
graph TD
    Start["Configuration Validation"] --> IdentifyConfigs["Identify Configuration<br>Files"]
    IdentifyConfigs --> ReadConfigs["Read Configuration<br>Files"]
    ReadConfigs --> ValidateSyntax["Validate Syntax<br>and Format"]
    ValidateSyntax --> SyntaxStatus{"Syntax<br>Valid?"}
    
    SyntaxStatus -->|"Yes"| CheckCompatibility["Check Compatibility<br>with Platform"]
    SyntaxStatus -->|"No"| FixSyntax["Fix Syntax<br>Errors"]
    FixSyntax --> RetryValidate["Retry Validation"]
    RetryValidate --> SyntaxStatus
    
    CheckCompatibility --> CompatStatus{"Compatible with<br>Platform?"}
    CompatStatus -->|"Yes"| ConfigSuccess["Configurations Validated<br>✅ PASS"]
    CompatStatus -->|"No"| AdaptConfigs["Adapt Configurations<br>for Platform"]
    AdaptConfigs --> RetryCompat["Retry Compatibility<br>Check"]
    RetryCompat --> CompatStatus
    
    style Start fill:#4da6ff,stroke:#0066cc,color:white
    style ConfigSuccess fill:#10b981,stroke:#059669,color:white
    style SyntaxStatus fill:#f6546a,stroke:#c30052,color:white
    style CompatStatus fill:#f6546a,stroke:#c30052,color:white
``` 

#### Configuration Validation Implementation:
```powershell
# Example: Validate configuration files for a web project
function Validate-Configurations {
    $configFiles = @(
        "package.json",
        "tsconfig.json",
        "vite.config.js"
    )
    
    $invalidConfigs = @()
    $incompatibleConfigs = @()
    
    foreach ($configFile in $configFiles) {
        if (Test-Path $configFile) {
            # Check JSON syntax for JSON files
            if ($configFile -match "\.json$") {
                try {
                    Get-Content $configFile -Raw | ConvertFrom-Json | Out-Null
                } catch {
                    $invalidConfigs += "$configFile (JSON syntax error: $($_.Exception.Message))"
                    continue
                }
            }
            
            # Specific configuration compatibility checks
            if ($configFile -eq "vite.config.js") {
                $content = Get-Content $configFile -Raw
                # Check for React plugin in Vite config
                if ($content -notmatch "react\(\)") {
                    $incompatibleConfigs += "$configFile (Missing React plugin for React project)"
                }
            }
        } else {
            $invalidConfigs += "$configFile (file not found)"
        }
    }
    
    # Display results
    if ($invalidConfigs.Count -eq 0 -and $incompatibleConfigs.Count -eq 0) {
        Write-Output "✅ All configurations validated and compatible"
        return $true
    } else {
        if ($invalidConfigs.Count -gt 0) {
            Write-Output "❌ Invalid configurations: $($invalidConfigs -join ', ')"
        }
        if ($incompatibleConfigs.Count -gt 0) {
            Write-Output "❌ Incompatible configurations: $($incompatibleConfigs -join ', ')"
        }
        return $false
    }
}
```

### 3️⃣ ENVIRONMENT VALIDATION

This step checks if the environment is properly set up for the implementation:

```mermaid
graph TD
    Start["Environment Validation"] --> CheckEnv["Check Build Environment"]
    CheckEnv --> VerifyBuildTools["Verify Build Tools"]
    VerifyBuildTools --> ToolsStatus{"Build Tools<br>Available?"}
    
    ToolsStatus -->|"Yes"| CheckPerms["Check Permissions<br>and Access"]
    ToolsStatus -->|"No"| InstallTools["Install Required<br>Build Tools"]
    InstallTools --> RetryTools["Retry Verification"]
    RetryTools --> ToolsStatus
    
    CheckPerms --> PermsStatus{"Permissions<br>Sufficient?"}
    PermsStatus -->|"Yes"| EnvSuccess["Environment Validated<br>✅ PASS"]
    PermsStatus -->|"No"| FixPerms["Fix Permission<br>Issues"]
    FixPerms --> RetryPerms["Retry Permission<br>Check"]
    RetryPerms --> PermsStatus
    
    style Start fill:#4da6ff,stroke:#0066cc,color:white
    style EnvSuccess fill:#10b981,stroke:#059669,color:white
    style ToolsStatus fill:#f6546a,stroke:#c30052,color:white
    style PermsStatus fill:#f6546a,stroke:#c30052,color:white
```

#### Environment Validation Implementation:
```powershell
# Example: Validate environment for a web project
function Validate-Environment {
    $requiredTools = @(
        @{Name = "git"; Command = "git --version"},
        @{Name = "node"; Command = "node --version"},
        @{Name = "npm"; Command = "npm --version"}
    )
    
    $missingTools = @()
    $permissionIssues = @()
    
    # Check build tools
    foreach ($tool in $requiredTools) {
        try {
            Invoke-Expression $tool.Command | Out-Null
        } catch {
            $missingTools += $tool.Name
        }
    }
    
    # Check write permissions in project directory
    try {
        $testFile = ".__permission_test"
        New-Item -Path $testFile -ItemType File -Force | Out-Null
        Remove-Item -Path $testFile -Force
    } catch {
        $permissionIssues += "Current directory (write permission denied)"
    }
    
    # Check if port 3000 is available (commonly used for dev servers)
    try {
        $listener = New-Object System.Net.Sockets.TcpListener([System.Net.IPAddress]::Loopback, 3000)
        $listener.Start()
        $listener.Stop()
    } catch {
        $permissionIssues += "Port 3000 (already in use or access denied)"
    }
    
    # Display results
    if ($missingTools.Count -eq 0 -and $permissionIssues.Count -eq 0) {
        Write-Output "✅ Environment validated successfully"
        return $true
    } else {
        if ($missingTools.Count -gt 0) {
            Write-Output "❌ Missing tools: $($missingTools -join ', ')"
        }
        if ($permissionIssues.Count -gt 0) {
            Write-Output "❌ Permission issues: $($permissionIssues -join ', ')"
        }
        return $false
    }
}
```

### 4️⃣ MINIMAL BUILD TEST

This step performs a minimal build test to ensure core functionality:

```mermaid
graph TD
    Start["Minimal Build Test"] --> CreateTest["Create Minimal<br>Test Project"]
    CreateTest --> BuildTest["Attempt<br>Build"]
    BuildTest --> BuildStatus{"Build<br>Successful?"}
    
    BuildStatus -->|"Yes"| RunTest["Run Basic<br>Functionality Test"]
    BuildStatus -->|"No"| FixBuild["Fix Build<br>Issues"]
    FixBuild --> RetryBuild["Retry Build"]
    RetryBuild --> BuildStatus
    
    RunTest --> TestStatus{"Test<br>Passed?"}
    TestStatus -->|"Yes"| TestSuccess["Minimal Build Test<br>✅ PASS"]
    TestStatus -->|"No"| FixTest["Fix Test<br>Issues"]
    FixTest --> RetryTest["Retry Test"]
    RetryTest --> TestStatus
    
    style Start fill:#4da6ff,stroke:#0066cc,color:white
    style TestSuccess fill:#10b981,stroke:#059669,color:white
    style BuildStatus fill:#f6546a,stroke:#c30052,color:white
    style TestStatus fill:#f6546a,stroke:#c30052,color:white
```

#### Minimal Build Test Implementation:
```powershell
# Example: Perform minimal build test for a React project
function Perform-MinimalBuildTest {
    $buildSuccess = $false
    $testSuccess = $false
    
    # Create minimal test project
    $testDir = ".__build_test"
    if (Test-Path $testDir) {
        Remove-Item -Path $testDir -Recurse -Force
    }
    
    try {
        # Create minimal test directory
        New-Item -Path $testDir -ItemType Directory | Out-Null
        Push-Location $testDir
        
        # Initialize minimal package.json
        @"
{
  "name": "build-test",
  "version": "1.0.0",
  "description": "Minimal build test",
  "main": "index.js",
  "scripts": {
    "build": "echo Build test successful"
  }
}
"@ | Set-Content -Path "package.json"
        
        # Attempt build
        npm run build | Out-Null
        $buildSuccess = $true
        
        # Create minimal test file
        @"
console.log('Test successful');
"@ | Set-Content -Path "index.js"
        
        # Run basic test
        node index.js | Out-Null
        $testSuccess = $true
        
    } catch {
        Write-Output "❌ Build test failed: $($_.Exception.Message)"
    } finally {
        Pop-Location
        if (Test-Path $testDir) {
            Remove-Item -Path $testDir -Recurse -Force
        }
    }
    
    # Display results
    if ($buildSuccess -and $testSuccess) {
        Write-Output "✅ Minimal build test passed successfully"
        return $true
    } else {
        if (-not $buildSuccess) {
            Write-Output "❌ Build process failed"
        }
        if (-not $testSuccess) {
            Write-Output "❌ Basic functionality test failed"
        }
        return $false
    }
}
```

## 📋 COMPREHENSIVE QA REPORT FORMAT

After running all validation steps, a comprehensive report is generated:

```
╔═════════════════════ 🔍 QA VALIDATION REPORT ══════════════════════╗
│                                                                     │
│  PROJECT: [Project Name]                                            │
│  TIMESTAMP: [Current Date/Time]                                     │
│                                                                     │
│  1️⃣ DEPENDENCY VERIFICATION                                         │
│  ✓ Required: [List of required dependencies]                        │
│  ✓ Installed: [List of installed dependencies]                      │
│  ✓ Compatible: [Yes/No]                                            │
│                                                                     │
│  2️⃣ CONFIGURATION VALIDATION                                        │
│  ✓ Config Files: [List of configuration files]                      │
│  ✓ Syntax Valid: [Yes/No]                                          │
│  ✓ Platform Compatible: [Yes/No]                                   │
│                                                                     │
│  3️⃣ ENVIRONMENT VALIDATION                                          │
│  ✓ Build Tools: [Available/Missing]                                │
│  ✓ Permissions: [Sufficient/Insufficient]                          │
│  ✓ Environment Ready: [Yes/No]                                     │
│                                                                     │
│  4️⃣ MINIMAL BUILD TEST                                              │
│  ✓ Build Process: [Successful/Failed]                              │
│  ✓ Functionality Test: [Passed/Failed]                             │
│  ✓ Build Ready: [Yes/No]                                           │
│                                                                     │
│  🚨 FINAL VERDICT: [PASS/FAIL]                                      │
│  ➡️ [Success message or error details]                              │
╚═════════════════════════════════════════════════════════════════════╝
```

## ❌ FAILURE REPORT FORMAT

If any validation step fails, a detailed failure report is generated:

```
⚠️⚠️⚠️ QA VALIDATION FAILED ⚠️⚠️⚠️

The following issues must be resolved before proceeding to BUILD mode:

1️⃣ DEPENDENCY ISSUES:
- [Detailed description of dependency issues]
- [Recommended fix]

2️⃣ CONFIGURATION ISSUES:
- [Detailed description of configuration issues]
- [Recommended fix]

3️⃣ ENVIRONMENT ISSUES:
- [Detailed description of environment issues]
- [Recommended fix]

4️⃣ BUILD TEST ISSUES:
- [Detailed description of build test issues]
- [Recommended fix]

⚠️ BUILD MODE IS BLOCKED until these issues are resolved.
Type 'VAN QA' after fixing the issues to re-validate.
```

## 🔄 INTEGRATION WITH DESIGN DECISIONS

The VAN QA mode reads and validates design decisions from the CREATIVE phase:

```mermaid
graph TD
    Start["Read Design Decisions"] --> ReadCreative["Parse Creative Phase<br>Documentation"]
    ReadCreative --> ExtractTech["Extract Technology<br>Choices"]
    ExtractTech --> ExtractDeps["Extract Required<br>Dependencies"]
    ExtractDeps --> BuildValidationPlan["Build Validation<br>Plan"]
    BuildValidationPlan --> StartValidation["Start Four-Point<br>Validation Process"]
    
    style Start fill:#4da6ff,stroke:#0066cc,color:white
    style ExtractTech fill:#f6546a,stroke:#c30052,color:white
    style BuildValidationPlan fill:#10b981,stroke:#059669,color:white
    style StartValidation fill:#f6546a,stroke:#c30052,color:white
```

### Technology Extraction Process:
```powershell
# Example: Extract technology choices from creative phase documentation
function Extract-TechnologyChoices {
    $techChoices = @{}
    
    # Read from systemPatterns.md
    if (Test-Path "memory-bank\systemPatterns.md") {
        $content = Get-Content "memory-bank\systemPatterns.md" -Raw
        
        # Extract framework choice
        if ($content -match "Framework:\s*(\w+)") {
            $techChoices["framework"] = $Matches[1]
        }
        
        # Extract UI library choice
        if ($content -match "UI Library:\s*(\w+)") {
            $techChoices["ui_library"] = $Matches[1]
        }
        
        # Extract state management choice
        if ($content -match "State Management:\s*([^\\n]+)") {
            $techChoices["state_management"] = $Matches[1].Trim()
        }
    }
    
    return $techChoices
}
```

## 🚨 IMPLEMENTATION PREVENTION MECHANISM

If QA validation fails, the system prevents moving to BUILD mode:

```powershell
# Example: Enforce QA validation before allowing BUILD mode
function Check-QAValidationStatus {
    $qaStatusFile = "memory-bank\.qa_validation_status"
    
    if (Test-Path $qaStatusFile) {
        $status = Get-Content $qaStatusFile -Raw
        if ($status -match "PASS") {
            return $true
        }
    }
    
    # Display block message
    Write-Output "`n`n"
    Write-Output "🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫"
    Write-Output "⛔️ BUILD MODE BLOCKED: QA VALIDATION REQUIRED"
    Write-Output "⛔️ You must complete QA validation before proceeding to BUILD mode"
    Write-Output "`n"
    Write-Output "Type 'VAN QA' to perform technical validation"
    Write-Output "`n"
    Write-Output "🚫 NO IMPLEMENTATION CAN PROCEED WITHOUT VALIDATION 🚫"
    Write-Output "🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫🚫"
    
    return $false
}
```

## 🧪 COMMON QA VALIDATION FIXES

Here are common fixes for issues encountered during QA validation:

### Dependency Issues:
- **Missing Node.js**: Install Node.js from https://nodejs.org/
- **Outdated npm**: Run `npm install -g npm@latest` to update
- **Missing packages**: Run `npm install` or `npm install [package-name]`

### Configuration Issues:
- **Invalid JSON**: Use a JSON validator to check syntax
- **Missing React plugin**: Add `import react from '@vitejs/plugin-react'` and `plugins: [react()]` to vite.config.js
- **Incompatible TypeScript config**: Update `tsconfig.json` with correct React settings

### Environment Issues:
- **Permission denied**: Run terminal as administrator (Windows) or use sudo (Mac/Linux)
- **Port already in use**: Kill process using the port or change the port in configuration
- **Missing build tools**: Install required command-line tools

### Build Test Issues:
- **Build fails**: Check console for specific error messages
- **Test fails**: Verify minimal configuration is correct
- **Path issues**: Ensure paths use correct separators for the platform

## 🔒 FINAL QA VALIDATION CHECKPOINT

```
✓ SECTION CHECKPOINT: QA VALIDATION
- Dependency Verification Passed? [YES/NO]
- Configuration Validation Passed? [YES/NO]
- Environment Validation Passed? [YES/NO]
- Minimal Build Test Passed? [YES/NO]

→ If all YES: Ready for BUILD mode
→ If any NO: Fix identified issues before proceeding
```




================================================================
End of Codebase
================================================================

================
File: cursor-memory-bank/MEMORY_BANK_OPTIMIZATIONS.md
================
# Memory Bank System Optimizations

This document presents a comprehensive overview of the optimizations implemented to enhance the Memory Bank system's token efficiency, context management, and overall performance.

## 🚀 Core Optimizations

### 1. Hierarchical Rule Loading System

The hierarchical rule loading system significantly reduces token usage by:

- Loading only essential rules during initialization
- Caching shared rules across modes
- Lazy-loading specialized rules only when needed
- Implementing complexity-based rule selection

**File**: [.cursor/rules/isolation_rules/Core/hierarchical-rule-loading.mdc](/.cursor/rules/isolation_rules/Core/hierarchical-rule-loading.mdc)

### 2. Progressive Creative Phase Documentation

The creative phase has been optimized with a progressive documentation approach:

- Focused, concise templates for initial documentation
- Detailed analysis available on demand
- Tabular format for efficient comparison of options
- Complexity-appropriate documentation scaling

**File**: [.cursor/rules/isolation_rules/Phases/CreativePhase/optimized-creative-template.mdc](/.cursor/rules/isolation_rules/Phases/CreativePhase/optimized-creative-template.mdc)

### 3. Optimized Mode Transitions

Mode transitions now use a unified context transfer protocol:

- Standardized transition documents
- Selective context preservation
- Rule caching during transitions
- Efficient handoff between modes

**File**: [.cursor/rules/isolation_rules/Core/mode-transition-optimization.mdc](/.cursor/rules/isolation_rules/Core/mode-transition-optimization.mdc)

### 4. Level-Specific Workflow Optimization

Each complexity level has been optimized:

- Level 1: Ultra-compact templates for quick fixes
- Level 2-4: Scaled documentation based on complexity
- Consolidated memory bank updates
- Streamlined verification processes

**Example File**: [.cursor/rules/isolation_rules/Level1/optimized-workflow-level1.mdc](/.cursor/rules/isolation_rules/Level1/optimized-workflow-level1.mdc)

### 5. Optimization Integration

Central coordination of all optimizations:

- Dependency management between components
- Configuration system for fine-tuning
- Monitoring and metrics for optimization

**File**: [.cursor/rules/isolation_rules/Core/optimization-integration.mdc](/.cursor/rules/isolation_rules/Core/optimization-integration.mdc)

## 📂 All Files Created or Modified

### Core System

1. [/.cursor/rules/isolation_rules/main-optimized.mdc](/.cursor/rules/isolation_rules/main-optimized.mdc)
   - New optimized main rule file
   - Implements adaptive complexity model
   - Integrates all optimizations

2. [/.cursor/rules/isolation_rules/Core/hierarchical-rule-loading.mdc](/.cursor/rules/isolation_rules/Core/hierarchical-rule-loading.mdc)
   - New hierarchical rule loading system
   - Implements rule caching and lazy loading
   - Significant token reduction

3. [/.cursor/rules/isolation_rules/Core/mode-transition-optimization.mdc](/.cursor/rules/isolation_rules/Core/mode-transition-optimization.mdc)
   - New optimized mode transition protocol
   - Preserves context between modes
   - Reduces transition overhead

4. [/.cursor/rules/isolation_rules/Core/optimization-integration.mdc](/.cursor/rules/isolation_rules/Core/optimization-integration.mdc)
   - Coordinates all optimization components
   - Manages dependencies between optimizations
   - Provides monitoring and metrics

### Level-Specific Optimizations

5. [/.cursor/rules/isolation_rules/Level1/optimized-workflow-level1.mdc](/.cursor/rules/isolation_rules/Level1/optimized-workflow-level1.mdc)
   - Streamlined workflow for quick bug fixes
   - Ultra-compact documentation templates
   - Consolidated memory bank updates

### Phase-Specific Optimizations

6. [/.cursor/rules/isolation_rules/Phases/CreativePhase/optimized-creative-template.mdc](/.cursor/rules/isolation_rules/Phases/CreativePhase/optimized-creative-template.mdc)
   - Progressive documentation approach
   - Token-efficient templates
   - Complexity-based scaling

## 💡 Key Innovations

1. **Hierarchical Rule Structure**
   - Organized rules into core, common, mode-specific, and specialized
   - Implemented rule dependency tracking
   - Created caching system for frequently used rules

2. **Progressive Documentation**
   - Created concise initial templates
   - Implemented "detail on demand" approach
   - Used visual indicators and compact formats

3. **Unified Context Transfer**
   - Standardized context preservation between modes
   - Created efficient transition documents
   - Implemented selective context updating

4. **Complexity-Based Scaling**
   - Adapted documentation requirements to task complexity
   - Created level-appropriate templates
   - Implemented streamlined workflows for simpler tasks

## 🔄 Workflow Comparison

### Original Workflow
1. Load all rules for current mode
2. Process according to mode requirements
3. Complete documentation per template
4. Switch to next mode with minimal context preservation

### Optimized Workflow
1. Load only essential rules initially
2. Load specialized rules as needed
3. Use progressive documentation appropriate to complexity
4. Preserve critical context during mode transitions
5. Use differential updates for memory bank files

## 🌟 Benefits Beyond Token Efficiency

1. **Improved User Experience**
   - Faster responses due to reduced token usage
   - More consistent context preservation
   - More efficient workflows

2. **Enhanced Flexibility**
   - Better adaptation to different task complexities
   - More scalable architecture
   - Configurable optimization settings

3. **Future-Proofing**
   - More extensible architecture
   - Better monitoring capabilities
   - Easier to add new optimizations

## 🚀 Usage Instructions

To use the optimized system:

1. Replace the existing main.mdc with main-optimized.mdc
2. Add the new optimization files to their respective directories
3. The system will automatically use the optimized components
4. No additional configuration required

## 🧪 Verification

The optimizations have been designed to maintain full compatibility with the existing Memory Bank system. All functionality remains intact while significantly improving token efficiency.

## 🔮 Future Optimization Opportunities

1. **Dynamic Template Generation**
   - Generate templates on-the-fly based on task characteristics
   - Further reduce boilerplate content

2. **Automatic Context Summarization**
   - Intelligently compress context for long-running tasks
   - Prioritize most relevant context information

3. **Cross-Task Knowledge Preservation**
   - Maintain key learnings across different tasks
   - Build a knowledge base of common solutions

4. **Adaptive Rule Partitioning**
   - Further divide rule files into smaller, more targeted segments
   - Enable more granular loading of rule components

---

These optimizations maintain all the structured development benefits of the original Memory Bank system while significantly improving its efficiency and scalability.

================
File: cursor-memory-bank/memory_bank_upgrade_guide.md
================
# Memory Bank System Upgrade: From Monolithic to Modular

## Introduction

I'm excited to introduce a significant upgrade to the Memory Bank system – evolving from a monolithic all-in-one approach to a modular, graph-based system that integrates with Cursor's custom modes. This document explains the reasons behind this transition, its benefits, and how to get the most out of the new system.

```mermaid
graph TD
    Old["Old System<br>Monolithic Approach"] --> New["New System<br>Modular JIT Architecture"]
    
    Old --- OldFeatures["• Single file structure<br>• All rules loaded at once<br>• Fixed workflow"]
    New --- NewFeatures["• Mode-specific rules<br>• Just-in-time loading<br>• Visual process maps<br>• Cursor custom modes integration"]
    
    style Old fill:#f8d486,stroke:#e8b84d
    style New fill:#4da6ff,stroke:#0066cc,color:white
    style OldFeatures fill:#ffe6cc,stroke:#ffa64d
    style NewFeatures fill:#cce6ff,stroke:#80bfff
```

## Why I'm Upgrading

The old Memory Bank system served well, providing a structured approach to task management with its adaptive complexity levels and comprehensive documentation. However, as projects grew in complexity, I identified several limitations:

1. **Context Inefficiency**: Loading all rules at once regardless of relevance
2. **Limited Visual Guidance**: Text-heavy instructions without visual process maps
3. **Token Waste**: Consuming context window with irrelevant rules
4. **One-Size-Fits-All Approach**: Less tailored to specific development phases
5. **Scalability Challenges**: Difficulty in maintaining a growing single-file system

While the new system offers significant advantages in efficiency and scalability, I acknowledge it does introduce a steeper learning curve. This trade-off is intentional – the increased initial complexity enables more powerful capabilities, better organization, and improved long-term development outcomes for complex projects.

## The New Isolation-Focused Architecture

The new system addresses these limitations through a modular, Just-In-Time (JIT) architecture that loads only the rules you need when you need them.

```mermaid
graph TD
    Command["User Mode Command"] --> ModeSwitch["Mode Switch"]
    ModeSwitch --> LoadRules["Load Only<br>Relevant Rules"]
    LoadRules --> ExecuteProcess["Execute Mode-Specific<br>Process"]
    ExecuteProcess --> UpdateMemory["Update<br>Memory Bank"]
    UpdateMemory --> NextMode["Transition to<br>Next Mode"]
    
    style Command fill:#f8d486,stroke:#e8b84d
    style ModeSwitch fill:#d971ff,stroke:#a33bc2,color:white
    style LoadRules fill:#4da6ff,stroke:#0066cc,color:white
    style ExecuteProcess fill:#4dbb5f,stroke:#36873f,color:white
    style UpdateMemory fill:#ffa64d,stroke:#cc7a30,color:white
    style NextMode fill:#ff5555,stroke:#cc0000,color:white
```

Importantly, the new system preserves the foundational 4-level complexity scale from the original system. This scale (Level 1: Quick Bug Fix, Level 2: Simple Enhancement, Level 3: Intermediate Feature, Level 4: Complex System) remains central to determining workflow paths and documentation requirements, ensuring continuity for users familiar with the original approach.

### Key Features of the New System

1. **Mode-Specific Visual Maps**: Clear visual representations for each development phase
2. **Just-In-Time Rule Loading**: Load only the rules needed for your current task
3. **Visual Decision Trees**: Guided workflows with clear checkpoints
4. **Technical Validation**: Dedicated QA processes to verify implementation readiness
5. **Platform-Aware Commands**: Automatically adapts commands to your operating system

### Graph-Based Efficiency

A fundamental enabler of the new system's capabilities is its graph-based architecture:

- **Optimized Path Navigation**: The system uses directed graphs to navigate complex decision trees with minimal overhead
- **Contextual Relationships**: Graph structures explicitly model relationships between development phases and components, enabling smarter transitions
- **Resource Optimization**: Each node in the graph loads only the resources needed for that specific step
- **Parallel Processing Potential**: The graph structure makes it easier to identify components that can be addressed in parallel

```mermaid
graph TD
    Start[Entry Point] --> A[Decision Node]
    A -->|Condition 1| B[Process B]
    A -->|Condition 2| C[Process C]
    B --> D[Next Step]
    C --> D
    
    style Start fill:#f9d77e,stroke:#d9b95c
    style A fill:#a8d5ff,stroke:#88b5e0
    style B fill:#c5e8b7,stroke:#a5c897
    style C fill:#ffcccc,stroke:#ff9999
    style D fill:#d9b3ff,stroke:#b366ff
```

**Before**: Linear execution paths with redundant rule evaluations.

**After**: Optimized traversal through decision points with clear conditionals and merge points.

This graph-based approach is particularly effective when working with large, complex projects where different components have varied requirements and dependencies. The system can efficiently navigate these complexities without overwhelming the context window.

### CREATIVE Mode and Claude's "Think" Tool

One notable aspect of the new system is that the CREATIVE mode is conceptually based on Anthropic's Claude "Think" tool methodology, as described in their [engineering blog](https://www.anthropic.com/engineering/claude-think-tool). This approach has been enhanced and integrated into the Memory Bank workflow:

- **Structured Exploration**: The CREATIVE mode guides users through systematic exploration of design options
- **Explicit Reasoning**: Requires documentation of pros and cons for different approaches
- **Component Breakdown**: Helps break complex problems into manageable components
- **Decision Documentation**: Creates formal records of design decisions with clear rationales
- **Continuous Refinement**: The implementation will continue to evolve as Claude's capabilities advance

This methodology has proven particularly effective for complex design decisions, ensuring that all options are thoroughly considered before implementation begins.

## Integration with Cursor Custom Modes

The new system takes full advantage of Cursor's custom modes feature, which allows for specialized AI behaviors for different tasks.

### What Are Cursor Custom Modes?

Cursor custom modes allow you to configure different AI behaviors with specific tools and custom instructions. The new Memory Bank system creates specialized modes for each development phase:

```mermaid
graph LR
    subgraph "Memory Bank Modes"
        VAN["VAN MODE<br>Initialization"]
        PLAN["PLAN MODE<br>Task Planning"]
        CREATIVE["CREATIVE MODE<br>Design Decisions"]
        IMPLEMENT["IMPLEMENT MODE<br>Code Implementation"]
        QA["QA MODE<br>Validation"]
    end
    
    VAN --> PLAN
    PLAN --> CREATIVE
    CREATIVE --> IMPLEMENT
    IMPLEMENT --> QA
    
    style VAN fill:#80bfff,stroke:#4da6ff
    style PLAN fill:#80ffaa,stroke:#4dbb5f
    style CREATIVE fill:#d9b3ff,stroke:#b366ff
    style IMPLEMENT fill:#ffcc80,stroke:#ffaa33
    style QA fill:#ff8080,stroke:#ff5555
```

Each mode loads only its required rule set, optimizing context usage and providing specialized guidance:

| Mode | Purpose | Key Features |
|------|---------|-------------|
| VAN | Initialization | Platform detection, file verification, complexity determination |
| PLAN | Task Planning | Requirements analysis, component identification, implementation strategy |
| CREATIVE | Design Decisions | Multiple options exploration, pros/cons analysis, design recommendations |
| IMPLEMENT | Code Implementation | Systematic building, command execution, testing |
| QA | Technical Validation | Dependency verification, configuration validation, build testing |

### Beyond Cursor's Standard Custom Modes Implementation

While Cursor's [documentation on custom modes](https://docs.cursor.com/chat/custom-modes) describes them primarily as standalone configurations with adjusted prompts and tool selections, Memory Bank significantly extends this concept:

#### Standard Cursor Custom Modes Approach

According to Cursor's documentation, custom modes typically consist of:
- Setting a name, icon, and shortcut
- Enabling or disabling specific tools
- Adding custom instructions (prompts)

Their example modes (Teach, Refactor, Plan, etc.) function as isolated configurations without inherent connections between them. Each mode is essentially a separate AI personality with specific instructions.

#### Memory Bank's Enhanced Custom Modes Approach

```mermaid
graph TD
    subgraph "Cursor's Standard Approach"
        M1["Mode 1<br>Static Instructions"]
        M2["Mode 2<br>Static Instructions"]
        M3["Mode 3<br>Static Instructions"]
    end
    
    subgraph "Memory Bank's Approach"
        MB1["VAN Mode<br>Dynamic Rules"]
        MB2["PLAN Mode<br>Dynamic Rules"]
        MB3["CREATIVE Mode<br>Dynamic Rules"]
        MB4["IMPLEMENT Mode<br>Dynamic Rules"]
        MB5["QA Mode<br>Dynamic Rules"]
        
        MB1 -->|"Passes Context"| MB2
        MB2 -->|"Passes Context"| MB3
        MB3 -->|"Passes Context"| MB4
        MB4 -->|"Passes Context"| MB5
        
        MemBank["Memory Bank Files<br>(Shared State)"]
        MB1 <-->|"Read/Write"| MemBank
        MB2 <-->|"Read/Write"| MemBank
        MB3 <-->|"Read/Write"| MemBank
        MB4 <-->|"Read/Write"| MemBank
        MB5 <-->|"Read/Write"| MemBank
    end
    
    style M1 fill:#f8d486,stroke:#e8b84d
    style M2 fill:#f8d486,stroke:#e8b84d
    style M3 fill:#f8d486,stroke:#e8b84d
    
    style MB1 fill:#80bfff,stroke:#4da6ff
    style MB2 fill:#80ffaa,stroke:#4dbb5f
    style MB3 fill:#d9b3ff,stroke:#b366ff
    style MB4 fill:#ffcc80,stroke:#ffaa33
    style MB5 fill:#ff8080,stroke:#ff5555
    style MemBank fill:#f9d77e,stroke:#d9b95c,stroke-width:3px
```

Memory Bank transforms custom modes into a comprehensive, interconnected system:

1. **Graph-Based Architecture**: 
   - Modes represent nodes in a development workflow with explicit transitions
   - Each mode understands its place in the overall development process
   - Visual process maps guide users through the appropriate sequence

2. **Workflow Integration**: 
   - Modes form a cohesive development process (VAN → PLAN → CREATIVE → IMPLEMENT → QA)
   - Each mode is aware of preceding and subsequent modes
   - Transitions between modes are formalized with specific entry/exit criteria

3. **Shared Memory**: 
   - Persistent state maintained across mode transitions via Memory Bank files
   - Tasks.md serves as the central source of truth across all modes
   - Each mode contributes specific types of information to the shared knowledge base

4. **Just-In-Time Rule Loading**: 
   - Each mode dynamically loads only its specific rule set
   - Rules are specialized for the current development phase
   - Context window is preserved for productive work
   - Rules can adapt based on project complexity level

5. **Visual Process Maps**: 
   - Each mode contains embedded Mermaid diagrams
   - Visual guidance for decision points and workflow options
   - Clear checkpoints to track progress within each phase

6. **Complexity-Adaptive Behavior**: 
   - Modes adjust their behavior based on the complexity level determined during initialization
   - Simpler projects follow streamlined processes
   - Complex projects receive more comprehensive guidance

### Benefits of This Approach

This enhanced approach to custom modes offers several advantages:

1. **Improved Context Utilization**: By loading only relevant rules, more context is available for actual development work
2. **Coherent Development Process**: Modes work together as a unified system rather than disconnected tools
3. **Phase-Appropriate Guidance**: Each development phase receives specialized guidance optimized for its needs
4. **Knowledge Persistence**: Important information is preserved across mode transitions
5. **Reduced Cognitive Overhead**: Developers can focus on the current phase without being distracted by irrelevant guidance

### Potential Future Enhancements

If this approach proves successful through testing, it could potentially inspire several enhancements to how custom modes are used:

1. **Formalized Mode Transitions**: More explicit handoffs between development phases
2. **Enhanced Visual Guidance**: More sophisticated process maps and decision trees
3. **Deeper Integration with Memory Bank**: More specialized document types for different development phases
4. **Custom Mode Templates**: Pre-configured mode sequences for different project types
5. **Team Collaboration**: Coordinated use of modes across multiple team members

While this implementation introduces more complexity in setup compared to standard custom modes, it offers significantly more powerful capabilities for structured development processes. The system transforms custom modes from isolated AI behaviors into components of a comprehensive development methodology.

## Real-World Benefits: Evidence from Projects

My testing with real-world projects (including a complex Todo application) demonstrated significant benefits from the new system:

1. **Enforced Development Discipline**: Mode switching created natural phase separations, reducing the tendency to jump directly to implementation
2. **Comprehensive Documentation**: Each mode produced specialized documentation with explicit design decisions
3. **Systematic Development**: Components were built according to plan in logical dependency order
4. **Flexibility When Needed**: Hybrid approaches (like QA in IMPLEMENT) worked effectively without losing structure

From the analysis document:

> "I observed tangible differences in development approach between modes. Each mode successfully optimized for its specific phase of development. The quality of the final application benefited from this structured approach."

## Comparison: Old vs. New System

| Aspect | Old System | New System |
|--------|------------|------------|
| **Structure** | Single file | Multiple specialized files |
| **Context Usage** | Loads everything at once | Just-in-time loading |
| **Guidance** | Text-based instructions | Visual process maps + text |
| **Decision Making** | Basic decision points | Comprehensive decision trees |
| **Technical Validation** | Basic verification | Dedicated QA processes |
| **Platform Awareness** | Limited | Comprehensive adaptation |
| **Memory Bank** | Same core files | Same core files with improved organization |
| **Documentation** | Standardized formats | Mode-specific specialized formats |
| **Complexity Levels** | 4-level scale | Same 4-level scale with enhanced process flows |

## When to Use Each System

```mermaid
graph TD
    Start["Which system<br>should I use?"] --> Question{"What's your<br>experience level?"}
    
    Question -->|"Beginner"| Old["Start with Old System<br>• Simpler to understand<br>• All in one place<br>• Easier learning curve"]
    Question -->|"Intermediate/<br>Advanced"| New["Use New System<br>• More powerful capabilities<br>• Better for complex projects<br>• Optimized context usage"]
    
    Old --> Progress["As you gain experience..."]
    Progress --> New
    
    style Start fill:#f8d486,stroke:#e8b84d
    style Question fill:#4da6ff,stroke:#0066cc,color:white
    style Old fill:#4dbb5f,stroke:#36873f,color:white
    style New fill:#ffa64d,stroke:#cc7a30,color:white
    style Progress fill:#d9b3ff,stroke:#b366ff
```

### Guidelines for Trying the New System

- **New Projects**: The new system works best when starting fresh projects rather than converting existing ones
- **Testing Approach**: If you want to try it with an existing project, make a backup first and experiment in a safe environment
- **No Formal Migration Path**: I haven't developed a formal migration path from old to new systems - it's currently designed for new implementations
- **Learning Projects**: Use the old system for simpler projects if you're still getting comfortable with the Memory Bank concept
- **Complex Projects**: The new system shines with multi-component projects requiring careful planning

## Getting Started with the New System

### Basic Commands

To activate different modes in the new system:

```
VAN - Initialize project and determine complexity
PLAN - Create detailed implementation plan
CREATIVE - Explore design options for complex components
IMPLEMENT - Systematically build planned components
QA - Validate technical implementation
```

### Example Workflow

1. Begin with `VAN` to initialize the project and determine complexity
2. For Level 2-4 tasks, transition to `PLAN` to create a comprehensive implementation plan
3. For components requiring design decisions, use `CREATIVE` to explore options
4. Implement the planned changes with `IMPLEMENT`
5. Validate the implementation with `QA` before completing

The complexity level (1-4) determined during the VAN mode will significantly influence your path through the workflow:
- **Level 1 tasks** may proceed directly to IMPLEMENT after VAN
- **Level 2-4 tasks** follow the full workflow with increasingly comprehensive planning and documentation

## Deep Dive: The Technical Architecture

For those interested in the technical details, the new system uses a graph-based approach with isolated rule files loaded just-in-time:

```mermaid
graph TD
    Main["main.mdc<br>Core Rules"] --> Platform["platform-awareness.mdc<br>OS Detection"]
    Main --> FileV["file-verification.mdc<br>File Structure"]
    Main --> ComplexityDT["complexity-decision-tree.mdc<br>Task Classification"]
    
    subgraph "Mode-Specific Maps"
        VanMap["van-mode-map.mdc"]
        PlanMap["plan-mode-map.mdc"]
        CreativeMap["creative-mode-map.mdc"]
        ImplementMap["implement-mode-map.mdc"]
        QAMap["qa-mode-map.mdc"]
    end
    
    Main --> VanMap & PlanMap & CreativeMap & ImplementMap & QAMap
    
    VanMap --> VanFiles["Platform Detection<br>File Verification<br>Complexity Determination"]
    PlanMap --> PlanFiles["Task Tracking<br>Planning Process<br>Component Identification"]
    CreativeMap --> CreativeFiles["Design Patterns<br>Creative Phase Enforcement<br>Options Analysis"]
    ImplementMap --> ImplementFiles["Command Execution<br>Implementation Guide<br>Testing Strategy"]
    QAMap --> QAFiles["Dependency Verification<br>Configuration Validation<br>Build Testing"]
    
    style Main fill:#f8d486,stroke:#e8b84d,stroke-width:2px
    style VanMap fill:#80bfff,stroke:#4da6ff,stroke-width:2px
    style PlanMap fill:#80ffaa,stroke:#4dbb5f,stroke-width:2px
    style CreativeMap fill:#d9b3ff,stroke:#b366ff,stroke-width:2px
    style ImplementMap fill:#ffcc80,stroke:#ffaa33,stroke-width:2px
    style QAMap fill:#ff8080,stroke:#ff5555,stroke-width:2px
```

### Memory Bank Continuity

While the rules are modularized, the Memory Bank files maintain continuity across modes:

```mermaid
graph LR
    subgraph "Memory Bank Files"
        Tasks["tasks.md<br>Source of Truth"]
        Active["activeContext.md<br>Current Focus"]
        Progress["progress.md<br>Implementation Status"]
        Creative["creative-*.md<br>Design Decisions"]
    end
    
    VAN["VAN MODE"] -.-> Tasks & Active
    PLAN["PLAN MODE"] -.-> Tasks & Active
    CREATIVE["CREATIVE MODE"] -.-> Tasks & Creative
    IMPLEMENT["IMPLEMENT MODE"] -.-> Tasks & Progress
    QA["QA MODE"] -.-> Tasks & Progress
    
    style Tasks fill:#f9d77e,stroke:#d9b95c,stroke-width:3px
    style Active fill:#a8d5ff,stroke:#88b5e0
    style Progress fill:#c5e8b7,stroke:#a5c897
    style Creative fill:#f4b8c4,stroke:#d498a4
    
    style VAN fill:#80bfff,stroke:#4da6ff
    style PLAN fill:#80ffaa,stroke:#4dbb5f
    style CREATIVE fill:#d9b3ff,stroke:#b366ff
    style IMPLEMENT fill:#ffcc80,stroke:#ffaa33
    style QA fill:#ff8080,stroke:#ff5555
```

## Practical Example: Todo App Development

Here's how I used the new system to develop a complex Todo application:

1. **VAN Mode**: Analyzed requirements, set up project structure, determined Level 3 complexity
2. **PLAN Mode**: Created comprehensive component hierarchy, identified dependencies, flagged components for creative exploration
3. **CREATIVE Mode**: Explored multiple options for state management and filtering implementation, documented pros/cons
4. **IMPLEMENT Mode**: Built components in logical sequence following the plan, with integrated QA validation
5. **Results**: More disciplined development process, better documentation, and higher quality final product

## Future Plans and Development Roadmap

This Memory Bank system is a personal hobby project that brings me joy to build and develop. I plan to continue evolving it based on user needs and my own experiments. Here are some areas I'm exploring for future development:

### Near-Term Improvements

1. **Further Optimization of JIT Rules**: Refining the rule loading system to provide even more efficient context utilization and faster response times
2. **User Feedback Integration**: Establishing a structured feedback loop to gather insights from early adopters and refine the system based on real-world usage patterns
3. **PRD Mode Development**: Creating a dedicated Product Requirements Document mode that leverages Cursor's advanced AI models to help users construct comprehensive product specifications within the same environment as their development work

### Additional Possibilities Under Consideration

4. **Team Collaboration Features**: Enhancing Memory Bank to support multiple users working simultaneously with shared context and coordinated mode transitions
5. **Customizable Modes**: Providing tools for users to create their own specialized modes beyond the current set, with custom rule configurations and process maps
6. **Cross-Project Memory**: Enabling the Memory Bank system to maintain relevant context across different projects, improving knowledge transfer and consistency
7. **Analytics Dashboard**: Developing tools to analyze development patterns, mode usage, and project progression to provide insights and suggest process improvements
8. **Integration with Version Control**: Creating deeper connections between Memory Bank documentation and code version history for better traceability

### Development Philosophy

As I develop these new features, I remain committed to these core principles:
- Creating enjoyable, powerful tools for structured development
- Focusing on new implementations rather than migration paths
- Balancing power and complexity with appropriate learning resources
- Preserving the foundational 4-level complexity scale that has proven effective

I welcome community input on which of these potential directions would be most valuable to prioritize in the development roadmap.

## Conclusion: The Path Forward

The new isolation-focused Memory Bank system represents a significant evolution in my approach to structured development. While it introduces a steeper learning curve, the benefits in terms of efficiency, guidance, and scalability make it worthwhile for complex projects.

My recommendations:
- **Beginners**: Start with the old system until comfortable with the core concepts
- **New Projects**: Use the new system primarily for new projects rather than trying to migrate existing ones
- **Testing**: If you want to try the new system with an existing project, make a backup first and experiment in a safe environment
- **Advanced Users**: Consider the new system for substantial development work on complex projects

This is an experimental system that I've created as a personal hobby project. I encourage you to try it, provide feedback, and adapt it to your own workflows. By leveraging Cursor's custom modes and visual process maps, the new Memory Bank system provides a powerful framework for disciplined, systematic development that scales with project complexity.

---

## Resources

- [Cursor Custom Modes Documentation](https://docs.cursor.com/chat/custom-modes)
- Memory Bank Reference Files (in .cursor/rules/isolation_rules/)
- Mode-specific instruction files (van_instructions.md, plan_instructions.md, etc.)
- [CREATIVE Mode and Claude's "Think" Tool](creative_mode_think_tool.md)

## The Need for Change

The previous Memory Bank implementation had several limitations:

- **Limited Context Capacity**: All rules and commands were loaded into a single context, reducing the available tokens for productive work
- **Fixed Workflow**: Little flexibility for adapting to different project complexities
- **Redundant Rule Loading**: Even simple tasks loaded the full ruleset, inefficient use of context
- **No Visual Guidance**: Difficult to understand the system's decision-making process
- **Limited Platform Awareness**: Platform-specific commands required manual adaptation

## Key Architectural Improvements

The new Memory Bank system addresses these limitations through:

![Architectural Changes](/path-to-diagram.png)

### 1. Just-In-Time (JIT) Rule Loading

Instead of loading all rules upfront, the system now:

- Loads only the rules relevant to the current development phase
- Uses visual maps to determine which rules to load at what time
- Dynamically adjusts rule complexity based on task requirements
- Preserves valuable context space for productive work

```mermaid
graph TD
    subgraph "Old System"
        OldMain[All Rules Loaded at Start]
    end
    
    subgraph "New System"
        Entry[Entry Point]
        Core[Core Rules]
        Phase1[Phase 1 Rules]
        Phase2[Phase 2 Rules]
        Phase3[Phase 3 Rules]
        
        Entry --> Core
        Core --> Phase1
        Core --> Phase2
        Core --> Phase3
    end
    
    style OldMain fill:#ffcccc,stroke:#ff9999
    style Entry fill:#ccffcc,stroke:#99ff99
    style Core fill:#ccffcc,stroke:#99ff99
    style Phase1 fill:#ccffcc,stroke:#99ff99
    style Phase2 fill:#ccffcc,stroke:#99ff99
    style Phase3 fill:#ccffcc,stroke:#99ff99
```

**Before**: All 25+ rules were loaded at initialization, consuming approximately 70% of the available context.

**After**: Only 3-7 rules are loaded at any given time, reducing context usage to approximately 15-20%.

### 2. Graph-Based Efficiency

The graph-based structure is a fundamental efficiency enabler in the new system:

- **Optimized Path Navigation**: The system uses directed graphs to navigate complex decision trees with minimal overhead
- **Contextual Relationships**: Graph structures explicitly model relationships between development phases and components, enabling smarter transitions
- **Resource Optimization**: Each node in the graph loads only the resources needed for that specific step
- **Parallel Processing Potential**: The graph structure makes it easier to identify components that can be addressed in parallel

```mermaid
graph TD
    Start[Entry Point] --> A[Decision Node]
    A -->|Condition 1| B[Process B]
    A -->|Condition 2| C[Process C]
    B --> D[Next Step]
    C --> D
    
    style Start fill:#f9d77e,stroke:#d9b95c
    style A fill:#a8d5ff,stroke:#88b5e0
    style B fill:#c5e8b7,stroke:#a5c897
    style C fill:#ffcccc,stroke:#ff9999
    style D fill:#d9b3ff,stroke:#b366ff
```

**Before**: Linear execution paths with redundant rule evaluations.

**After**: Optimized traversal through decision points with clear conditionals and merge points.

### 3. Mode-Specific Visual Process Maps

Each mode now has its own visual process map that:

- Clearly illustrates the workflow for that specific development phase
- Provides explicit decision points and conditional branches
- Adapts to project complexity levels
- Offers visual checkpoints to track progress

```mermaid
graph TD
    Start[Start] --> Assess[Assess Project]
    Assess --> Complexity{Complexity Level?}
    Complexity -->|Simple| SimplePath[Simple Path]
    Complexity -->|Complex| ComplexPath[Complex Path]
    
    style Start fill:#c5e8b7,stroke:#a5c897
    style Assess fill:#a8d5ff,stroke:#88b5e0
    style Complexity fill:#f9d77e,stroke:#d9b95c
    style SimplePath fill:#f4b8c4,stroke:#d498a4
    style ComplexPath fill:#f4b8c4,stroke:#d498a4
```

### 4. Technical Validation and Platform Awareness

The system now includes:

- **Automated Platform Detection**: Automatically adapts commands for Windows, MacOS, or Linux
- **File Structure Verification**: Validates project structure before proceeding
- **QA Checkpoints**: Dedicated technical validation phase with specific validation criteria
- **More Accurate Command Generation**: Platform-specific commands with higher success rates

================
File: cursor-memory-bank/optimization-journey/00-introduction.md
================
# MEMORY BANK SYSTEM: INTRODUCTION

> **TL;DR:** The Memory Bank System evolved through nine optimization rounds to address verbosity, redundancy, maintenance challenges, process scaling, decision quality, creative phase implementation, and context window optimization. The latest improvement implements a Visual Navigation Layer with selective document loading that dramatically reduces context window usage, allowing the AI more working space while maintaining process integrity.

## 🎯 SYSTEM PURPOSE & INITIAL STATE

The Memory Bank System was designed to overcome a fundamental limitation of LLMs: their inability to retain context between sessions. The system creates a structured documentation architecture that serves as the AI's "memory" across interactions, consisting of:

- Core documentation files (projectbrief.md, productContext.md, etc.)
- Structured workflow with verification steps
- Command execution protocols
- Documentation creation and maintenance rules

While effective, the initial system had several opportunities for optimization:
- Verbose documentation requiring significant context window space
- Rigid structures that were sometimes cumbersome
- Redundancies across multiple files
- Heavy maintenance overhead

================
File: cursor-memory-bank/optimization-journey/01-efficiency-and-clarity.md
================
# 🔄 OPTIMIZATION ROUND 1: EFFICIENCY & CLARITY

## 🚨 Key Issues Identified
- Documentation too verbose, consuming excessive context window space
- Visual hierarchy lacking clear indication of importance
- Abstract explanations instead of concrete examples
- Inconsistent reference patterns

## ✅ Key Improvements
1. **Priority-Based Content Organization**
   - Added "TL;DR" sections at the top of each file
   - Placed mission-critical instructions at the beginning
   - Implemented progressive disclosure (essentials first, details later)

2. **Visual Hierarchy Improvements**
   - Used consistent emoji markers for different content types (🚨, ✅, ❌, 📋, ✓)
   - Created tables for reference information
   - Added visual separation between different severity levels

3. **Content Optimization**
   - Removed redundancies across files
   - Replaced abstract explanations with concrete examples
   - Trimmed verbose explanations while preserving meaning
   - Converted passive voice to active instructions

4. **Reference System Refinements**
   - Created standardized reference syntax with brief context
   - Added clear indications of when to consult external files
   - Grouped related references together

5. **Embedded Verification Mechanisms**
   - Added "checkpoint" prompts at critical junctions
   - Implemented lightweight verification steps
   - Created simple inline checklists

================
File: cursor-memory-bank/optimization-journey/02-system-self-assessment.md
================
# 🔄 OPTIMIZATION ROUND 2: SYSTEM SELF-ASSESSMENT

## 🚨 Key Issues Identified
1. Inconsistent task status updates between .cursorrules and activeContext.md
2. Section tracking list not consistently updated
3. Example files not being explicitly referenced
4. Context limitations when working with multiple files

## ✅ Key Improvements
1. **Task Status Tracking Improvements**
   - Added prominent 🔄 SYNC command template
   - Created explicit moments for synchronization

2. **Section Progress Tracking Improvements**
   - Added 🔄 SECTION UPDATE template
   - Created explicit moment to update the section tracking list

3. **Reference Triggers Enhancement**
   - Added standardized 📚 REFERENCE CHECK format
   - Improved visual indicators for references

4. **Context Window Optimization**
   - Created "Minimal Mode" for constrained contexts
   - Streamlined essential instructions

5. **Section Checkpoint System**
   - Added structured checkpoints at section boundaries
   - Created clear verification steps for section completion

================
File: cursor-memory-bank/optimization-journey/03-redundancy-elimination.md
================
# 🔄 OPTIMIZATION ROUND 3: REDUNDANCY ELIMINATION

## 🚨 Key Issues Identified
1. Task statuses duplicated across multiple files (.cursorrules, activeContext.md, progress.md)
2. Implementation details duplicated between files
3. Recent changes information duplicated
4. Maintenance overhead due to synchronizing information across files

## ✅ Key Improvements
1. **Centralized Task Registry**
   - Created tasks.md as single source of truth for tasks
   - Updated other files to reference instead of duplicate
   - Simplified task tracking to single-file updates

2. **Domain Separation**
   - Established clear boundaries for what belongs in each file
   - Prevented overlapping content between files
   - Created reference templates for each domain

3. **Cross-Reference System**
   - Implemented standardized cross-reference syntax
   - Replaced duplication with references
   - Created guidelines for maintaining references

================
File: cursor-memory-bank/optimization-journey/04-single-source-of-truth.md
================
# 🔄 OPTIMIZATION ROUND 4: SINGLE SOURCE OF TRUTH IMPLEMENTATION

## 🚨 Key Issues Identified
1. Despite introducing tasks.md, the system still instructed updating task status in multiple files
2. Dual-file update process (both .cursorrules AND activeContext.md) created synchronization errors
3. Complex command verification with nested if-statements caused terminal crashes
4. Inconsistent documentation references confused task tracking

## ✅ Key Improvements
1. **True Single Source of Truth**
   - Designated tasks.md as the ONLY file for task status tracking
   - Removed all instructions to update task status in .cursorrules
   - Modified all files to reference but not duplicate task information
   - Added explicit verification for tasks.md existence

2. **Command Execution Safety**
   - Simplified file verification processes to avoid terminal crashes
   - Removed nested if-statements in Windows batch commands
   - Added safer versions of common commands
   - Trusted the AI's existing knowledge of file operations

3. **Documentation Role Clarification**
   - .cursorrules: Project patterns and intelligence only
   - activeContext.md: Implementation details and current focus
   - progress.md: Overall progress and references to tasks
   - tasks.md: All task status tracking

4. **Technical Fixes**
   - Corrected MDC reference links in main.mdc
   - Fixed verification checklist for single source approach
   - Enhanced platform-specific documentation
   - Simplified real-time update formats

================
File: cursor-memory-bank/optimization-journey/05-adaptive-complexity-model.md
================
# 🔄 OPTIMIZATION ROUND 5: ADAPTIVE COMPLEXITY MODEL

## 🚨 Key Issues Identified
1. One-size-fits-all process was too rigid for varying task complexities
2. Bug fixes and simple tasks required excessive documentation
3. Complex tasks sometimes received insufficient architectural attention
4. Documentation burden sometimes slowed problem-solving
5. Context window usage inefficient for simple tasks
6. Creative work phases interrupted by excessive task tracking

## ✅ Key Improvements
1. **Adaptive Complexity Levels**
   - Implemented four complexity levels (1-4) from quick bug fixes to complex systems
   - Scaled process rigor to match task requirements
   - Created level-specific workflows and documentation expectations

2. **Level-Appropriate Task Tracking**
   - Defined task update frequency by complexity level
   - Simplified tracking for Level 1 (bug fixes)
   - Enhanced tracking for Level 4 (complex systems)

3. **Creative Phase Handling**
   - Added explicit creative phase markers
   - Created creative checkpoint system
   - Established process for returning to task tracking after creative work

4. **Process Scaling Rules**
   - Defined criteria for complexity level determination
   - Created guidelines for when to escalate complexity level
   - Implemented level-specific verification requirements

5. **Streamlined Level 1 Process**
   - Created minimal workflow for quick bug fixes
   - Reduced documentation burden for simple tasks
   - Maintained essential task tracking

6. **Enhanced Level 4 Process**
   - Added architectural considerations
   - Created comprehensive planning requirements
   - Implemented detailed verification checkpoints

================
File: cursor-memory-bank/optimization-journey/06-self-assessment-recommendations.md
================
# 🔄 OPTIMIZATION ROUND 6: RECOMMENDATIONS FROM SELF-ASSESSMENT

Based on field testing of the Adaptive Memory Bank System across different complexity levels, several refinements were identified. The system successfully scaled between complexity levels, maintained the single source of truth, and provided appropriate verification processes. However, self-assessment revealed opportunities for enhancement.

## 🚨 Areas for Improvement
1. Creative phase handling not explicitly marked during implementation
2. Reference checking format not consistently used
3. Implementation notes sometimes lacking sufficient detail
4. Level 1 process could be further streamlined
5. Templates for common implementation patterns needed

## ✅ Recommended Enhancements

1. **Enhanced Creative Phase Handling**
   - Add more prominent reminders about creative phase markers
   - Include creative phase examples in workflow.mdc
   - Create visual indicators for entering/exiting creative phases
   - Add creative checkpoint templates

2. **Simplified Reference Checking**
   - Create level-specific reference check templates
   - Add simplified format for Level 1 tasks
   - Include reference check reminders in each section
   - Automate reference check integration

3. **Implementation Documentation Guidelines**
   - Provide clear examples of implementation documentation at each level
   - Create templates for common implementation patterns
   - Add level-specific implementation detail requirements
   - Include technology-specific documentation templates

4. **Further Level 1 Streamlining**
   - Create ultra-lightweight process for trivial bug fixes
   - Reduce documentation requirements for simple fixes
   - Implement one-step verification for Level 1 tasks
   - Provide specialized templates for common bugs

5. **Implementation Pattern Templates**
   - Create templates for common implementation patterns
   - Add specialized templates for web development, API design, etc.
   - Include reusable code pattern documentation
   - Develop framework-specific templates

================
File: cursor-memory-bank/optimization-journey/07-structured-creative-thinking.md
================
# 🔄 OPTIMIZATION ROUND 7: STRUCTURED CREATIVE THINKING

Despite previous improvements to creative phase handling, real-world usage revealed that creative phases were often skipped during Level 3-4 tasks, leading to premature implementation without sufficient design exploration. Inspired by the "think" tool concept, which provides dedicated thinking space for complex problem-solving, we enhanced the creative phase system to ensure systematic thinking for complex decisions.

## 🚨 Key Issues Identified
1. **Missing Integration in Task Flow**: Creative phases were documented but not fully integrated into the task workflow
2. **Optional Rather Than Mandatory**: Creative phases were treated as optional rather than required for Level 3-4 tasks
3. **Implementation Bias**: Tendency to jump straight to coding without thorough design exploration
4. **Insufficient Verification**: No explicit checks for creative phase usage in validation steps
5. **Process Compartmentalization**: Creative phases treated as separate from the main workflow rather than integral

## ✅ Key Improvements
1. **Mandatory Creative Phases for Level 3-4 Tasks**
   - Made creative phases required, not optional, for complex tasks
   - Added explicit directive in Global Rules stating "Creative phases are MANDATORY for all major design/architecture decisions in Level 3-4 tasks"
   - Created creative-phase-triggers.mdc with clear guidelines on when creative phases must be used

2. **Structured Thinking Framework**
   - Enhanced creative phase format with systematic problem breakdown
   - Added verification steps in creative checkpoints
   - Implemented systematic verification against requirements for each option
   - Added risk assessment and edge case identification

3. **Task Planning Integration**
   - Updated TASK PLANNING section to require identification of components needing creative phases
   - Modified Level 3-4 workflows to explicitly include creative phase planning
   - Added creative phase placeholders in task templates for complex components

4. **Enhanced Verification System**
   - Added creative phase verification to all checkpoints
   - Updated TOP 5 MOST COMMON FAILURES to include "Missing creative phases"
   - Enhanced WORKFLOW VERIFICATION to check for creative phase usage
   - Added verification for creative phase outputs in documentation

5. **Detailed Domain-Specific Templates**
   - Created specialized templates for Algorithm Design, UI/UX Design, and Architecture Planning
   - Added domain-specific verification steps for each creative phase type
   - Implemented systematic alternative analysis with pros/cons comparison
   - Added performance, security, and scalability considerations to templates

================
File: cursor-memory-bank/optimization-journey/08-creative-phase-enforcement.md
================
# 🔄 OPTIMIZATION ROUND 8: CREATIVE PHASE ENFORCEMENT & METRICS

Despite previous improvements to creative phases, real-world feedback revealed that creative phases were sometimes mentally performed but not properly documented, allowing implementation to proceed without formal design exploration. This optimization round creates strict enforcement mechanisms and objective quality metrics for creative phases.

## 🚨 Key Issues Identified
1. **Lack of Explicit Enforcement**: Creative phases could be skipped despite being mandatory
2. **Process Skipping**: Implementation could proceed without proper creative phase documentation
3. **Missing Verification Gateway**: No strict checkpoint blocked implementation without creative phases
4. **Documentation Gap**: Design decisions were mentally performed but not formally documented
5. **Quality Variation**: No objective metrics to evaluate creative phase quality
6. **Insufficient Integration**: Creative phases not explicitly integrated into the standard workflow

## ✅ Key Improvements
1. **Hard Gateway Implementation**
   - Created new creative-phase-enforcement.mdc with strict gateway mechanisms
   - Implemented hard implementation blocking without completed creative phases
   - Added explicit verification checklist for creative phase completeness
   - Created formal completion confirmation for creative phases

2. **Workflow Structure Enhancement**
   - Updated workflow.mdc to include creative phases as explicit workflow step
   - Added formal transition markers for creative phases
   - Integrated creative phases as standard part of Level 3-4 workflows
   - Created dedicated creative phase section in tracking lists

3. **Enhanced Checkpoint System**
   - Added dedicated pre-implementation creative phase checkpoint
   - Created verification points that block implementation without creative phases
   - Added creative phase checks to implementation step checkpoints
   - Enhanced implementation reminders to include creative phase requirements

4. **Quality Metrics Framework**
   - Created new creative-phase-metrics.mdc with objective evaluation criteria
   - Implemented weighted decision matrices for option comparison
   - Added domain-specific evaluation criteria for different creative phase types
   - Developed risk assessment framework for design decisions
   - Created historical pattern comparison framework

5. **Structured Evaluation Tools**
   - Implemented decision quality scoring system with minimum thresholds
   - Created ready-to-use criteria sets for common architectural decisions
   - Added verification metrics for solution validation
   - Implemented standardized decision documentation templates

================
File: cursor-memory-bank/optimization-journey/09-context-optimization.md
================
# 🔄 OPTIMIZATION ROUND 9: CONTEXT OPTIMIZATION THROUGH VISUAL NAVIGATION

Despite the improvements in creative phase enforcement and metrics, real-world usage revealed significant context window inefficiencies. The system was loading numerous documentation files simultaneously, consuming excessive context space and leaving insufficient room for the AI to process complex tasks. This optimization round introduces a Visual Navigation Layer with selective document loading to dramatically improve context window efficiency.

## 🚨 Key Issues Identified
1. **Context Window Overconsumption**: Too many documents loaded simultaneously, wasting valuable context space
2. **Cognitive Load Inefficiency**: Text-based linear processing requiring sequential reading of entire documents
3. **Navigation Confusion**: Unclear guidance on which documents to reference at each process stage
4. **Redundant Information Loading**: Loading entire documents when only specific sections were needed
5. **Process State Ambiguity**: Difficulty tracking current phase in the process without reloading status information
6. **Implementation Barrier**: Context limitations restricting implementation capacity for complex tasks

## ✅ Key Improvements
1. **Selective Document Loading Protocol**
   - Implemented phase-specific document lists that load only relevant files
   - Created "just-in-time" document reference system for specialized information
   - Developed document context management commands for each phase transition
   - Reduced context window usage by ~60% through selective loading

2. **Visual Process State Tracking**
   - Created persistent visual process state indicator requiring minimal context space
   - Implemented compact visual markers for phase transitions
   - Developed standardized emoji-based visual hierarchy for information importance
   - Reduced cognitive load through pattern recognition (significantly faster than text processing)

3. **Pattern-Based Information Processing**
   - Implemented standardized visual patterns for different information types
   - Created consistent visual markers for process stages
   - Developed visual checkpoints that require minimal context space
   - Enhanced information density through visual hierarchies

4. **Dynamic Context Adjustment System**
   - Created "Minimal Mode" for severely constrained contexts
   - Implemented complexity-based document loading (fewer documents for simpler tasks)
   - Developed context window optimization commands for manual adjustments
   - Added context usage monitoring and recommendations

5. **Context-Optimized Creative Phases**
   - Redesigned creative phase markers to maximize information density
   - Implemented standardized creative checkpoint format requiring minimal context
   - Created visual decision matrices with optimized space usage
   - Developed compact option comparison formats

6. **Task Tracking Optimization**
   - Reinforced tasks.md as single source of truth to eliminate redundant loading
   - Implemented compact task tracking format with visual markers
   - Created standardized status indicators requiring minimal context space
   - Developed reference-based rather than duplication-based progress tracking

## 📊 Measured Impact
- **Context Efficiency**: Reduced context window usage by approximately 60%
- **Information Processing**: Visual system processes information significantly faster than text
- **Navigation Efficiency**: Reduced time spent searching for relevant documentation by 75%
- **Cognitive Load**: Significantly reduced working memory requirements through visualization
- **Implementation Capacity**: Increased available context space for complex implementation tasks

================
File: cursor-memory-bank/optimization-journey/10-current-system-state.md
================
# CURRENT SYSTEM STATE

> **TL;DR:** The Memory Bank System has evolved into a token-optimized, hierarchical framework with just-in-time rule loading, progressive documentation, and efficient context preservation across mode transitions.

## 🎯 CORE SYSTEM OPTIMIZATIONS

### 1. Hierarchical Rule Loading
- Just-In-Time (JIT) loading of specialized rules
- Core rule caching across mode transitions
- Complexity-based rule selection
- Significant reduction in token usage

### 2. Progressive Documentation
```mermaid
graph TD
    Start["Creative Phase<br>Initiation"] --> P1["1️⃣ PROBLEM<br>Define scope"]
    P1 --> P2["2️⃣ OPTIONS<br>List alternatives"]
    P2 --> P3["3️⃣ ANALYSIS<br>Compare options"]
    P3 --> P4["4️⃣ DECISION<br>Select approach"]
    P4 --> P5["5️⃣ GUIDELINES<br>Document implementation"]
    
    P3 -.->|"On Demand"| Details["Detailed Option<br>Analysis"]
    
    style Start fill:#d971ff,stroke:#a33bc2,color:white
    style P1 fill:#4da6ff,stroke:#0066cc,color:white
    style P2 fill:#ffa64d,stroke:#cc7a30,color:white
    style P3 fill:#4dbb5f,stroke:#36873f,color:white
    style P4 fill:#d94dbb,stroke:#a3378a,color:white
    style P5 fill:#4dbbbb,stroke:#368787,color:white
    style Details fill:#e699d9,stroke:#d94dbb,color:white,stroke-dasharray: 5 5
```

### 3. Optimized Mode Transitions
- Unified context transfer protocol
- Standardized transition documents
- Selective context preservation
- Improved context retention between modes

### 4. Enhanced Level Workflows
- Level 1: Ultra-compact templates for quick fixes
- Level 2: Balanced 4-phase workflow with simplified templates
- Level 3: Optimized creative phase exploration
- Level 4: Tiered documentation templates for enterprise projects

### 5. Token-Optimized Architecture
```mermaid
graph TD
    Root["Memory Bank<br>Common Rules"] --> Core["Core Rules<br>Shared Across Modes"]
    
    Core --> L1["Level 1<br>Rules"]
    Core --> L2["Level 2<br>Rules"]
    Core --> L3["Level 3<br>Rules"]
    Core --> L4["Level 4<br>Rules"]
    
    Core --> VM["Mode<br>Visual Maps"]
    
    Core --> Phase["Phase-Specific<br>Rules"]
    
    Phase --> VAN_Rules["VAN Mode<br>Rules"]
    Phase --> PLAN_Rules["PLAN Mode<br>Rules"]
    Phase --> CREATIVE_Rules["CREATIVE Mode<br>Rules"]
    Phase --> IMPLEMENT_Rules["IMPLEMENT Mode<br>Rules"]
    Phase --> REFLECT_Rules["REFLECT Mode<br>Rules"]
    Phase --> ARCHIVE_Rules["ARCHIVE Mode<br>Rules"]
    
    style Root fill:#4da6ff,stroke:#0066cc,color:white
    style Core fill:#ffa64d,stroke:#cc7a30,color:white
    style Phase fill:#4dbb5f,stroke:#36873f,color:white
```

## 🔄 OPTIMIZATION EFFICIENCY

### Mode-Specific Optimizations
1. **VAN Mode**
   - Efficient complexity determination with minimal overhead
   - Platform-aware commands with reduced token usage
   - Streamlined file verification processes

2. **PLAN Mode**
   - Complexity-appropriate planning templates
   - Progressive disclosure of planning details
   - Tabular format for task organization

3. **CREATIVE Mode**
   - Progressive documentation with tabular comparisons
   - "Detail-on-demand" approach for creative exploration
   - Efficient option analysis templates

4. **IMPLEMENT Mode**
   - Streamlined implementation guidance
   - Level-appropriate verification processes
   - Consolidated status tracking

5. **REFLECT/ARCHIVE Modes**
   - Context-aware review mechanisms
   - Efficient knowledge preservation
   - Optimized documentation formats

### Context Management Improvements
- Unified context transfer protocol between modes
- Selective preservation of critical information
- Differential memory bank updates to minimize token usage
- Mode-specific context compression techniques

## 📊 TOKEN EFFICIENCY IMPROVEMENTS

### Rule Loading Optimization
- Hierarchical rule structure for efficient navigation
- Rule dependency tracking to prevent redundant loading
- Conditional rule loading based on complexity level
- Rule caching across mode transitions

### Documentation Efficiency
- Progressive disclosure model for complex documentation
- Tabular formats for efficient option comparison
- Level-appropriate documentation scaling
- Standardized templates with minimal boilerplate

### Memory Bank Optimization
- Differential updates to minimize token usage
- Context compression for frequently accessed information
- Selective synchronization across modes
- Structured knowledge organization

## 🎯 CURRENT FOCUS

1. **Architecture Refinement**
   - Fine-tuning the hierarchical rule loading system
   - Optimizing rule dependencies and relationships
   - Enhancing the adaptive complexity model

2. **Documentation Enhancement**
   - Further template optimization for each level
   - Improving tabular comparison formats
   - Refining progressive documentation approaches

3. **Context Preservation**
   - Enhancing the unified context transfer protocol
   - Improving transition document efficiency
   - Developing better context pruning algorithms

4. **Integration Enhancement**
   - Strengthening coordination between optimization components
   - Improving monitoring and metrics for optimization
   - Developing more sophisticated configuration options

## 🚀 NEXT STEPS

1. **Advanced Token Optimization**
   - Dynamic template generation based on task characteristics
   - Automatic context summarization for long-running tasks
   - Partial rule loading within specialized rule files

2. **Cross-Task Learning**
   - Knowledge preservation between similar tasks
   - Common solution patterns repository
   - Intelligent suggestion system based on historical decisions

3. **Workflow Automation**
   - Automated mode transitions based on task state
   - Intelligent rule selection based on usage patterns
   - Dynamic complexity adjustment during workflow

4. **Interface Enhancement**
   - Improved visual process maps with interactive elements
   - Better progress tracking and visualization
   - Enhanced transition guidance between modes

The system has been significantly optimized for token efficiency while maintaining all the structured development benefits of the original approach. These optimizations enable more complex projects to be handled effectively within token constraints while providing an improved user experience.

================
File: cursor-memory-bank/optimization-journey/11-key-lessons.md
================
# 📝 KEY LESSONS LEARNED

1. **Context Efficiency is Mission-Critical**
   - Context window optimization directly impacts AI performance
   - Selective document loading preserves context for complex processing
   - Visual patterns require significantly less context space than text
   - Single source of truth eliminates redundant information loading

2. **Visual Processing Dramatically Reduces Cognitive Load**
   - Visual information processing is ~60,000× faster than text
   - Pattern recognition enables rapid process state awareness
   - Visual hierarchies improve information density
   - Standardized visual markers reduce context requirements

3. **Selective Loading Beats Comprehensive Documentation**
   - Loading only phase-relevant documents preserves context space
   - Just-in-time reference loading prevents context overconsumption
   - Complexity-based document loading scales efficiently
   - Reference-based systems outperform duplication-based systems

4. **Process Enforcement Requires Minimal Context**
   - Visual checkpoints provide efficient verification
   - Compact process state tracking preserves context
   - Pattern-based violation detection requires minimal overhead
   - Visual alerts communicate efficiently without verbose explanation

5. **Continuous Context Optimization Drives Performance**
   - Regular context window assessments reveal optimization opportunities
   - Context monitoring enables dynamic adjustments
   - Minimal mode provides fallback for extreme constraints
   - Context-aware process scaling adapts to available resources

================
File: cursor-memory-bank/optimization-journey/11-methodological-integration.md
================
# 🔄 METHODOLOGICAL INTEGRATION

Optimization Round 13 focused on deepening the system's methodological foundations while maintaining strict isolation principles:

1. **Claude "Think" Tool Integration**
   - Aligned CREATIVE mode with Claude's systematic problem-solving approach
   - Implemented structured phases for problem decomposition
   - Created visual process maps for methodology visualization
   - Established clear parallels between methodologies for consistency

2. **Mode-Specific Rule Isolation**
   - Eliminated global rule dependencies for cleaner architecture
   - Implemented strict mode-based rule containment
   - Preserved global rule space for future extensibility
   - Enhanced system modularity through isolation

3. **Visual Process Mapping**
   - Developed comprehensive mode-specific process maps
   - Created hierarchical visualization of decision points
   - Implemented cross-mode transition guidelines
   - Established clear entry points and flow patterns

4. **Architectural Documentation**
   - Enhanced documentation clarity through visual aids
   - Created explicit methodology comparisons
   - Documented architectural decisions and rationales
   - Established clear upgrade paths for users

5. **Quality Assurance Integration**
   - Implemented mode-specific QA checkpoints
   - Created validation frameworks for each mode
   - Established clear quality metrics and standards
   - Developed systematic verification procedures

This optimization round represents a significant maturation of the Memory Bank system, establishing stronger methodological foundations while maintaining strict isolation principles. By aligning with established methodologies like Claude's "Think" tool while preserving modularity through mode-specific rules, the system achieves both theoretical rigor and practical flexibility. The introduction of comprehensive visual process maps further enhances usability while maintaining the system's commitment to context efficiency.

================
File: cursor-memory-bank/optimization-journey/12-future-directions.md
================
# 🚀 FUTURE DIRECTIONS

Based on the context optimization achievements of Optimization Round 9, future enhancements could include:

1. **Context-Aware Compression Techniques**
   - Develop information compression algorithms for documentation
   - Create context-sensitive abbreviation systems
   - Implement dynamic detail levels based on context availability
   - Design ultra-compact reference formats for constrained environments

2. **Advanced Pattern Recognition System**
   - Improve visual pattern efficiency through standardization
   - Develop hierarchical visual markers with nested information
   - Create pattern-based information retrieval system
   - Implement context-sensitive pattern adaptation

3. **Context Prediction and Preloading**
   - Develop predictive loading of likely-needed documents
   - Create smart unloading of no-longer-relevant information
   - Implement context history for efficient backtracking
   - Design working memory optimization for complex tasks

4. **Minimal-Footprint Creative Thinking**
   - Develop ultra-compact creative phase formats
   - Create visual decision frameworks with minimal context requirements
   - Implement progressive disclosure for complex creative phases
   - Design context-aware creative technique selection

5. **Cross-Reference Optimization**
   - Create hyperlink-like reference system for efficient navigation
   - Develop context-aware reference resolution
   - Implement reference caching for frequent lookups
   - Design minimal-context cross-document navigation system

The Memory Bank System with Visual Navigation represents a significant breakthrough in context window optimization, enabling the AI to operate more efficiently while maintaining comprehensive process guidance. By dramatically reducing context consumption through selective loading and visual patterns, the system provides more available working space for the AI to process complex tasks, making previously context-limited operations now possible and efficient.

================
File: cursor-memory-bank/optimization-journey/12-key-lessons.md
================
# 📝 KEY LESSONS LEARNED

1. **Methodological Integration Enhances Structure**
   - Claude's "Think" tool methodology provides robust foundation for CREATIVE mode
   - Visual process maps significantly improve workflow understanding
   - Mode-specific isolation enables cleaner architecture
   - Systematic approach leads to better design decisions

2. **Graph-Based Architecture Optimizes Flow**
   - Directed graphs enable efficient decision tree navigation
   - Contextual relationships model development phases clearly
   - Resource optimization through node-specific loading
   - Parallel processing opportunities become more apparent

3. **Just-In-Time Loading Maximizes Efficiency**
   - Mode-specific rule loading preserves context space
   - Complexity-based document loading scales effectively
   - Dynamic rule adaptation based on project needs
   - Reduced context consumption through selective loading

4. **Visual Processing Dramatically Improves Understanding**
   - Mode-specific process maps provide clear guidance
   - Visual decision trees reduce cognitive load
   - Checkpoint visualization enables progress tracking
   - Pattern-based violation detection requires minimal overhead

5. **Isolation Principles Enable Scalability**
   - Mode-specific containment reduces interference
   - Clean separation of concerns through specialized modes
   - Preserved global rule space for future extensibility
   - Enhanced modularity through strict isolation

================
File: cursor-memory-bank/optimization-journey/13-future-directions.md
================
# 🚀 FUTURE DIRECTIONS

Building on the methodological integration and isolation-focused architecture, future enhancements will focus on:

1. **Enhanced JIT Rule System**
   - Further optimize rule loading efficiency
   - Implement smarter context utilization
   - Develop faster response times
   - Create dynamic rule complexity adaptation

2. **Team Collaboration Features**
   - Enable multi-user shared context
   - Coordinate mode transitions across teams
   - Implement shared memory bank states
   - Create collaborative decision tracking

3. **Cross-Project Intelligence**
   - Maintain context across different projects
   - Enable knowledge transfer between codebases
   - Implement project pattern recognition
   - Create reusable decision templates

4. **Analytics and Insights**
   - Track development patterns and mode usage
   - Analyze project progression metrics
   - Generate optimization recommendations
   - Monitor context efficiency trends

5. **Version Control Integration**
   - Connect documentation with code history
   - Track decision evolution over time
   - Enable memory bank state versioning
   - Create decision-aware branching strategies

The Memory Bank system will continue evolving as a personal hobby project, with a focus on creating enjoyable, powerful tools for structured development. Future improvements will maintain the core 4-level complexity scale while expanding capabilities through:

- Deeper integration with Claude's evolving capabilities
- Enhanced visual process mapping
- Expanded mode-specific optimizations
- Improved cross-mode state management
- Advanced technical validation features

This development path reflects a commitment to balancing power and complexity while preserving the system's fundamental principles of efficiency, clarity, and systematic development.

================
File: cursor-memory-bank/optimization-journey/13-methodological-integration.md
================
# 🔄 METHODOLOGICAL INTEGRATION

Optimization Round 13 focused on deepening the system's methodological foundations while maintaining strict isolation principles:

1. **Claude "Think" Tool Integration**
   - Aligned CREATIVE mode with Claude's systematic problem-solving approach
   - Implemented structured phases for problem decomposition
   - Created visual process maps for methodology visualization
   - Established clear parallels between methodologies for consistency

2. **Mode-Specific Rule Isolation**
   - Eliminated global rule dependencies for cleaner architecture
   - Implemented strict mode-based rule containment
   - Preserved global rule space for future extensibility
   - Enhanced system modularity through isolation

3. **Visual Process Mapping**
   - Developed comprehensive mode-specific process maps
   - Created hierarchical visualization of decision points
   - Implemented cross-mode transition guidelines
   - Established clear entry points and flow patterns

4. **Architectural Documentation**
   - Enhanced documentation clarity through visual aids
   - Created explicit methodology comparisons
   - Documented architectural decisions and rationales
   - Established clear upgrade paths for users

5. **Quality Assurance Integration**
   - Implemented mode-specific QA checkpoints
   - Created validation frameworks for each mode
   - Established clear quality metrics and standards
   - Developed systematic verification procedures

This optimization round represents a significant maturation of the Memory Bank system, establishing stronger methodological foundations while maintaining strict isolation principles. By aligning with established methodologies like Claude's "Think" tool while preserving modularity through mode-specific rules, the system achieves both theoretical rigor and practical flexibility. The introduction of comprehensive visual process maps further enhances usability while maintaining the system's commitment to context efficiency.

================
File: cursor-memory-bank/optimization-journey/README.md
================
# MEMORY BANK SYSTEM: OPTIMIZATION JOURNEY

> **TL;DR:** The Memory Bank System evolved through multiple optimization rounds, from initial efficiency improvements to methodological integration with Claude's "Think" tool. The system now features mode-specific isolation, visual process maps, and a modular architecture that enables scalable, systematic development while maintaining context efficiency.

## 📑 TABLE OF CONTENTS

| Document | Description |
|----------|-------------|
| [00-introduction.md](00-introduction.md) | Introduction and system purpose |
| [01-efficiency-and-clarity.md](01-efficiency-and-clarity.md) | Optimization Round 1: Efficiency & Clarity |
| [02-system-self-assessment.md](02-system-self-assessment.md) | Optimization Round 2: System Self-Assessment |
| [03-redundancy-elimination.md](03-redundancy-elimination.md) | Optimization Round 3: Redundancy Elimination |
| [04-single-source-of-truth.md](04-single-source-of-truth.md) | Optimization Round 4: Single Source of Truth Implementation |
| [05-adaptive-complexity-model.md](05-adaptive-complexity-model.md) | Optimization Round 5: Adaptive Complexity Model |
| [06-self-assessment-recommendations.md](06-self-assessment-recommendations.md) | Optimization Round 6: Recommendations from Self-Assessment |
| [07-structured-creative-thinking.md](07-structured-creative-thinking.md) | Optimization Round 7: Structured Creative Thinking |
| [08-creative-phase-enforcement.md](08-creative-phase-enforcement.md) | Optimization Round 8: Creative Phase Enforcement & Metrics |
| [09-context-optimization.md](09-context-optimization.md) | Optimization Round 9: Context Optimization Through Visual Navigation |
| [10-current-system-state.md](10-current-system-state.md) | Current System State |
| [11-methodological-integration.md](11-methodological-integration.md) | Integration with Claude's Think Methodology |
| [12-key-lessons.md](12-key-lessons.md) | Key Lessons Learned |
| [13-future-directions.md](13-future-directions.md) | Future Directions and Scaling Vision |

## 📋 OPTIMIZATION JOURNEY OVERVIEW

This documentation details the evolution of the Memory Bank System through several key phases:

### Early Optimization (Rounds 1-5)
1. **Efficiency & Clarity**: Addressing verbosity and improving visual hierarchy
2. **System Self-Assessment**: Adding verification mechanisms and improving tracking
3. **Redundancy Elimination**: Creating centralized task registry and domain separation
4. **Single Source of Truth**: Implementing true single source for task tracking
5. **Adaptive Complexity Model**: Introducing four complexity levels for different tasks

### Process Refinement (Rounds 6-9)
6. **Self-Assessment Recommendations**: Enhancing creative phase handling and streamlining processes
7. **Structured Creative Thinking**: Mandating creative phases for Level 3-4 tasks
8. **Creative Phase Enforcement**: Implementing hard gateways and quality metrics
9. **Context Optimization**: Adding selective document loading and visual navigation

### Latest Developments (Rounds 10-13)
10. **System State Assessment**: Comprehensive evaluation of optimizations
11. **Methodological Integration**: Alignment with Claude's Think tool methodology
12. **Key Lessons Consolidation**: Synthesis of critical insights
13. **Future Directions**: Vision for scaling and collaboration

## 🔍 LATEST SYSTEM ACHIEVEMENTS

The most recent developments have yielded significant improvements:

- **Methodological Integration**: Alignment with Claude's "Think" tool methodology
- **Mode Isolation**: Strict containment of rules within specific modes
- **Visual Process Maps**: Comprehensive guidance through development phases
- **Just-In-Time Loading**: Optimized context usage through selective rule loading
- **Graph-Based Architecture**: Efficient decision tree navigation and resource optimization

## 🧠 MEMORY BANK SYSTEM CORE PRINCIPLES

The system now maintains these enhanced core principles:

1. **Methodological Foundation**: Structured approach based on proven methodologies
2. **Mode-Specific Isolation**: Clean separation of concerns through specialized modes
3. **Visual Processing**: Comprehensive process maps and decision trees
4. **Just-In-Time Efficiency**: Load only what's needed when it's needed
5. **Continuous Evolution**: Regular assessment and improvement of the system

```mermaid
graph BT
    %% Early Phase Nodes
    E1["🔍 01-03: Foundation<br>• Initial Optimization<br>• Self Assessment<br>• Redundancy Elimination"]
    E2["⚙️ 04-05: Architecture<br>• Single Source of Truth<br>• Adaptive Complexity<br>• 4-Level Scale"]
    
    %% Middle Phase Nodes
    M1["🎨 06-08: Creative Evolution<br>• Process Refinement<br>• Structured Thinking<br>• Phase Enforcement"]
    M2["🧩 09-10: System Maturity<br>• Context Optimization<br>• Visual Navigation<br>• State Management"]
    
    %% Latest Phase Nodes
    L1["🤔 11: Think Integration<br>• Claude Methodology<br>• Mode Isolation<br>• Visual Process Maps"]
    L2["📚 12: Key Insights<br>• JIT Rule Loading<br>• Graph Architecture<br>• Mode Separation"]
    L3["🚀 13: Future Vision<br>• Team Collaboration<br>• Cross-Project Intel<br>• Analytics Integration"]

    %% Connections
    E1 -->|"Efficiency First"| E2
    E2 -->|"Process Evolution"| M1
    M1 -->|"System Growth"| M2
    M2 -->|"Methodology Shift"| L1
    L1 -->|"Learning & Growth"| L2
    L2 -->|"Future Planning"| L3

    %% Key Themes with Emojis
    KT1["⚡ Speed & Clarity<br><i>60% Context Reduction</i>"]
    KT2["🏗️ System Design<br><i>Modular Architecture</i>"]
    KT3["👁️ Visual Approach<br><i>Significant Processing Gains</i>"]
    KT4["🎯 Mode Focus<br><i>Specialized Workflows</i>"]
    KT5["🧠 Think Method<br><i>Structured Decisions</i>"]

    %% Learnings & Challenges
    LC1["❌ Avoided:<br>Global Rules<br>Manual Tracking"]
    LC2["✅ Worked Well:<br>Visual Maps<br>JIT Loading"]
    LC3["🔄 Evolved:<br>Creative Process<br>Mode Transitions"]
    
    %% Theme Connections
    E1 --- KT1
    E2 --- KT2
    M1 --- KT3
    M2 --- KT4
    L1 --- KT5

    %% Learning Connections
    E2 --- LC1
    M2 --- LC2
    L2 --- LC3

    %% Styling
    style E1 fill:#f9d77e,stroke:#d9b95c,color:black
    style E2 fill:#f9d77e,stroke:#d9b95c,color:black
    
    style M1 fill:#a8d5ff,stroke:#88b5e0,color:black
    style M2 fill:#a8d5ff,stroke:#88b5e0,color:black
    
    style L1 fill:#c5e8b7,stroke:#a5c897,color:black
    style L2 fill:#c5e8b7,stroke:#a5c897,color:black
    style L3 fill:#c5e8b7,stroke:#a5c897,color:black
    
    style KT1 fill:#ffcccc,stroke:#ff9999,color:black
    style KT2 fill:#ffcccc,stroke:#ff9999,color:black
    style KT3 fill:#ffcccc,stroke:#ff9999,color:black
    style KT4 fill:#ffcccc,stroke:#ff9999,color:black
    style KT5 fill:#ffcccc,stroke:#ff9999,color:black
    
    style LC1 fill:#ffd9b3,stroke:#ffb366,color:black
    style LC2 fill:#d9f2d9,stroke:#97d097,color:black
    style LC3 fill:#d9b3ff,stroke:#b366ff,color:black

    %% Subgraph Styling
    subgraph "🌟 Latest Phase: Integration & Scale"
        L1
        L2
        L3
    end
    
    subgraph "🔄 Middle Phase: Process & Validation"
        M1
        M2
    end
    
    subgraph "🎯 Early Phase: Efficiency & Structure"
        E1
        E2
    end
```

## Development Phases Overview

### Early Focus (Chapters 1-5)
- Established foundational efficiency principles
- Developed systematic approach to development
- Created core architecture and complexity model

### Middle Phase (Chapters 6-10)
- Refined creative processes and enforcement
- Implemented visual processing techniques
- Achieved significant context optimization

### Latest Phase (Chapters 11-13)
- Integrated with Claude's "Think" methodology
- Implemented strict mode-specific isolation
- Established vision for future scaling

The Memory Bank system continues to evolve as a personal hobby project, focusing on creating powerful tools for structured development while maintaining the core 4-level complexity scale that has proven effective throughout its evolution.

================
File: cursor-memory-bank/README.md
================
# Memory Bank System v0.7-beta

A token-optimized, hierarchical task management system that integrates with Cursor custom modes for efficient development workflows.

```mermaid
graph TD
    Main["Memory Bank System"] --> Modes["Custom Modes"]
    Main --> Rules["Hierarchical Rule Loading"]
    Main --> Visual["Visual Process Maps"]
    Main --> Token["Token Optimization"]
    
    Modes --> VAN["VAN: Initialization"]
    Modes --> PLAN["PLAN: Task Planning"]
    Modes --> CREATIVE["CREATIVE: Design"]
    Modes --> IMPLEMENT["IMPLEMENT: Building"]
    Modes --> REFLECT["REFLECT: Review"]
    Modes --> ARCHIVE["ARCHIVE: Documentation"]
    
    style Main fill:#4da6ff,stroke:#0066cc,color:white
    style Modes fill:#f8d486,stroke:#e8b84d,color:black
    style Rules fill:#80ffaa,stroke:#4dbb5f,color:black
    style Visual fill:#d9b3ff,stroke:#b366ff,color:black
    style Token fill:#ff9980,stroke:#ff5533,color:black
```

> **Personal Note**: Memory Bank is my personal hobby project that I develop for my own use in coding projects. As this is a personal project, I don't maintain an issues tracker or actively collect feedback. However, if you're using these rules and encounter issues, one of the great advantages is that you can ask the Cursor AI directly to modify or update the rules to better suit your specific workflow. The system is designed to be adaptable by the AI, allowing you to customize it for your own needs without requiring external support.

## About Memory Bank

Memory Bank is a personal project that provides a structured approach to development using specialized modes for different phases of the development process. It uses a hierarchical rule loading architecture that loads only the rules needed for each phase, optimizing token usage and providing tailored guidance.

### Token-Optimized Architecture

Version 0.7-beta introduces significant token optimization improvements:

- **Hierarchical Rule Loading**: Only loads essential rules initially with specialized lazy-loading
- **Progressive Documentation**: Implements concise templates that scale with task complexity
- **Optimized Mode Transitions**: Preserves critical context efficiently between modes
- **Level-Specific Workflows**: Adapts documentation requirements to task complexity

See the [Memory Bank Optimizations](MEMORY_BANK_OPTIMIZATIONS.md) document for detailed information about all optimization approaches.

### Beyond Basic Custom Modes

While Cursor's documentation describes custom modes as primarily standalone configurations with basic prompts and tool selections, Memory Bank significantly extends this concept:

- **Graph-Based Mode Integration**: Modes are interconnected nodes in a development workflow rather than isolated tools
- **Workflow Progression**: Modes are designed to transition from one to another in a logical sequence (VAN → PLAN → CREATIVE → IMPLEMENT → REFLECT → ARCHIVE)
- **Shared Memory**: Persistent state maintained across mode transitions via Memory Bank files
- **Adaptive Behavior**: Each mode adjusts its recommendations based on project complexity
- **Built-in QA Functions**: QA capabilities can be called from any mode for technical validation

This approach transforms custom modes from simple AI personalities into components of a coordinated development system with specialized phases working together.

### CREATIVE Mode and Claude's "Think" Tool

The CREATIVE mode in Memory Bank is conceptually based on Anthropic's Claude "Think" tool methodology, as described in their [engineering blog](https://www.anthropic.com/engineering/claude-think-tool). The v0.7-beta implements an optimized version with:

- Progressive documentation with tabular option comparison
- "Detail-on-demand" approach that preserves token efficiency
- Structured templates that scale with complexity level
- Efficient context preservation for implementation phases

For a detailed explanation of how Memory Bank implements these principles, see the [CREATIVE Mode and Claude's "Think" Tool](creative_mode_think_tool.md) document.

## Key Features

- **Hierarchical Rule Loading**: Load only the essential rules with specialized lazy-loading
- **Progressive Documentation**: Concise templates that scale with task complexity
- **Unified Context Transfer**: Efficient context preservation between modes
- **Mode-Specific Visual Maps**: Clear visual representations for each development phase
- **Level-Specific Workflows**: Adapted processes based on complexity (Levels 1-4)
- **Platform-Aware Commands**: Automatically adapts commands to your operating system

## Installation Instructions

### Prerequisites

- **Cursor Editor**: Version 0.48 or higher is required.
- **Custom Modes**: Feature must be enabled in Cursor (Settings → Features → Chat → Custom modes).
- **AI Model**: Claude 3.7 Sonnet is recommended for best results, especially for CREATIVE mode's "Think" tool methodology.

### Step 1: Get the Files

Simply clone this repository into your project directory:

```
git clone https://github.com/vanzan01/cursor-memory-bank.git
```

Alternatively, you can download the ZIP file from GitHub and extract it to your project folder.

This provides you with all the necessary files, including:
- Rule files in `.cursor/rules/isolation_rules/`
- Mode instruction files in `custom_modes/` directory
- Template Memory Bank files in `memory-bank/`

### Step 2: Setting Up Custom Modes in Cursor

**This is the most critical and challenging part of the setup.** You'll need to manually create six custom modes in Cursor and copy the instruction content from the provided files:

#### How to Add a Custom Mode in Cursor

1. Open Cursor and click on the mode selector in the chat panel
2. Select "Add custom mode"
3. In the configuration screen:
   - Enter the mode name (you can include emoji icons like 🔍, 📋, 🎨, ⚒️ by copy-pasting them at the beginning of the name)
   - Select an icon from Cursor's limited predefined options
   - Add a shortcut (optional)
   - Check the required tools
   - Click on **Advanced options**
   - In the empty text box that appears at the bottom, paste the custom instruction content from the corresponding file

<table>
  <tr>
    <td align="center"><em>Example configuration screen:</em></td>
    <td align="center"><em>Result in mode selection menu:</em></td>
  </tr>
  <tr>
    <td valign="top">
      <img src="assets/custom_mode_setup_1.png" alt="Custom Mode Configuration Screen" width="300"/>
    </td>
    <td valign="top">
      <img src="assets/custom_mode_setup_2.png" alt="Custom Modes in Menu" width="300"/>
    </td>
  </tr>
</table>

#### Mode Configuration

For each mode, configure as follows:

1. **VAN MODE** (Initialization)
   - **Name**: 🔍 VAN
   - **Tools**: Enable "Codebase Search", "Read File", "Terminal", "List Directory"
   - **Advanced options**: Paste from `custom_modes/van_instructions.md`

2. **PLAN MODE** (Task Planning)
   - **Name**: 📋 PLAN
   - **Tools**: Enable "Codebase Search", "Read File", "Terminal", "List Directory"
   - **Advanced options**: Paste from `custom_modes/plan_instructions.md`

3. **CREATIVE MODE** (Design Decisions)
   - **Name**: 🎨 CREATIVE
   - **Tools**: Enable "Codebase Search", "Read File", "Terminal", "List Directory", "Edit File"
   - **Advanced options**: Paste from `custom_modes/creative_instructions.md`

4. **IMPLEMENT MODE** (Code Implementation)
   - **Name**: ⚒️ IMPLEMENT
   - **Tools**: Enable all tools
   - **Advanced options**: Paste from `custom_modes/implement_instructions.md`

5. **REFLECT MODE** (Review)
   - **Name**: 🔍 REFLECT
   - **Tools**: Enable "Codebase Search", "Read File", "Terminal", "List Directory"
   - **Advanced options**: Paste from `custom_modes/reflect_archive_instructions.md` (REFLECT section)
   
6. **ARCHIVE MODE** (Documentation)
   - **Name**: 📚 ARCHIVE
   - **Tools**: Enable "Codebase Search", "Read File", "Terminal", "List Directory", "Edit File"
   - **Advanced options**: Paste from `custom_modes/reflect_archive_instructions.md` (ARCHIVE section)

> **Note**: REFLECT and ARCHIVE instructions are combined in a single file to optimize for Cursor's character limits while maintaining functionality. Thanks to GitHub user @joshmac007 for implementing this optimization.

For additional help on setting up custom modes in Cursor, refer to the [official Cursor documentation on custom modes](https://docs.cursor.com/chat/custom-modes).

### QA Functionality

QA is not a separate custom mode but rather a set of validation functions that can be called from any mode. You can invoke QA capabilities by typing "QA" in any mode when you need to perform technical validation. This approach provides flexibility to conduct verification at any point in the development process.

## Basic Usage

1. **Start with VAN Mode**:
   - Switch to VAN mode in Cursor
   - Type "VAN" to initiate the initialization process
   - VAN will analyze your project structure and determine complexity

2. **Follow the Workflow Based on Complexity**:
   - **Level 1 tasks**: May proceed directly to IMPLEMENT after VAN
   - **Level 2 tasks**: Simplified workflow (VAN → PLAN → IMPLEMENT → REFLECT)
   - **Level 3-4 tasks**: Full workflow (VAN → PLAN → CREATIVE → IMPLEMENT → REFLECT → ARCHIVE)
   - **At any point**: Type "QA" to perform technical validation

3. **Mode-Specific Commands**:
   ```
   VAN - Initialize project and determine complexity
   PLAN - Create detailed implementation plan
   CREATIVE - Explore design options for complex components
   IMPLEMENT - Systematically build planned components
   REFLECT - Review and document lessons learned
   ARCHIVE - Create comprehensive documentation
   QA - Validate technical implementation (can be called from any mode)
   ```

## Core Files and Their Purposes

```mermaid
graph LR
    subgraph "Memory Bank Files"
        Tasks["tasks.md<br>Source of Truth"]
        Active["activeContext.md<br>Current Focus"]
        Progress["progress.md<br>Implementation Status"]
        Creative["creative-*.md<br>Design Decisions"]
        Reflect["reflect-*.md<br>Review Documents"]
    end
    
    style Tasks fill:#f9d77e,stroke:#d9b95c,stroke-width:3px
    style Active fill:#a8d5ff,stroke:#88b5e0
    style Progress fill:#c5e8b7,stroke:#a5c897
    style Creative fill:#f4b8c4,stroke:#d498a4
    style Reflect fill:#b3e6cc,stroke:#66c999
```

- **tasks.md**: Central source of truth for task tracking
- **activeContext.md**: Maintains focus of current development phase
- **progress.md**: Tracks implementation status
- **creative-*.md**: Design decision documents generated during CREATIVE mode
- **reflect-*.md**: Review documents created during REFLECT mode

## Troubleshooting

### Common Issues

1. **Mode not responding correctly**:
   - Verify custom instructions were copied completely (this is the most common issue)
   - Ensure the correct tools are enabled for each mode
   - Check that you've switched to the correct mode before issuing commands
   - Make sure you pasted the instructions in the "Advanced options" text box

2. **Rules not loading**:
   - Make sure the `.cursor/rules/isolation_rules/` directory is in the correct location
   - Verify file permissions allow reading the rule files

3. **Command execution issues**:
   - Ensure you're running commands from the correct directory
   - Verify platform-specific commands are being used correctly

## Version Information

This is version v0.7-beta of the Memory Bank system. It introduces significant token optimization improvements over v0.6-beta while maintaining all functionality. See the [Release Notes](RELEASE_NOTES.md) for detailed information about the changes.

### Ongoing Development

The Memory Bank system is actively being developed and improved. Key points to understand:

- **Work in Progress**: This is a beta version with ongoing development. Expect regular updates, optimizations, and new features.
- **Feature Optimization**: The modular architecture enables continuous refinement without breaking existing functionality.
- **Previous Version Available**: If you prefer the stability of the previous version (v0.1-legacy), you can continue using it while this version matures.
- **Architectural Benefits**: Before deciding which version to use, please read the [Memory Bank Upgrade Guide](memory_bank_upgrade_guide.md) to understand the significant benefits of the new architecture.

## Resources

- [Memory Bank Optimizations](MEMORY_BANK_OPTIMIZATIONS.md) - Detailed overview of token efficiency improvements
- [Release Notes](RELEASE_NOTES.md) - Information about the latest changes
- [Cursor Custom Modes Documentation](https://docs.cursor.com/chat/custom-modes)
- [Memory Bank Upgrade Guide](memory_bank_upgrade_guide.md)
- [CREATIVE Mode and Claude's "Think" Tool](creative_mode_think_tool.md)
- Mode-specific instruction files in the `custom_modes/` directory

---

*Note: This README is for v0.7-beta and subject to change as the system evolves.*

================
File: cursor-memory-bank/RELEASE_NOTES.md
================
# Memory Bank System Release Notes

> **Personal Note**: Memory Bank is my personal hobby project that I develop for my own use in coding projects. As this is a personal project, I don't maintain an issues tracker or actively collect feedback. However, if you're using these rules and encounter issues, one of the great advantages is that you can ask the Cursor AI directly to modify or update the rules to better suit your specific workflow. The system is designed to be adaptable by the AI, allowing you to customize it for your own needs without requiring external support.

## Version 0.7-beta - Token-Optimized Workflows

> Building upon the architectural foundations established in v0.6-beta.1, this release introduces significant token efficiency optimizations and enhanced workflow capabilities with substantial improvements in context management.

### 🌟 Major Features

#### Hierarchical Rule Loading System _(New)_
- Just-In-Time (JIT) loading of specialized rules
- Core rule caching across mode transitions
- Complexity-based rule selection
- Significant reduction in rule-related token usage

#### Progressive Documentation Framework _(New)_
- Concise templates that scale with task complexity
- Tabular formats for efficient option comparison
- "Detail-on-demand" approach for creative phases
- Streamlined documentation without sacrificing quality

#### Optimized Mode Transitions _(Enhanced)_
- Unified context transfer protocol
- Standardized transition documents
- Selective context preservation
- Improved context retention between modes

#### Enhanced Multi-Level Workflow System _(Enhanced)_
- **Level 1: Quick Bug Fix Pipeline**
  - Ultra-compact documentation templates
  - Consolidated memory bank updates
  - Streamlined 3-phase workflow

- **Level 2: Enhancement Pipeline**
  - Balanced 4-phase workflow
  - Simplified planning templates
  - Faster documentation process

- **Level 3: Feature Development Pipeline**
  - Comprehensive planning system
  - Optimized creative phase exploration
  - Improved context efficiency

- **Level 4: Enterprise Pipeline**
  - Advanced 6-phase workflow
  - Tiered documentation templates
  - Enhanced governance controls

### 🔄 Process Improvements

#### Token-Optimized Architecture
- Reduced context usage for system rules
- More context available for actual development tasks
- Adaptive complexity scaling based on task requirements
- Differential memory bank updates to minimize token waste

#### Mode-Based Optimization
- **VAN Mode**: Efficient complexity determination with minimal overhead
- **PLAN Mode**: Complexity-appropriate planning templates
- **CREATIVE Mode**: Progressive documentation with tabular comparisons
- **IMPLEMENT Mode**: Streamlined implementation guidance
- **REFLECT Mode**: Context-aware review mechanisms
- **ARCHIVE Mode**: Efficient knowledge preservation

#### Advanced Workflow Optimization
- Intelligent level transition system
- Clear complexity assessment criteria
- Streamlined mode switching
- Enhanced task tracking capabilities

### 📚 Documentation Enhancements
- Level-specific documentation templates
- Progressive disclosure model for complex documentation
- Standardized comparison formats for design decisions
- Enhanced context preservation between documentation phases

### 🛠 Technical Improvements
- Graph-based rule architecture for efficient navigation
- Rule dependency tracking for optimal loading
- Context compression techniques for memory bank files
- Adaptive rule partitioning for targeted loading

### 📋 Known Issues
- None reported in current release

### 🧠 The Determinism Challenge in AI Workflows

While Memory Bank provides robust structure through visual maps and process flows, it's important to acknowledge an inherent limitation: the non-deterministic nature of AI agents. Despite our best efforts to create well-defined pathways and structured processes, language models fundamentally operate on probability distributions rather than fixed rules.

This creates what I call the "determinism paradox" – we need structure for reliability, but rigidity undermines the adaptability that makes AI valuable. Memory Bank addresses this through:

- **Guiding rather than forcing**: Using visual maps that shape behavior without rigid constraints
- **Bounded flexibility**: Creating structured frameworks within which creative problem-solving can occur
- **Adaptive complexity**: Adjusting guidance based on task requirements rather than enforcing one-size-fits-all processes

As a companion to Memory Bank, I'm developing an MCP Server (Model-Context-Protocol) project that aims to further address this challenge by integrating deterministic code checkpoints with probabilistic language model capabilities. This hybrid approach creates a system where AI can operate flexibly while still following predictable workflows – maintaining the balance between structure and adaptability that makes Memory Bank effective.

When using Memory Bank, you may occasionally need to guide the agent back to the intended workflow. This isn't a failure of the system but rather a reflection of the fundamental tension between structure and flexibility in AI systems.

### 🔜 Upcoming Features
- Dynamic template generation based on task characteristics
- Automatic context summarization for long-running tasks
- Cross-task knowledge preservation
- Partial rule loading within specialized rule files
- MCP integration for improved workflow adherence

### 📝 Notes
- This release builds upon v0.6-beta.1's architectural foundation
- Significantly enhances JIT Rule Loading efficiency 
- No manual migration required
- New files added to `.cursor/rules/isolation_rules/` directory

### 🔧 Requirements
- Requires Cursor version 0.48 or higher
- Compatible with Claude 3.7 Sonnet (recommended) and newer models
- Compatible with all existing Memory Bank v0.6-beta.1 installations

### 📈 Optimization Approaches
- **Rule Loading**: Hierarchical loading with core caching and specialized lazy-loading
- **Creative Phase**: Progressive documentation with tabular comparisons
- **Mode Transitions**: Unified context transfer with selective preservation
- **Level 1 Workflow**: Ultra-compact templates with consolidated updates
- **Memory Bank**: Differential updates and context compression

---
Released on: May 7, 2025




================================================================
End of Codebase
================================================================
